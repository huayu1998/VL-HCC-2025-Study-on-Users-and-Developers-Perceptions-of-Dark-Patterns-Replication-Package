url,title,html_url,body,created_at,updated_at,state,comments,Research#1_Theme,Research#2_Theme,Final_Theme,categoraization,miscellaneous,,final_categories,final_categories_lowercase,,stat_categegories,
https://api.github.com/repos/ikedaosushi/tech-news/issues/5970,Amazon dark patterns,https://github.com/ikedaosushi/tech-news/issues/5970,"Amazon dark patterns<br>
So I go into the app, scroll through my orders, click on the item I bought and click the button to leave a review. After spending ~5 to ~10 minutes filling it out I get this message.<br>
https://ift.tt/2zYmvRc",2018-08-01T04:19:27Z,2018-08-01T04:19:27Z,open,0,"Amazon, usage of dark pattern in software","Amazon, review","Amazon, Obstructions",DPs used in software,,,DPs used in software,dps used in software,,DPs used in software,164
https://api.github.com/repos/UMNLibraries/umnlibraries.github.io/issues/11,Examples of dark patterns?,https://github.com/UMNLibraries/umnlibraries.github.io/issues/11,"Working on the copy for dark patterns, I wondered if it might be worth including an example or two. The term ""dark pattern"" and the way it's described sounds so dire, folks might overlook their own dark patterns that seem mild in comparison (like tricky modal email sign-ups). ",2019-06-19T18:31:58Z,2019-06-19T18:45:56Z,open,1,examples of dark pattern,"asking for examples, comparisons of dark patterns",dark pattern example,DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,DPs prevention in software,118
https://api.github.com/repos/frontendweekly/feeds/issues/687,Dark Patterns by the Boston Globe,https://github.com/frontendweekly/feeds/issues/687,"[Dark Patterns by the Boston Globe](http://ift.tt/1VwChGj) / After years of falling revenue, some newspapers have resorted to deception to boost their subscription numbers. These dishonest tactics are sometimes called &ldquo;&hellip;
",2016-04-27T22:47:11Z,2016-04-27T22:47:11Z,open,0,"Boston Globe, usage of dark pattern in software, falling revenue, users subscription","link not working, deception for subcriprion",Boston Globe,DPs used in software,,,DPs used in software,dps used in software,,DPs examples/definitions,97
https://api.github.com/repos/frontendweekly/feeds/issues/2001,Are Notifications A Dark Pattern? | Designlab blog,https://github.com/frontendweekly/feeds/issues/2001,"[Are Notifications A Dark Pattern? | Designlab blog](http://ift.tt/2tXhQXg) / Have you ever had a nightmare where you were literally drowning in little red notification badges? I did once, and it got me thinking: what actually are&hellip;",2017-08-01T00:34:41Z,2017-08-01T00:34:41Z,open,0,"Designlab, blog, deceptive design practice, notification ","notifications, advertising, manipulation, nagging","Designlab blog, notifications feature",DPs or not,,,DPs or not,dps or not,,Papers/Docs/Sources,48
https://api.github.com/repos/dwyl/learn-user-experience-testing/issues/18,The Dark (Patterns) Side of UX Design,https://github.com/dwyl/learn-user-experience-testing/issues/18,"http://colingray.me/wp-content/uploads/2018_Grayetal_CHI_DarkPatternsUXDesign.pdf
[2018_Grayetal_CHI_DarkPatternsUXDesign.pdf](https://github.com/dwyl/learn-user-experience-testing/files/2372920/2018_Grayetal_CHI_DarkPatternsUXDesign.pdf)

via/comments: https://news.ycombinator.com/item?id=17962469",2018-09-11T22:29:40Z,2018-12-20T09:37:40Z,open,1,research paper (The Dark (Patterns) Side of UX Design),link not working,"""The Dark (Patterns) Side of UX Design""",Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,DPs in design coding,28
https://api.github.com/repos/nelsonic/nelsonic.github.io/issues/491,"Add dark pattern for navigation on mobile, like MSC",https://github.com/nelsonic/nelsonic.github.io/issues/491,"https://fil.forbrukerradet.no/wp-content/uploads/2018/06/2018-06-27-deceived-by-design-final.pdf
via: https://news.ycombinator.com/item?id=17406186
snapshot: [2018-06-27-deceived-by-design-final.pdf](https://github.com/nelsonic/nelsonic.github.io/files/2141949/2018-06-27-deceived-by-design-final.pdf) (_in case for any reason the link above does not work..._)
",2018-06-27T15:48:30Z,2018-06-27T15:48:30Z,open,0,document (DECEIVED BY DESIGN),"info asymmetries, ""force"" users to consent, violations and illegal","""DECEIVED BY DESIGN in Tech Company"", cookie consent, GDPR ","DPs related regulation, Papers/Docs/Sources",,,DPs related regulation,dps related regulation,,DPs related regulation,19
https://api.github.com/repos/j0lv3r4/wp-whiteboard/issues/20,,https://github.com/j0lv3r4/wp-whiteboard/issues/20,,2017-09-18T22:11:17Z,2017-09-18T22:11:17Z,open,0,"implementation, mobile, navigation design, MSC","no description, no comments",,,,,Papers/Docs/Sources,papers/docs/sources,,DPs detection Tools,13
https://api.github.com/repos/lgarron/first-world/issues/25,iTunes pushes for Apple Music Connect and uses dark pattern for toggling,https://github.com/lgarron/first-world/issues/25,"Requires checking a box for ""Disable"":
<img width=""656"" alt=""screenshot 2015-12-24 02 57 15"" src=""https://cloud.githubusercontent.com/assets/248078/11993829/59fd0406-a9ea-11e5-9b09-c4d3ff450ffa.png"">
",2015-12-24T11:00:53Z,2017-09-07T09:24:40Z,open,0,"iTunes, Apple music, usage of dark pattern in software, forced action","iTunes, toggling","iTunes, Apple music, preselection",DPs used in software,,,DPs used in software,dps used in software,,DPs prevention in design,13
https://api.github.com/repos/net-art-and-cultures/the-toolkit/issues/39,Obstacle Course: Twitter Post,https://github.com/net-art-and-cultures/the-toolkit/issues/39,Popup that asks the user to post about dark patterns to their twitter,2019-11-26T20:33:12Z,2019-11-26T20:35:23Z,open,0,"Twitter post, user experience","Twitter, popup","Twitter, post, pop-up, user dark pattern experiences",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,DPs or not,5
https://api.github.com/repos/net-art-and-cultures/the-toolkit/issues/45,"write ""About"" Statement",https://github.com/net-art-and-cultures/the-toolkit/issues/45,"write the about statement, then update the about.html page and the README.md page with the same statement",2019-11-26T20:55:37Z,2019-12-09T18:46:30Z,open,4,"about statement, toolkit, dark pattern combating, autonomy gained","The Tool Kit, mental gymnastics, benefits users with autonomy to fight dp","toolkit, autonomy gained, dark pattern combating",DPs in design coding ,,,DPs in design coding,dps in design coding,,Miscellaneous,29
https://api.github.com/repos/frontendweekly/feeds/issues/2291,Hooked and booked  Jeremy Keith  Medium,https://github.com/frontendweekly/feeds/issues/2291,"[Hooked and booked &ndash; Jeremy Keith &ndash; Medium](http://ift.tt/2hC4ZGv) / At Booking.com , they do a lot of A/B testing . At Booking.com , they&rsquo;ve got a lot of dark patterns . I think there might be a connection. A/B testing is a&hellip;",2017-11-20T23:48:56Z,2017-11-20T23:48:56Z,open,0,"Booking, usage of dark patterin in software, blog","A/B testing, website called Medium","Medium post, Booking.com",DPs used in software,,,DPs used in software,dps used in software,,Total,534
https://api.github.com/repos/duckduckgo/community-platform/issues/1515,"Dude, where's the feedback button? Plus some feedback",https://github.com/duckduckgo/community-platform/issues/1515,"I was about to give some product feedback (I am using DDG on FF 58.0, Ubuntu) but a Product Feedback form or something was nowhere to be found (I may have overlooked it, though, so bear with me if that's the case).

My feedback was: I do not always see a good way to get a shareable URL for a query with the privacy setting for search using POST. And even if there is something to share (with query parameters), then it does not point to, say, the Video tab. Always the first tab is loaded. Example:

```
https://duckduckgo.com/?q=dark+patterns&t=canonical
```
Not saying you are applying dark patterns, but this was my query where I noticed the Video tab thing :smiley: 

You might create a small area to easily copy a complete URL. Query sharing is a good way to promote DDG, I found.",2018-04-11T17:58:59Z,2018-04-11T17:59:22Z,open,0,miscellaneous,"DDG - Ubuntu, feedback feature not found, ""dark pattern"" written in web link",miscellaneous,miscellaneous,"""dark pattern"" written in web link",,miscellaneous,miscellaneous,,,
https://api.github.com/repos/GoodTechnologyCollective/GTS/issues/1,Add weights to the principles,https://github.com/GoodTechnologyCollective/GTS/issues/1,"All of the principals are not of equal weight.  in my humble opinion The addictive nature and dark patterns would weigh more than planned obsolescence.

I'm not sure what appropriate weights would be at this time however this comment is to suggest that a weighing mechanism is included.",2019-01-09T15:16:24Z,2019-01-09T15:16:24Z,open,0,miscellaneous,weighing mechanism for principles,miscellaneous,miscellaneous,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/cmaxw/devchat-eleventy/issues/66,I like being out of date,https://github.com/cmaxw/devchat-eleventy/issues/66,That shit is obnoxious.  Write a respectful message.  I didn't even read the article because that crap is annoying and condescending,2019-11-05T16:14:51Z,2019-11-19T15:43:00Z,open,1,"deceptive design practice, confirmshaming","""confirmshaming"", provocation, ways to avoid dp",comfirmshaming designs/examples,DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ikedaosushi/tech-news/issues/17034,A directory of direct links to delete your account from web services.,https://github.com/ikedaosushi/tech-news/issues/17034,"A directory of direct links to delete your account from web services.<br>
Can't find what you're looking for? Help make justdelete.me better. Many companies use dark pattern techniques to make it difficult to find how to delete your account. JustDelete.me aims to be a directory of urls to enable you to easily delete your account from web services.<br>
https://ift.tt/2G18Yew",2019-09-03T12:32:55Z,2019-09-03T12:32:55Z,open,0,"deceptive design practice, account deletion, obstruction","account deletion, sneaking","account deletion, sneaking",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/GSA/code-gov-web/issues/123,Do not hijack clicks on external links,https://github.com/GSA/code-gov-web/issues/123,"When I click on the link to go to your repo, I know I'm clicking a link that leaves code.gov. You even say so:

![screen shot 2016-11-03 at 6 58 08 pm](https://cloud.githubusercontent.com/assets/321667/19991985/8e2e6afc-a1f7-11e6-84f2-6a930be95b35.png)

Hijacking links feels like a dark pattern on the web, where hyperlinks matter. If I mouse over a button and see the link, I expect to be taken to that link.",2016-11-04T02:00:19Z,2018-02-09T16:25:55Z,open,21,"hijacking link, implementation, examples of dark pattern","""hijacking links"", popup, obstruction, law","hijacking link, obstructions","DPs used in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/xxv-inc/plasma-contracts/issues/1,synthetic minds verifier modifications,https://github.com/xxv-inc/plasma-contracts/pull/1,"**Important: These changes are temporary, and just illustrative for current SM version to get verifier/synthesizer operating. This is not supposed to be a merge candidate.**

Given Synthetic Minds' vOct2018 tool chain, the following edits are needed:

1. Inline imports
1. Naive implementation of PriorityQueue (until we get the Solver to natively understand unbounded PQ ADTs)
1. Keccak polymorphism redirected through named functions.
1. Cosmetic changes to work around front end missing features: create ERC20 variable instead of inline instantiation, transfer vs send, multiple return values refactored into their own accessor functions.
1. Abstract away SafeMath and inline Math.max ops.
1. Not use any of the dark patterns as described in https://github.com/omisego/plasma-contracts/pull/34",2018-10-20T23:42:41Z,2018-12-06T17:24:57Z,open,0,prevention of dark pattern,"verifier, example of dp avoided",avoid dark pattern,DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/dwyl/hq/issues/527,[Security] PROOF online filing for Companies House,https://github.com/dwyl/hq/issues/527,"After I completed our Confirmation Statement, I was offered this:

> PROOF (PROtected Online Filing) is a free service offering additional protection for your company from the threat of fraudsters and corporate identity theft.

> PROOF ensures that the following filings can only be filed online (paper filings will be rejected)
> * Registered office address
> * Officer appointments, terminations or changes
> * Annual return

I don't really see any reason to _not_ do it, as I can't think of when we'd be filing things via paper post anyway.

(It's also not clear to what extent this is a `service` - it's just an instruction to not accept paper submissions 🤷‍♂️ )

@nelsonic as dwyl's Worf/Odo/Tuvok, what do you think?",2019-02-06T14:18:57Z,2019-02-06T15:00:53Z,open,1,"implementation, comfirmshaming ","interface interferences, forced action","forced action, confirmshaming, interface interferences",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/mikewest/cookies-over-http-bad/issues/7,special OPT_OUT cookie?,https://github.com/mikewest/cookies-over-http-bad/issues/7,"> Should we special-case the cookie value ""OPT_OUT""? It would be unfortunate indeed if removing old cookies meant that users who had opted out of interest-based advertising started being targeted again. Perhaps excluding the special value OPT_OUT (and asking advertisers to standardize on it?) is justifiable.

That will only lead sites to use OPT_OUT for everything, no? What's so bad about standardizing on the DNT header instead, which can and does expose per-browser UI (instead of having to work around varying dark patterns on every. single. website's ""consent"" form) and would contain approximately the same information without potential for being abused (as it's not site-controllable)?",2018-08-15T15:32:42Z,2018-08-15T15:32:42Z,open,0,"prevention of dark pattern, opt-out cookie","opt-out cookie for all websites, avoid dp","opt-out cookie, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/aws/aws-cdk/issues/2973,Allow overriding default removal policy,https://github.com/aws/aws-cdk/issues/2973,"**Note: for support questions, please first reference our [documentation](https://docs.aws.amazon.com/cdk/api/latest), then use [Stackoverflow](https://stackoverflow.com/questions/ask?tags=aws-cdk)**. This repository's issues are intended for feature requests and bug reports.

* **I'm submitting a ...**
  - [ ] :beetle: bug report
  - [x] :rocket: feature request
  - [ ] :books: construct library gap
  - [ ] :phone: security issue or vulnerability => Please see [policy](https://github.com/awslabs/aws-cdk/security/policy)
  - [ ] :question: support request => Please see note at the top of this template.


* **What is the current behavior?**
*If the current behavior is a :beetle:bug:beetle:: Please provide the steps to reproduce*

The default removal policy for stateful resources is to retain the resource. This means that, for example, buckets will never be deleted.

* **What is the expected behavior (or behavior of feature suggested)?**

It would be nice if it was possible to override this default behavior at the stack level and/or at the toolkit level. For example, I'd argue that development stacks would want the default to be ""delete"".

* **What is the motivation / use case for changing the behavior or adding this feature?**

Reports from users that they don't understand why the CDK leaves all this garbage in their accounts.

",2019-06-20T21:56:48Z,2023-06-30T16:40:37Z,open,3,"dark pattern in coding, resource management behaviors","overriding policy, CDK leaves unnecessary info, feature update suggestion",miscellaneous,miscellaneous,"dark pattern in coding, overriding policy",,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/canonical-web-and-design/blog.ubuntu.com/issues/437,Can subscribe to newsletter without checking “I agree to receive information”,https://github.com/canonical-web-and-design/blog.ubuntu.com/issues/437,"1\. Go to [blog.ubuntu.com](https://blog.ubuntu.com/).
2\. In the “Newsletter signup” form, enter an e-mail address.
3\. Leave the “I agree to receive information…” checkbox unchecked.
4\. Click “Subscribe now”.

What happens: “Success: Thank you for subscribing! You will begin receiving emails as new content is posted. You may unsubscribe any time by clicking the link in the email.”

What should happen:
3\. the checkbox isn’t present if it has no effect; or
4\. the subscribe button is disabled when you haven’t checked the checkbox; or
5\. clicking the button produces an error and highlights the checkbox.",2018-12-07T12:32:49Z,2019-04-12T10:28:49Z,open,7,"prevention of dark pattern in implementation, checkbox","newsletter sign-up, checkbox, forced action","checkbox, preselection, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/whatwg/notifications/issues/108,Require user gesture for notification permission request,https://github.com/whatwg/notifications/issues/108,"(This is a cross-post of [this WICG post](https://discourse.wicg.io/t/require-user-gesture-for-notification-permission-request/2366) based on [this suggestion](https://twitter.com/marcosc/status/911742921392586753))

I’ve noticed some websites ask for permission to send notifications immediately on the first visit. [This is annoying](https://twitter.com/MattWilcox/status/910776534524448768), enough that [guides appear showing how to turn them off](https://www.howtogeek.com/288946/how-to-stop-websites-from-asking-to-show-notifications/). It’s also surprising that these days a website often cannot even start autoplaying media upon visiting a page - to avoid annoying users - but it can still ask for you to permanently allow the website to send you notifications at any time, which is a good channel for spam.

I can’t think of any good reason someone would click “Allow” for notifications right away, without knowing anything about the website, the kind of content it will send, and the frequency. The user has likely not even clicked or touched inside the page yet. Nobody can make a good decision at this point. It seems websites are relying on users making bad decisions: hopefully some people will click “Allow” by accident, and then the website can spam them.

Why not require a user gesture? It would block this dark pattern entirely and still allow legitimate sites to work. It seems likely to improve the user experience since even if a website shows a prompt with a button to enable notifications right away, they’d probably at least try to explain why it’s useful to do so. I suspect many sites would instead relegate the option to a less intrusive UI.",2017-09-24T10:25:59Z,2022-05-18T21:55:52Z,open,10,"deceptive design practice, ask for permission","notification permission too quick, nagging","ask permission, nagging, deceptive design",DPs in design coding ,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/MozillaFestival/mozfest-program-2018/issues/441,User Flow liquid data visualisation,https://github.com/MozillaFestival/mozfest-program-2018/issues/441,"**[ UUID ]** c38462de-2044-467c-a70b-b319372170c6

**[ Session Name ]** User Flow liquid data visualisation
**[ Primary Space ]** Web Literacy
**[ Secondary Space ]** Privacy and Security

**[ Submitter's Name ]** Matt Stempeck
**[ Submitter's Affiliated Organisation ]** Bad Idea Factory
**[ Submitter's GitHub ]** @mstem












### What will happen in your session?
This is a visual aid to help explain the work: http://bit.lyliquidmotiontoys

User Flow is series of art pieces that animate the web's dark patterns. Each piece visualizes the flow of users (represented as colorful oil bubbles) through a set of common conversion marketing funnels. By building on an existing accessible metaphor, liquid motion toys, each piece invites participants to pick it up, flip it over, and enjoy watching web analytics unfold in real-time in the physical world. Together, the set instills web literacy while offering a moment of reflection on how marketers channel our attention through their elaborate scaffolds.

Materials:
Laser-cut acrylic
Acrylic cement
Mineral oil
Food dye

### What is the goal or outcome of your session?
It can be difficult to understand or visualize how web service providers treat users. This exhibit will vividly bring to life abstract ideas like conversion marketing and multivariate testing. Each laser-cut acrylic ""wireframe"" emulates a common approach to extracting value from streams of web traffic (in other words, us), including:

- Drip campaigns
- A/B and multivariate testing
- The effect of interventions on conversion rates
- Re-targeting

Participants will come away with an experience seeing how each tactic operates.


### If your session requires additional materials or electronic equipment, please outline your needs.
Colourful markers and sheet paper would be wonderful

If you'd like me to demonstrate creating one's own liquid data visualisations, I could also use a couple bottles of mineral oil, food dye, and salt


### Time needed
All weekend, as an installation, exhibit or drop-in session
",2018-07-31T20:39:39Z,2018-09-01T16:23:07Z,open,1,"user flow, deceptive design practice","User Flow, animate dp, web literacy, liquid data visualization",,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/itchio/itch.io/issues/481,"Alternate styling for ""No thanks, just take me to the downloads""",https://github.com/itchio/itch.io/issues/481,"When using the Pay What You Want model, I've seen users hesitate about downloading my game because the buy_form_widget heavily promotes donations, at the expense of communicating clearly that it's optional.

The styling and phrasing of the ""No thanks, just take me to the downloads"" makes it kind of hard to see for the less savy of users. 

**Proposals** 
- style the link in such a way that it's made at least as visible as the other options (bigger font, button styling, etc.)
- let the game creator decide on a styling and/or phrasing for this link
- let the game creator choose between discrete styling (current) and more visible styling.

Thanks for considering it ;)
",2016-06-23T07:52:10Z,2016-08-17T06:53:53Z,open,4,prevention of dark pattern in implmentation,"styling, download button, sneaking","download button, sneaking, avoid dark pattern",DPs in design coding ,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/lavab/web/issues/286,Implement accounts.wipe functionality to safely delete all emails/contacts,https://github.com/lavab/web/issues/286,"There was an API call for this, does it work @pzduniak?
",2015-03-13T14:26:36Z,2015-07-28T10:22:13Z,open,17,"prevention of dark pattern in implementation, account deletion","account deletion, data saving, obstruction","account deletion, obstrucion, avoid dark patterns","DPs prevention in software, DPs examples/definitions",,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/matomo-org/tag-manager/issues/46,favour privacy-friendly third-party-tags,https://github.com/matomo-org/tag-manager/issues/46,"While researching new tags, I noticed that a huge selection of third-party-tags in TagManager has one disadvantage: It makes it easy for Matomo-Users to infringe the website users privacy with a few clicks and without thinking about the implications by adding Facebook, Twitter and Google Analytics to the website. 

To counteract, we could highlight tags that only depend on privacy-focused, open-source and/or self-hosted services. (Obviously Matomo, but also Sentry.io)

An alternative would be doing the opposite and adding [F-Droid-like](https://f-droid.org/wiki/page/AntiFeatures) anti-feature warnings to all other, but I'm afraid that they will probably be the majority.",2018-07-27T09:31:37Z,2018-08-04T09:43:32Z,open,3,"deceptive design practice, consent form, annoying user experience","third-party tags, consent mechanism, privacy issue","consent form, privacy issue, deceptive design practice",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/stacks-archive/app-mining/issues/146,Email required for Authentication,https://github.com/stacks-archive/app-mining/issues/146,"Some apps require that the user provide an email to access the app. In some cases, this email is required before the user even signs in with Blockstack. It is our view that this requirement runs counter to the Blockstack ethos because it forces app users to give away personal information to a third party before even using the app. It is our position that is not compliant with Blockstack authentication which only requires the signed authentication token to access the app.

**Proposal:** Apps that *require* email in addition to Blockstack auth should be treated as if they are using 3rd party sign in methods and scored as such. Blockstack Browser should also make email optional by providing an option to skip it.",2019-09-03T13:14:09Z,2019-10-15T01:12:00Z,open,9,"Blockstack, usage of dark pattern in software, email required, forced action","email verification, email required before website onboarding","Blockstack, email required, forced action",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/willingc/pep-communication/issues/1,User persona: potential contributor focused on a single itch,https://github.com/willingc/pep-communication/issues/1,"There's a somewhat subtle component of the Discourse/mailing list debate that I've been thinking about after running into it a few times lately, and this might be a good place to capture it?

There are a number of projects where I'm a highly invested core maintainer, and I want to see all the issues/discussions/whatever. But there are also other areas, where I have a very strong interest in a very specific topic, but I'm not otherwise interested in subscribing to the firehose. This is one place where Github's per-issue subscriptions are great. For example, I'm subscribed to https://github.com/pypa/warehouse/issues/726 and https://github.com/pytest-dev/pytest/issues/935, which are tracking issues for two specific features that I care about a lot, but I'm definitely not interested in seeing everything happening in warehouse or pytest.

It's also something that mailing lists are really bad at. Concrete examples:

* https://github.com/python/mypy/issues/6073: in this issue I filed, Guido eventually suggested moving it over to the typing-sig list.

* https://github.com/golang/go/issues/29011#issuecomment-451785315: here one of the core Go developers requested I open a discussion on the golang-nuts mailing list

I'd *like* to push these forward, but in both cases they're currently stalled out, purely because the thought of subscribing to yet another mailing list firehose fills me with unbearable malaise. (Also, subscribing and unsubscribing to mailing lists is always this annoying multi-step process – ""ugh, which email address did I use?"" I know it's not intentionally a [dark pattern thing](https://darkpatterns.org/types-of-dark-pattern/roach-motel), but it still ends up as a major executive function tax.) So....... those contributions are just lost, I guess :-(.

Mailing lists work great for core contributors who want the firehose and who expect to remain subscribed indefinitely. But they're really unfriendly to both casual contributors, and also contributors who are highly invested in a specific topic, but where that topic doesn't equal ""everything on this mailing list, forever"".

I suspect this is a significant barrier to new contributors, that's invisible to core contributors.",2019-03-01T03:31:57Z,2020-07-27T01:49:56Z,open,3,"deceptive design practice, mailing list (un)subscription ","Github, firehose, subscription ","GitHub, mailing list (un)subscription, deceptive design practice",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/psu-libraries/scholarsphere-3/issues/1520,BePress Reporting,https://github.com/psu-libraries/scholarsphere-3/issues/1520,"I thought we may have had something in here similar, but I wasn't able to find it. As a user I would like to receive a monthly report about how many times my files have been downloaded and my total downloads, via email, with a link to my dashboard. This is common in BePress. I'm attaching a screen shot of that. (may be worth noting this request came in from users). 
![screen shot 2019-02-04 at 10 47 56 am](https://user-images.githubusercontent.com/398837/52219802-5b4e9880-286b-11e9-9f83-6043f3c253e6.png)
",2019-02-04T15:55:47Z,2019-07-18T15:05:49Z,open,6,"prevention of dark pattern in implementation, opt-in/out",,"opt-in/out, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/play-co/devkit/issues/214,"[Feature Request] Device > ""rateGame"" Method",https://github.com/play-co/devkit/issues/214,"It would be useful to have a ""rateGame"" method.

`device.rateGame()`

At present I use the following code, it has **many** pitfalls

```
// Android?
if(device.isAndroid){
    // Google Play
    window.open('https://play.google.com/store/apps/details?id='+CONFIG.packageName);
    // window.open('market://details?id=com.oodavid.buttonup');
    // Amazon App Store
    // window.open('http://www.amazon.com/gp/mas/dl/android?p='+CONFIG.packageName);
    // window.open('amzn://apps/android?p='+CONFIG.packageName);
} else if(device.isIOS){
    // iOS App Store
    window.open('https://itunes.apple.com/us/app/button-up/id'+CONFIG.ios.appleID+'?mt=8');
    // window.open('itms-apps://itunes.apple.com/app/id'+CONFIG.ios.appleID);
    // window.open('itmss://itunes.apple.com/app/id'+CONFIG.ios.appleID);
} else {
    console.error('Cant rate');
}
```

_I have a funny feeling the iOS one breaks on some versions of iOS (I only have one device to test on)_
## Desired Features
- Android to work between markets: Play, Amazon, [Some of These](http://appflood.com/blog/top-10-alternative-app-stores-from-china-2013)
- iOS to work between versions

For android it could just have Google Play to start with, adding new markets would just be an enhancement
",2015-03-17T11:06:18Z,2015-11-29T13:39:11Z,open,2,"usage of dark pattern in implementation, rating system","direct customers for rating between markets/versions, dp for 5 stars","rating system, nagging",DPs in design coding ,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/buriburisuri/speech-to-text-wavenet/issues/63,Pretrained model using all three corpus,https://github.com/buriburisuri/speech-to-text-wavenet/issues/63,"First, I would say thank you for making this awesome repository, 
I've been trying to train the model with all the dataset from 3 corpus but it seems will take really long time (need about 30 hours for single epoch. I'm using GTX1070 in SLI).

is it possible to provide a pretrained model with all the three dataset? as the current pretrained model is trained only with VCTK dataset if I'm not wrong

Thank you very much",2017-04-10T22:45:35Z,2018-09-23T08:38:18Z,open,13,"ufile.io, usage of dark patterm, clickbait, ads, data hostage taking","pretrained model, file with dp example-ads,clickbait","ufile.io, clickbait, ads",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/ensemble-engine/ensemble/issues/108,Let rules reference characters by ID?,https://github.com/ensemble-engine/ensemble/issues/108,"Let rules reference characters directly? This would mean accepting character IDs in the conditions and effects of trigger rules and volition rules, and in the conditions, effects, and influence rules of actions). 

This is relevant for example, for actions that only the player-character can take, or a domain that has a traditional protagonist that many other actions, desires, etc, reference or focus on. 

Even though it's desirable, in the sense that it's more procedural and better code reuse, to write all your rules so they can be bound to any character, in practice it's way common to want to explicitly link some of your rules to particular characters. Like for special treatment of the player-character. The assumption that you should write rules that could be applicable to all characters, or maximally rebound, seems like it was inherited from _Prom Week_ (where there was no single player-character, and all characters had access to symmetrical actions/volitions/rules for reasoning about the world). 

So I think we should allow this, to make it easy, but should maybe advise users to write rules with generic roles as much as possible in the materials and stuff, because I also think this explicit character naming thing can be overused and lead to dark patterns in your simulation design. 

## Current Workaround

The current work-around is to use 'named character traits', as illustrated in the Lovers and Rivals example:

1. Create schema types for different character names:
```json
{ 
  ""schema"": [{
    ""category"" : ""trait"",
    ""isBoolean"" : true,
    ""directionType"" : ""undirected"",
    ""types"" : [""named hero"", ""named love"", ""named rival"", ""anyone""],
    ""actionable"" : false,
    ""defaultValue"" : false
  }]
}
```

2. Give each character their name trait in your history JSON or using `ensemble.set()` at the beginning of the simulation:
```json
{ 
  ""history"": [{
    ""pos"": 0,
    ""data"": [{
      ""category"" : ""trait"",
      ""type"" : ""named hero"",
      ""first"" : ""hero"",
      ""value"" : true
    },{
      ""category"" : ""trait"",
      ""type"" : ""named love"",
      ""first"" : ""love"",
      ""value"" : true
    },{
      ""category"" : ""trait"",
      ""type"" : ""named rival"",
      ""first"" : ""rival"",
      ""value"" : true
    }]
  }]
}
```

3. Use the schema type corresponding to the character you want to reference to bind them to the  `""first""` or `""second""` role in any rule condition. For example, this volition rule:
```json
{
  ""type"": ""volition"",
  ""rules"": [{
    ""name"": ""The hero REALLY wants to increase closeness to the love"",
    ""conditions"": [
      {
        ""category"": ""trait"",
        ""type"": ""named hero"",
        ""first"": ""x"",
        ""value"": true
      },{
        ""category"": ""trait"",
        ""type"": ""named love"",
        ""first"": ""y"",
        ""value"": true
      }
    ],
    ""effects"": [
      {
        ""category"": ""feeling"",
        ""type"": ""closeness"",
        ""first"": ""x"",
        ""second"": ""y"",
        ""weight"": 20,
        ""intentType"": true
      }
    ]
  }]
}
```
## Proposal
Not sure what it should look like though...

One possibility: use character IDs as values in the role properties (`""first""`, `""second""`) of effects. No need to bind them in the condition?
```json
{
  ""type"": ""volition"",
  ""rules"": [{
    ""name"": ""The hero REALLY wants to increase closeness to the love"",
    ""conditions"": [],
    ""effects"": [
      {
        ""category"": ""feeling"",
        ""type"": ""closeness"",
        ""first"": ""hero"",
        ""second"": ""love"",
        ""weight"": 20,
        ""intentType"": true
      }
    ]
  }]
}
```
^ If we use this, we'd have to hold character IDs as keywords that you can't use as normal role names in rules. 

Another possibility: Allow a new kind of `""name""`, `""character""`, or `""characterID""` condition statement to bind characters to abstract roles and then use the roles in effects. 
```json
{
  ""type"": ""volition"",
  ""rules"": [{
    ""name"": ""The hero REALLY wants to increase closeness to the love"",
    ""conditions"": [
      {
        ""name"": ""hero"", 
        ""first"": ""x"",
        ""value"": true
      },{
        ""name"": ""love"",
        ""first"": ""y"",
        ""value"": true
      }
    ],
    ""effects"": [
      {
        ""category"": ""feeling"",
        ""type"": ""closeness"",
        ""first"": ""x"",
        ""second"": ""y"",
        ""weight"": 20,
        ""intentType"": true
      }
    ]
  }]
}
```",2019-12-23T21:50:10Z,2019-12-23T21:51:12Z,open,0,miscellaneous,"rules for particular characters, overused character naming leading to dp",miscellaneous,miscellaneous,overused character naming,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/nirjan-dev/learning-to-code/issues/30,Mario Kart tour case study,https://github.com/nirjan-dev/learning-to-code/issues/30,"[link to article](https://growth.design/case-studies/mario-kart-revenue-model)

Stories = Retention

When building a product or a game, users need to understand the purpose of what they do.

Games have become really good at immersing players into a story, to increase retention and engagement.1

However, here, it's hard to understand what the user fights against

Scarcity

Humans place a higher value on a scarce object and a lower value on those that are in abundance.1

Here, the scarce comes from the limited time ""Tour"" and the shop with its daily selections.

It is clearly used to add value to items that don't necessarily have any.

Loot Boxes: Engineered Addiction

Loot boxes are virtual rewards that you can pay for to have a chance at getting a virtual item.

They are now widely spread because they generate more than 25% of all gaming revenues by creating gambling addictions.1

The government is starting to pay attention and recommends to control them under gambling laws.

Shaping

Shaping is the process of reinforcing behaviors that are closer to the target behavior.1

In this case, this is a very scammy approach to encourage gambling behaviors, by making users familiar with the action of ""firing the pipe"" during the onboarding.

Dark Pattern - hiding the real value of money

Game designers have found ways to create complex game economics to dissociate money from the game with multiple game currencies.1 One of the drawbacks is users getting confused and spending large sums of money.

In this case, how much is a coin? After a few approximations 1000 coins = ~8$

Why not make it clear in the game?

Faking Real players?

Why lie and do as if players were real?1

Some might say, it's to prepare their multiplayer launch. But why ""prepare"" it. Why not be clear that you're racing against bots. It'll make that multiplayer launch that much more exciting!

As of now, it serves an arguable purpose of increasing your desire to gamble to get those items.

Providing Exit Points

Usually, inviting users to leave your platform after a particular milestone is a very healthy practice. It can even potentially increase retention.1

However, here, it doesn't gracefully invite you to come back tomorrow, it just stops rewarding you for your efforts. 

Here are 5 things to avoid when building your revenue model:
⓵ 😈 FAKING SCARCITY: Scarcity is a powerful nudge to help people make decisions when it’s real. If you fake or add scarce for no good reason, then people will react the opposite way.
⓶ 🎲 LOTTERY: When building game or product dynamics, make sure fundamental progress doesn’t rely on a lottery. This is pure gambling and will discourage the majority of users. Plus, it'll be illegal soon...
⓷ 🛑 LIMITING DAILY REWARDS: Encouraging people to come back another day after reaching a milestone is a great way to increase retention. However, don’t stop potential progress if people want to continue. 
⓸ 🤝 FAKING INTERACTIONS: Everything that’s fake is just bad… Especially when you fake human beings. 
⓹ 🧠 SHAPING DARK BEHAVIORS: Slowly rewarding users for behaviors that are closer and closer to the target behaviors is a great way to build engagement, except when it’s used to create an addiction for gambling purposes.
",2019-10-24T07:04:00Z,2019-10-24T07:04:00Z,open,0,"Mario Kart, dark pattern in gaming, fake social proof","Mario Kart, examples and ways to build dp","Mario Kart, gaming, fake social proof",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/protobufjs/protobuf.js/issues/716,cliDependencies and npm dependency,https://github.com/protobufjs/protobuf.js/issues/716,"protobuf.js version: 6.6.5

When using the CLI version of protobuf.js, some additional dependencies are installed (they are defined without versions in `cliDependencies` of the `package.json`.
There are a few issues with this approach that I hope we can find a solution for:
* The project I am using is using `yarn`, meaning that wherever `pbjs` was installed into does not have `npm` available on CI.
* Locally there is npm available, but quite often the install fails:
```yarn gen-js v0.21.3
$ ./proto/gen.js.sh
installing jsdoc@^3.4.2
installing tmp@0.0.31
installing espree@^3.1.3
installing escodegen@^1.8.1
module.js:472
    throw err;
    ^

Error: Cannot find module 'espree'
    at Function.Module._resolveFilename (module.js:470:15)
    at Function.Module._load (module.js:418:25)
    at Module.require (module.js:498:17)
    at require (internal/module.js:20:19)
    at Object.<anonymous> (/Users/joscha/Development/wala/wala-sodaqone_3/node_modules/protobufjs/cli/targets/static.js:7:18)
    at Module._compile (module.js:571:32)
    at Object.Module._extensions..js (module.js:580:10)
    at Module.load (module.js:488:32)
    at tryModuleLoad (module.js:447:12)
    at Function.Module._load (module.js:439:3)
error Command failed with exit code 1.
```
* The dependencies that are installed on-the-fly are not part of any `yarn.lock` or `npm-shrinkwrap.json`, meaning that the installation can 1) not be cached easily 2) not be reproduced easily 3) yarn will blow away any installed packages not part of the lock file any time `yarn install` is run 4) `npm shrinkwrap` will wet itself because there are additional packages installed.

A couple solutions come to mind:
* Make these actual `dependencies` - after all they are used at runtime
* Create a `protobuf.js-cli` package that has a dependency on the `protobuf.js` package and on all the CLI dependencies. That way this package could be lightweight for the people that are not interested in the CLI.

What do you think?",2017-03-23T11:36:36Z,2021-06-17T03:23:24Z,open,15,miscellaneous,"dependencies, shadow invoking NPM",miscellaneous,miscellaneous,shadow invoking NPM,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/iv-org/invidious/issues/740,More descriptive home page,https://github.com/iv-org/invidious/issues/740,"Whenever Invidious gets linked to, people are left confused what it actually is ([latest example](https://old.reddit.com/r/firefox/comments/czy3i5/invidition_youtube_to_invidious_redirector_addon/ez4dw88/)).

I propose adding some informational text at the top of the home page for logged-out users, that explains what Invidious is, some of its main features and provides a call to action (register and import subscriptions). Final text tbd.

Secondly, I'd also switch to showing the *popular* page by default, as it is a better representation of what the instance's registered users actually watch. *Popular* also hosts many familiar channels, letting users know that the content is actually from Youtube, and not hosted by Invidious itself. (videos on the _top_ page aren't representative, as they can appear after only 1 person watched them through Invidious and often are in foreign languages and/or from not widely known personalities)

I've hacked up a quick mock-up in the devtools, but if this is something that is accepted, I can create a proper pull request and put some more effort into a nice looking UI and making it e.g. dismissable.

![screenshot](https://imgur.com/8pZFkhi.png)


<details><summary>code of the mockup (click to expand)</summary>

```html
<!-- inserted instead of the popular/top/trending bar -->
<div>
    <h1>Welcome to Invidious</h1>
    <p>Invidious is a featureful Youtube-player, that respects your privacy.
        </p><p>Features:
        </p><ul>
            <li>Audio-only mode
</li><li>Dark mode
</li><li>No ads
</li><li>Lightweight
</li><li>Doesn't require a Google account
</li><li>Support for Reddit comments
</li><li> ... and others! Click to <a href=""https://github.com/omarroth/invidious/blob/master/README.md"">learn more</a>
    </li></ul>
        <p><button>create an account and import your subscriptions now</button>
    </p><p>Here is a selection of videos that our community is interested in:
    </p><div class=""pure-u-1 pure-u-md-1-4""></div>
</div>
```

</details>
",2019-09-07T04:18:49Z,2022-06-25T12:35:30Z,open,10,miscellaneous,"Invidious' homepage, dismiss button color choice bad, potential sneaking","color contrast of button, sneaking",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/EFForg/privacybadger/issues/1606,Completely disable blocking on optout.aboutads.info,https://github.com/EFForg/privacybadger/issues/1606,"I recently got linked to http://optout.aboutads.info/ from a Google opt-out page. Privacy Badger seems to have blocked 65 requests to advertisers participating in that page.

Obviously it's doing its job pretty well, but in this particular case we actually probably want to allow those requests through since for once requests to these domains are for a privacy-protecting purpose, not the other way around ;)",2017-08-27T04:23:03Z,2023-02-01T14:48:17Z,open,16,"Privacy Badger, popup, opt-out cookies, detection tool, prevention of dark pattern in software","opt out ad blocking, Google, making user aware","Privacy Badger, opt-out cookie, avoid dark pattern",DPs prevention in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/mastodon/mastodon/issues/11339,"Properly federate ""like"" objects",https://github.com/mastodon/mastodon/issues/11339,"<!-- Please use a concise and distinct title for the issue -->

<!-- Consider: Could it be implemented as a 3rd party app using the REST API instead? -->

### Pitch

1. Incoming `like` objects are applied to posts, and posts are fetched for newly seen ones (similar to how `announce` objects are handled.
2. Any generated `like` objects are federated to all followers (and of course the poster), similar to how replies work.

### Motivation

Many Fediverse softwares, for example, Prismo and PeerTube, threat likes as important information, so Mastodon should properly handle them.  Also, this would further fill out federated timelines, since you'd see all posts that anyone followed on your instance likes, as opposed to only the ones they boost or reply to.",2019-07-17T19:35:16Z,2024-01-29T15:33:07Z,open,43,miscellaneous,"Incoming 'like' objects, favorite/boost counts, sneaking, deliberately hiding",miscellaneous,miscellaneous,"sneaking, hiding",,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/tgstation/tgstation/issues/28275,In game windows and pop-ups sometimes takes several seconds to load or fail entirely,https://github.com/tgstation/tgstation/issues/28275,"Server revision compiled on: 2017-06-08
6f5157 (The show server revision command does not work properly in Goonchat)

BYOND version 511.1384, Internet Explorer 11.

Many in-game menus and pop-ups often take several seconds, sometimes exceeding 30, to display. At times, a menu seems to time out entirely. I have had this happen with ghost role prompts, computer interfaces such as the R&D console, TGUI interfaces on things such as APCs and Air alarms, and even the changelog.

I have no additional data on this issue as it seems to affect any pop-up, no matter the interface type used.",2017-06-09T17:02:01Z,2022-03-19T04:07:36Z,open,26,"miscellaneous (Windows, system update, forced action)","takes longer seconds for loading windows, pop-ups, windows 10/11 have dp adware",miscellaneous,miscellaneous,"Windows, system update, popups, nagging",,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/zdia/gorilla/issues/190,Critical: Can't see password on macOS Mojave,https://github.com/zdia/gorilla/issues/190,After login i can't see window with my password tree. Its happened after upgrade to macOS Mojave. Will be it fixed?,2018-09-25T09:46:26Z,2019-10-17T16:05:31Z,open,23,"miscellaneous (Apple, gatekeeper, usage of dark pattern in software)","MacOS Mojave, Apple's gatekeeper error message, misleading","Apple, gatekeeper, misleading",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/rstudio/shiny/issues/2500,Action button doesn't pop back up after a click,https://github.com/rstudio/shiny/issues/2500,"After running the example in `shiny::actionButton` and clicking on the action button, I see:

<img width=""944"" alt=""image"" src=""https://user-images.githubusercontent.com/4196/59553302-b189c180-8f58-11e9-8ff6-03ed6ea4e024.png"">

This looks like the button is still pressed down; it should pop back up on mouse up.",2019-06-15T15:33:23Z,2023-06-27T18:42:52Z,open,10,"prevention of dark pattern in implmentation, visual interference, hidden focus button","button stayes pressed down after action being completed, hiding focus","hidden focus button, interface interference, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/qutebrowser/qutebrowser/issues/2707,Telemetry,https://github.com/qutebrowser/qutebrowser/issues/2707,"Right now qutebrowser doesn't phone home (except for crash reports, if instructed by the user), but from time to time it'd be nice to have some data on how it's used.

I think there should be some way to get some basic statistics for qutebrowser users, of course strictly opt-in (e.g. by asking on the first start).

Values I can think of which could be useful:

- Unique randomized ID (UUID4)
- Version numbers (qutebrowser, Python, Qt, dependencies)
- OS/distribution
- Used backend
- Customized settings, without any values except for settings which have a choice of fixed values

What do people think of that? Are there any privacy issues with that kind of data I haven't considered?",2017-06-08T21:08:11Z,2019-11-01T17:34:31Z,open,23,"Telemetry, usage of dark pattern in implementation, data collection ","qutebrowser, get more user data(e.g. how many people use it), sneaking","Telemetry, data collection",DPs in design coding ,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tg-z/web-clip/issues/181,Announcing Decentralized Networks Workshop | Distributed Web of Care,https://github.com/tg-z/web-clip/issues/181,"[Distributed Web of Care](http://distributedweb.care/)
------------------------------------------------------

Free, public workshop for the WYFY School, in partnership with BUFU. 8.11.2019 6:30 - 8 p.m. at the School for Poetic Computation, NYC. This posting is a work in progress guide for Decentralized Networks Workshop.

![](http://distributedweb.care/static/images/wyfy/dandelions.svg)

*   Social media: Instagram
*   Cloud computing: Amazon Web Services
*   Cloud storage: Google Drives
*   _Postscript on the Societies of Control_ by Gilles Delueze
*   [_Control Society_](http://poeticcomputation.info/chapters/ch.3/) by Taeyoon Choi
*   Capitalization of attention economy: [_How to do Nothing: Resisting Attention Economy_](https://www.penguinrandomhouse.com/books/600671/how-to-do-nothing-by-jenny-odell/9781612197494/) by Jenny Odell
*   Erasure or overexposure of the marginalized communities: [_The internet thinks you’re a robot, and other ‘dark patterns’ people with disabilities face online_](https://www.abc.net.au/news/science/2019-07-13/dark-patterns-online-captcha-accessibility-disability-community/11301054) by Ariel Bogle
*   “If memes reiterate the inequities between black creators and white appropriators, can they also move us into a new collective blackness?” [_Poor Meme, Rich Meme_](https://reallifemag.com/poor-meme-rich-meme/) by Aria Dean

  
![](http://distributedweb.care/static/images/wyfy/questions.png)
  

### 1\. Silicon Valley Perspectives

*   History of Utopias and idealism
*   Hackers and counterculture
*   The Whole Earth Catalogue
*   Information sovereignty
*   “[Information wants to be free](https://en.wikipedia.org/wiki/Information_wants_to_be_free)”
*   Suburbanization of the Web: Squarespace

  
![](http://distributedweb.care/static/images/wyfy/party.png)
  

### 2\. A variety of decentralizations

*   Community networks: [Digital Stewards Training](https://alliedmedia.org/dctp/digitalstewards) and [Digital Defense Playbook](https://www.odbproject.org/wp-content/uploads/2019/03/ODB_DDP_HighRes_Spreads.pdf) by Detroit Community Technology Project
*   Peer to Peer protocols: [Hong Kong’s protesters put AirDrop to ingenious use to breach China’s Firewall](https://qz.com/1660460/hong-kong-protesters-use-airdrop-to-breach-chinas-firewall/)
*   Mesh network: [NYC Mesh](https://www.nycmesh.net/) and DWEB Camp [Mesh topology](https://github.com/dweb-camp-2019/meshnet)
*   Offline first: [El Paquete Semanal](https://en.wikipedia.org/wiki/El_Paquete_Semanal) in Cuba
*   Solar-powered:[LOW←TECH MAGAZINE](https://solar.lowtechmagazine.com/)
*   [Association for Progressive Communications](https://www.apc.org/en)
*   How is a users’ privacy honored in each cases?
*   How is a users’ identity defined in each cases?

### 3\. An alternative to Google Drives

*   [Dat](http://datproject.org/)
*   [How-to](http://distributedweb.care/posts/codesocieties/) Demonstrations
*   Art projects: [Dat Zine Library](https://coolguy.website/projects/dat-zine-library/index.html) by Zach Manderville, ‘For the Birds’ Podcast

  
![](http://distributedweb.care/static/images/wyfy/ssb.jpg)
  

### 4\. An alternative to Instagram

*   [Secure Scuttlebutt](https://www.scuttlebutt.nz/)(SSB)
*   Friendly [new site](https://ssb-landing.netlify.com/)
*   How-to Demonstrations
*   [Principles](https://www.scuttlebutt.nz/principles/): “Environment reflecting Technology reflecting Community reflecting Society.”
*   [Network Topology](https://www.scuttlebutt.nz/concepts/): “it maps a the social network on to a computer network that is essentially the same topology! that is, the connections between humans maps approximately to the the connections between computers. if you follow someone, you really actually follow them at the data layer.”

_SSB concepts and terms_

*   [Identity](https://www.scuttlebutt.nz/concepts/identity): “The private key is your secret not to be shared with anyone. The public key is used as your identifier.”
*   Local first: “offline first” Peer to Peer protocol
*   [Feed](https://www.scuttlebutt.nz/concepts/feed): “A feed is a signed append-only sequence of messages. Each identity has exactly one feed.”
*   Append-only log: Once you publish, you can’t edit or delete
*   Global [Gossip](https://www.scuttlebutt.nz/concepts/gossip) Network: [Gossip protocol](https://en.wikipedia.org/wiki/Gossip_protocol)

![](https://d33wubrfki0l68.cloudfront.net/4ec9ab624bc94d3829331cacc850c6d78a4ad6b2/01f43/assets/gossip-graph2.png)

*   What actually happens?:[Protocol guide](https://ssbc.github.io/scuttlebutt-protocol-guide/)
*   Client: [Patchwork](https://ahdinosaur.github.io/patchwork-downloader/) and [Patchbay](https://github.com/ssbc/patchbay), what are the differences?
*   Friend hops: Show hops option in Patchbay
*   [Pub](https://www.scuttlebutt.nz/concepts/pub): ‘Always-online friend,’ SSB on a server which you can follow to connect with friends remotely
*   SSB Community: [Scuttle Camp](https://one.camp.scuttlebutt.nz/)
*   Conversations on SSB: A reading group about ‘White fragility,’ discussion about ‘Decolonizing technology,’ a channel about ‘Vegan junkfood’ and etc
*   Creative projects: Scuttlebooth

  
![](http://distributedweb.care/static/images/wyfy/ssb.png)
  

### 5\. QTPOC perspectives

*   A conversation about conflict of needs: Preservation of privacy and intimacy versus Openness and inclusivity
*   Abuse, misuse, harassment scenarios: White supremacy, hate speech and toxic masculine behaviors
*   Decolonizing the internet
*   Honoring the indigeneous and traditional communities, land and the environment
*   Deaf and Disabled rights on the Decentralized web

### 6\. Critical perspectives

*   Corporate appropriations and re-centralization
*   “Decentralization is not the goal. Orthogonality of Data, Transport, Identity ‘not used to capture each other, they are 90 degrees from each other’ for Information freedom and user agency. For a sense of self and privacy” - Peter Wang’s [talk](https://www.youtube.com/watch?time_continue=1314&v=-z47R9wN5SQ) at the DWEB Camp
*   Military contracts: Brooklyn Start Up [GoTenna](https://gotennamesh.com/products/mesh) lands a [contract](https://www.usaspending.gov/#/keyword_search/gotenna) with the Department of Homeland Security, U.S. Customs and Border Protection

### 7\. Group discussion

*   QTPOC safe space on Decentralized Web
*   Code of conduct and community stewardship
*   Copyright versus ownership of ideas and identity

### 8 . Leaving with a positive note

*   [_Three protocols and a future of the decentralized internet_](https://blog.datproject.org/2019/03/22/three-protocols-and-a-future-of-the-decentralized-internet/) by Darius Kazemi
*   [Run your own social](https://runyourown.social/):How to run a small social network site for your friends by Darius Kazemi
*   [Our Networks](https://ournetworks.ca/) in Toronto
*   [Radical Networks](https://radicalnetworks.org/) in New York
*   [Allied Media Conference](https://www.alliedmedia.org/amc) in Detroit
*   [DWEB Camp](https://dwebcamp.org/) in San Francisco
*   [Remembering the First DWeb Camp, July 2019](https://blog.archive.org/2019/07/31/remembering-the-first-dweb-camp-july-2019/) By Frances Sawyer
*   [The Internet’s Old Guard](https://reading.supply/post/432f6903-c7cd-4cb0-a894-c09155a8ca8b) By Jay Graber
*   [Transforming Ourselves to Transform Our Networks](https://medium.com/decentralized-web/transforming-ourselves-to-transform-our-networks-f4511a3d7483) by mai ishikawa sutton

### 9\. A case for emergent networks

*   “trust the people and they become trustworthy. trust the people and you will become trustworthy.” [trust the people](http://adriennemareebrown.net/2019/07/01/trust-the-people-2/) by adrienne maree brown
*   “We are not idealistic. Decentralization is not a solution to the problems of the centralized networks. However, we are not pessimistic. Decentralized networks, when they are designed by the folx traditionally marginalized from the networks, LGBTQPOC, Deaf, Disabled, Indigenous and traditional communities, can lead to an equitable, distribtued web of care.” by Taeyoon Choi

### 10\. Activity suggestions

*   Create an append-only journal with peers
*   Build your own social network with peers
*   Role play a situation for community stewardship and protection
*   List your priorities for data privacy
*   Map your ‘orthogonal’ approach for a better web

### Support

Much love for [BUFU](http://bufubyusforus.com/thewyfyschool), [The School for Poetic Computation](http://sfpc.io/), SFPC [Code Societies](http://sfpc.io/codesocieties-winter-19) and [Melanie Hoff](https://melanie-hoff.com/) for supporting the WYFY School, [Flawless Hacks](http://flawlesshacks.com/) for supporting the ‘work in progress’ zine and the DWEB Camp and the Secure Scuttlebutt community.

* * *

![](http://distributedweb.care/static/images/og.jpg)

Distributed Web of Care is an initiative to _code to care_ and _code carefully_.

The project imagines the future of the internet and consider what care means for a technologically-oriented future. The project focuses on personhood in relation to accessibility, identity, and the environment, with the intention of creating a distributed future that’s built with trust and care, where diverse communities are prioritized and supported.

The project is composed of collaborations, educational resources, skillshares, an editorial platform, and performance. Announcements and documentation are hosted on this site, as well as essays by select artists, technologists, and activists.

Distributed on [Dat](dat://distributedweb.care/) and [GitHub](https://github.com/tchoi8/distributedwebofcare).

* * *

*   Aug 10, 2019
    
    ### [Announcing Decentralized Networks Workshop](http://distributedweb.care/posts/decentralized-networks/)
    
*   May 24, 2019
    
    ### [On Stewardship](http://distributedweb.care/posts/on-stewardship/)
    
*   May 23, 2019
    
    ### [Movement Scores](http://distributedweb.care/posts/movement-scores/)
    
*   May 4, 2019
    
    ### [Who Owns the Stars: The Trouble with Urbit](http://distributedweb.care/posts/who-owns-the-stars/)
    
*   May 1, 2019
    
    ### [Announcing WYFY School with BUFU](http://distributedweb.care/posts/wyfy/)
    
*   Mar 5, 2019
    
    ### [Announcing Lecture Performance at the Whitney Museum](http://distributedweb.care/posts/whitney/)
    
*   Feb 25, 2019
    
    ### [Announcing Call for Deaf or Disabled Stewards](http://distributedweb.care/posts/stewards/)
    
*   Feb 7, 2019
    
    ### [Making Space in Online Archives](http://distributedweb.care/posts/online-achives/)
    
*   Jan 29, 2019
    
    ### [Accessibility Dreams](http://distributedweb.care/posts/accessibility-dreams/)
    
*   Jan 28, 2019
    
    ### [Creative Self Publishing](http://distributedweb.care/posts/creative-publishing/)
    
*   Jan 11, 2019
    
    ### [Racial Justice in the Distributed Web](http://distributedweb.care/posts/racial-justice/)
    
*   Dec 29, 2018
    
    ### [Announcing LACA Residency](http://distributedweb.care/posts/laca/)
    
*   Dec 28, 2018
    
    ### [Announcing DWC at Code Societies](http://distributedweb.care/posts/codesocieties/)
    
*   Dec 21, 2018
    
    ### [Building a Museum 353 Years in the Future](http://distributedweb.care/posts/ari/)
    
*   Sep 11, 2018
    
    ### [Finding Intimacy within Black Feminist Criticism](http://distributedweb.care/posts/findingintimacy/)
    
*   Jul 26, 2018
    
    ### [still stuck with words](http://distributedweb.care/posts/stillstuckwithwords/)
    
*   Jul 26, 2018
    
    ### [Distributed Dance Floor](http://distributedweb.care/posts/distributeddancefloor/)
    
*   Jun 27, 2018
    
    ### [Announcing Skillshares: Peers in Practice](http://distributedweb.care/posts/skillshares/)
    
*   Jun 27, 2018
    
    ### [Announcing the Distributed Web of Care Party](http://distributedweb.care/posts/party/)
    
*   Jun 27, 2018
    
    ### [Communities and New Infrastructures](http://distributedweb.care/posts/cleo/)
    
*   Jun 27, 2018
    
    ### [New Gardens](http://distributedweb.care/posts/callil/)
    
*   May 20, 2018
    
    ### [Announcing Summer 2018 Fellows](http://distributedweb.care/posts/summer-2018-fellows/)
    
*   Apr 28, 2018
    
    ### [DWC Merchandise: Care Shirt & Hoodie](http://distributedweb.care/posts/products/)
    
*   Apr 27, 2018
    
    ### [Announcing Artists in Residence at Ace Hotel New York](http://distributedweb.care/posts/air/)
    
*   Apr 18, 2018
    
    ### [Documentation: Ethics and Archiving the Web](http://distributedweb.care/posts/eaw/)
    
*   Apr 18, 2018
    
    ### [Call for Fellows and Stewards](http://distributedweb.care/posts/callforfellows/)
    
*   Apr 17, 2018
    
    ### [Code of Conduct](http://distributedweb.care/posts/coc/)
    
*   Mar 18, 2018
    
    ### [About](http://distributedweb.care/posts/about/)
    
*   [Distributed Web of Care](http://distributedweb.care/)
    ------------------------------------------------------",2019-09-16T19:33:54Z,2020-03-03T05:06:00Z,open,0,miscellaneous (Decentralized Networks Workshop),"examples of dp in ""captcha"" and other ""are you a robot"" verifications",miscellaneous,miscellaneous,"""are you a robot"" verifications",,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/TeamWin/Team-Win-Recovery-Project/issues/851,Provide option to uninstall TWRP app,https://github.com/TeamWin/Team-Win-Recovery-Project/issues/851,"I tried to install the official app using TWRP-3.0.3. The app seems to be closed source, so I want to remove it again.
adb uninstall me.twrp.twrpapp doesn't work, even as root.
Please provide an option in the recovery-GUI to remove the app again.

In the mean time - does anybody know a way to get rid of the app again?",2017-02-11T15:51:23Z,2021-09-04T10:27:08Z,open,44,"TWRP, usage of dark pattern in software, app uninstallation, obstruction","TWRP app, uninstalling issue, closed source software, malware, interface interferrence ","TWRP, app uninstallation, obstruction",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/WedgeServer/wedge/issues/5,Header has been removed in upstream,https://github.com/WedgeServer/wedge/issues/5,See https://github.com/mholt/caddy/pull/1866,2017-09-15T06:04:29Z,2018-03-28T23:54:02Z,open,15,"Caddy, usage of dark pattern in software, trick users buying paid products","marketing for users to get the paid product, manipulation","Caddy, trick users buying paid products",DPs used in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/Rich-Harris/degit/issues/30,Additional actions,https://github.com/Rich-Harris/degit/issues/30,"2.1.0 brings the concept of *actions* — see #28.

So far we have `clone` and `remove`. I can think of a few others that might be useful:

* `rename` — for moving files out of the way to prevent them being clobbered by clone
* `replace` — for replacing placeholder stuff in particular files, such as [this TODO](https://github.com/Rich-Harris/typescript-lib/blob/7200d6638568818a4339fb8cbc4007b8469a10f7/package.json#L2). Would need to come after a...
* `prompt` — get some user input. [terkelg/prompts](https://github.com/terkelg/prompts) has some nice conventions we could adopt.

So you could do this sort of thing:

```js
[
  {
    ""action"": ""prompt"",
    ""questions"": [
      { ""type"": ""text"", ""name"": ""name"", ""message"": ""What is the project name?"" }
    ]
  },
  {
    ""action"": ""replace"",
    ""delimiters"": [""<<"", "">>""],
    ""values"": [""name""],
    ""files"": [""package.json""]
  }
]
```

then if you had a package.json like

```js
{
  ""name"": ""<<name>>"",
  ...
}
```

it would get filled in. Not fully baked (maybe the `replace` action should run in the *context* of the prompt?) but you get the idea. cc @mhkeller if you have thoughts",2018-03-12T13:21:52Z,2022-05-20T14:31:40Z,open,19,"usage of dark pattern in coding, (y/N) prompt, command shell, package installation","confirm with user before execution, potential dp code in bash script","dark pattern in coding, package installing, command shell",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/GitHawkApp/GitHawk/issues/192,Growth hacking,https://github.com/GitHawkApp/GitHawk/issues/192,"I [shared a thread](https://twitter.com/_ryannystrom/status/890680066870571008) about current download stats. Pretty crummy! I'm building this app for myself first, but want to learn more about App Store marketing. I've written apps that have been featured before, but I figured since this is free (and I wont stop tweeting about it) it'd take off to a thousand downloads a week (give or take).

Opening this issue to document ideas about ways to improve reach/downloads:

- [ ] More targeted keywords
- [x] Rename in App Store
- [x] Prompt for reviews (maybe after marking a few threads as read)
- [ ] FB ads (I have a credit)
- [x] [Blogging](http://whoisryannystrom.com/)
- [x] Static landing page/site (SEO)
- [x] Add a ""Posted with Freetime"" (+link) when commenting
- [ ] Post in HN/Dribbble/DN (what else?)
- [ ] Localize app + store listing
- [x] Marketing video
- [x] More focused screenshots (like w/ colors + words)

- [x] Add App Store badge+link in Readme
- [ ] Ask for GH stars in some way? Not sure how / where
- [ ] Somehow promote the accessibility features might help?
- [x] Fancier tweets for new versions and ask for retweets?
- [ ] Option to share the app with your friends / coworkers / etc in Settings?

The challenge: w/e we do, it should be (basically) free.",2017-07-27T23:56:59Z,2020-06-04T17:32:48Z,open,35,"deceptive design practice, app rating, app sharing","building app, short link/signatures to market","deceptive design practice, rating system",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/wet-boew/wet-boew/issues/7896,"Mark optional fields as ""optional"" instead of required fields as ""required""",https://github.com/wet-boew/wet-boew/issues/7896,"To increase the likely-hood users enter in optional information, according to research, It would be better to mark ""Optional"" fields as ""Optional"" rather than marking ""Required"" fields as ""Required"". Citation:
http://preibusch.de/publications/Preibusch-Krol-Beresford__voluntary_over-disclosure.pdf

From the abstract: "" In our experiment, we found that making some fields mandatory
jeopardized voluntary disclosure for the remaining optional fields.""

In order to implement this, we would have to change how form labels work as seen here: 
- https://wet-boew.github.io/wet-boew-styleguide/v4/design/forms-en.html#labels 
- https://wet-boew.github.io/v4.0-ci/demos/formvalid/formvalid-en.html

We would also then put a statement before the form: 'All fields are required unless indicated as optional' which according to research tests well. 

Here is some further discussion and analysis:
http://ux.stackexchange.com/questions/50584/mark-or-dont-mark-required-fields-if-all-are-required
",2017-02-16T15:57:23Z,2019-04-17T14:41:14Z,open,30,"prevention of dark pattern in design, required/optional field, tranparency","removiing ""optional"", sneaking, misleading","required/optional field, misleading, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/github/site-policy/issues/204,Mark Fernandes's improvements to the main GitHub terms and conditions,https://github.com/github/site-policy/pull/204,"Please contact me if you disagree with any of my changes or you are unsure about any of them.

I use the general rule of thumb that less is better.

No need to say things like 'thank you'. If you want to say 'thank you', say it on your home page. People have little time, and want to spend as little time as possible reading user agreements such as this one.

Sometimes I've changed the ordering of statements because it makes for easier comprehension.

Sometimes I've just taken text out that is unnecessary.

I've tried to make changes so that for the vast majority of your users, it is quicker to get through them. Eg. majority of users probably don't use the APIs, so I've changed the terms so that you aren't forced to read the terms relating to the APIs if it is not relevant to you.

On the face of it, it may seem better to inform users about everything so that they are fully informed. However, in reality, users (especially ones not representing organisations), find it hard to mentally keep in mind all of the details of a user agreement. This means that informing them about everything can actually mean that they are less aware rather than more aware. If you try to be more selective with what you communicate, they can end-up being in fact more informed because they find the communication less unwieldy.

Using bullet points can make for better comprehension because it is generally a better visual organisation of information.

Sometimes, I've moved text so that a 'you can skip the rest of this section' statement can be made. So what happens, is that you read important stuff at the top (text sometimes moved to the top), and then you hit such a skipping statement so that you can skip the rest of the section.

Sometimes sentences have been combined to say the same thing with less words, in hopefully a clearer way. On the other hand, at least in one place I've split a very long-winded sentence into a few sentences, to make for easier comprehension. You find such very long-winded sentences in legal contracts. Even though they may be legally sound, they are generally very difficult to read.

Most of the changes should be easy to understand.

Further Advice
==============

You can:
- look at the advice I gave to Microsoft regarding one of their terms and conditions documents, that can be accessed by going to: https://answers.microsoft.com/en-us/skype/forum/all/processing-the-microsoft-services-agreement-legal/e104804e-c2c0-413f-b8e5-180a2b029415 .
- look at how the BBC website terms and conditions (https://www.bbc.co.uk/usingthebbc/terms/) are arranged, and try to draw inspiration from them, in order to simplify the presentation, and improve the accessibility of, your terms.",2019-12-06T18:52:25Z,2023-11-07T00:34:16Z,closed,14,"deceptive design practice, prevention of dark patterm, collapsible texts, terms and conditions",definitions and examples,"deceptive design practice, avoid dark pattern, terms and conditions",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/hql287/Manta/issues/246,sidebar overflow problem,https://github.com/hql287/Manta/issues/246,"Found some design bugs on linux, probably also showing on macOS and windows ...

(1) the pathfield in the invoice tab of the settings overlays notifications popups:
![notification-overlayed-by-pathfield](https://user-images.githubusercontent.com/9143480/36940324-23ac0860-1f41-11e8-84fc-205a0cee685c.png)

(2) preview window has still multiple scrollbars, if it gets too small:
![preview-multiple-scrollbars](https://user-images.githubusercontent.com/9143480/36940325-23ca6972-1f41-11e8-9e1f-af2238d5eb89.png)

(3) if the preview window gets too small the buttons collapse and the buttontext overflows:
![small-window-preview-buttons](https://user-images.githubusercontent.com/9143480/36940326-23e48ec4-1f41-11e8-9314-89218c662efa.png)

@hql287 you can assign this to me ...

Feedback about these bugs on windows and macOS would be nice!",2018-03-03T23:22:26Z,2023-11-10T13:39:45Z,closed,26,"prevention of dark pattern in design, button size, UI design","sidebar overflow, obstruction by makinf button wider","button size, UI/UX design, obstruction, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/jitsi/jitsi-meet/issues/1662,Desktop view available for mobile,https://github.com/jitsi/jitsi-meet/issues/1662,"Please correct me if I should not reopen this topic.
I tried to remove this on the head of my html meta name=""viewport"" content=""width=device-width, initial-scale=1.0"" but its still detecting that I'm using mobile device so I conclude that the mobile detection is based on actual mobile device not on the width.

I'm trying to use the desktop view on specific page. Is there a way on the api to force them to use desktop view in mobile device?

![mobile](https://user-images.githubusercontent.com/2825333/26954706-156416f6-4ce4-11e7-95a4-99166d8f49ca.png)",2017-06-12T00:05:20Z,2023-11-22T10:51:36Z,closed,48,"jitsi-meet, usage of dark pattern, forced action, mobile/laptop switching","Jitsi Meet, forcing from mobile to desktop","Jitset Meet, mobile/laptop switching, forced action",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/cypress-io/cypress/issues/4021,No longer fail runs based on recording limit,https://github.com/cypress-io/cypress/issues/4021,"I can't see any explanation for this behavior [here](https://docs.cypress.io/dashboard/overview/runs-dashboard.html#) so I'm going to assume this is a bug or a feature request for something that may have been overlooked.

### Current behavior:
Once I've reached my recording limits for a month (on the free tier), I get this error:
```
It looks like this is your first time using Cypress: 3.2.0

[16:10:43]  Verifying Cypress can run /root/.cache/Cypress/3.2.0/Cypress [started]
[16:10:45]  Verifying Cypress can run /root/.cache/Cypress/3.2.0/Cypress [completed]

Opening Cypress...
You've exceeded the limit of private test recordings under your free plan this month. The limit is 500 private test recordings.

To continue recording tests this month you must upgrade your account. Please visit your billing to upgrade to another billing plan.

https://on.cypress.io/dashboard/organizations/<org_id>/billing
error Command failed with exit code 1.
```

### Desired behavior:

I'd prefer that you let my tests still run and execute and just print a warning that the tests aren't being recorded. That way I can continue to run the tests with `--record` in CI all month long and just take advantage of the recordings whenever I am within my limit for that month.

I can't update my CI scripts to know when I'm within the limit or when I'm not so I will always run the risk of getting failing CI runs because I might cross the limit threshold. The only safe thing would be for me to not ever record runs in CI, but I would prefer not to do that. I love your dashboard and I would love to take advantage of it as much as possible. 

I understand I'm on the free tier and I'm not exactly your target customer so I understand if you chose to stick with test failures as some way of pushing users to the paid tier. But I don't have the money for the paid tier on this small side project so I would be forced to stop using the dashboard all together. 

### Versions

Cypress 3.2.0

### Thanks in advance
",2019-04-24T16:36:03Z,2023-10-05T15:51:06Z,closed,23,"Cypress, usage of dark pattern in software, paid customers ","cypress run, gives error when ran out of trial limits, obstruction, forced action","Cypress, forced action, trick users buying paid products",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/OBOFoundry/OBOFoundry.github.io/issues/118,"Explore use of Disqus on pages: principles, ontologies",https://github.com/OBOFoundry/OBOFoundry.github.io/issues/118,"Continued from #5 
On the call we discussed the possibility of using disqus on these pages. See: 

[9/22/15 8:49:38 AM] Chris Mungall: https://disqus.com/
[9/22/15 8:50:07 AM] Chris Mungall: http://stackoverflow.com/questions/21446165/how-do-i-use-disqus-comments-in-github-pages-blog-markdown
",2015-09-22T16:30:16Z,2022-09-01T21:00:40Z,closed,10,"Disqus, usage of dark pattern in software, data harvester, privacy issue","Disqus, data collecting, unethical","Disqus, data collection, privacy issue",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/element-hq/element-web/issues/8380,redacted,https://github.com/element-hq/element-web/issues/8380,redacted,2019-02-02T20:00:50Z,2022-07-15T16:09:26Z,closed,1,"E2E UX, deceptive design practice, Riot",,deceptive design practice,DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/microsoft/TemplateStudio/issues/2901,DataGrid + UWP,https://github.com/microsoft/TemplateStudio/issues/2901,"I'm new to UWP, is it possible to have a menu control on a cell within a DataGrid; if so a simple example of the syntax would be grateful. Thank you.",2019-02-05T20:43:35Z,2022-06-25T00:05:03Z,closed,8,"UWP, DataGrid, deceptive design practice","menu control wthin DataGrid, code that could be potential dp","DataGrid, dark pattern in coding, deceptive design practice",DPs in design coding,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/markmur/markmurray.blog/issues/2,Create Blog “killing-ux-dark-patterns-with-chrome-extensions”,https://github.com/markmur/markmurray.blog/pull/2,Automatically generated by Netlify CMS,2019-02-26T21:53:50Z,2022-02-11T21:50:57Z,closed,0,"miscellaneous (Blog, Chrome extension, dark pattern detection)","Chrome extensions to remove dp, ",miscellaneous,miscellaneous,"Chrome extension, detection tool",,DPs used in software,dps used in software,,,
https://api.github.com/repos/mozilla-mobile/focus-android/issues/1949,"Pop-up issue with no possibility to hit ""back""",https://github.com/mozilla-mobile/focus-android/issues/1949,"via email convo with @antlam 

I've seen this mostly on websites that are ""shady"", like Sports live streaming websites.

- Essentially, the user is loading a web page they want, then the ""invasive ad"" takes over and they're on a web page they didn't ask to load. 
- Then they hit ""back"" in our UI but get caught in this loop that just reloads the ad (web page redirect). This is quite frustrating indeed, and I usually just tap the back button like crazy - which usually puts be back at web page where I got the live streaming link.
- Note: I'm unsure how much of this is a web-compat issue versus something we can do as the browser?",2017-12-07T14:15:51Z,2022-04-24T10:50:56Z,closed,11,"prevention of dark pattern in design, redirection loop","pop-up with no back button, redirection loop of the same webpage","redirection loop, pop-up, obstructiobn, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/julia-vscode/julia-vscode/issues/514,no easy opt out of telemetry,https://github.com/julia-vscode/julia-vscode/issues/514,"The telemetry dialogue does not provide a button ""I do not want to send telemetry"", the only thing you can do is to ignore the dialogue, which will pop up at every restart of VSCode, or go to the options and and change the value of `julia.enableTelemetry` to `false`. 
It took me 10 minutes to do figure that out, is annoying and gives a bad impression about the plugin's respect for user privacy (it is about actions not statements).

And btw, does the plugin send telemetry if you ignore the dialogue?",2018-06-15T07:31:06Z,2022-10-15T13:10:08Z,closed,36,"Telemetry, opt-in/out, plugins, obstruction","telemetry, opt-out, freeriding action","Telemetry, opt-in/out, obstruction",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/sparkle-project/Sparkle/issues/924,Don’t steal focus / use notifications to announce new updates,https://github.com/sparkle-project/Sparkle/issues/924,"Using notification popup provided by the OS may be a better way to notify about updates, especially for background apps which currently steal focus.

Last time I investigated that the problem was users can configure notifications as ""Banners"" or ""Alerts"", and I didn't see an API to check which one user has selected. This meant that we couldn't rely on using notification's buttons (to have an Install button like the macOS itself), since they're only visible in Alert mode.",2016-11-22T02:29:43Z,2022-06-13T06:17:39Z,closed,14,"App Store, usage of dark patttern in software, update notification","notifications for updates on background only apps, App Store, no easy way to dismiss","App Store, update notification, obstruction",DPs used in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/cerner/terra-framework/issues/491,[terra-abstract-modal] investigate closeOnOutsideClick,https://github.com/cerner/terra-framework/issues/491,"## Investigation

- per OCS and modals/dialogs generally, clicking outside (on the overlay) to close a traditional modal would never be recommended, but since Abstract-Modal is an elemental building block with features to support multiple concepts, need to investigate how the `closeOnOutsideClick` is being used, if needed, and implications of changing default value to `false`, so that special use cases could opt-in but not be provided as default.",2018-10-30T16:46:02Z,2021-10-11T22:03:08Z,closed,2,"deceptive design practice, X/cancel button","modals requiring X button or cancel, obstruction","modals, X/cancel button, obstruction",DPs examples/definitions,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/gitcoinco/web/issues/4603,Dark patterns,https://github.com/gitcoinco/web/issues/4603,"As a user, requiring to enable a checkbox for an action to not occur is misleading and is considered a [dark pattern](https://en.wikipedia.org/wiki/Dark_pattern) (it has confused me a number of times)

<img width=""619"" alt=""Screen Shot 2019-06-09 at 9 48 48 PM"" src=""https://user-images.githubusercontent.com/168240/59173159-732b7700-8b00-11e9-8195-21cbd8c9c99f.png"">

proposing that the checkboxes be inverted so that checking to enable means that you do receive the selected emails.",2019-06-10T04:55:14Z,2020-11-30T00:19:16Z,closed,5,"deceptive design practice, inverted checkboxes, email preference options","example, checking boxes to stop some features, hidden info, sneaking","inverted checkbooxes, hidden info, deceptive design practices",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/element-hq/element-web/issues/10093,Prompt to accept identity server policies before inviting them to a room,https://github.com/element-hq/element-web/issues/10093,"Prompt for accepting IS terms before inviting a user by email address (if you haven't already agreed to that IS's policies)

There's another beat on which we need to capture accepting the IS's policies - before associating a new email address with your account _and choosing to publish that association on the IS - but that's tracked in https://github.com/vector-im/riot-web/issues/10159#issuecomment-505480951",2019-06-18T11:04:28Z,2021-03-05T10:18:41Z,closed,11,"UX deisgn, prevention of dark pattern in software, privacy terms, forced action","forced to accept IS policies, enhancing features","UI/UX design, forced action, privacy issue, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/postmanlabs/postman-app-support/issues/7654,Ask for workspace before importing collection from Run in Postman button,https://github.com/postmanlabs/postman-app-support/issues/7654,"<!--
Please read through the [guidelines](https://github.com/postmanlabs/postman-app-support#guidelines-for-reporting-issues) before creating a new issue.
-->

**Is your feature request related to a problem? Please describe.**
Currently for users on the free plan, if they import collections with requests that may exceed the sharing limit, there is no warning and the older Collections just get archived.

_References:_
* https://www.getpostman.com/pricing
* https://learning.getpostman.com/docs/postman/launching-postman/collaboration/#usage-limit-for-free-users

**Describe the solution you'd like**
User should be warned indicating that the Collection that they are importing will put them over the limit and will trigger archiving of collections.

At this stage, the UI may also provide a way to select one of the Personal workspaces - so that the user may continue to import into their personal workspace.

**Describe alternatives you've considered**
None available.

**Additional context**
Logged by Postman.
I thought of this after one of our users found the current flow confusing as every time they re-imported their archived collections, the older ones would get re-archived.",2019-11-17T20:30:21Z,2021-02-04T05:43:23Z,closed,9,"Postman, upgrade, paid version, deceptive design practice","upgrade to recover lost data, forced action, emotional manipulation","Postman, upgrade for lost data, forced action, deceptive design practice",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/wireapp/wire-webapp/issues/5754,Blank Log-In page on Firefox,https://github.com/wireapp/wire-webapp/issues/5754,*Nevermind. Bugs are not addressed and getting worse so giving up on Wire. The promise to never leave the Personal branch behind in favor of an Enterprise product has been broken like every other project that says that. My fault for falling for it again. The Personal account sign up has even been buried on the website using dark patterns so people likely won't even know it's an option were they willing to put up with the buggy mess.,2019-02-07T18:03:59Z,2020-08-05T21:33:31Z,closed,12,"Firefox, blank page, promote enterprise account, hard to see personal account, visual interference ",hidden feature to sign up with personal account,"Firefox, difficult signup with personal account, sneaking, interface interference",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/klaro-org/klaro-js/issues/123,Possibility to accept all cookies and hide decline in notice,https://github.com/klaro-org/klaro-js/pull/123,"Added option to accept all cookies at once.
Added option to replace ""decline all"" with open modal.
Added privacy policy link to notice",2019-11-18T09:03:09Z,2020-08-14T10:59:26Z,closed,19,"privacy policy consent, prevention of dark pattern in software, regulation ","cookies, 'accept all' as an example, ways to avoid dp","cookie consent, privacy issue, avoid dark pattern, regulation","DPs prevention in software, DPs examples/definitions, DPs related regulation ",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/buildkite/feedback/issues/199,How to delete an account?,https://github.com/buildkite/feedback/issues/199,"Hi, how do i delete my account? Can't find anything in Personal Settings.
",2016-10-12T11:00:42Z,2020-07-01T05:28:58Z,closed,12,"Buildkite, usage of dark pattern in software, obstructions","no option to delete ac without emailing, interface interference ","Buildkite, account deletion, obstruction",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/datatogether/reading_datatogether/issues/73,Moderation Readings,https://github.com/datatogether/reading_datatogether/issues/73,"To be facilitated by @frijol and @RangerMauve. Schedule for 2020 semester here: https://github.com/datatogether/reading_datatogether/issues/71

**This topic covers factors that impact the content that we see. How do platforms balance freedom of expression versus consent to avoid offensive content, navigate algorithmic versus human moderation and curation, or incentivize different types of interaction? What are downstream effects of these choices?**

We use these issues to solicit additional reading suggestions from the community. **Please add suggestions below!** Ultimately, the facilitators will choose the reading selections for their session.

Here are some readings that were suggested for this topic in the [Data Together Annual Meeting](https://docs.google.com/document/d/1-uPPavAgzS0tp9seD4ekLVtAPp54mvkWbD0eK6jxK08/edit#heading=h.hfcp3ei3qrqn):

* Short piece on moderation for Something Awful: https://www.theverge.com/2019/6/26/18744264/something-awful-youtube-moderation-rich-kyanka-lgbtq 
* Moderation for Facebook: https://www.theverge.com/2019/6/19/18681845/facebook-moderator-interviews-video-trauma-ptsd-cognizant-tampa
* Instructables, do they have any writing about their moderation style vs e.g. hackaday for the same purpose?
* ""Free speech"" both real and as a framing device

--
Maybe goes in here: Is Open source a gift economy or a barter system?

* How do economic forces shape what technical resources are  built & shared. The structural advantages of being a maintainer?
* Incentives for opening. Docker as an interesting use case
* Maybe “token economy” book https://www.goodreads.com/book/show/48219912-token-economy
* This thread on SSB including:
* Christian Bundy: https://viewer.scuttlebot.io/%256a2FQ4J1aCwVGyU2ROQPXfsyrZQhsa2tQ9nJYg262Qk%3D.sha256
* Substack tweet exchange: https://viewer.scuttlebot.io/%25BuTtZihbQ1Ffn5bV20E8oBic2OvzMzFkdGvlxJJhmIQ%3D.sha256
* Kelsey: https://viewer.scuttlebot.io/%25LtCFpMuVEmnPHwR24R%2Fye67mhUepIN8dnor1CXfYveA%3D.sha256 and https://viewer.scuttlebot.io/%25Apkub6c3nqnkGFXy9dYD9z5iOVNY%2BkfJa%2FUeVnX9YF4%3D.sha256 
* Rico: https://onezero.medium.com/the-internet-relies-on-people-working-for-free-a79104a68bcc


--
Maybe goes in here: UX and the dweb

* Usability of dweb tech and applications
* Dark patterns of tech: https://www.darkpatterns.org/
* Human Centred Design Considered Harmful: https://www.jussipasanen.com/human-centred-design-considered-harmful/?utm_source=hackernewsletter&utm_medium=email&utm_term=design

",2019-10-21T18:31:49Z,2020-05-28T18:33:47Z,closed,5,miscellaneous (documentations/resources of dark patterns example),definitions,documentation ,Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/robinparisi/tingle/issues/48,Suggestion: Back button closes modal (at least on mobiles),https://github.com/robinparisi/tingle/issues/48,"First off, thanks for this great script.

It would be nice if the modal closed upon clicking the back button on a mobile device.

This is something that's always bugged me about modals (probably more of a nag on Android devices). When I first took a look at your demo, then opened the modal, I reflexively clicked the back button to close it and ended up leaving your site. Yes, I see the close button. Yes, I've dealt with modals a million times, but on a mobile device automatic reflexes kick in and it's unavoidable. I doubt the regular website visitor handles this much different.

I've seen a few rare number of modal scripts tackle this, typically by having to juggle the browser's back and forward history. I found your script from vanillalist and none of the eight pure javascript modals they have listed implement this.

Some discussion on this topic:
http://www.mylearning.in/2015/06/close-modal-pop-up-on-back-button.html
http://ux.stackexchange.com/questions/53163/good-idea-to-have-back-button-close-a-modal-window
https://gist.github.com/thedamon/9276193
https://forum.ionicframework.com/t/closing-modal-with-android-back-button/3207/20

Thanks.",2017-03-09T19:39:49Z,2020-04-28T17:51:14Z,closed,4,"usage & prevention of dark pattern, override back button","resolving how to close modal, example that override coud be dp","modal, override back button, UI/UX design, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/camunda/camunda-modeler/issues/1586,Privacy Preferences,https://github.com/camunda/camunda-modeler/pull/1586,Closes #1543,2019-11-14T13:53:19Z,2020-03-06T09:26:01Z,closed,3,"usage & prevention of dark pattern in software, preselection, preselected checkboxes, user privacy preferences","prechecked boxes for privacy, interfacee interfrence - preselection","privacy issue, preselction, avoid dark patterns","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/dependabot/feedback/issues/216,Q: how to disable dependabot for a repository?,https://github.com/dependabot/feedback/issues/216,"I've [decided to not use dependabot](https://github.com/php-coder/mystamps/commit/dfebf4d9c05a6f0b0628b89532ad9f35810a74da) any more but I couldn't find in the UI how to turn it off for my repository?

Thanks!",2018-10-16T20:23:54Z,2020-05-13T12:43:49Z,closed,9,"GitHub, dependabot disable, usage of dark pattern in software, obstruction","disabling dependabot, auto opt-in, preselection ","GitHub, dependabot disable, opt-in/out, preselection, obstruction",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/fog/fog/issues/2525,Digital Ocean API is not told to scrub (securely delete) VM on destroy,https://github.com/fog/fog/issues/2525,"Major security issue: the Digital Ocean API has a parameter on the destroy call to securely scrub the root blockdev on VM destroy, preventing future customers from reading the data left on disk by your VM.

This is surely a digitalocean security issue, but they're passing it on to users by making it a parameter - rather shitty of them.  This is documented in their API at https://cloud.digitalocean.com/api_access - see ""scrub_data"".

Fog does not pass this parameter, leaving Fog-destroyed VMs vulnerable to later customers stealing the data contained on them.
",2013-12-30T03:42:02Z,2020-10-07T13:15:19Z,closed,56,"Digital Ocean API, usage of dark pattern, user-hostile defaults, preselection","Digital Ocean API, passes info from one user to another without warning, privacy breaching, unethical","Digital Ocean API, privacy issue, default feature, preselection",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/mozilla/doh-rollout/issues/125,Get rid of dark patterns,https://github.com/mozilla/doh-rollout/issues/125,"The average user has no idea what ""DNS"" or ""Cloudflare"" are, nor the privacy impact of this setting.

The opt-out is labelled ""disable protection,"" which seemingly forces them into uninformed consent.  If I were a non-technical user, I would have no clue that clicking ""OK, got it"" means that Cloudflare, a company unrelated to Mozilla, now gets to know about every web site I visit.

Further, there is no link to Cloudflare's privacy policy or the Mozilla/Cloudflare [TRR agreement](https://wiki.mozilla.org/Security/DOH-resolver-policy).  Firefox's [Cloud Services Agreement](https://www.mozilla.org/en-US/about/legal/terms/services/) makes no mention of DoH.  The user should be prompted to read the resolver policy before ""agreeing"" to it.

May I suggest better text? Something like:

> Your privacy matters.  When you type a URL into Firefox, the Domain Name Service (DNS) is used to find the network address associated with the domain name.  Your DNS operator—normally your internet service provider or your company's network administrator—is able to see what websites you are visiting. If you enable this setting, Firefox will securely route your DNS requests whenever possible to a service provided by Cloudflare, instead of the service provided by your network operator, which prevents them from snooping on these requests.  Cloudflare's agreement with Mozilla (the maker of Firefox) about what they can do with your data can be found [here](https://wiki.mozilla.org/Security/DOH-resolver-policy).
> 
> Yes, use Cloudflare instead of my network provider
> No, continue to trust my existing network provider
",2019-09-30T21:26:13Z,2019-10-08T20:25:34Z,closed,1,"Cloudflare, DNS (domain name service), prevention of dark pattern, privacy policy","Cloudfare/DNS in Firefox, unethical privacy setting, lack of info for non-technical users","Cloudfare/DNS, Firefox, privacy issue, avoid dark pattern",DPs prevention in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/dhowe/spectre/issues/174,Design for post-experience pages,https://github.com/dhowe/spectre/issues/174,,2019-05-27T22:54:48Z,2020-02-28T18:12:12Z,closed,23,"Spectre, usage of dark pattern in software, dark ads task, TOS (term of service) in dark pattern","design enhancement, gamification","Spectre, UI/UX design, ads, terms and conditions",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mozilla-extensions/firefox-voice/issues/591,"Negative feedback ""Submit"" button resets ""Doorhanger""",https://github.com/mozilla-extensions/firefox-voice/issues/591,"### Prerequisites:
Mic permissions are enabled.
A command is made beforehand.

### STR:
1. Use the shortcut or click on the mic icon from the browser toolbar.
2. Click on the sad emoticon from the ""How was your last experience"" section.
3. Once the ""What went wrong?"" section is displayed, click on the green ""Submit"" button.

### Expected result:
A ""Thanks for your feedback"" message is displayed.

### Actual result:
The ""Doorhanger"" resets and displays the ""Listening"" state.

### Notes:
Reproduced on Mac 10.14.6 and Win10x64 with Firefox Nightly 72.0a1 (64-bit).
If text is written in the text box, then the ""Submit"" button is clicked, a ""Thanks for your feedback"" message is displayed. (2nd gif)

![1](https://user-images.githubusercontent.com/54401091/69147940-d66ffb00-0adb-11ea-9b59-9b3718e0fd52.gif)

![9](https://user-images.githubusercontent.com/54401091/69548731-8b089180-0fa0-11ea-97a9-d2b1df518a72.gif)

",2019-11-19T12:50:36Z,2019-12-12T12:27:36Z,closed,6,"Mozilla, deceptive design practice, rating system, forcedaction?","after hitting ""submit"" Wiki resets for ""doorhanger"", nagging/forced action for feedback","Mozilla, feedback, deceptive design practice, forced action",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/liferay-design/liferay.design/issues/543,"Closing action not available for the ""join us"" banner ",https://github.com/liferay-design/liferay.design/issues/543,"**Describe the bug**
I can't close the ""join us"" banner. 

**Steps to Reproduce**
1. Go to 'https://liferay.design/'

**Screenshots**
![image](https://user-images.githubusercontent.com/21216422/65015389-b37d6b00-d921-11e9-81ee-0fd134e8f773.png)

**Desktop**
 - OS: macOS Mojave 10.14.6 
 - Browser: Chrome  
 - Version: 76.0.3809.132 

**Reasoning**
It's ok to steal space to the page but at least let users recover that space. 

",2019-09-17T06:15:10Z,2019-09-18T14:01:54Z,closed,4,"Liferay.Design, usage & prevention of dark pattern in software, hidden close button, visual interference",no exit for modal,"Literacy.Design, modal, interface interference, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/jdm-contrib/jdm/issues/346,"JHM / JSM - ""JustHelpMe"" / ""JustSupportMe""?",https://github.com/jdm-contrib/jdm/issues/346,"I love the UI of JDM and how accessible all the info is, and I thought about how it might be applied to other ""dark pattern""-ish areas.

I know there are others doing this idea, but what about finding the best solution for support from a helpdesk? Providing/fetching/pointing to their phone number, email address, chat links, etc., and, if needed, grouped by department within the company. And maybe the most recommended option to use, what people have had the most success with, pros and cons of each, who uses bots and copy/paste messages to answer problems, etc.?

I suggest this because sometimes it's just as hard to find real people to help with an issue as it is to figure out how to delete an account. Let me know what you think!",2019-09-24T01:33:58Z,2019-09-30T02:33:36Z,closed,3,"miscellaneous (UI of JDM, JHM - justhelpme, JSM - justsupportme)",JDM/JSM tp reduce dp usage,"UI/UX design, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/fraction/oasis/issues/28,Improve navigation (sidebar?),https://github.com/fraction/oasis/issues/28,"**What version of this package are you using?** 2.9.7

**What problem do you want to solve?** The top navbar is simple, but not very ergonomic (especially on small screens). I think we should improve it, but I'm not sure how.

**What do you think is the correct solution to this problem?** I think a Patchwork-style sidebar is reasonable on desktop, but I'm not sure what to do on mobile. Here's a very rough sketch that wouldn't take very long to implement:

![Screenshot from 2019-12-16 11-48-02](https://user-images.githubusercontent.com/537700/70937945-1acaba00-1ffa-11ea-95c2-645e643c6517.png)

I'm inspired to make a Shellogram-style sidebar that's more interactive, but I'm in some technical debt that would make that difficult right now. I should probably just repay that debt. My mistake was implementing a tree-like dependency graph where the most often-used tools (database connection, main template, etc) are leaf nodes, when *really* I think the leaf nodes should be the code that's used the least.

## Now

![index](https://user-images.githubusercontent.com/537700/70938426-02a76a80-1ffb-11ea-9be7-3b1b32d7f362.png)

## Maybe future?

![maybe-future](https://user-images.githubusercontent.com/537700/70938671-76e20e00-1ffb-11ea-9560-99b5a73d0d79.png)

**Are you willing to submit a pull request to implement this change?** Yep.
",2019-12-16T19:59:17Z,2020-01-30T01:29:19Z,closed,15,"miscellaneous (prevetion of dark pattern, FOMO - fear of missing out)",example to avoid dp,"avoid dark pattern, fake scarcity",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/pixelfed/pixelfed/issues/267,Refactor post presenter,https://github.com/pixelfed/pixelfed/issues/267,"- The buttons and indicators are not readily visible.
- Different aspect ratios cause a jarring reflow of the container.
- Galleries auto-advance in a slideshow, which does not allow viewing one photo for an extended period of time.
- Galleries only show the first photo in timelines.

Possible approaches:
- Use a square container for album posts of differing aspect ratio, and apply `object-fit: contain` (similar to #244)
- Filmstrip view instead of a slideshow

For controls:
- Either add a background or shadow to the overlay controls, or possibly move them outside the image container?",2018-06-14T09:27:39Z,2019-10-16T04:15:57Z,closed,3,"usage of dark pattern in social media, advertisement, IG/FB image viewers, taller media, more screen space",,"ads, social media, UI/UX design",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/privacytools/privacytools.io/issues/741,✨ Feature Suggestion | Darkpatterns Category,https://github.com/privacytools/privacytools.io/issues/741,"To raise public awareness make a seperate page with several dark patterns explainded that are being used by survcap companies to manipulate users and steer behavior towards desirable.

## Description:

e.g. [on twitter](https://twitter.com/darkpatterns)
(Speaking of twitter. Signing up with a non survcap email (e.g. tuta) is pretty much impossible (works flawlessly on mastodon and github though.)

Could/should also include what websites use which kind of (re)CAPTCHA (version) and it's dependencies. This also communicates the power position of **s**urv**ca**p cor**ps** (SCAPS) Maybe we can graph it using [d3js](https://github.com/d3/d3) (it's also open-source).
",2019-01-26T02:34:14Z,2019-08-15T00:54:13Z,closed,6,dark pattern examples (usage in survcap companies),"SurveillanceCapitalism companies, awareness for and examples ",SurveillanceCapitalism companies,DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/stacks-archive/app-mining/issues/151,Unsigned native apps,https://github.com/stacks-archive/app-mining/issues/151,"As @larrysalibra talked about [App Mining NIL proposals](https://forum.blockstack.org/t/august-2019-app-mining-nil-proposals-and-policy-clarifications):

> We’ve recently seen a number of native apps for both macOS and Windows. Most of these apps are unsigned by the developer and will not install in default configurations of both operating systems unless the user overrides the security settings to allow installation of software from unknown developers. This is dark pattern behavior we don’t want to encourage because it unsafe for users and unsafe for our reviewers.
> 
> Policy: Apps must be installable using the default security settings on a fresh install of the targeted operating system. Apps that require overriding default operating system security settings will be ineligible.

Please help me to understand these:

- Why these are safety issues?
- Does Blockstack want to play the rule of closed app stores? For example, like Google Play that controls the app identities and how they work or give the app creator what it provides the users? An open and private world with a safe identity to let users choose what they want? Or as we call it here CantBeEvil.
- What part of buying a license will help safety or how it is aligned with values of Blockchain, decentralisation or privacy?
- Who controls the web safety? We have encryption and SSL, and they are there for Desktop apps too, so why give the OS providers ransom for a sign?

These messages are mostly not a safety issue, and they are primarily a Buy-A-License from OS provider issue. 
We have BlackHole, and it has Windows, and Mac clients and both of them have security messages Larry talked about. We did try to solve them before releasing apps as no one wants to give their users an ugly welcome, but some problems prevented us:
Microsoft and Apple will sell you the license if you register the app completely with them. Otherwise, they show you the message even if there is no security flaw with the app.
Take [Norton case](https://community.norton.com/en/forums/blockstackorg-dapps-and-norton), they flagged BH without any security reason, and a user asked them, and they removed it quickly.

We had emails from some users that told us about this, and almost all of them knew the situation and just wanted to let us know. As we targeted professional users, that was and still not an issue for us, and the user base is growing beautifully for an app with a need to install, and more people are talking about it, eg [today post](https://www.densediscovery.com/issues/52).
If this wants to go with the proposal, either we should leave our privacy behind and go with OS providers (who are not good famous of privacy or even safety) or leave the native apps behind as there is no control on the web apps.

My thought is that it is an OS issue, not Blockstack or NIL as it is not related to privacy, security, identity, storage or even encryption. I would be happy to know more about how we can solve this and provide a better experience or also there is a way to prevent these messages.

P.S. Please take a look at [VirusTotal report](https://www.virustotal.com/gui/file/99fe70d6e53ac718a2e51c730becb36494a7fd187a1d632e25daa0868a34c9ef/detection) for a proper safety check.",2019-09-03T15:40:32Z,2019-11-05T17:35:46Z,closed,3,miscellaneous (overrides the security settings to allow installation of software from unknown developers),concern and solutions for native apps by unknown developers that needs overriding security settings for installation,miscellaneous,miscellaneous,overrides the security settings to allow installation of software from unknown developers,,DPs used in software,dps used in software,,,
https://api.github.com/repos/slatex/LaTeXML-Plugin-sTeX/issues/123,re-pass test suite,https://github.com/slatex/LaTeXML-Plugin-sTeX/pull/123,"Revived the 00_cds.t with this PR.

Question for @tkw1536 : why did the locator details change? 
 * the `anonymous_string` change I understand, and is harmless
 * the change in CMP1's `line;column` numbers seems more important, and may be inaccurate -- i haven't had the time to stare it down w.r.t the tex source.",2018-11-24T04:15:00Z,2019-09-18T11:20:14Z,closed,7,miscellaneous,,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/FabricMC/fabric/issues/341,Fabric particles v1,https://github.com/FabricMC/fabric/pull/341,"This is an alternative approach to implementing the particles API. The forward facing interface is a little simpler and registering particles that use a custom sprite supplier is identical to vanilla.

Creating a particle type (client and server):
```
	public static final DefaultParticleType SIMPLE_TEST_PARTICLE = FabricParticleTypes.simple();
	public static final DefaultParticleType CUSTOM_TEST_PARTICLE = FabricParticleTypes.simple();

    @Override
    public void onInitialize() {
        Registry.register(Registry.PARTICLE_TYPE, new Identifier(""testmod"", ""simple""), SIMPLE_TEST_PARTICLE);
        Registry.register(Registry.PARTICLE_TYPE, new Identifier(""testmod"", ""custom""), CUSTOM_TEST_PARTICLE);
    }
```

Registering a particle factory (client):
```
	@Override
	public void onInitializeClient() {
		ParticleFactoryRegistry.getInstance().register(SIMPLE_TEST_PARTICLE, SimpleTestParticle::new);
		ParticleFactoryRegistry.getInstance().register(CUSTOM_TEST_PARTICLE, CustomTestParticle.Factory::new);
	}
```

The particle classes:
```
	@Environment(EnvType.CLIENT)
	static class SimpleTestParticle extends SpriteBillboardParticle {

		public SimpleTestParticle(ParticleEffect effect, World world, double x, double y, double z, double velX, double velY, double velZ) {
			super(world, x, y, z, velX, velY, velZ);

			setSprite(MinecraftClient.getInstance().getItemRenderer().getModels().getSprite(Items.BARRIER));
		}

		@Override
		public ParticleTextureSheet getType() {
			return ParticleTextureSheet.PARTICLE_SHEET_TRANSLUCENT;
		}
	}

	@Environment(EnvType.CLIENT)
	static class CustomTestParticle extends AnimatedParticle {

		protected CustomTestParticle(World world, double x, double y, double z, SpriteProvider sprites) {
			super(world, x, y, z, sprites, 1);

			setSprite(sprites.getSprite(world.random));
		}

		@Environment(EnvType.CLIENT)
		public static class Factory implements ParticleFactory<DefaultParticleType> {

			private final FabricSpriteProvider sprites;

			public Factory(FabricSpriteProvider sprites) {
				this.sprites = sprites;
			}

			@Override
			public Particle createParticle(DefaultParticleType type, World world, double x, double y, double z, double vX, double vY, double vZ) {
			   return new CustomTestParticle(world, x, y, z, sprites);
			}
		}
	}
```

<s>Among these are also some helper. `ParticleUtils` provides some methods to spawn a particle that accept position and velocity as `Vec3d`.</s>",2019-08-15T10:46:00Z,2019-09-29T17:53:37Z,closed,40,miscellaneous,discussion of dark and light pattern,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/atom/atom/issues/12281,Add telemetry consent setting,https://github.com/atom/atom/pull/12281,"New telemetry consent setting that will be used by metrics and exception-reporter to determine whether to collect anonymous usage statistics, exception reports etc.

All parts are required for this to work correctly;
- https://github.com/atom/atom/pull/12281
- https://github.com/atom/metrics/pull/66
- https://github.com/atom/exception-reporting/pull/20
- https://github.com/atom/about/pull/37
- https://github.com/atom/welcome/pull/48
",2016-08-02T05:04:57Z,2019-11-28T10:34:41Z,closed,35,"Telemetry, Atom, prevention of dark pattern in software","confusing wording, difficult to understand, dp- distraction","Teletmetry, Atom, trick wording, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/forem/forem/issues/266,[Bad UIX] Remove important links from the footer,https://github.com/forem/forem/issues/266,"![image](https://user-images.githubusercontent.com/581458/43758250-3031146e-9a24-11e8-874c-5517d6ca8df0.png)
Please stop that, remove the important links from the footer if you already know that pages have infinite scrolling.",2018-08-07T06:28:49Z,2019-09-24T07:24:41Z,closed,20,"Bad UI design, usage & prevention of dark patterns, infinite scrolling","infinite scroll, footer and sidebar replicated same things","infinite scroll, UI/UX design, avoid dark patterns","DPs prevention in software, DPs examples/definitions",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/webcompat/web-bugs/issues/35002,www.reddit.com - site is not usable,https://github.com/webcompat/web-bugs/issues/35002,"<!-- @browser: Firefox Mobile 68.0 -->
<!-- @ua_header: Mozilla/5.0 (Android 7.0; Mobile; rv:68.0) Gecko/68.0 Firefox/68.0 -->
<!-- @reported_with:  -->
<!-- @extra_labels: browser-fenix -->

**URL**: https://www.reddit.com/r/aws/comments/bv70k8/aurora_postgres_disastrous_experience/

**Browser / Version**: Firefox Mobile 68.0
**Operating System**: Android 7.0
**Tested Another Browser**: No

**Problem type**: Site is not usable
**Description**: Can't press button to ""view in browser"" or ""view in app""
**Steps to Reproduce**:
This is honestly a dark-pattern UX issue, but I can't press the (stupid) button to ""view page in browser"" -- which happens to display a Chrome icon. I am trying to ween myself from dopamine-trigger addiction cycle websites like Reddit, so have uninstalled the Reddit app. In any case, clicking the ""view in app"" button doesn't ""trigger"" anything either.

<details>
<summary>Browser Configuration</summary>
<ul>
  <li>None</li>
</ul>

</details>

_From [webcompat.com](https://webcompat.com/) with ❤️_",2019-07-10T04:43:43Z,2019-07-19T14:43:44Z,closed,2,"Reddit, usage of dark pattern in software, disabled click button ",button not working,"Reddit, disabled button, deceptive design practice",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/syncthing/syncthing/issues/4977,Disable rescan button while scanning instead of hiding it,https://github.com/syncthing/syncthing/issues/4977,"A few times now, I've clicked the wrong button for a folder because it switched to/from the Scanning/Syncing state, hiding/showing the Rescan button and causing all the buttons to the left to shift over. It feels like a little bit of a dark pattern (though obviously not intentionally malicious). It makes sense to me to set the Disabled attribute on the button rather than hiding it entirely.

![rescan-disabled](https://user-images.githubusercontent.com/28599170/40779958-79c9bfc6-649c-11e8-8e02-908544a7c6f0.png)
",2018-05-31T11:35:41Z,2019-06-02T07:02:35Z,closed,2,"bad UI design, deceptive design practice, button positions changing causing mistaked clicked",more of design suggestion,"UI/UX design, deceptive design practice, misleading",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/canonical/lxd/issues/6096,LXD config non-maintainable when daemon wontstart,https://github.com/canonical/lxd/issues/6096,"<!--
Github issues are used for bug reports. For support questions, please use [our forum](https://discuss.linuxcontainers.org).

Please fill the template below as it will greatly help us track down your issue and reproduce it on our side.  
Feel free to remove anything which doesn't apply to you and add more information where it makes sense.
-->

# Required information

 * Distribution: Ubuntu bionic
 * Distribution version: 18.04.3 LTS
 * The output of ""lxc info"" or if that fails:
   * Kernel version: 5.0.0-23-lowlatency
   * LXC version: 
   * LXD version: 3.0.3
   * Storage backend in use: ZFS

# Issue description

When daemon encounters a storage error it try to be smart, but gone completely unconfigurable.
History:
* Host installed as Root-on-ZFS, with separate `hostname-zroot\lxd` dataset for LXD only.
* Initially LXD configured to use this dataset, inside host zpool
* Host migrated from two zpools (`hostname-zroot` and `hostname-srv`) to one, named `hostname`
* Then, LXD daemon wont nor start nor configure

E.g.: another etc'less tool I use is `targetcli`. It has issues too after pool moving, but it start and keep himself configurable. More then, it support export and import config, so issue fixed remotely with simple `sed`

# Steps to reproduce

 1. Create any storage pool
 2. Stop LXD
 3. Rename or move pool by any manner, keeping data safe and accessible
 4. Start LXD

# Information to attach

 - [ ] Any relevant kernel output (`dmesg`)
 - [ ] Container log (`lxc info NAME --show-log`)
 - [ ] Container configuration (`lxc config show NAME --expanded`)
 - [x] Main daemon log (at /var/log/lxd/lxd.log or /var/snap/lxd/common/lxd/logs/lxd.log)
> t=2019-08-17T21:34:58+0300 lvl=info msg=""Initializing storage pools""
> t=2019-08-17T21:34:58+0300 lvl=eror msg=""Failed to start the daemon: ZFS storage pool \""hostname-zroot/lxd\"" could not be imported: cannot import 'hostname-zroot': no such pool available\n""
 - [ ] Output of the client with --debug
 - [ ] Output of the daemon with --debug (alternatively output of `lxc monitor` while reproducing the issue)
",2019-08-17T19:11:04Z,2019-08-18T08:47:25Z,closed,2,"usage of dark pattern, non-editable configuration",,"non-editable configuration, deceptive design practice",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/netblue30/firejail/issues/2895,leave Github,https://github.com/netblue30/firejail/issues/2895,"# Abandon Github

Firejail caters for security enthusiasts, and yet the development platform is hosted by Microsoft -- a privacy abuser.  To improve the credibility of the project and attract privacy-respecting developers, please consider moving away from Github.

## Privacy problems with Microsoft Github

1. MS feeds other privacy abusers:
   1. (2012) MS spent $35 million on Facebook advertisements, making it the third highest financial supporter of a notorious privacy abuser that year.
   1. Github uses Amazon AWS which triggers several privacy and ethical problems:
      1. Amazon [paid $195k](http://cal-access.sos.ca.gov/Campaign/Committees/Detail.aspx?id=1401518&view=late1&session=2017) to [fight privacy in CA](https://arstechnica.com/tech-policy/2018/04/facebook-donated-200000-to-kill-a-privacy-law-but-now-its-backtracking/).
      1. Amazon supported CISA.
      1. Amazon is making an astronomical investment in facial recognition.
      1. Amazon uses FedEx (an NRA-supporting ALEC member who feeds republican warchests via ALEC and NRA [republican policy is detrimental to individual privacy]).
      1. Amazon distributes NRAtv which promotes a privacy-hostile political party and the resulting policies.  Also sells the Trump line of suits in their webshop.
      1. Amazon spent $30 million and ranked in the top 5 promoters of Facebook ads in 2012 (thus substantially feeding a privacy abuser).
      1. Amazon supplies AWS to Palantir, a database firm that exploits social media to [facilitate](https://www.govtech.com/biz/Documents-Reveal-ICE-Used-Palantir-for-Deportations.html) ICE and CBP to enforce Trump's inhumane *zero tolerance* immigration policy that entails child-parent separation.  Palantir was also co-founded by a notorious scumbag (Peter Thiel).
      1. Amazon [supplies](https://www.seattletimes.com/business/amazon-employees-demand-company-cut-ties-with-ice/) facial recognition to law enforcement who use it to abuse civil liberties.
      1. Amazon drug tests its employees, thus intruding on their privacy outside the workplace and also harming their healthcare.
      1. Amazon runs an extreme sweatshop that greatly diminishes quality of life.  The consequential mental health crisis is [evidenced](https://gizmodo.com/report-amazon-warehouses-called-911-for-mental-health-1833220938) by 189 calls from Amazon warehouses to 911 in five years.
      1. Amazon was caught using dark money to finance the climate denial movement.
1. Github is Tor-hostile [according to Tor project](https://trac.torproject.org/projects/tor/wiki/org/doc/ListOfServicesBlockingTor#ComputingTechnical).  GH has started forcing Tor users through an extra email verification step that effectively discourages bug reports:  ![github-tor_hostility](https://user-images.githubusercontent.com/21023035/61580062-10fd6300-aafd-11e9-8bf2-64faddf63760.png)
1. MS is a PRISM corporation prone to mass surveillance
1. MS lobbies for privacy-hostile policy:
   1. MS supported CISPA and CISA unwarranted information exchange bills, and CISA passed.
   1. (2018) MS [paid](http://cal-access.sos.ca.gov/Campaign/Committees/Detail.aspx?id=1401518&view=late1&session=2017) $195k to [fight privacy in CA](https://arstechnica.com/tech-policy/2018/04/facebook-donated-200000-to-kill-a-privacy-law-but-now-its-backtracking/)
1. MS supplies Bing search service which gives high rankings to [privacy-abusing](https://github.com/privacytoolsIO/privacytools.io/issues/374#issuecomment-460077544) CloudFlare websites.
1. MS supplies hotmail.com email service, which uses vigilante extremist org *Spamhaus* to force residential internet users to share all their e-mail metadata and payloads with a corporate third-party.
1. MS drug tests its employees, thus intruding on their privacy outside the workplace.
1. MS products (Office in particular) violate the GDPR
1. MS was caught financing a facial recognition project for the Israeli military to use against the Palestinian people they are oppressing.

## Alternatives

1. self-hosting (Gogs, Gitea, Gitlab, etc.)
   1. (+) avoids the ""shake-up"" problem of shrinking the community each time the project moves (there is no risk that the privacy factors would later take a negative turn).
1. Bitbucket
   1. (-) dodgy j/s up the yin yang that [clusterfucks uMatrix](https://github.com/privacytoolsIO/privacytools.io/issues/843#issuecomment-483830547)
   1. (-) has some relationship with Netlify, who uses AWS
   1. (-) non-free software?
1. Launchpad
1. [Gitlab](https://gitlab.com) (would be a poor choice)
   1. (-) Hostile treatment of Tor users trying to register.
   1. (-) Hostile treatment of new users who attempt to register with a `@spamgourmet.com` forwarding email address to track spam and to protect their more sensitive internal email address.
   1. (-) CAPTCHAs Tor users even *after* they've established an account and have proven to be a non-spammer.
      1. (-) CAPTCHAs break robots and robots are not necessarily malicious.  E.g. I could have had a robot correcting a widespread misspelling error in all my posts.
      1. (-) CAPTCHAs put humans to work for machines when it is machines that should work for humans.
      1. (-) CAPTCHAs are defeated.  Spammers find it economical to use third-world sweat shop labor for CAPTCHAs while legitimate users have this burden of broken CAPTCHAs.
      1. (-) The CAPTCHA puzzle is sourced from Google.  So Google is likely getting compensated in some way and Google is likely also recording IP address, browser print, and the page the CAPTCHA is served to in order to add to someones tracking info.
      1. (-) Google's CAPTCHA often forces users to run non-free Javascript.
      1. (-) The puzzle is often broken.  This amounts to a denial of service:
![gitlab_google_recaptcha](https://user-images.githubusercontent.com/18015852/51769530-9d494300-20e3-11e9-9830-1610b3ae9059.png)
1. notabug.org (""NAB"") ([privacy policy](https://notabug.org/tos#Privacy)).  Based on a liberated fork of gogs.
   1. (+) [supports Tor](https://notabug.org/tor) (although the *onion* web UI is currently disabled in response to attack, so the onion site only accepts git connections)
   1. (+) supports SSH keys and SSH over Tor
   1. (+) no CAPTCHAs
   1. (+) registration very non-intrusive, and not controlling about where you get your email
   1. (-) noteworthy drawback unrelated to privacy: e-voting non-existent.
   1. (-) noteworthy drawback unrelated to privacy: NAB doesn't associate PGP keys to users, so PGP signed commits may be unavailable or more manual work needed.
   1. (-) IRC support channel is dead.
1. [Codeberg](https://codeberg.org/).  Runs on [Gitea](https://docs.gitea.io/en-us/), which is a Gogs fork.
   1. (+) web UI works on Tor (probably SSH as well)
   1. (+) supports SSH and GPG keys
   1. (+) registration very non-intrusive, and not controlling about where you get your email
   1. (+) functions without any j/s, and the javascript that exists is all 1st-party
   1. (+) supports e-voting
   1. (+) hosts Jeff Cliff's [CF-Tor](https://codeberg.org/crimeflare/cloudflare-tor) project which is one of the most credible and competently staffed privacy projects.  
   1. (-) logins don't work from all Ungoogled Chromium installations
   1. (-) no onion address

## Going forward

I suggest moving to **Codeberg.org** or **Notabug.org**.
",2019-08-08T13:36:35Z,2019-11-23T18:26:32Z,closed,13,miscellaneous (usage of dark pattern in software),"dark money and patterns in Github, reasons to not use Github","GitHub, examples","DPs used in software, DPs examples/definitions",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/atom/atom/issues/20182,Atom still spies on the user even prior to consent request,https://github.com/atom/atom/issues/20182,"### Description

Atom is contacting Microsoft/GitHub processes running on Amazon servers on first launch **without consent**, and leaking my IP address and timestamp to the manufacturer, as well as transmitting the fact that I use Atom (via outbound request) to thousands of other people and organizations.

### Steps to Reproduce

1. Launch Atom for the first time

**Expected behavior:**

No telemetry is sent.

**Actual behavior:**

Telemetry is sent.

Atom transmits my IP address (and implicit timestamp) to the manufacturer and thousands of other people.

At no point am I prompted for consent prior to this happening.  This happens *silently*.

Only **after** this information has been sent out of my machine does the main application window open with the consent dialog (which has its own issues).

<img width=""548"" alt=""Screen Shot 2019-11-26 at 10 22 52"" src=""https://user-images.githubusercontent.com/408977/69661425-395f1600-1037-11ea-9cfd-64f6959d4f60.png"">
<img width=""577"" alt=""Screen Shot 2019-11-26 at 10 22 56"" src=""https://user-images.githubusercontent.com/408977/69661427-395f1600-1037-11ea-9246-c93edb428562.png"">

**Reproduces how often:**  100% of the time on first launch

### Versions

1.41.0 x64 osx

### Additional Information

A user's IP address, as well as the tracking/telemetry/analytics/autoupdate target host IP are both transmitted from the user's machine at time of first launch (adding a timestamp to these first two pieces of data).

This tuple of (user source IP, atom.io destination ip, TCP port, TLS SNI hostname, timestamp) **leaks usage information** to thousands of different people when it is sent from the user's computer: ISP, hosting providers, network interchanges, intelligence services (hi Ed!), Microsoft internal systems administrators, GitHub systems administrators, and Amazon network administrators.  The user is given **no opportunity** to opt out of this, to prevent it, and is **not even made aware of it happening**.

This means that the work on #12281 is *incomplete*.  The software is still **transmitting user data without consent** before the consent dialog even appears.

Wikipedia defines spyware as:

> Spyware is a software that aims to gather information about a person or organization, sometimes without their knowledge, and send such information to another entity without the consumer's consent. 

## Required Elements

1. software :white_check_mark: atom is software
1. *gathers information about a person* :white_check_mark: information that the user is launching Atom for the first time
1. *without their knowledge* :white_check_mark: no information is displayed to the user when the request is made, or any time thereafter
1. *send information to another entity* :white_check_mark: sends data to ISP, routers, hosting companies and staff, GitHub, Microsoft, Amazon, and NSA
1. *without the user's consent* :white_check_mark: no consent was asked or provided, and indeed, did not exist

Presently, Atom does *all of these* on first launch.",2019-11-26T18:33:42Z,2019-11-27T01:13:54Z,closed,18,"Atom, usage of dark pattern in software, privacy issues, data leaking","Atom, security issue without consent, privacy Zuckering","Atom. privacy issue, data collection",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/w3c/aria/issues/166,ARIA: should there be a password role?,https://github.com/w3c/aria/issues/166,"html has a password input
UIA has a password property
(maybe other apis do too?)
Should aria have a role=password?
",2016-01-12T19:57:26Z,2019-11-19T18:46:35Z,closed,31,miscellaneous (pre-selected show password checkbox),"ARIA, password, low security settings","ARIA, password, checkbox, preselection",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/meatstuff/itstuff/issues/30,Link Dump - July 2019,https://github.com/meatstuff/itstuff/issues/30,"## ECO
- [ ] Eco stuff https://www.theregister.co.uk/2019/07/17/icarus_outage_turning_it_off_and_on_again_aboard_the_iss/
- [x] Solein (Electric Food) https://www.theguardian.com/environment/2019/jun/29/plan-to-sell-50m-meals-electricity-water-air-solar-foods

## POLIOTICKS
- [ ] https://www.hackread.com/researchers-exploit-lte-flaws-to-send-fake-presidential-alerts/
- [x] https://arstechnica.com/tech-policy/2019/06/trump-tweets-will-get-warning-labels-if-they-break-rules-twitter-says/#p3

## CRYPTO
- [ ] https://www.theregister.co.uk/2019/06/28/iran_bitcoin_electricity_demand/
- [ ] https://www.theguardian.com/technology/2019/jul/02/bitcoin-price-10000-facebook-libra-cryptocurrency tl;dr was up, now down
- [ ] eh https://medium.com/celohq/introducing-alfajores-1b162ebcb44d

## DRUNK ELON HOME GO
- [ ] e e e e lon lon lon https://www.theguardian.com/technology/2019/jul/17/elon-musk-neuralink-brain-implants-mind-reading-artificial-intelligence
- [ ] https://arstechnica.com/science/2019/07/musks-newest-startup-is-venturing-into-a-series-of-hard-problems/#p3
- [x] Moarlon https://www.theguardian.com/music/shortcuts/2019/jul/17/peeled-eyeballs-isolation-tanks-and-neuroplastic-goals-is-grimess-training-regime-for-real

## DON'T BE EVIL, GOOGLE
- [x] https://www.theregister.co.uk/2019/07/16/google_ban_on_tech_support_ads/ <-- being evil

## YOUPOOP
- [x] https://www.theregister.co.uk/2019/07/03/youtube_bans_hacking_videos/
- [x] https://www.techdirt.com/articles/20190710/22264042559/youtube-finally-demands-specificity-copyright-claimants.shtml

## INTERNET OF SHIT
- [ ] https://www.theregister.co.uk/2019/07/03/zipato_hardcoded_key/
- [ ] https://www.theregister.co.uk/2019/07/18/smart_diapers_pampers/
- [x] Hackable MedTronic insulin pumps – insecure kit recalled https://www.theregister.co.uk/2019/06/28/medtronic_insulin_pump_recall/

## LULZ
- [ ] noisy neighbours = drones + fireworks https://www.thepoke.co.uk/2019/07/17/this-guy-was-fed-up-with-his-noisy-neighbours-so-he-took-a-very-2019-revenge/ [no sound, so we can't use it in the show goddamn]
- [x] Suspected dark-web meth dealers caught when buying stamps https://www.theregister.co.uk/2019/06/28/dark_web_stamps/

## PSA
- [ ] Public announcement - https://www.bbc.co.uk/news/amp/business-49043425

## FFS
- [ ] Boeing’s 737 Max Software Outsourced to $9-an-Hour Engineershttps://www.bloomberg.com/news/articles/2019-06-28/boeing-s-737-max-software-outsourced-to-9-an-hour-engineers
- [ ] https://www.theregister.co.uk/2019/07/01/windows_phone_death_march_continues_no_more_app_updates_for_8x_holdouts/
- [ ] https://webtransparency.cs.princeton.edu/dark-patterns/

## UNSOCIAL MEDIA
- [x] https://www.theregister.co.uk/2019/07/01/wikipedia_founder_calls_for_social_media_strike/
- [ ] https://www.forbes.com/sites/zakdoffman/2019/07/20/russian-intelligence-has-been-hacked-with-social-media-and-tor-projects-exposed/
- [ ] https://www.theguardian.com/uk-news/2019/jul/20/scotland-yards-twitter-account-breached-in-series-of-bizarre-posts
- [x] Do we care https://www.bbc.co.uk/news/world-49026935 Instagram hides likes count in international test 'to remove pressure'
- [ ] Can you trust FaceApp with your face? https://www.bbc.co.uk/news/technology-49018103 yay russia

## ARRRR
- [ ] Anti-piracy drm https://www.theregister.co.uk/2019/06/28/microsoft_ebooks_death/
- [ ] https://www.ispreview.co.uk/index.php/2019/07/get-it-right-copyright-holders-scrap-uk-isp-piracy-letters-scheme.html

## SPAEC
- [x] https://www.theregister.co.uk/2019/07/15/galileo_outage/
- [ ] https://www.theregister.co.uk/2019/07/17/europe_gps_satellites_galileo_down/
- [ ] https://www.nasa.gov/specials/apollo50th/events.html we looking at this at all?
- [ ] shall we start with a quote from arthur c. clarke's ""July 20, 2019: Life in the 21st Century"" for shits and giggles or compare for lulz

## MISC
- [ ] https://www.theguardian.com/technology/2019/jul/10/microsoft-to-open-first-european-store-in-central-london Raspberry pi and Microsoft?
- [ ] https://www.blender.org/press/epic-games-supports-blender-foundation-with-1-2-million-epic-megagrant/
- [ ] bbc flood https://www.bbc.co.uk/news/business-49015609
",2019-07-23T13:06:14Z,2019-08-04T23:24:30Z,closed,0,"documentation of dark pattern, paper",examples in shopping websites,"shopping websites, doucmentation ",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/matthewmain/kiss_the_sky/issues/75,login signup,https://github.com/matthewmain/kiss_the_sky/pull/75,"To Do (NOTE: This pr will be closed with a fresh one once all changes have been made and ready for review)

- [x] - create styleguide.md 
- [ ] - add requests to check for username and email 
- [ ] - add all icons to `images`
- [ ] - add green color and checkmark after success api call
- [ ] - add red x for ""already taken"" 
- [ ] - use ""reload"" icon to spin for waiting for api...
- [x] - auto pause game
- [ ] - fade in / out 
- [ ] - snap back to game after success (some sort of success notificaiton)
- [ ] - check hover state for all elms... 
- [ ] - add email OR username to DB flow

@matthewmain I did go off your design a bit here. Just enlarged the font-size a bit. We can change it back if you like. I don't know why but this just looked different when I added the vars and actually saw it on the page. So, i've been staring at it too much. please let me know what you think as I think I've developed blinders from trying to figure out if it looks right or now. 

<img width=""797"" alt=""Screen Shot 2019-04-27 at 12 37 37 PM"" src=""https://user-images.githubusercontent.com/15821138/56853282-33f7ec80-68eb-11e9-81cc-aef971f562e9.png"">

Also, I put all the text for both sign up/in in the state object so that it'd be an easy to find place to change any of the text if need be.... it's under `webapp/client/src/pages/SignIn_LogIn/signIn_logIn.js`
<img width=""708"" alt=""Screen Shot 2019-04-27 at 12 56 38 PM"" src=""https://user-images.githubusercontent.com/15821138/56853344-ef208580-68eb-11e9-8893-84fb1d044b2c.png"">
",2019-04-27T17:51:14Z,2019-05-03T20:37:16Z,closed,1,"Kiss the Sky, usage of dark pattern in gaming, ""keep playing without signing in"", visual interference",design suggestion to avoid dp,"Kiss the Sky, gaming, interface interference",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/codesandbox/codesandbox-client/issues/1232,Added alert when saving frozen sandbox,https://github.com/codesandbox/codesandbox-client/pull/1232,"**What kind of change does this PR introduce?**

This PR adds a browser alert prior to saving a frozen sandbox. The alert describes that the sandbox will be forked.

Also included is a minor code spelling fix (FreezeConatainer > FreezeContainer)

**What is the current behavior?**

Currently saving a frozen sandbox will silently fork the sandbox, similar to saving a sandbox your don't own.

Issue #1212 mentioned that a prompt identifying that the sandbox will be forked could be useful.

**What is the new behavior?**

When saving edits to a frozen sandbox which you own, an alert will appear describing that the sandbox will be forked.

**Checklist**:

- [ ] Documentation
- [ ] Tests
- [x] Ready to be merged <!-- In your opinion, is this ready to be merged as soon as it's reviewed? -->
- [x] Added myself to contributors table <!-- this is optional, see the contributing guidelines for instructions -->

**Comments / Questions**

Q: Could this be a `confirm()` rather than an `alert()`?

A: This would be my ideal implementation, allowing the user to cancel and 'unfreeze' their sandbox if they wish. Unfortunately I don't know a way to cancel the proceeding cerebral `sequence` (which would need to be approached generically as save is triggered in many places). I'd be interested in seeing other approaches to this problem which allow this functionality.

Q: Does this negatively affect UX?

A: As mentioned in the issue prompting this work, the application silently forking a frozen sandbox felt like a bit of a dark pattern to the individual raising the issue. I'm happy to offer up this PR, and get feedback around the UX impact of it.

If anyone can think of a message clearer than ""This sandbox is frozen, and will be forked."" please let me know, I feel the message might not be clear to someone who doesn't know the concept of 'frozen' and 'forked' sandboxes 😃",2018-10-24T22:27:43Z,2019-04-04T11:26:16Z,closed,4,"frozen sandbox, deceptive design practice",freezing sandbox,"frozen sandbox, deceptive design practice",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/humanetech-community/awareness-program/issues/60,Don't count on me,https://github.com/humanetech-community/awareness-program/issues/60,"# ""Don't Count On Me"" Campaign

<!-- Please fill in the information below each header according to the instructions.

       - Do NOT remove section headers. Instead add the placeholder text if the section is not needed.
       - You can leave the comments. They can be helpful when editing the issue later on.
       - Replace brackets with appropriate information (unless part of a link), leaving formatting intact.
       - The non-comments texts below provide examples, unless they are placeholder text

    Note: You will not be wasting your time documenting all this. The information in this issue
          should be copied to the Campaign README.md after your feedback is incorporated.
-->

## Info 

<!-- Provide short name that reflects the gist of the campaign, used as working title.
      Also add the link to community forum topic that is used for general discussion. 

      Valid values for 'Status' are: Ideation, Preparing, Launched, Finished
      Valid values for 'Affiliation' are: Official, Unofficial
      Original idea: Link to forum user that first came up with campaign idea
      Coordinator: Link to forum user responsible for coordinating tasks for this campaign, or 'TBD'
-->

- Name: **Don't count on me**
- Theme: [Resocialized media](https://github.com/humanetech-community/humanetech-community-awareness/issues/61)
- Status: Ideation
- Affiliation: Unofficial
- Original idea: [micheleminno](https://community.humanetech.com/u/micheleminno/summary)
- Coordinator: TBD
- General discussion: [Let’s force social apps to remove numbers from profiles](https://community.humanetech.com/t/let-s-force-social-apps-to-remove-numbers-from-profiles/1466)

## Summary 

<!-- Clear and concise explanation in 1-3 lines of text. -->

Raise awareness on the role of metrics (n. of followers/friends/likes/ ..)  in social media, and take action to have them removed.

## Goals

<!-- Bullet list of the intended effects of the campaign, separated by empty lines. -->

- Raise awareness with the public how metrics in social media are unnecessary and only serve to increase their dependency on them.

- Force social media companies to acknowledge that users are against counters in social media profiles and feeds.

- Organize frivolous actions for social media users to participate in, to send clear signals to the platform operators and apply public pressure to change.



## Audience

<!-- The demographic audience the campaign is targeted to. -->

- All people that use social media as they are now or would use them if they were more human and metrics-free.

## Success criteria

<!-- (optional) Bullet list detailing how success is measured. -->

- Design actions that are continuated by social media users without the need for community attention
- Other success criteria should be defined based on the deliverables we create.

## Retrospective

<!-- (optional) Analysis of results after campaign has ended, to see if success criteria were met, and to learn lessons for future campaigns. Use the placeholder text is no retrospective was held yet. Add a date indicator if possible (e.g. 'after 3 months', '24-11-2018'). -->

- No retrospective has been held yet. The first retrospective is planned at [retrospective date].

## Description

<!-- A longer, more elaborate description (one or more paragraphs of text) -->

No more n. of followers, n. of likes and so on. It’s a simple but powerful change. it’s the core of the addiction: we see numbers, our brain makes automatic comparisons, we ultimately suffer and strive for more dopamine when the counter increments. In the ideal scenario envisioned by this campaign, social media users would continue to see if someone likes or follows, but no aggregation on users’ actions would be made (how many users did something). That’s where masses of strangers weirdly affect our expectations and our rewards.

## Deliverables

<!-- Sub-headers with the planned deliverables and their summaries. Update this later to reflect changes.  The second sub-header gives an example. -->

### [Deliverable type]: [Deliverable name 1](deliverable1-url) 

[Deliverable summary]

### [Deliverable type]: [Deliverable name 2](deliverable2-url)

[Deliverable summary]

## Strategy

<!-- Outline the (draft) strategy required to attain the success criteria (one or more paragraphs of text, use formatting - like lists - where appropriate). Use this placeholder text if this section is not needed:

- This campaign does not require a strategy. Strategy is defined on the Theme, or in Deliverables.
 -->

- This is a complex campaign. Besides the (not too long) description, provide a link to a separate [strategy document](campaigns/[campaign-folder]/campaign-strategy.md).

- Additionally you can point to general strategy resources in the `/strategy` folder.

## Funding

<!-- (optional) Financial requirements, required budget, ways to obtain funds (keep it short, couple of paragraphs, some bullets). If necessary link to separate detailed funding document. Use the placeholder text if no funding is required. -->

- No funding is required to execute this campaign. 

## Milestones

<!-- (optional) Bullet list of past and future milestones for the campaign. Or placeholder bullet ""No milestones have been defined."" -->



## Resources

<!-- (optional) Links to relevant folders, files and external information, or leave the placeholder text. -->

- Cognitive and behavioral science pattern that are implemented in social media (see [forum listing](https://community.humanetech.com/t/collecting-cognitive-science-patterns-that-are-at-play-on-social-media/2951))
",2018-11-12T10:29:18Z,2019-04-27T09:52:14Z,closed,3,darkpattern hallofshame in software,ways to raise dp awareness,dark pattern education,DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/glitch-soc/mastodon/issues/691,Add confirmation dialog when posting media without description,https://github.com/glitch-soc/mastodon/pull/691,"Fixes #211.

Option:
![screenshot_2018-08-29 dev instance 2](https://user-images.githubusercontent.com/384364/44809210-5a378200-abce-11e8-9997-792d35b6ca30.png)

When posting a toot with media missing descriptions:
![screenshot_2018-08-29 dev instance 3](https://user-images.githubusercontent.com/384364/44809220-5efc3600-abce-11e8-999a-92866987b31f.png)

On cancel, the description input for the first media without description is focused.

I'm open for suggestions regarding the wording.
Also, the options menu is getting crowded, I'm not sure how to fix that.

EDIT: Changed wording a bit",2018-08-29T14:13:38Z,2019-03-14T14:28:56Z,closed,4,"usage of dark pattern, non-highlighted ""send anyway""","confirmation while posting without description, design suggestion, manipulation",UI/UX design,"DPs used in software, DPs examples/definitions",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/iCHAIT/awesome-macOS/issues/499,Add Dictionaries to Utilities section,https://github.com/iCHAIT/awesome-macOS/pull/499,"<!-- Thanks for contributing to awesome-macOS  -->

<!-- Please fill out the following: -->

0. [x] I have read the [Contribution Guidelines](https://github.com/iCHAIT/awesome-macOS/blob/master/.github/contributing.md)
1. [x] Project URL: https://dictionaries.io
2. [x] Why should this project be added: It makes the native Dictionaries.app much more useful for people that speak multiple languages. Because it only adds data for a native app, it is already tightly integrated into macOS.
3. [x] End all descriptions with a full stop/period
4. [x] Entry is ordered alphabetically
5. [x] Appropriate icon(s) added if applicable (OSS, freeware)

<!--

Again, please read https://github.com/iCHAIT/awesome-macOS/blob/master/.github/contributing.md if you didn't yet.

-->
",2018-05-09T17:49:37Z,2019-03-13T16:05:31Z,closed,3,"dictionaries.io, usage of dark pattern, FREE DOWNLOAD time-limited trail version","trial version downloaded without warning, sneaking","dictionaries.io, auto download, forced action",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/23,"Store number of buttons, imgs, links inside each segment",https://github.com/aruneshmathur/dark-patterns/issues/23,"Elements such as buttons may help clustering certain dark patterns, e.g. confirm shaming with ""No, I don't want..."" buttons or links.

Let's store the number of element types contained in each segment.",2018-11-29T18:55:12Z,2019-02-02T23:13:07Z,closed,1,"dark pattern buttons, comfirmshaming",confirm shaming,"UI/UX design, confirmshaming",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/atom/welcome/issues/72,Update consent copy,https://github.com/atom/welcome/pull/72,"### Requirements

* Filling out the template is required. Any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion.
* All new code requires tests to ensure against regressions

### Description of the Change

This updates the telemetry consent copy.

Before | After
--- | ---
![before](https://user-images.githubusercontent.com/378023/53000769-71b04300-346c-11e9-8a72-02f75ac345e6.png) | ![after](https://user-images.githubusercontent.com/378023/53138040-4e020f80-35c8-11e9-8ff7-2e22f3c78dcd.png)

### Alternate Designs

N/A

### Benefits

It removes the ""dark patterns"" of the current design.

- By making both buttons blue, both options get equal importance.
- The copy doesn't make users feel guilty for ""not helping"".
- The copy is reduced which might encourage people to read it.

### Possible Drawbacks

- This might affect how many people opt-in vs opt-out.
- We give the community another chance to discuss this topic.

### Applicable Issues

None, but it's something that we got called out for in the past.
",2019-02-19T08:42:03Z,2019-02-22T01:38:44Z,closed,3,"Atom, Telemetry, prevention of dark pattern, consent ",removing dp by no design heirarchy ,"Telemetry, Atom, cookie consent, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/12,Switch to OpenWPM,https://github.com/aruneshmathur/dark-patterns/issues/12,"@gunesacar and I discussed that we should to move away from vanilla Selenium and integrate our crawler with OpenWPM.

OpenWPM has several logging capabilities that may be of use to us in the long term (e.g., HTTP logging to determine requests that correspond to the Dark Patterns we discover).",2018-10-11T23:09:17Z,2019-02-02T23:13:07Z,closed,5,"OpenWPM, logging capobilities, HTTP logging, identify and analyze dark pattern","OpenWPM, Http logging","Open WPM, HTTP logging",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/13,Evaluating MutationObserver,https://github.com/aruneshmathur/dark-patterns/issues/13,"[MutationObserver](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver) is a Web API that logs changes to the DOM.

We could use this API to log Dark Patterns that emerge only after the page has loaded (e.g., Ajax calls) or through certain user interactions (e.g., on selecting product attribute).

As a first step, we could manually examine how it behaves on a small set of shopping websites.",2018-10-11T23:16:40Z,2019-02-02T23:13:07Z,closed,7,"MutationObserver, web API, log/detect dark patterns, ","MutationObserver, API to log dp","MutationObserver, API to log, detection",DPs detection Tools,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/jmartin82/mmock/issues/78,Disable default stat collection. Update README.,https://github.com/jmartin82/mmock/issues/78,"I noticed the CLI switch `-server-statistics` having a default value `true`. Though you are collecting anonymous stats, its a _dark pattern_ to leave this switch enabled by default.

Any privacy concerned user will definitely be caught by surprise.
1. There is no prominent mention in the README that stats are collected by `mmock` by default. Though there is a mention of statistics in the `Contributors` it doesn't convey that the tool collects anonymous stats.
2. The CLI switches listed in the README don't feature this flag (perhaps not updated). I happened to find this switch only after running the tool with `-h`; after which I began to inspect rest of the code.

I know this is a very subjective issue. You are entitled to your PoV. But, my request to you is:
1. Please disable this switch by default.
1. Please display information in a very prominent location in the README about mmock's statistic collection, the actual data collected and what can the user do to enable/disable it.

Please let me know your views. Please also let me know if you'd like a PR for this change. TIA.",2019-03-11T20:50:30Z,2019-03-15T13:07:38Z,closed,3,"usage and prevention of dark pattern, default stat collection, preselection","collecting anonymous stats, why/how to avoid dp","default stat collection, preselection",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/streetmix/streetmix/issues/793,Mailing list signup form,https://github.com/streetmix/streetmix/issues/793,"I'm working on a mailing list and populating it with a small list of existing supporters. But we should also include some way of opting into a mailing list for people who want to stay on top of Streetmix news and happenings in their mailbox. I was thinking of a popup embeddable form, like this:

![image](https://user-images.githubusercontent.com/2553268/35701080-e3644dbc-0762-11e8-858d-e9d4d4c1f50b.png)

Dialog UI [are already present in the application](https://github.com/streetmix/streetmix/tree/master/assets/scripts/dialogs) so the two parts that need more careful thought / implementation are:

1. the insides of the dialog. What goes in it? How does it work? What does feedback (success, error) look like?
2. how to display the dialog. What sequence of actions (or sequences) trigger the dialog, or prevent triggering of the dialog?

---

Some thoughts on each (not exhaustive).

**1. Internal: what's in the dialog?**

- No dark patterns -- no one's job depends on satisfying a conversion metric, so don't do anything that shames the user into signing up. It's okay if they don't.
- Sign up prompt should be short but say something that promises the newsletter delivers value. What I'd like to do with the newsletter, include (but not limited to) letting people know about progress and updates with Streetmix, maybe ask for beta testers on experimental features, showcase case studies of people using Streetmix, point out interesting/cool things happening in general with placemaking and streetscape improvements. The frequency would be no more than once per week but more likely no more than once or twice a month.
- The mailing list system is Mailchimp. Should we use something like [Upscribe](https://upscri.be/) for embedded forms or grow our own?
- Success and error states should happen in the dialog itself (there is no separate confirmation dialog).
- Ideally portions of the dialog box content isn't tightly coupled to dialog boxes themselves, in case it gets incorporated into something else (e.g. user dashboard)

**2. External: what triggers the dialog?**

- We can pop up a dialog when a user visits the page, if certain conditions are met (the main ones are 1. this is not your first time visiting Streetmix; 2. there is no other notice/message on the site that takes priority). Should we do this? How many times does a person visit before we show this? If it's dismissed (no conversion), does it ever come back? (my hunch is no)
- Some sites trigger a popup but after X time has elapsed on the site or Y interaction has occurred. Should we do this?
- Let's say there is no auto-popup, or the popup was dismissed, but someone wants to sign up for the mailing list later, without us prompting them. How do they find it? Is it a menu option? Is it a button to trigger the dialog or a separate embed on the About dialog or some other location? Is the ideal place to put this (or any sign up form) part of a user flow that doesn't exist yet (e.g. user dashboard) so the initial solution for this is temporary?
",2018-02-01T20:35:15Z,2019-05-22T22:49:59Z,closed,2,"prevention of dark pattern in software, no comfirmshaming of mailing list signup",design that avoids signing up with dp,"UI/UX design, confirmshaming, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/privacytools/privacytools.io/issues/274,Add a section for why Chrome/Chromium should not be used just like the Windows 10 section?,https://github.com/privacytools/privacytools.io/issues/274,Chrome/Chromium is the most used browser currently. Adding warnings and reasons against it may be a good idea.,2017-07-17T10:45:25Z,2019-09-07T01:55:19Z,closed,25,"UX experience, security, privacy, Chrome, Windows, consent permission","Chrome, option in settings to config the browser, preselection","Chrome, privacy issue, preselection",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Ultimaker/Cura/issues/2840,Collecting Data Prompt shown although disabled,https://github.com/Ultimaker/Cura/issues/2840,"I disabled the preference to ""Send (anonymous) print information"".
Yet I am nagged with the prompt ""Collecting Data ... You can disable this ... Dismiss"" every single time I start Cura 3.0.4 :/

Is it another setting that I am missing? Please fix, if not.",2017-11-24T17:00:53Z,2019-03-25T16:34:43Z,closed,6,"Cura, usage of dp in software, data collection prompt, privacy issue","Data collection, nagging, ","Cura, data collection, privacy issue, nagging",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/barnardos/design-system/issues/294,Add young people guidance,https://github.com/barnardos/design-system/issues/294,"_As a user of the Design System
I want to know how to create products for children and young people (cyp)
So that I create a consistent experience across products_

## Links and resources

Relates to:
#413 

## Acceptance Criteria

* [x] Add guidance to design system
",2018-08-17T15:51:11Z,2019-03-07T22:53:34Z,closed,3,"good UX design practices (for children and young people), avoid dark patterns","awareness to not include dp in websites/apps for children, young audience","UI/UX design, avoid dark patterns",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/elastic/kibana/issues/30327,[Maps] Fix tileload error messaging / Fix heatmap error message,https://github.com/elastic/kibana/pull/30327,"Fixes false error messages that are most apparent in Cloud deployments.

Closes https://github.com/elastic/kibana/issues/29886
Closes https://github.com/elastic/kibana/issues/29863
Closes https://github.com/elastic/kibana/issues/29866

- [x] remove tile-error detection. It is buggy and relies on undocumented internal API from mapbox-gl. There is no real viable alternative at this point. The bugs are explained here https://github.com/elastic/kibana/issues/29886#issuecomment-461171475 and here https://github.com/elastic/kibana/issues/29886#issuecomment-461180338.
- [x] do not persist error state in descriptors. Error-messages will no longer reappear after saving.
- [x] refactor to use new naming scheme for app-lifecycle state in the descriptors. These should be prepended with `__`
- [x] tests

This also closes https://github.com/elastic/kibana/issues/30343, by introducing a default implementation of Layer#getOrdinalFields





",2019-02-06T22:19:42Z,2019-02-07T23:02:29Z,closed,16,"miscellaneous (dp in coding, layers removed from TOC, mismatched configurations)","heatmap fixing, removing layers, leaving no scope for users to edit and fix config issue","no editing configurations, forced action",DPs in design coding,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/MetaMask/Design/issues/49,Opt-in screen for analytics,https://github.com/MetaMask/Design/issues/49,"We need to show users a screen that asks for opt-in screen to  allowing MetaMask report basic usage metrics. We very much want people to enroll (rather than opt-out) so that we have data that can inform our product development. At the same time, it's important to (a) allow users to opt-out if they want to, and (b) inform users about what specific privacy protections we can promise. 

Some text we may want to include on the opt-in screen..
```
MetaMask would like to gather basic usage data to
better understand how our users interact with the extension.
This data will be used to continually improve the UX of our product.
If you care about the usability of the Ethereum ecosystem, 
please consider allowing these basic analytics

MetaMask will... 
* never collect addresses, keys, transactions, balances, or any other personal information
* never collect your IP Address
* never sell any data for profit. Ever!
* always allow you to un-enroll from these analytics via the settings menu.
* maintain a public dashboard of aggregate data for the community to learn from
```

More details to come based on conversations with Kyokan around Matomo specifics and conversation with Legal

cc @danjm @cjeria @omnat ",2018-11-08T20:47:51Z,2019-04-02T13:46:11Z,closed,13,"MetaMask, prevention of dark pattern in software, consent screen, opt-in, no-preselection","opt-in, privacy, no preselection, yes/no button","MetaMask, opt-in/out, privacy issue, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/fac-unb/campus-online/issues/17,Navbar: reduce dark pattern on AuthButton,https://github.com/fac-unb/campus-online/pull/17,,2018-09-04T12:42:34Z,2018-09-04T12:43:56Z,closed,0,miscellaneous (reduction of dp in AuthButton),,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/kittinunf/fuel/issues/133,Missing PATCH-Verb,https://github.com/kittinunf/fuel/issues/133,"Is there a possibility to issue PATCH-requests without using the semi-standard `X-HTTP-Method-Override` header, e.g. `Fuel.patch(...)`?

Maybe I'm just not seeing it, there is a patch method defined [here](https://github.com/kittinunf/Fuel/blob/5ce5955b34a2f237ed3b3c223415da74619ad4ab/fuel/src/main/kotlin/com/github/kittinunf/fuel/core/Method.kt#L8) but it's not exposed like GET, POST, PUT or DELETE. Is there a reason for this?",2017-03-01T13:02:29Z,2018-11-26T19:41:03Z,closed,5,,"PATCH-verb, time consuming, indirect, API gateway can be used",,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/WordPress/gutenberg/issues/9077,Remove the two click publish requirement,https://github.com/WordPress/gutenberg/issues/9077,"This is more of a feature request as nothing is technically broken here, but the workflow to publish a post seems like a poor user experience. Currently, the workflow is to finish writing and building your post out and then click the blue publish button right in the top right.

Once clicked a panel slides out and asks you if you're sure you want to publish the post. Compare that to the TinyMCE experience where you click publish once (which is sort of inline with the content) and then you've publish the post.

My expectations here would be to remove this additional panel and have that button submit the changes there and then. This would also reduce the UI making it less complicated.",2018-08-17T09:35:51Z,2019-01-28T21:30:49Z,closed,12,"Gutenberg, prevention of dark pattern, opt-out, no obstructions","additional button to publish, extra step, obstruction","Gutenberg, opt-in/out, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/11,"Switch to ""Behind the Overlay"" to close overlay dialogs",https://github.com/aruneshmathur/dark-patterns/issues/11,"Overlay dialogs -- such as the one shown below -- may break our code that navigates product pages. We need to be able to detect and close them, just as any user would.

![image](https://user-images.githubusercontent.com/460515/46379118-dd377680-c66b-11e8-90b1-e9f10d50a62b.png)


We have a script that currently does this: https://github.com/aruneshmathur/dark-patterns/blob/master/src/crawler/zindex.js. The script detects a \<div\> element, if there's one, with the highest z-index value (this is non-trivial, beware), and then searches for elements within this \<div\> that have an attribute whose name or value matches ""close"". If these elements are found, it clicks them to dismiss the overlay.

@gunesacar found a Chrome extension that does this too. I suspect their code is tested more thoroughly than ours. We should consider switching at some point.

Extension name: [Behind the Overlay](https://chrome.google.com/webstore/detail/behindtheoverlay/ljipkdpcjbmhkdjjmbbaggebcednbbme?hl=en)
Extension repository: https://github.com/NicolaeNMV/BehindTheOverlay/blob/master/chrome/js/overlay_remover.js",2018-10-02T21:58:19Z,2018-11-03T12:34:47Z,closed,1,"manipulative overlay dialogs, dp detection ","avoid overlay dialogues, obstruction","manipulative overlay dialogs, detection",DPs detection Tools,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/forem/forem/issues/288,Stop using the Fake Notifications Dark Pattern,https://github.com/forem/forem/pull/288,"<!--- Prepend PR title with [WIP] if work in progress. Remove when ready for review. -->

## What type of PR is this? (check all applicable)
- [ ] Refactor
- [ ] Feature
- [x] Bug Fix

## Description

A fake notification is displayed for non-logged-in users

## Mobile & Desktop Screenshots/Recordings (if there are UI changes)

Before:
![firefox_2018-08-09_07-19-18](https://user-images.githubusercontent.com/226692/43865292-85afe924-9ba5-11e8-8e21-56af1d3303ce.png)

After:
![2018-08-09_07-19-52](https://user-images.githubusercontent.com/226692/43865295-8881ab7e-9ba5-11e8-81c2-c6218d52f4b6.png)

## Added to documentation?
  - [ ] docs.dev.to
  - [ ] readme
  - [x] no documentation needed

## What gif best describes this PR or how it makes you feel?

![alt-text](https://media.giphy.com/media/SGT03NX8u32ZG/giphy.gif)",2018-08-08T21:34:41Z,2018-08-09T00:00:25Z,closed,5,"Forem, open-source software, prevention of dark pattern, no fake notifications","false notifications, unethical","Forem, notifications feature, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/7,Toggle product attributes on websites,https://github.com/aruneshmathur/dark-patterns/issues/7,"Many websites require certain product attributes (e.g. size, color) to be selected before adding to cart. Clothing websites are one such example.

We need to be able to select these attributes through our crawls. We should also consider exploring the space of product attributes since these may contain dark patterns. See example below, where on selecting a particular shoe size, the website claims ""You just missed it""; this creates urgency.

![screen shot 2018-09-05 at 12 59 27 pm](https://user-images.githubusercontent.com/460515/45109162-aaea3600-b10c-11e8-9290-aafa73879758.png)


",2018-09-05T17:08:36Z,2018-09-08T18:00:28Z,closed,0,"usage of dark pattern in software, e-commerce, fake-urgency","shopping websites, manipulation, urgency with certain messages","e-commerce, fake-urgency",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/forem/forem/issues/858,"The ""Fake Comment"" signup CTA is asshole design.",https://github.com/forem/forem/issues/858,"**Is your feature request related to a problem? Please describe.**
The ""Fake Comment"" signup CTA is a dark pattern that hits on asshole design:

<img width=""817"" alt=""screen shot 2018-10-08 at 8 33 09 am"" src=""https://user-images.githubusercontent.com/2179708/46618976-b5b23500-cad5-11e8-8590-8e48d7482e11.png"">

In this case, lampshading a bad/sleazy growth hacking strategy makes it even *worse* than just playing it straight.

**Describe the solution you'd like**
A Signup CTA isn't inherently bad, but there are a number of more ethical ways to get it across without compromising conversion rate:

* Don't make the automated comment appear it's from a real user.
* Add style/color elements to explicitly distinguish it from a comment.
* _Change the copy so it's not so passive-aggressive_. Honestly, after seeing it I have zero desire to register for the site.

**Describe alternatives you've considered**
N/A

**Additional context**
CTA template in repo: https://github.com/thepracticaldev/dev.to/blob/65110550d8c2231f73ff99ae305a46b7b0bcb4f9/app/views/comments/_login_cta_comment.html.erb",2018-10-08T15:46:23Z,2018-10-08T18:50:16Z,closed,2,"usage of dark pattern in software, ""fake comment"", signup CTA (call-to-action)","showing fake comments to sign up user, nagging, obstruction","fake social proof, signup CTA (call-to-action)",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/aruneshmathur/dark-patterns/issues/1,Data pre-processing,https://github.com/aruneshmathur/dark-patterns/issues/1,"The data file `data/sites_with_rank_sorted.csv` has four columns: `url`, `popularity_rank`, `category`, and `overall_rank`.

`popularity_rank` refers to a rank based on the popularity of a website. Subdomains within a specific website may have different `popularity_rank` values. 

`overall_rank` refers to the Alexa rank of the website. A website and its subdomains have the same `overall_rank`. Also, if a website is repeated in more than one category, it has the same `overall_rank`.

We want to ensure that if a website has subdomains in the dataset, they carry meaning from the point of view of dark pattern measurements. If not, we intend to remove those subdomains and retain only the base domain.

Once this procedure is complete, we should have a list of websites that interest us. We can then sort them by `popularity_rank`.",2018-07-27T16:09:46Z,2018-09-02T14:11:56Z,closed,1,,categorizing/ranking based on dp,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Automattic/jetpack/issues/9658,"Request: Change ""enable backups"" dark pattern attempt",https://github.com/Automattic/jetpack/issues/9658,"Friends,

I saw a notice saying ""protect your site before making major changes"" and a button saying ""enable backups""

My thought was ""Wow! Jetpack now offer a site backup utility for free accounts????!!!!!""

The answer is obviously, no, you don't. But if sure looks that way by using a button saying ""enable"" rather than ""purchase"" or ""upgrade"".

I feel like Automattic are better than this. Thoughts?",2018-05-29T18:47:36Z,2018-05-31T17:52:08Z,closed,2,"Jetpack, usage of dark pattern, ""enable backup"" button","using ""enable backup"" instead of purchase, manipulation","Jatpack, ""enable backup"" button, sneaking, trick users buying paid products",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/Automattic/wp-calypso/issues/27125,Tabbed navigation for wp.com plans and signup,https://github.com/Automattic/wp-calypso/pull/27125,"This PR updates plans page both on /plans and in signup to have personal/business tabs.

Related to the blogger plan project p9jf6J-Sn-p2

**Testing instructions:**

1. Follow instructions in D20180-code and make sure you are in the `test` group
1. Confirm signup steps with plan selection looks like this:

<img width=""1118"" alt=""zrzut ekranu 2018-10-29 o 15 58 08"" src=""https://user-images.githubusercontent.com/205419/47658563-7c7c5a80-db93-11e8-8d1e-18d46152c5bb.png"">
<img width=""949"" alt=""zrzut ekranu 2018-10-29 o 15 58 12"" src=""https://user-images.githubusercontent.com/205419/47658564-7d14f100-db93-11e8-9b2e-d0c9ca135d58.png"">

1. Confirm plans page looks like this:

<img width=""1077"" alt=""zrzut ekranu 2018-10-29 o 15 58 02"" src=""https://user-images.githubusercontent.com/205419/47658562-7c7c5a80-db93-11e8-980c-cbc02caa9db5.png"">
<img width=""1066"" alt=""zrzut ekranu 2018-10-29 o 15 57 24"" src=""https://user-images.githubusercontent.com/205419/47658560-7c7c5a80-db93-11e8-98c6-362f6390c672.png"">

1. Follow instructions in D20180-code and make sure you are in the `control` group
1. Confirm that you can't any see tabs on `/plans` or during the signup
1. Confirm that jetpack signup flow works just like in production
",2018-09-11T10:38:15Z,2018-11-08T20:40:47Z,closed,16,"wp.com, WordPress, usage of dark pattern in software, hidden cost","design suggestion for plan signup, sneaking","WordPress, hidden cost, sneaking",DPs used in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/brave/brave-ios/issues/280,"Private Mode ""Learn More"" new copy/design",https://github.com/brave/brave-ios/issues/280,"The no-tabs private mode state that displays the usual information about private mode currently has a ""Learn more about private tabs."" button to have parity with 1.6.

This will be need to be replaced by longer copy explaining more details around private mode, or by instead showing that longer copy some different way upon clicking the ""Learn more"" button.

![private-notabs](https://images.zenhubusercontent.com/5b4cfb87b69de9433c0523d6/34014459-449f-44a3-9391-911363d3da3b)
",2018-09-24T18:30:14Z,2018-11-10T01:51:21Z,closed,17,"Brave ,VPN, prevention of dark pattern, privacy feature access","example, network interaction to understand privacy, forced action","Brave, VPN, privacy issue, forced action",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/w3c/wpub/issues/321,"What is an ""opaque origin"" and why do we care?",https://github.com/w3c/wpub/issues/321,"This comes up in obtaining a manifest and in the life cycle diagrams. But a trip to the HTML spec is no help, defining ""opaque origin"" as:

> An internal value, with no serialisation, for which the only meaningful operation is testing for equality.

How would a document end up having an opaque origin? 



",2018-08-27T23:52:40Z,2019-02-05T22:32:54Z,closed,50,"miscellaneous (opaque origin, sandboxed document in coding)",,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Ultimaker/Cura/issues/3722,[Request] Direct Download Links for logged-in users?,https://github.com/Ultimaker/Cura/issues/3722,"<!--
The following template is useful for filing new issues. Processing an issue will go much faster when this is filled out, and issues which do not use this template WILL BE REMOVED.

Before filing, PLEASE check if the issue already exists (either open or closed) by using the search bar on the issues page. If it does, comment there. Even if it's closed, we can reopen it based on your comment.

Also, please note the application version in the title of the issue. For example: ""[3.2.1] Cannot connect to 3rd-party printer"". Please do not write thigns like ""Request:"" or ""[BUG]"" in the title; this is what labels are for.

It is also helpful to attach a project (.3mf or .curaproject) file and Cura log file so we can debug issues quicker.
Information about how to find the log file can be found at https://github.com/Ultimaker/Cura/wiki/Cura-Preferences-and-Settings-Locations. To upload a project, try changing the extension to e.g. .curaproject.3mf.zip so that github accepts uploading the file. Otherwise we recommend http://wetransfer.com, but other file hosts like Google Drive or Dropbox work well too.

Thank you for using Cura!
-->

**Application Version**
All

**Platform**
All

**Steps to Reproduce**
Try to download a copy of Cura.

**Actual Results**
Note the same form comes up every. damn. time. and you have to fill in the same. damn. info.

**Expected results**
Site should recognize a returning user and offer up a direct download link  without a survey.
",2018-04-25T16:45:49Z,2018-05-24T15:37:48Z,closed,4,"Cure, usage of dark pattern, trick users to fill out form","no direct download links, fill up form, obstruction","Cure, trick users to fill out form, sneaking, interface interference",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/aragon/issues/issues/86,"Tiny, long, hard to read EULA on start",https://github.com/aragon/issues/issues/86,"At the very least, a human-readable summary should be included at the top, with the full text below.

The window is really small, you have to scroll really far, which encourages people to accept without reading the full EULA. This seems like a very intentional dark pattern.

Aragon 0.3.0 on macOS Sierra",2017-09-18T22:03:59Z,2018-04-05T12:22:58Z,closed,0,"deceptive design practices, EULA (End-User License Agreement), long and tiny texts","small long window for EULA, too inconvenient to read, so frustrate users in accepting"," EULA (End-User License Agreement), UI/UX Design, interface interference",DPs examples/definitions,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/Automattic/wp-calypso/issues/23117,Remove obsolete multiDomainRegistrationV1 AB test,https://github.com/Automattic/wp-calypso/pull/23117,"Fixes https://github.com/Automattic/wp-calypso/issues/15346 (in a roundabout way)

This removes a very old (pre-OSS) `multiDomainRegistrationV1` AB test that affected the G Suite checkout page. Furthermore, it's `datestamp` was `20200721`, so no user was eligible for this test and everyone was getting assigned to the default `singlePurchaseFlow` variation (at least until July of 2020 when this test would kick in).

I tried searching for it but couldn't find any relevant documentation, except for this post by @lucasartoni where its removal was requested p1v4f2-1TI-p2.

### Visual changes
- **Before**  `date < July 21, 2020`

![before](https://user-images.githubusercontent.com/1182160/37140351-adad9d9e-22b1-11e8-899e-2d85a9cf9c3a.png)

- **Before - back to the future version** `date > July 21, 2020` 90% of users would see this. Disclaimer: prices and features may vary :smile: 

![keep-searching](https://user-images.githubusercontent.com/1182160/37140369-cefe28ba-22b1-11e8-912f-09861f66301e.png)

- **After**

![just-checkout](https://user-images.githubusercontent.com/1182160/37140423-fd7b596a-22b1-11e8-8387-f455c52c7316.png)

I decided to:
- remove the `Keep searching` option because `Back` button above already covers that functionality in a more consistent way.
- leave `Checkout` button in place instead of a link because the existing usage is kind of a dark pattern, and we have an ESLint warning against usages like these anyway. As a side effect, this will also resolve layout issues mentioned in https://github.com/Automattic/wp-calypso/issues/15346.

### Testing instructions
1. Navigate to `/domains/manage/` and click on `Add domain`.
2. On next page select some suggested domain.
3. Verify that `Checkout` and `Yes, Add Email` still work as expected.
4. Verify that everything looks fine on small screen sizes.
5. Verify that issue from https://github.com/Automattic/wp-calypso/issues/15346 is no longer present.

",2018-03-08T08:33:39Z,2018-03-14T22:23:32Z,closed,11,"Calypso by WordPress, usage of dark pattern in software, visual interference","software design, easy checkout","Calypso, WordPress, interface interference",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/signalapp/Signal-Android/issues/6927,"Profiles: no way to hide the ""share profile with group"" message",https://github.com/signalapp/Signal-Android/issues/6927,"As the title says: if I don't want to share my profile with a group, there is no way to just hide the message that suggest doing so. There should be a way to change idea later and share the profile, but that bar is annoying.

An indicator to know if the profile is shared or not is also missing.

Not sure if this also happens in conversations with people not in the contacts list.",2017-09-06T22:23:04Z,2018-04-03T04:11:58Z,closed,10,"Signal (signal.org) Android, usage of dark pattern in software, obstructions, hard to disable profile shared","Signal, no way to not share profile info in groups, forced action","Signal, privacy issue, forced action",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/WordPress/gutenberg/issues/4811,Try showing plugin notices above the editor,https://github.com/WordPress/gutenberg/pull/4811,"These notices aren't pretty. But now they're visible, so you kind of have to deal with them before you can edit. This is one approach we can take — the other being _hide them_ and let the user deal with them on another screen in the wp-admin than the editor screen. 

Thoughts? What's the best approach? Are there other approaches?

Screenshot:

![screen shot 2018-02-01 at 18 57 39](https://user-images.githubusercontent.com/1204802/35694585-0ffe76bc-0782-11e8-918b-a7e88e8e4cfb.png)
",2018-02-01T18:00:26Z,2018-02-27T18:29:34Z,closed,17,"Gutenburg, prevention of dark pattern, avoided non-dismissable notices ","non-dismissable notices, obstruction","Gutenberg, non-dismissable notices, obstruction, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/davidhalter/jedi/issues/958,citing autocomplete-python-jedi,https://github.com/davidhalter/jedi/pull/958,"Hi,

I modified the REAME.rst and usage.rst to cite also [autocomplete-python-jedi](https://atom.io/packages/autocomplete-python-jedi)  as a plugin for Atom.
It's a fork created following the [issues](https://github.com/autocomplete-python/autocomplete-python/issues?utf8=%E2%9C%93&q=is%3Aissue%20is%3Aopen%20refactor%20OR%20owner%20OR%20telemetry%20) that `autocomplete-python` has with [kite](https://kite.com).

The only political choice I've made is to list `autocomplete-python-jedi` before `autocomplete-python`.

best",2017-08-23T11:01:38Z,2017-09-07T08:58:14Z,closed,2,"usage of dark pattern in coding, autocomplete-python",,miscellaneous,miscellaneous,"usage of dark pattern in coding, autocomplete-python",,DPs used in software,dps used in software,,,
https://api.github.com/repos/uswds/uswds/issues/64,"Feature Request: Prohibit the use of carousels, backed with reasons. Showcase best practices for alternatives to carousels",https://github.com/uswds/uswds/issues/64,,2015-06-23T17:54:32Z,2017-10-26T20:29:10Z,closed,12,"Carousel, not sure","removing carousels for better design, documentation",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/uBlockOrigin/uAssets/issues/690,[Request for block] Crypto Miners,https://github.com/uBlockOrigin/uAssets/issues/690,"I would love to see ublock start blocking the crypto miners that people have started to embed on their pages (or `fetch`)

### URL(s) where the issue occurs

**Warning, these link will end up consuming over 80% of your CPU**

https://gus.host
https://spoopy.link/facebook.com 
https://thepiratebay.org/search/Some%20Movie/0/99/0

### Describe the issue

This page requests this: https://gus.host/coins.js via a script tag, which in turn runs a `fetch` to grab this script: `https://coin-hive.com/lib/coinhive.min.js`. This script then hammers your CPU cores.",2017-09-15T00:18:28Z,2017-10-05T03:02:13Z,closed,111,"uBlockOrigin (uBo), usage of dark pattern, auto opt-in, abusive behavior","crypto miner, naming ""Dark Pattern""","uBlockOrigin (uBo), opt-in/out",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ThePacielloGroup/inclusive-design-principles/issues/23,A little feedback,https://github.com/ThePacielloGroup/inclusive-design-principles/issues/23,"This is excellent and I think will be helpful..

* I think the term `editorial` is not widely understood.
* Be consistent - I really want to say 'avoid dark patterns' and link to [this rant] by Craig(https://www.sitepoint.com/annoying-web-dark-patterns) :)
* Give Control -> Make it Stop - add auto play videos as well as animations? Death to parallax!
* Offer choice  - an example could be `Search and Browse`. Plus `do NOT disable paste into passwords` 
* Prioritise content - How about adding - consider the users task / needs over your goal but perhaps too contentious. Certainly concidering the restrainst of small screen sizes is important both for people on small screens and a good experience on larger screes where you can easily add also sorts of cruft. Am so tempted to say 'Banks - this means no sales pitches all over the page' LOL
* Add Value - Add ' but do not assume all platform features will work for everyone' eg PE / PWA

HTH
",2017-05-31T10:16:37Z,2017-06-09T10:50:58Z,closed,5,"prevention of dark pattern, inclusive design practices",examples in a wesbite ,"avoid dark pattern, UI/UX Design",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ossu/computer-science/issues/407,Algorithms courses appear to be trial only,https://github.com/ossu/computer-science/issues/407,The Coursera versions of the algorithms courses appear to have gone to a 7-day trial only with no open enrollment. The Stanford version of the first two courses is still available.,2017-05-17T02:08:01Z,2017-07-16T08:32:56Z,closed,11,"Coursera, usage of dark pattern in software, trick wording, free 7-days trail","Coursera enrollment, font size small, interface interference","CourseEra, trick users buying paid products, trick wording, interface interference",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/sarahmeyer/brooklynjs.github.io/issues/1,Talk proposal on Dark Patterns: A WebVR game,https://github.com/sarahmeyer/brooklynjs.github.io/pull/1,"Dark Patterns is WebVR interactive narrative on the future of web surveillance. In this talk, Caroline & I will go over our process of conceptualizing and designing for VR game development, coding for WebVR, failures, frustrations and learnings in design & implementation.",2016-11-28T20:47:55Z,2016-11-28T20:48:56Z,closed,0,"dark pattern in WebVR, web surveillance, VR game",,"gaming, web surveillance, VR",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ember-cli/ember-cli/issues/4310,Run generators without creating tests,https://github.com/ember-cli/ember-cli/issues/4310,"I couldn't find a way to use generators without creating tests. Would anyone be opposed to this option?
",2015-06-18T21:03:19Z,2017-07-18T22:28:52Z,closed,16,"miscellaneous (""dark pattern"" to promote good developer behavior, testing generation)","code, confirm shaming for deleting test file","code testing, dark pattern to promote good behavior, confirmshaming",DPs in design coding,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/magento/magento2/issues/8163,Modern Cryptography for Magento (provided by libsodium),https://github.com/magento/magento2/issues/8163,"I'd like to propose the adoption of [sodium_compat](https://github.com/paragonie/sodium_compat) into the next release of Magento, so that everyone can enjoy modern cryptography with misuse-resistant interfaces.

### Preconditions

Before sodium_compat can be trusted, it must be audited by a competent third party. See https://github.com/paragonie/sodium_compat/issues/8 for the discussion about this initiative, and [this SitePoint article](https://www.sitepoint.com/what-would-you-pay-to-make-27-of-the-web-more-secure/) for the answers to the most obvious questions you may have as you're reading this.

(If anyone at Magento Inc. is interested in contributing towards getting sodium_compat audited, please get in touch either publicly at https://github.com/paragonie/sodium_compat/issues/8 or privately at `security at paragonie dot com`.)",2017-01-17T10:08:43Z,2017-02-03T17:47:04Z,closed,4,"Magento, usage of dark pattern, forced action, signup/log-in required","Magento, asks for log in after filling in ideas, obstruction","Magento, signup/log-in required, forced action",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/neutraltone/awesome-stock-resources/issues/130,Dryicons,https://github.com/neutraltone/awesome-stock-resources/pull/130,"added DryIcons to the Icons section
",2016-07-29T18:29:15Z,2016-08-31T10:29:36Z,closed,1,"DryIcons, usage of dark patterns",,DryIcons,DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/guardian/frontend/issues/14410,Promote comments with a sticky banner,https://github.com/guardian/frontend/pull/14410,"## What does this change?

Add a new AB test to measure the effect of a sticky banner prompting to join the discussion in the comments.

I'm trying not to be too annoying, so the banner is only visible while the main content is in view. (it doesn't appear immediately on page load and goes away when you scroll to related content, outbrain, comments, footer and so on).

Slightly contrary to what I just said, the banner is not dismissable, it comes in and goes away at its own will. Clicking on it takes you down to the comments without expanding it.

The related PR on discussion frontend is guardian/discussion-frontend#10
## What is the value of this and can you measure success?

People should interact more with comments (go to next page, toggle more comments, change sort order, stuff like that). We don't care much about posting (at least in this test).
## Does this affect other platforms - Amp, Apps, etc?

No

<!--
Run the AMP test suite with `make validate-amp`

You should also validate a specific page that your change affects by adding the amp query string along with the development hash: http://localhost:3000/sport/2016/aug/25/katie-ledecky-first-pitch-washington-nationals-bryce-harper?amp=1#development=1

The AMP validation results will appear in your console.
-->
## Screenshots

![out](https://cloud.githubusercontent.com/assets/680284/18708303/2548d968-7ff2-11e6-9d2f-f4620cf00d9e.gif)
",2016-09-21T11:26:14Z,2016-09-26T14:57:02Z,closed,10,"usage of dark pattern, nagging, sticky banner to promote comments","promoting comment and not letting user remove it, obstruction, interface intereference","sticky banner, comments, interface interference",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mozilla/bedrock/issues/4103,"Fix Bug 1264972, roll out winning version of plugin check page",https://github.com/mozilla/bedrock/pull/4103,"## Description

Rolls out the winning version of the plugin check page tests.
## Bugzilla

https://bugzilla.mozilla.org/show_bug.cgi?id=1264972
## Testing

This page has been in production for a while as one of the variations that was tested so, a check off the page in Fx and a look over the code changes should suffice.
## Checklist
- [ ] Requires l10n changes.
- [x] Related functional & integration tests passing.
",2016-04-29T11:57:46Z,2016-05-13T17:51:24Z,closed,17,"usage of dark pattern in software, newsletter sign up increasing","newsetter signup, security issue","newsletter signup, privacy issue",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Financial-Times/o-tracking/issues/51,Promise-based API,https://github.com/Financial-Times/o-tracking/issues/51,"Could we consider a Promise-based API for `page` and `event` please? It should use an existing implementation if present, rather than bundling a new one.
",2015-08-03T19:44:09Z,2016-01-28T16:27:58Z,closed,2,"prevention of dark pattern in open-source, API","not letting user add/remove to tracking, API","API, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/pwdo/FFC6-Call-For-Speakers/issues/21,Bad Boys of Design,https://github.com/pwdo/FFC6-Call-For-Speakers/issues/21,"# _Bad Boys of Design_
## About myself
- Name: Tajo Oja
- Country of Origin: Estonia
- Occupation & Company: Design Lead at Fraktal
- URL to my website: https://www.fraktal.co
- Contact: tajo@fraktal.co
## About my topic

You've all heard the age-old mantra of ""Good design saves the world"". I'll show you how that hippy talk will get you nowhere and how to lie, cheat and steal your way to the top. With the help of dark patterns, deceptive design and other deliciously evil tricks.

This is for all the soul-searching designers, disillusioned front-end devs and everyone else who's ever felt cheated on the web. We'll look at the great evil powers on the net (LinkedIn, Ryanair etc.) and compare them to the real world dark behemoths.
## Additional info
- I've spoken about design before at European conferences like ConversionSummit 2014, Refresh 2015 + countless of domestic conferences in Estonia.
- A few sample slides from the talk https://www.dropbox.com/s/fv8qyf0go1oogle/badboysofdesign%20abridged.pdf?dl=0
- I'd only request a travel budget, no speaking fee.
",2015-09-22T16:11:27Z,2015-11-07T15:23:12Z,closed,0,"dark pattern education, talk of ""bad boys of design""",shows how dp could be used in design,"dark pattern education, talk of ""bad boys of design""",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/guardian/frontend/issues/1607,CSS storage,https://github.com/guardian/frontend/pull/1607,"As discussed in thread #1168, this is a simple (proof-of-concept) asynchronous CSS loader that caches the response in localStorage for inline access on subsequent requests (which takes original inspiration from best practices by [Google and Bing](http://www.stevesouders.com/blog/2011/03/28/storager-case-study-bing-google/)) .

This is an attempt to reduce the second reflow we have as a result of placing the global CSS in the foot of the page for performance reasons.

**Please review and give feedback.**
### Notes:
- Only supported by _modern browsers_, everyone else gets a fallback link element in the foot.
- Stores CSS against the MD5 key, therefore deploys with new CSS will invalidate the cache. Potential to be useless if users jump between servers that have different CSS versions.
- Based on these [perf tests](http://jsperf.com/basket-js-versus-browser-cache/2) the browser cache is always _slightly_ faster than localStorage I/O reads, but we gain the speed back by doing this inline in the <head> rather than the foot of page, and prevent second reflow. 
- This can only be benchmarked properly in PROD using the visual timeline tools in WPT.
- Should it go behind a switch so we can benchmark more easily?

![Performance boost](https://i.chzbgr.com/maxW500/5047993600/hAD868BAF/)
",2013-09-17T09:00:33Z,2015-10-12T11:05:35Z,closed,8,not sure,"cookie consent, example",cookie consent,DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/mailpile/Mailpile/issues/822,Implement a fix for Gmail's crazy disabled IMAP,https://github.com/mailpile/Mailpile/issues/822,"Accessing Gmail via IMAP is by default turned off. A user must manually go to the settings of their ""Less Secure Apps"" section and enable it [http://google.com/settings/security/lesssecureapps](http://google.com/settings/security/lesssecureapps). This is a UX dark pattern, as it scares people from using standards compliant IMAP email clients out of fear!

![ux_gmail_less_secure_apps](https://cloud.githubusercontent.com/assets/48677/3936342/680e81d0-24a0-11e4-9810-5e95f147173a.png)

![ux_gmail_less_secure_apps_2](https://cloud.githubusercontent.com/assets/48677/3936343/6dbd2bfe-24a0-11e4-8053-03c6a2538d5d.png)

@BjarniRunar seems to think there is a technical work around but it will take development time. Other ideas are some user popup windows that explain how to do this to users!

Google© also nicely sends a warning email to the account owner filled with nice FUD and discourages people from using any non Google® products...

![gmail_blocking_other_email_accounts](https://cloud.githubusercontent.com/assets/48677/3942719/3c52a95e-2572-11e4-97c2-23f70564bd67.png)
",2014-08-15T17:32:49Z,2015-08-06T21:26:45Z,closed,9,"Gmail via IMAP (Internet Message Access Protocol) turned off by default, usage of dark pattern, preselection ","IMAP disabled, emotional manipulation, sneaking"," IMAP (Internet Message Access Protocol), Gmail, default, preselection",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/caelum/mamute/issues/165,Add ability to move logout link to user profile,https://github.com/caelum/mamute/pull/165,"As many websites are moving away from exposing the logout button too much, this pull request enables site owner to move the 'logout' button out of the main menu into the user profile.
",2015-05-23T11:41:52Z,2015-05-24T21:04:43Z,closed,1,"usage of dark pattern, log-out link out of profile, obstructions ","hiding logout button, sneaking, intereface interference","log-out issue, sneaking, obstruction",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/jxnblk/plangular/issues/55,Autoplay?,https://github.com/jxnblk/plangular/issues/55,"Is there an autoplay setting?

And thank you for creating this project. A really great player.
",2015-02-21T05:26:58Z,2015-03-28T17:48:43Z,closed,2,"prevention of dark pattern in software, autoplay setting","autoplay, example","autoplay setting, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/gorhill/uBlock/issues/272,New permissions,https://github.com/gorhill/uBlock/issues/272,"Noted in the [0.9.8.2](https://github.com/gorhill/uBlock/releases/tag/0.9.8.2) release that uBlock requires a new permission _""privacy""_. 

Is this warning related? _""Read and change all your data on websites you visit.""_?

![screen shot 2015-06-01 at 14 46 54](https://cloud.githubusercontent.com/assets/156303/7914181/4ba6eb84-086d-11e5-8410-f29fe360c6ac.png)
",2015-06-01T13:53:43Z,2015-06-04T00:38:25Z,closed,21,"uBlock, prevention of dark pattern, against dp, opt-out, Chrome's prefetching is dp",tools to avoid dp,"uBlock, opt-in/out, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/alphagov/finder-frontend/issues/120,Auto check checboxes,https://github.com/alphagov/finder-frontend/pull/120,"[yes this is a dark-pattern] We have decided to auto check checkboxes because we know from research that most users want to subscribe to both types of alert for the MHRA medical device alerts and drug alerts.
",2014-11-14T16:39:51Z,2014-11-14T17:48:22Z,closed,0,"Finder, usage of dark pattern in software, preselection, auto-check checkboxes, MHRA and drugs alert ","autocheck boxes, preselection","Finder, auto-check boxes, preselection",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/openfarmcc/OpenFarm/issues/112,Checkbox for Email Newsletter Consent on Signup Screen,https://github.com/openfarmcc/OpenFarm/issues/112,"And a way to auto-add the email to our Mailchimp account for those who keep the box checked.
",2014-08-29T01:31:33Z,2014-10-11T15:20:18Z,closed,3,"OpenFarm, Mailchimp, usage of dark pattern in software, preselection, auto-select checkbox, newsletter subscribtion ","checkbox for consent, opt-in instead of opt-out preferred, preselection","OpenFarm, Mailchimp, opt-in/out, cookie consent, auto-check boxes, preselection",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/deshack/melany/issues/218,Add license for third party software,https://github.com/deshack/melany/issues/218,"- Glyphicons
- wp_bootstrap_navwalker
- dark pattern from Twenty Fourteen
",2014-04-16T09:25:56Z,2014-08-02T11:03:49Z,closed,0,miscellaneous (dark pattern from Twenty Fourteen),,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ytdl-org/youtube-dl/issues/1674,--------------------,https://github.com/ytdl-org/youtube-dl/issues/1674,"---
",2013-10-28T10:18:07Z,2013-10-28T14:57:00Z,closed,4,,fix for dp?,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/joonas-fi/joonas.fi/issues/80,PayPal currency conversion dark pattern,https://github.com/joonas-fi/joonas.fi/issues/80,,2021-03-04T07:47:22Z,2021-03-04T07:47:22Z,open,0,PayPal currency conversion using dp,,"PayPal, currency conversion",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/frontendweekly/feeds/issues/4776,Little UX crimes: a collection of Dark Patterns in design,https://github.com/frontendweekly/feeds/issues/4776,[Little UX crimes: a collection of Dark Patterns in design](https://uxdesign.cc/little-ux-crimes-a-collection-of-dark-patterns-in-design-7783b75195e0) /,2020-06-12T01:47:04Z,2020-06-12T01:47:04Z,open,0,"Medium, blog post, dark pattern education, UX crimes, collection of DPs in design ",examples of dp,"Medium, UI/UX Design, dark pattern education",Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/bocoup/ccpa-authorized-agent/issues/28,Dark pattern in POA re: authority in case of incapacitation,https://github.com/bocoup/ccpa-authorized-agent/issues/28,"This optional statement in the POA is contradictory. Figure @dazzaji can take a look and that it's easiest to track progress here.

<img width=""749"" alt=""Screen Shot 2021-02-04 at 4 28 20 PM"" src=""https://user-images.githubusercontent.com/26640476/107152867-69db5900-6938-11eb-875f-af420d0607de.png"">


",2021-02-07T16:34:44Z,2021-02-08T16:42:25Z,open,1,"usage of dark pattern in software, dp in POA (power of attorney), trick wording, double-negation","select to NOT, confusing, obstruction","double negation, trick wording, POA (power of attorney)",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/theiaconf/CardSort/issues/33,Shedding Light on Dark Patterns: A Case Study on Digital Harms,https://github.com/theiaconf/CardSort/issues/33,,2021-04-09T17:32:54Z,2021-04-09T17:32:54Z,open,0,miscellaneous (Shedding Light on Dark Patterns: A Case Study on Digital Harms),,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/wingman-jr-addon/wingman_jr/issues/40,Research ways to get user image feedback,https://github.com/wingman-jr-addon/wingman_jr/issues/40,"-While maintaining privacy
-With easy-to-use, free tech
-And not enabling psychological dark patterns (e.g. now I'll submit all the pron)",2020-01-26T01:06:41Z,2023-09-16T01:43:36Z,open,7,prevention of dark pattern,avoiding psychological dp for feedback,"feedback, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ikedaosushi/tech-news/issues/29836,Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites (2019) (princeton.edu),https://github.com/ikedaosushi/tech-news/issues/29836,"Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites (2019) (princeton.edu)<br>
<br>
https://ift.tt/31WRFCk",2021-02-02T01:00:12Z,2021-02-02T01:00:12Z,open,0,"paper, documentation in dark pattern",defnitions and examples,"dark pattern education, documentation",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/soerface/template-python-package/issues/3,Fix license,https://github.com/soerface/template-python-package/issues/3,As it currently stands the template tricks the user in releasing their code under the MIT license. This is a dark pattern and should be remedied by removing the `LICENSE` file in the projects root directory.,2020-06-20T19:04:07Z,2020-07-25T22:55:46Z,open,1,"usage of dark pattern in coding, MIT license, coding releasing without noticing","MIT license, releasing code","MIT license, coding releasing without informing",DPs in design coding ,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/agent725/peer2product/issues/7,double nag screen on bankwire gateway,https://github.com/agent725/peer2product/issues/7,"Many users are used to clicking on 'Next' blindly. This makes for many unpaid orders, which then cannot be sent to the customer. A double-nag screen as 'dark pattern' will likely solve this problem.",2020-09-14T11:29:32Z,2020-09-14T11:31:10Z,open,1,"use dp to warning users in a good maner, double-nag screen, avoid wrong payment","bankwire gateaway, nagging to avoid unpaid orders","nagging, dark pattern to promote good behavior",DPs in design coding ,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/hackforla/expunge-assist/issues/410,[PAUSE STUFF] Determine Content accessibility needs,https://github.com/hackforla/expunge-assist/issues/410,"### Overview
Determine accessibility needs and make a plan to implement them. 

Can include for example word choice (A UX example would be: using deceptive design rather than ""dark pattern""), writing for screen readers, adding alt text, etc. 

See also Dev issue https://github.com/hackforla/expunge-assist/issues/487

Define Content accessibility goals. This issue follows up on UXR accessibility goals issue #959.  

When looking at this issue and starting again, please review and adapt below. 

### Action Items
- [ ] Initiate this discussion with Design to see how we can proceed together 
- [ ] Determine what accessibility needs users have and the tools needed
- [ ] Determine content accessibility recommendations
- [ ] Update content/writing guidelines with accessibility guidelines
- [ ] Update website and collaborate with any necessary teams

From other issue (now closed)
- [ ] Review accessibility standards and guidelines such as WCAG
- [ ] Brainstorm content accessibility goals in this [document ](https://docs.google.com/document/d/1QWZBCVfy64yKlDhyj2yPWhA1Jn03MDw1kof-hnScCD8/edit?pli=1#heading=h.o4imd8fnkgfn)
- [ ] Identify 3-4 accessibility goals for UXR accessibility research by 7/7

### Resources/Instructions 

From now closed issue:
- [ ] Read the [ADA Compliance Guide](https://www.ada.gov/pcatoolkit/chap5toolkit.htm).
- [ ] [The a11y project](https://www.a11yproject.com/)
- [ ] Issue #959 websites and resources
- [ ] [Web Content Accessibility Guidelines (WCAG) website](https://wcag.com/resource/what-is-wcag/)
- [ ] [W3C Web Accessibility Initiative (WAI)](https://www.w3.org/WAI/roles/writers/) 

See also https://github.com/hackforla/expunge-assist/issues/410
",2021-12-17T11:02:54Z,2024-03-11T20:28:57Z,open,2,"usage of dark pattern in design, content accessibility needs design","content accessibility, deceptive design over dp suggestion?","UI/UX Design, content accessibility",DPs in design coding ,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/element-hq/element-web/issues/16495,"Verify this login & verify this session - Skip button changes position in second ""are you sure"" dialog.",https://github.com/element-hq/element-web/issues/16495,"### Description

Verify this login & verify this session - Skip button changes position in second ""are you really sure"" dialog.
This is a problem, because it provides a confusing UX. This can be considered a dark pattern technique, not respectting the user's choice to skip, and steer the user to a developer desired option. Please respect the users.

### Steps to reproduce

1. Log out and log back in again
2. Try skipping the verification dialogs (login and verify)

Expected result: The app to respect my SKIP and proceed with unverified session and login
Actual result: an ""are you sure?"" nag dialog with shuffled Skip button to make it even harder to skip, no respect for the user choice

### Version information

Element version: 1.7.21
olm version: 3.2.1

For the web app:

- **Browser**: Chrome, Firefox latest February 2021
- **OS**: Windows 10 latest February 2021
- **URL**: https://app.element.io/#/login

![1](https://user-images.githubusercontent.com/7951056/108559462-a83f2380-72fb-11eb-95ae-3eab65041552.PNG)",2021-02-19T20:45:59Z,2023-09-22T07:17:38Z,open,1,"prevention of dark pattern in software, don't use verification for log-in/out","skip' button becomes 'are you sure?', nagging, obstruction, interface interference","nagging, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/vtex/typescript/issues/21,Check SonarQube,https://github.com/vtex/typescript/issues/21,"**What is to be discussed?**

SonarQube is a great static analysis tool that can detect dark-patterns, security flaws and elusive bugs way deeper than a linter can. We should check if we can use it in some of our projects.

Does someone have previous experience with it? I've only used it once.

**Additional context**

Reference: https://www.sonarsource.com/products/codeanalyzers/sonarjs.html",2020-01-16T16:52:24Z,2020-01-21T18:36:22Z,open,1,"SonarQube, dark pattern detection tools, usage of detection tool in project",SonarQube detection tool,"SonarQube, detection",DPs detection Tools,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/scalableminds/webknossos/issues/5234,Use protobufjs-cli package once it is released,https://github.com/scalableminds/webknossos/issues/5234,"Executing the tests locally (`yarn test`) fails, because protobufjs internally calls `npm install` to install some dependencies. In the past we've included these dependencies in our own `devDependencies` but this breaks without notice if protobufjs adds new dependencies and is confusing. They have [recognized this](https://github.com/protobufjs/protobuf.js/issues/716) as the dark pattern causing problems that it is and will release a separate protobufjs-cli package which includes these dependencies. Let's switch to that once it [becomes available](https://github.com/protobufjs/protobuf.js/pull/1535).",2021-03-03T17:45:47Z,2022-05-30T15:01:47Z,open,1,"protobufjs-cli package, usage of dark pattern in coding, dependencies-added automatically",adding dependencies makes it break,"protobufjs-cli package, dependencies-added automatically",DPs in design coding ,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/uchicago-computation-workshop/Fall2021/issues/10,11/18: Chetty,https://github.com/uchicago-computation-workshop/Fall2021/issues/10,"Comment below with a well-developed group question about the reading for this week's workshop.

One person can submit on the group's behalf and put the Group Name in the submission for credit.

Please post your question by Wednesday 11:59 PM, and upvote at least three of your peers' comments on Thursday prior to the workshop. You need to use 'thumbs-up' for your reactions to count towards 'top comments,' but you can use other emojis on top of the thumbs up.",2021-11-13T16:51:25Z,2021-11-18T17:11:37Z,open,29,"dark pattern education, course assignment, dark pattern-related discussion","examples and discussions, deletion process","dark pattern education, documentation",Papers/Docs/Sources,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/Nertivia/issues/issues/26,Chat streaks,https://github.com/Nertivia/issues/issues/26,"**Why:**
Keep the dms active

**Feature:**
Just like snap streaks but Nertivia streaks where both people have to talk within a 24 hour period(midnight to midnight UTC) then show some sort of trophy on the dms with your streak
",2021-05-23T21:18:39Z,2021-05-23T21:54:39Z,open,1,"deceptive design practices, chat streaks, Nertivia Streaks (users must interact within a 24-hour period to maintain a streak in DMs), Snapchat streaks","Nertivia, chat streaks, forced action","Nertivia, chat streaks, deceptive design practices",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/MSRHack2022/Hackathon/issues/5,Participation in MSR Hackathon: Team Magna Carta Libertatum,https://github.com/MSRHack2022/Hackathon/issues/5,"Participants: Kaylea Champion @kayleachampion, Wm Salt Hale @altsalt (both University of Washington)
Project: We propose to extend GrimoireLab as needed in order to support an analysis of software licensing. We seek to extract and organize license data collected from repositories, enrich it with category schemes developed by NGOs concerned with software licensing, and analyze the data longitudinally using both category-driven and text processing techniques. 

Potential research questions: 
How is license usage changing over time? 
Can we detect dark patterns such as license ratcheting through automated means?",2021-10-13T22:09:47Z,2021-11-23T19:51:00Z,open,6,"dark pattern detection in software license, automatic detect license ratcheting",way to avoid dp,"detection, avoid dark pattern",DPs detection Tools,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/w3ctag/security-questionnaire/issues/106,Add a section for preventing behaviours that are abusive toward users,https://github.com/w3ctag/security-questionnaire/issues/106,"At our virtual W3CTAG face-to-face, we reviewed a [related issue](https://github.com/w3ctag/ethical-web-principles/issues/25) on the [Ethical Web Principles](https://www.w3.org/2001/tag/doc/ethical-web-principles/).

We concluded that dark patterns are, in fact, a subset of abusive practices. We spend a lot of energy brainstorming abusive practices when we are doing design reviews, and we think it would be good for the web community if spec authors did something similar (before their work came to us).

The [Security and Privacy Self Questionnaire](https://w3ctag.github.io/security-questionnaire/) is our current mechanism to prompt spec authors to think through what might go wrong.

Our abuse scenarios weren't specifically security or privacy related: for example, if a site asks you to ""click okay to prove you're not a robot"", and your ""Okay"" actually grants permission for push notifications (without your knowledge) — that is an abusive behaviour, but not compromising your security or privacy.

We agreed that we would find a way to add the topic into the Questionnaire. This issue is to kick that off. ",2020-09-23T17:45:04Z,2023-10-16T00:32:06Z,open,3,"W3CTAG (W3C Technical Architecture Group - working group in w3c), prevention of dark pattern, follow ethical web principles",dp as abusive behavior ,"W3CTAG, avoid dark pattern, unethical principles",DPs prevention in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/metinkale38/prayer-times-android/issues/186,Drop google tracking from the app,https://github.com/metinkale38/prayer-times-android/issues/186,"I like this app because unlike Muslim Pro app, it is open source. The reason I would never install an app like Muslim Pro is its heavy tracking and [recently the selling of its users data](https://www.vice.com/en/article/g5bq89/muslim-pro-location-data-military-xmode), along with other numerous issues (ads, buisness model, privacy policy, dark patterns...etc) 

I noticed that this app is also using Google Analytics (according to this [report](https://reports.exodus-privacy.eu.org/en/reports/215168/#trackers)) which is worrying, especially for this kind of app. So I am suggesting dropping the use of such tracking tools especially from Google. If you want an alternative analytics tool, that is privacy-friendly and open-source check out [Plausible](https://plausible.io)  or  [Matomo](https://matomo.org). ",2021-11-28T10:08:30Z,2021-11-28T17:32:43Z,open,1,"Muslim Pro, Google tracking, prevention usage of dark pattern in software, users' data selling","Crashlytics, Muslim Pro, Google Analytics, data selling","Musllim Pro, Google tracking, privacy issue, data collection, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/gchenfc/sci-hub-now/issues/43,feature request: automatically redirect?,https://github.com/gchenfc/sci-hub-now/issues/43,"I do not allow 1st party cookies by default, and many predatory publishers have an annoying habit of redirecting to a `/action/cookieAbsent` URL when that is the case. This dark pattern is especially annoying when opening pages in new tabs, because the original URL is discarded (not accessible via the back button, for instance).

As such, a feature I would find very welcome is something like the [Old Reddit Redirect](https://github.com/tom-james-watson/old-reddit-redirect) extension, to automatically redirect.

Technically I'm not sure what a reasonable way of doing that would be, maybe redirect any URL that contains a DOI? Or have some sort of list of known hosts? I still thought it would be worth opening an issue to provoke a discussion.

Thanks for maintaining this extension!",2021-10-02T07:15:47Z,2021-10-02T21:24:54Z,open,4,"usage of dark pattern in software, consent cookie, new tab, automatic redirect, nagging","consent cookie, new tab, obstruction, nagging","cookie consent, new tab, automatic redirect, naggingg",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/AletheiaWareLLC/bcfynego/issues/2,Registration Progress Bar Sticks at 0% Until Complete,https://github.com/AletheiaWareLLC/bcfynego/issues/2,"Reported by @andydotxyz when registering the progress bar does not increment correctly, instead it sticks at 0% until complete.

I suspect this is due to the first operation (generating RSA 4096bit key pair) taking a much longer time than the others. Unfortunately the RSA generation doesn't provide a callback to get incremental progress. Perhaps an infinite progress bar would be better?",2021-03-30T16:05:30Z,2021-04-09T15:34:46Z,open,2,"deceptive design practices, progress bar sticks to 0% until complete, infinite progress bar to ",infinite progress bar to show completion,"infinite progress bar, deceptive design practices",DPs examples/definitions,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/headllines/hackernews-weekly/issues/57,Hacker News Weekly Top 10 @2021-05-10,https://github.com/headllines/hackernews-weekly/issues/57,"1. **[Hosting SQLite databases on GitHub Pages or any static file hoster](https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/)**
1806 points by [phiresky](https://news.ycombinator.com/user?id=phiresky) 1 week ago | [244 comments](https://news.ycombinator.com/item?id=27016630)

2. **[Instagram ads Facebook won't show you](https://signal.org/blog/the-instagram-ads-you-will-never-see)**
1227 points by [HieronymusBosch](https://news.ycombinator.com/user?id=HieronymusBosch) 5 days ago | [175 comments](https://news.ycombinator.com/item?id=27040470)

3. **[LiveLeak shuts down after 15 years online](https://techstartups.com/2021/05/05/liveleak-shuts-15-years-online/)**
1014 points by [ro_bit](https://news.ycombinator.com/user?id=ro_bit) 3 days ago | [669 comments](https://news.ycombinator.com/item?id=27058178)

4. **[Crazy New Ideas](http://paulgraham.com/newideas.html)**
886 points by [razin](https://news.ycombinator.com/user?id=razin) 3 days ago | [761 comments](https://news.ycombinator.com/item?id=27061789)

5. **[I’ve had the same supper for 10 years](https://www.theguardian.com/lifeandstyle/2021/apr/16/experience-ive-had-the-same-supper-for-10-years)**
854 points by [pumpkinhead](https://news.ycombinator.com/user?id=pumpkinhead) 2 days ago | [720 comments](https://news.ycombinator.com/item?id=27082522)

6. **[Please fix the AWS free tier before somebody gets hurt](https://cloudirregular.substack.com/p/please-fix-the-aws-free-tier-before)**
832 points by [forrestbrazeal](https://news.ycombinator.com/user?id=forrestbrazeal) 5 days ago | [438 comments](https://news.ycombinator.com/item?id=27044371)

7. **[ClearURLs – automatically remove tracking elements from URLs](https://github.com/ClearURLs/Addon/)**
800 points by [stanislavb](https://news.ycombinator.com/user?id=stanislavb) 4 days ago | [304 comments](https://news.ycombinator.com/item?id=27047243)

8. **[Request for comments regarding topics to be discussed at Dark Patterns workshop](https://www.regulations.gov/document/FTC-2021-0019-0001/comment)**
768 points by [sincerely](https://news.ycombinator.com/user?id=sincerely) 1 week ago | [529 comments](https://news.ycombinator.com/item?id=27017041)

9. **[Back in 1993, I was taking a number theory class](https://twitter.com/EricLengyel/status/1389106103179378689)**
722 points by [renameme](https://news.ycombinator.com/user?id=renameme) 6 days ago | [213 comments](https://news.ycombinator.com/item?id=27031242)

10. **[HTML Tips (2020)](https://markodenic.com/posts/html-tips/)**
683 points by [web_master](https://news.ycombinator.com/user?id=web_master) 4 days ago | [133 comments](https://news.ycombinator.com/item?id=27054348)

",2021-05-10T01:05:40Z,2021-05-10T01:05:41Z,open,0,"Hacker News Daily, resources of dark pattern, government regulation, FTC, workshop discussion",,documentation,Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/KhronosGroup/SPIRV-Tools/issues/4146,Suggestion: warning on missing --target-env to spirv-val,https://github.com/KhronosGroup/SPIRV-Tools/issues/4146,"This may not be desired, but I wasted a couple of hours today tracking down a bug that would have been caught much sooner had I remembered that vulkan environment specific validation is only done if you pass `--target-env vulkan1.x`.

Would it be possible to soft warn (i.e. not fail but print a message) if you invoke `spirv-val` with no `--target-env` at all? Telling the user that they may missing some important validation in that case. If someone wants to validate without respect to a client API they can still explicitly specify `--target-env spv1.x`, but usually SPIR-V is intended for one of the client APIs.

It feels like a bit of a dark pattern to silently disable validation that the user probably cares about. We can't guess which API they will use (though I'd argue that defaulting to vulkan from the start would be good that ship has sailed) but I think we should at least tell the user that the validator probably isn't catching everything.",2021-02-19T14:33:24Z,2023-06-16T16:44:14Z,open,0,"usage of dark pattern in coding, sliently disable validation, --target-env to spirv-val","disabling validation without warning, obstruction, sneaking","disable validation, sneaking",DPs in design coding ,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/headllines/hackernews-daily/issues/289,Hacker News Daily Top 10 @2021-05-03,https://github.com/headllines/hackernews-daily/issues/289,"1. **[Bob Cassette Rewinder: Hacking Detergent DRM](https://github.com/dekuNukem/bob_cassette_rewinder)**
994 points by [dekuNukem](https://news.ycombinator.com/user?id=dekuNukem) 14 hours ago | [324 comments](https://news.ycombinator.com/item?id=27013880)

2. **[Hosting SQLite databases on GitHub Pages or any static file hoster](https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/)**
726 points by [phiresky](https://news.ycombinator.com/user?id=phiresky) 7 hours ago | [117 comments](https://news.ycombinator.com/item?id=27016630)

3. **[Request for comments regarding topics to be discussed at Dark Patterns workshop](https://www.regulations.gov/document/FTC-2021-0019-0001/comment)**
533 points by [sincerely](https://news.ycombinator.com/user?id=sincerely) 7 hours ago | [346 comments](https://news.ycombinator.com/item?id=27017041)

4. **[Bringing GNU Emacs to Native Code (2020)](https://arxiv.org/abs/2004.02504)**
346 points by [textread](https://news.ycombinator.com/user?id=textread) 1 day ago | [122 comments](https://news.ycombinator.com/item?id=27011013)

5. **[Ignoring Docker updates is a paid feature now?](https://twitter.com/moyix/status/1388586550682861568)**
249 points by [andreareina](https://news.ycombinator.com/user?id=andreareina) 14 hours ago | [185 comments](https://news.ycombinator.com/item?id=27013865)

6. **[The Linux kernel has surpassed one million git commits](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/)**
243 points by [calmingsolitude](https://news.ycombinator.com/user?id=calmingsolitude) 11 hours ago | [113 comments](https://news.ycombinator.com/item?id=27014732)

7. **[California appeals court finds Amazon responsible for 3rd party sellers products](https://www.theverge.com/2021/5/1/22414185/california-appeals-court-amazon-marketplace-responsible-third-party-hoverboard)**
241 points by [MBCook](https://news.ycombinator.com/user?id=MBCook) 1 day ago | [79 comments](https://news.ycombinator.com/item?id=27010976)

8. **[What3Words – The Algorithm](https://cybergibbons.com/security-2/what3words-the-algorithm/)**
222 points by [ykat7](https://news.ycombinator.com/user?id=ykat7) 11 hours ago | [133 comments](https://news.ycombinator.com/item?id=27015046)

9. **[What's Salesforce? (2019)](https://retool.com/blog/salesforce-for-engineers/)**
214 points by [eddywebs](https://news.ycombinator.com/user?id=eddywebs) 7 hours ago | [127 comments](https://news.ycombinator.com/item?id=27016600)

10. **[AirTag Teardown Part One: Yeah, This Tracks](https://www.ifixit.com/News/50145/airtag-teardown-part-one-yeah-this-tracks)**
193 points by [tosh](https://news.ycombinator.com/user?id=tosh) 10 hours ago | [170 comments](https://news.ycombinator.com/item?id=27015416)

",2021-05-03T00:33:20Z,2021-05-03T00:33:20Z,open,0,"Hacker News Daily, resources of dark pattern, government regulation, FTC, workshop discussion",,documentation,Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/headllines/hackernews-daily/issues/343,Hacker News Daily Top 10 @2021-06-26,https://github.com/headllines/hackernews-daily/issues/343,"1. **[Nvidia Canvas](https://www.nvidia.com/en-gb/studio/canvas/)**
557 points by [forgingahead](https://news.ycombinator.com/user?id=forgingahead) 21 hours ago | [172 comments](https://news.ycombinator.com/item?id=27626610)

2. **[Blood test that finds 50 types of cancer is accurate enough to be rolled out](https://www.theguardian.com/society/2021/jun/25/blood-test-that-finds-50-types-of-cancer-is-accurate-enough-to-be-rolled-out)**
554 points by [kieranmaine](https://news.ycombinator.com/user?id=kieranmaine) 14 hours ago | [362 comments](https://news.ycombinator.com/item?id=27628740)

3. **[I was let go for refusing to deploy a dark pattern](https://www.peachesnstink.com/p/6pJoCuczOj8cxCUQDMlfQv)**
533 points by [codingclaws](https://news.ycombinator.com/user?id=codingclaws) 12 hours ago | [448 comments](https://news.ycombinator.com/item?id=27629543)

4. **[“Please don't waste maintainers' time on your KPI grabbing patches”](https://lkml.org/lkml/2021/6/18/153)**
475 points by [belter](https://news.ycombinator.com/user?id=belter) 12 hours ago | [234 comments](https://news.ycombinator.com/item?id=27629366)

5. **[User Inyerface – A worst-practice UI experiment](https://userinyerface.com/)**
437 points by [andyjih_](https://news.ycombinator.com/user?id=andyjih_) 4 hours ago | [119 comments](https://news.ycombinator.com/item?id=27635310)

6. **[Open Source Farming Robot](https://farm.bot/)**
363 points by [antoinec](https://news.ycombinator.com/user?id=antoinec) 16 hours ago | [197 comments](https://news.ycombinator.com/item?id=27628101)

7. **[As the Pandemic Recedes, Millions of Workers Are Saying 'I Quit'](https://www.npr.org/2021/06/24/1007914455/as-the-pandemic-recedes-millions-of-workers-are-saying-i-quit)**
319 points by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) 13 hours ago | [290 comments](https://news.ycombinator.com/item?id=27629094)

8. **[Hacker reveals smart meters are spilling secrets about the Texas snowstorm](https://www.dailydot.com/debug/hacker-smart-meter-texas-snowstorm/)**
255 points by [certifiedloud](https://news.ycombinator.com/user?id=certifiedloud) 10 hours ago | [174 comments](https://news.ycombinator.com/item?id=27630651)

9. **[Go 1.17 is deprecating the traditional use of 'go get'](https://utcc.utoronto.ca/~cks/space/blog/programming/GoAndDeprecatingGoGet)**
249 points by [nitinreddy88](https://news.ycombinator.com/user?id=nitinreddy88) 10 hours ago | [198 comments](https://news.ycombinator.com/item?id=27630625)

10. **[Bflat: C# as you know it but with Go-like tooling](https://github.com/MichalStrehovsky/bflat)**
234 points by [tate](https://news.ycombinator.com/user?id=tate) 6 hours ago | [108 comments](https://news.ycombinator.com/item?id=27634456)

",2021-06-26T00:18:40Z,2021-06-26T00:18:40Z,open,0,"Hacker News Daily, resources of dark pattern, commentcastles discussion",fired for not deploying dp,"discussion, avoid dark pattern",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/headllines/hackernews-daily/issues/196,Hacker News Daily Top 10 @2021-01-31,https://github.com/headllines/hackernews-daily/issues/196,"1. **[Element (Matrix chat app) suspended from the Google Play Store](https://twitter.com/element_hq/status/1355290296947499013)**
1749 points by [redsolver](https://news.ycombinator.com/user?id=redsolver) 1 day ago | [561 comments](https://news.ycombinator.com/item?id=25964226)

2. **[Website Fingerprinting on Early QUIC Traffic](https://arxiv.org/abs/2101.11871)**
291 points by [pueblito](https://news.ycombinator.com/user?id=pueblito) 8 hours ago | [93 comments](https://news.ycombinator.com/item?id=25969886)

3. **[Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites (2019)](https://webtransparency.cs.princeton.edu/dark-patterns/)**
277 points by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) 11 hours ago | [88 comments](https://news.ycombinator.com/item?id=25968531)

4. **[Siliconpr0n: High Resolution Chip Maps](https://siliconpr0n.org/map/)**
276 points by [lelf](https://news.ycombinator.com/user?id=lelf) 23 hours ago | [76 comments](https://news.ycombinator.com/item?id=25964865)

5. **[Offline Algorithms in Low-Frequency Trading](https://queue.acm.org/detail.cfm?id=3448307)**
272 points by [hypomnemata](https://news.ycombinator.com/user?id=hypomnemata) 12 hours ago | [72 comments](https://news.ycombinator.com/item?id=25968348)

6. **[Apple Silicon M1 supports “billion of colors” a.k.a. HDR 10-bit output](https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/)**
233 points by [singhkays](https://news.ycombinator.com/user?id=singhkays) 1 day ago | [193 comments](https://news.ycombinator.com/item?id=25964501)

7. **[University of Leicester firing all pure math faculty](https://twitter.com/wtgowers/status/1355184163020804099)**
225 points by [rfurmani](https://news.ycombinator.com/user?id=rfurmani) 15 hours ago | [198 comments](https://news.ycombinator.com/item?id=25967382)

8. **[""ERROR: could not open temporary file"" after upgrade to Mac OS Big Sur](https://github.com/PostgresApp/PostgresApp/issues/610)**
220 points by [devops000](https://news.ycombinator.com/user?id=devops000) 15 hours ago | [234 comments](https://news.ycombinator.com/item?id=25967594)

9. **[Show HN: Collection of deep learning implementations with side-by-side notes](https://nn.labml.ai)**
220 points by [vpj](https://news.ycombinator.com/user?id=vpj) 14 hours ago | [14 comments](https://news.ycombinator.com/item?id=25967641)

10. **[New Xquartz release with native Apple Silicon support](https://www.mail-archive.com/xquartz-dev@lists.macosforge.org/msg01027.html)**
212 points by [ismiseted](https://news.ycombinator.com/user?id=ismiseted) 15 hours ago | [37 comments](https://news.ycombinator.com/item?id=25967442)

",2021-01-31T00:23:26Z,2021-01-31T00:23:27Z,open,0,"Hacker News Daily, resources of dark pattern, docs/papers",examples with shopping websites,"e-commerce, documentation",Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/lensapp/lens/issues/3697,Lens have some tracking and tries to phone a couple of third party even at first launch,https://github.com/lensapp/lens/issues/3697,"**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Launch Lens on mac with Little Snitch enabled
2. Noticed the many popups from services it tries to call

**Expected behavior**
Many of those services shouldn't be phoned for just displaying links, nor should the telemetry send anything before the user had the time to express its consent or not at first launch, that second part especially is a requirement for GDPR.

**Screenshots**
This is from just a first launch with absolutely nothing done with the application yet:
![Screenshot 2021-08-30 at 12 14 05](https://user-images.githubusercontent.com/709500/131324263-d14b91a6-853a-4856-a594-ebc5009dfedf.png)


**Environment (please complete the following information):**
- Lens Version: 5.1.3
- OS: OSX
- Installation method (e.g. snap or AppImage in Linux): Homebrew Cask
",2021-08-30T10:15:40Z,2022-11-02T12:51:13Z,open,6,"regulation, gdpr compliance, users explicitly consent with telemetry send, data collection consent","Lens, avoid dp to collect data","GDPR, data collection, regulation, Teletmetry","DPs related regulation, DPs prevention in software",,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/sybrew/the-seo-framework/issues/581,Add automated (custom) overlay to social images,https://github.com/sybrew/the-seo-framework/issues/581,"Hi everyone

It would be nice, if SEO framework would be able to automatically generate the og-image for a blogpost based on the selected feature image for that post + an ""overlay image"" (i.e. a partly transparent png file).

Thank you very much for the great plugin!",2021-05-10T15:07:47Z,2022-07-17T22:30:38Z,open,6,"overlay dark pattern, fake ""play"" button, ","overlay, fake ""play"" button, manipulation","overlay, fake ""play"" button, UI/UX Design",DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/jeremy21212121/trivia-frontend/issues/9,[feature] store stats to enable cool visualizations and other features,https://github.com/jeremy21212121/trivia-frontend/issues/9,"We should be storing results to enable displaying neat visualizations (something to do offline until full offline play #6 is enabled) as well as other possible features in the future.

Examples of visualizations include avg score per category/difficulty/etc, line graph of performance over time, etc.

Another feature it could enable is referencing past performance after a guess. For example, the results view could display 'Congrats! You got that question on your second try!', 'Third time's the charm!' or 'Ouch! You got that one right last time. Don't you remember?'

In the meantime, we could start storing results client-side with indexedDB or a library like `nedb` that will use indexedDB if available otherwise fall back to an in-memory store. That way we will have previous results to draw from when the subsequent features are ready.

## What should be stored? ##

With each guess, we should store:

- The unique question id
- The date/time
- The result (right or wrong)
- The difficulty
- The category

That works out to ~100 bytes per question stored, assuming we make no effort to use an efficient representation (ie. storing booleans/numbers as strings, which we won't be doing). So we should have no trouble staying under the data storage limits for PWAs (~20-50mb)",2020-02-25T07:37:05Z,2020-02-27T04:02:03Z,open,1,"prevention of dark pattern in design, gaming, no usage of leaderboard/other gimmicks",avoiding adding leader board,"gaming, avoid leaderboard, UI/UX design, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/crystal-lang/crystal-book/issues/448,Improve site (hosting + analytics),https://github.com/crystal-lang/crystal-book/issues/448,"[I was questioning myself about the usefulness of Google Analytics](https://github.com/crystal-lang/crystal-book/pull/437#issuecomment-742131353), then thought the site could also be on GitHub Pages instead of S3.

This can be unrelated topics, but not that much because GH Pages provides basic stats.

The reasons to remove/switch from Google Analytics:
- likely most of us have ad-blockers and/or anti-privacy blockers, so GA is not accurate.
- basic analytics can already be achieved by parsing logs
- are the advanced feature provided by GA really used?

Switching to GitHub Pages provides this benefits:
- simpler/more secure, by not having to deal with Amazon IAM/secrets in this repo for deployment.
- cheaper, S3 + CloudFront are already quite cheap but GH Pages is free.
- built-in basic stats to know the most popular pages and where the traffic comes from.
- little bonus: independence from the AWS owner (owned by the Crystal org or Manas?) 

As a disadvantage, this means using a subdomain instead of the current sub-bolder. According to https://blog.cloudflare.com/subdomains-vs-subdirectories-best-practices-workers-part-1/, the SEO will be similar.",2020-12-11T15:19:05Z,2021-11-24T17:19:05Z,open,8,"miscellaneous (gdpr compliance, explictly user approval before tracking technology, no dark pattern)","GDPR, refuse button, nagging","GDPR, avoid dark pattern, regulation","DPs related regulation, DPs prevention in software",,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/117,Daily Hacker News 27-12-2020,https://github.com/xueyuanl/daily-hackernews/issues/117,"
# Daily Hacker News
  
1. [**Fun with IP address parsing**](https://blog.dave.tf/post/ip-addr-parsing/) `blog.dave.tf` [`comments`](https://news.ycombinator.com/item?id=25545967)  
2. [**What If You Could Do It All Over?**](https://www.newyorker.com/magazine/2020/12/21/what-if-you-could-do-it-all-over) `www.newyorker.com` [`comments`](https://news.ycombinator.com/item?id=25547448)  
3. [**API pagination design**](https://solovyov.net/blog/2020/api-pagination-design/) `solovyov.net` [`comments`](https://news.ycombinator.com/item?id=25547716)  
4. [**California Public Utilities Commission fired director who exposed missing $200M**](https://www.propublica.org/article/she-noticed-200-million-missing-then-she-was-fired) `www.propublica.org` [`comments`](https://news.ycombinator.com/item?id=25548938)  
5. [**Starship / Super Heavy**](https://www.faa.gov/space/stakeholder_engagement/spacex_starship/starship_super_heavy/) `www.faa.gov` [`comments`](https://news.ycombinator.com/item?id=25547438)  
6. [**Apple Silicon M1 Die-Shots**](https://www.techinsights.com/blog/two-new-apple-socs-two-market-events-apple-a14-and-m1) `www.techinsights.com` [`comments`](https://news.ycombinator.com/item?id=25547151)  
7. [**A review of Dominion, 4000 plays later**](https://dominionstrategy.com/2012/05/29/dominionreview/) `dominionstrategy.com` [`comments`](https://news.ycombinator.com/item?id=25542058)  
8. [**I reverse engineered Google Docs to play back any document's keystrokes (2014)**](http://features.jsomers.net/how-i-reverse-engineered-google-docs/) `features.jsomers.net` [`comments`](https://news.ycombinator.com/item?id=25545361)  
9. [**Lost nuclear device atop of Nanda Devi**](https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device) `www.livehistoryindia.com` [`comments`](https://news.ycombinator.com/item?id=25547123)  
10. [**Raycast (YC W20) Is Hiring Fullstack Software Engineers (Remote, UTC ± 3 Hours)**](https://raycast.com/jobs/software-engineer-fullstack) `raycast.com` [`comments`](https://news.ycombinator.com/item?id=25549396)  
11. [**Print this file, your printer will jam (2008)**](https://nedbatchelder.com/blog/200811/print_this_file_your_printer_will_jam.html) `nedbatchelder.com` [`comments`](https://news.ycombinator.com/item?id=25543386)  
12. [**The Future of RTS**](https://docs.google.com/document/d/1RIAmHaInU_tb-Xv9EMZ6SP2zLE50t91zI2ThINwCHHo/edit) `docs.google.com` [`comments`](https://news.ycombinator.com/item?id=25547450)  
13. [**Run More Stuff in Docker**](https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/) `jonathan.bergknoff.com` [`comments`](https://news.ycombinator.com/item?id=25547205)  
14. [**Oxford and AstraZeneca Covid-19 vaccine: ""potency miscalculation""**](https://www.reuters.com/article/us-health-coronavirus-britain-vaccine-sp-idUKKBN28Y0XU) `www.reuters.com` [`comments`](https://news.ycombinator.com/item?id=25548342)  
15. [**Mastering Pinterest SEO: An insider's guide**](https://blog.aesthetic.com/blog/pinterest-guide/) `blog.aesthetic.com` [`comments`](https://news.ycombinator.com/item?id=25546430)  
16. [**5 Books That Changed My Business**](https://capitalandgrowth.org/answers/Article/3516328/5-Books-That-Changed-My-Business) `capitalandgrowth.org` [`comments`](https://news.ycombinator.com/item?id=25549435)  
17. [**Kit FUI – User interfaces found in films**](https://www.saji8k.com/kit-fui/) `www.saji8k.com` [`comments`](https://news.ycombinator.com/item?id=25547352)  
18. [**One red paperclip**](https://en.wikipedia.org/wiki/One_red_paperclip) `en.wikipedia.org` [`comments`](https://news.ycombinator.com/item?id=25539433)  
19. [**Seasonal Spirals**](https://observablehq.com/@yurivish/seasonal-spirals) `observablehq.com` [`comments`](https://news.ycombinator.com/item?id=25547862)  
20. [**Types of Dark Patterns**](https://darkpatterns.org/types-of-dark-pattern.html) `darkpatterns.org` [`comments`](https://news.ycombinator.com/item?id=25547708)  
21. [**Give your Mac imaginary unlimited storage thanks to Disk Utility’s bug**](https://eclecticlight.co/2020/12/26/give-your-mac-imaginary-unlimited-storage-thanks-to-disk-utilitys-bug/) `eclecticlight.co` [`comments`](https://news.ycombinator.com/item?id=25544835)  
22. [**Show HN: CodeSwing – A CodePen-like interactive playground, built into VS Code**](https://github.com/codespaces-contrib/codeswing) `github.com` [`comments`](https://news.ycombinator.com/item?id=25545153)  
23. [**Partial order and non-Boolean logic**](https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html) `wordsandbuttons.online` [`comments`](https://news.ycombinator.com/item?id=25545543)  
24. [**Christmas Is Bird-Counting Season**](https://fivethirtyeight.com/features/christmas-is-bird-counting-season-for-60000-americans/) `fivethirtyeight.com` [`comments`](https://news.ycombinator.com/item?id=25532168)  
25. [**Photocatalyst splits water into H and O2 at quantum efficiency near 100%**](https://fuelcellsworks.com/news/photocatalyst-that-can-split-water-into-hydrogen-and-oxygen-at-a-quantum-efficiency-close-to-100/) `fuelcellsworks.com` [`comments`](https://news.ycombinator.com/item?id=25542505)",2020-12-27T09:10:20Z,2020-12-27T09:10:20Z,open,0,"Hacker News Daily, resources of dark pattern, DP website, type of DPs",,documentation,Papers/Docs/Sources,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/441,Daily Hacker News 19-11-2021,https://github.com/xueyuanl/daily-hackernews/issues/441,"
# Daily Hacker News
  
1. [**The Spiral Staircase Myth (2020)**](https://triskeleheritage.triskelepublishing.com/mediaeval-mythbusting-blog-2-the-man-who-invented-the-spiral-staircase-myth/) `triskeleheritage.triskelepublishing.com` [`comments`](https://news.ycombinator.com/item?id=29274875)  
2. [**80386DX ISA single board microcomputer**](https://alexandrugroza.ro/microelectronics/system-design/isa-80386dx-sbmc/index.html) `alexandrugroza.ro` [`comments`](https://news.ycombinator.com/item?id=29273829)  
3. [**SerenityOS demo at Handmade Seattle 2021 [video]**](https://media.handmade-seattle.com/serenityos/) `media.handmade-seattle.com` [`comments`](https://news.ycombinator.com/item?id=29270776)  
4. [**Fragment of lost 12th-century epic poem found in another book’s binding**](https://www.theguardian.com/books/2021/nov/18/fragment-of-lost-12th-century-epic-poem-found-in-another-books-binding) `www.theguardian.com` [`comments`](https://news.ycombinator.com/item?id=29274241)  
5. [**Google Play permitting alternative billing systems for users in South Korea**](https://developers-kr.googleblog.com/2021/11/enabling-alternative-billing-in-korea-en.html) `developers-kr.googleblog.com` [`comments`](https://news.ycombinator.com/item?id=29272923)  
6. [**Cracking the Adventure Time Cipher (2016)**](https://aaronrandall.com/blog/cracking-the-adventure-time-cipher/) `aaronrandall.com` [`comments`](https://news.ycombinator.com/item?id=29238979)  
7. [**Acquisition of chess knowledge in AlphaZero**](https://en.chessbase.com/post/acquisition-of-chess-knowledge-in-alphazero) `en.chessbase.com` [`comments`](https://news.ycombinator.com/item?id=29272000)  
8. [**Where is Ruby Headed in 2021?**](https://bignerdranch.com/blog/where-is-ruby-headed-in-2021/) `bignerdranch.com` [`comments`](https://news.ycombinator.com/item?id=29272682)  
9. [**Solar-driven water splitting at 13.8% solar-to-hydrogen efficiency**](https://pubs.acs.org/doi/10.1021/acssuschemeng.1c03565) `pubs.acs.org` [`comments`](https://news.ycombinator.com/item?id=29269596)  
10. [**Stacker (YC S20) Is Hiring Across Engineering**](https://www.stackerhq.com/careers#job-listing) `www.stackerhq.com` [`comments`](https://news.ycombinator.com/item?id=29274544)  
11. [**Google SAPI: Generate sandboxes for C/C++ libraries automatically**](https://github.com/google/sandboxed-api) `github.com` [`comments`](https://news.ycombinator.com/item?id=29273530)  
12. [**HomeBrew Computers Web-Ring**](https://www.homebrewcpuring.org/) `www.homebrewcpuring.org` [`comments`](https://news.ycombinator.com/item?id=29272595)  
13. [**Duff’s Device in 2021**](https://belaycpp.com/2021/11/18/duffs-device-in-2021/) `belaycpp.com` [`comments`](https://news.ycombinator.com/item?id=29272953)  
14. [**Summer of ’59:  the practical side of the 1559 papal conclave**](https://www.historytoday.com/archive/review/summer-59) `www.historytoday.com` [`comments`](https://news.ycombinator.com/item?id=29262275)  
15. [**Open-Source Plastic Scanner**](https://plasticscanner.com/) `plasticscanner.com` [`comments`](https://news.ycombinator.com/item?id=29269584)  
16. [**A concept that took hold in the ’70s haunted everything from seat belts to masks**](https://slate.com/technology/2021/11/risk-compensation-debunked-masks-rapid-tests-vaccines-safety.html) `slate.com` [`comments`](https://news.ycombinator.com/item?id=29238655)  
17. [**If You’re So Smart, Why Aren’t You Rich?**](https://www.technologyreview.com/2018/03/01/144958/if-youre-so-smart-why-arent-you-rich-turns-out-its-just-chance/) `www.technologyreview.com` [`comments`](https://news.ycombinator.com/item?id=29275083)  
18. [**Intrepid robot is the Wall-E of the deep sea**](https://www.wired.com/story/this-intrepid-robot-is-the-wall-e-of-the-deep-sea/) `www.wired.com` [`comments`](https://news.ycombinator.com/item?id=29240108)  
19. [**Elicit**](https://elicit.org) `elicit.org` [`comments`](https://news.ycombinator.com/item?id=29262357)  
20. [**Spy camera detection using smartphone time-of-flight sensors**](https://dl.acm.org/doi/10.1145/3485730.3485941) `dl.acm.org` [`comments`](https://news.ycombinator.com/item?id=29267168)  
21. [**Debugging a weird 'file not found' error**](https://jvns.ca/blog/2021/11/17/debugging-a-weird--file-not-found--error/) `jvns.ca` [`comments`](https://news.ycombinator.com/item?id=29258967)  
22. [**Show HN: I made a drag and drop website builder that works on mobile**](https://straw.page) `straw.page` [`comments`](https://news.ycombinator.com/item?id=29270909)  
23. [**Things you are allowed to do, academic edition**](https://bastian.rieck.me/blog/posts/2021/things/) `bastian.rieck.me` [`comments`](https://news.ycombinator.com/item?id=29267982)  
24. [**I analyzed SaaS billing dark patterns**](https://quolum.com/blog/saas/i-analyzed-saas-billing-dark-patterns/) `quolum.com` [`comments`](https://news.ycombinator.com/item?id=29255445)  
25. [**TensorFlow Graph Neural Networks**](https://blog.tensorflow.org/2021/11/introducing-tensorflow-gnn.html) `blog.tensorflow.org` [`comments`](https://news.ycombinator.com/item?id=29268780)",2021-11-19T09:06:52Z,2021-11-19T09:06:52Z,open,0,"Hacker News Daily, resources of dark pattern, doc",,documentation,"Papers/Docs/Sources, DPs examples/definitions",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/268,Daily Hacker News 30-05-2021,https://github.com/xueyuanl/daily-hackernews/issues/268,"
# Daily Hacker News
  
1. [**Amazon Refused to Refund $7k After Shipping an Empty Box Instead of a Sony A1**](https://fstoppers.com/news/amazon-refused-refund-7000-after-shipping-empty-box-instead-sony-a1-564979) `fstoppers.com` [`comments`](https://news.ycombinator.com/item?id=27331075)  
2. [**Trials begin on lozenge that rebuilds tooth enamel**](https://dental.washington.edu/trials-begin-on-lozenge-that-rebuilds-tooth-enamel/) `dental.washington.edu` [`comments`](https://news.ycombinator.com/item?id=27328663)  
3. [**“Computer science is not about computers”**](https://quoteinvestigator.com/2021/04/02/computer-science/) `quoteinvestigator.com` [`comments`](https://news.ycombinator.com/item?id=27330400)  
4. [**Photographer Charles Ebbets takes iconic photo “Lunch atop a skyscraper” (1932)**](https://www.reddit.com/r/interestingasfuck/comments/nn4q4j/heres_a_photo_of_the_photographer_charles_c/) `www.reddit.com` [`comments`](https://news.ycombinator.com/item?id=27324888)  
5. [**All the best engineering advice I stole from non-technical people (2019)**](https://bellmar.medium.com/all-the-best-engineering-advice-i-stole-from-non-technical-people-eb7f90ca2f5f) `bellmar.medium.com` [`comments`](https://news.ycombinator.com/item?id=27330031)  
6. [**PolarDB, yet another open source database system based on PostgreSQL**](https://github.com/alibaba/PolarDB-for-PostgreSQL) `github.com` [`comments`](https://news.ycombinator.com/item?id=27330342)  
7. [**Scottish Café**](https://en.wikipedia.org/wiki/Scottish_Café) `en.wikipedia.org` [`comments`](https://news.ycombinator.com/item?id=27329131)  
8. [**Show HN: paperd.ink – open-source e-paper development board**](https://paperd.ink) `paperd.ink` [`comments`](https://news.ycombinator.com/item?id=27331311)  
9. [**Create AI videos by simply typing in text**](https://www.synthesia.io/) `www.synthesia.io` [`comments`](https://news.ycombinator.com/item?id=27328205)  
10. [**Flexport is hiring employees all over the world**](https://www.flexport.com/careers) `www.flexport.com` [`comments`](https://news.ycombinator.com/item?id=27331208)  
11. [**GPG-Tui, a Terminal User Interface for GnuPG**](https://orhun.dev/blog/introducing-gpg-tui/) `orhun.dev` [`comments`](https://news.ycombinator.com/item?id=27329598)  
12. [**Waking up one hour earlier can lower chance of major depression**](https://medlifestyle.news/2021/05/29/waking-up-one-hour-earlier-can-lower-a-persons-chance-of-major-depression-by-23-new-research-finds/) `medlifestyle.news` [`comments`](https://news.ycombinator.com/item?id=27328290)  
13. [**Our digital pasts weren’t supposed to be weaponized like this**](https://www.nytimes.com/2021/05/29/technology/emily-wilder-firing-ap.html) `www.nytimes.com` [`comments`](https://news.ycombinator.com/item?id=27329338)  
14. [**Synthetic living machines: A new window on life**](https://www.sciencedirect.com/science/article/pii/S2589004221004739) `www.sciencedirect.com` [`comments`](https://news.ycombinator.com/item?id=27320975)  
15. [**Philip K. Dick: A Visionary Among the Charlatans (1975)**](https://www.depauw.edu/sfs/backissues/5/lem5art.htm) `www.depauw.edu` [`comments`](https://news.ycombinator.com/item?id=27327755)  
16. [**Offload Mental Simulation**](https://shalabh.com/programmable-systems/offload-mental-simulation.html) `shalabh.com` [`comments`](https://news.ycombinator.com/item?id=27330740)  
17. [**Dark Patterns Hall of Shame**](https://www.darkpatterns.org/hall-of-shame) `www.darkpatterns.org` [`comments`](https://news.ycombinator.com/item?id=27328863)  
18. [**Show HN: DarkHN – Dark Mode Mirror for Hacker News**](https://darkhn.herokuapp.com/) `darkhn.herokuapp.com` [`comments`](https://news.ycombinator.com/item?id=27329809)  
19. [**The Remarkable Life of Eugène-François Vidocq, Inventor of Modern Detective Work**](https://allthatsinteresting.com/eugene-francois-vidocq) `allthatsinteresting.com` [`comments`](https://news.ycombinator.com/item?id=27330466)  
20. [**Submerged Italian Village Resurfaces After 70 Years Underwater**](https://www.smithsonianmag.com/smart-news/medieval-italian-village-briefly-surfaces-after-70-years-underwater-180977838/) `www.smithsonianmag.com` [`comments`](https://news.ycombinator.com/item?id=27322753)  
21. [**Abolish High School (2015)**](https://harpers.org/archive/2015/04/abolish-high-school/) `harpers.org` [`comments`](https://news.ycombinator.com/item?id=27328111)  
22. [**What is the Fourth Dimension? (1884)**](https://en.wikisource.org/wiki/What_is_the_Fourth_Dimension%3F) `en.wikisource.org` [`comments`](https://news.ycombinator.com/item?id=27329211)  
23. [**The Mammoth Pirates**](https://www.rferl.org/a/the-mammoth-pirates/27939865.html) `www.rferl.org` [`comments`](https://news.ycombinator.com/item?id=27325053)  
24. [**NFT’s aren’t a harmless digital fad – they’re a disaster for our planet**](https://www.theguardian.com/commentisfree/2021/may/29/non-fungible-tokens-digital-fad-planet-nfts-artists-fossil-fuels) `www.theguardian.com` [`comments`](https://news.ycombinator.com/item?id=27331023)  
25. [**Amazon devices will soon automatically share your Internet with neighbors**](https://arstechnica.com/gadgets/2021/05/amazon-devices-will-soon-automatically-share-your-internet-with-neighbors/) `arstechnica.com` [`comments`](https://news.ycombinator.com/item?id=27328087)",2021-05-30T09:32:03Z,2021-05-30T09:32:03Z,open,0,"Hacker News Daily, resources of dark pattern, DP website, hall of shame",dp hall of shame,"hall of shame, documentation",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/242,Daily Hacker News 03-05-2021,https://github.com/xueyuanl/daily-hackernews/issues/242,"
# Daily Hacker News
  
1. [**Rust's Most Unrecognized Contributor**](https://brson.github.io/2021/05/02/rusts-most-unrecognized-contributor) `brson.github.io` [`comments`](https://news.ycombinator.com/item?id=27022120)  
2. [**Stack on a Budget – A collection of services with free tiers**](https://github.com/255kb/stack-on-a-budget) `github.com` [`comments`](https://news.ycombinator.com/item?id=27022075)  
3. [**The End of AMP**](https://www.lafoo.com/the-end-of-amp/?twclid=11389086688677404673) `www.lafoo.com` [`comments`](https://news.ycombinator.com/item?id=27021914)  
4. [**Dissecting the Apple M1 GPU, Part IV**](https://rosenzweig.io/blog/asahi-gpu-part-4.html) `rosenzweig.io` [`comments`](https://news.ycombinator.com/item?id=27019249)  
5. [**Don't make customers hunt for the Sign In button on your website**](https://blog.stunning.co/stop-making-your-paying-customers-hunt-for-the-sign-in-button-on-your-website/) `blog.stunning.co` [`comments`](https://news.ycombinator.com/item?id=27020560)  
6. [**Diffie-Hellman for the Layman**](https://borisreitman.medium.com/diffie-hellman-for-the-layman-7df6095011d9) `borisreitman.medium.com` [`comments`](https://news.ycombinator.com/item?id=27005204)  
7. [**Co-founder of Neuralink leaves the company**](https://www.engadget.com/co-founder-leaves-elon-musk-neuralink-164856798.html) `www.engadget.com` [`comments`](https://news.ycombinator.com/item?id=27020934)  
8. [**How Tech Loses Out**](https://berthub.eu/articles/posts/how-tech-loses-out/) `berthub.eu` [`comments`](https://news.ycombinator.com/item?id=27015327)  
9. [**Request for comments regarding topics to be discussed at Dark Patterns workshop**](https://www.regulations.gov/document/FTC-2021-0019-0001/comment) `www.regulations.gov` [`comments`](https://news.ycombinator.com/item?id=27017041)  
10. [**Hosting SQLite databases on GitHub Pages or any static file hoster**](https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/) `phiresky.github.io` [`comments`](https://news.ycombinator.com/item?id=27016630)  
11. [**Office 365 leaking BCC domain name**](https://www.reddit.com/r/Office365/comments/n3qky1/office_365_leaking_bcc_domain_name/) `www.reddit.com` [`comments`](https://news.ycombinator.com/item?id=27022600)  
12. [**Bootstrapping an Amiga without a bootable floppy**](https://www.rvalles.net/bootstrapping-an-amiga-without-a-bootable-amiga-floppy.html) `www.rvalles.net` [`comments`](https://news.ycombinator.com/item?id=27021469)  
13. [**One Year of TILs**](https://simonwillison.net/2021/May/2/one-year-of-tils/) `simonwillison.net` [`comments`](https://news.ycombinator.com/item?id=27017604)  
14. [**Thinking for Programmers (2014) [video]**](https://channel9.msdn.com/Events/Build/2014/3-642) `channel9.msdn.com` [`comments`](https://news.ycombinator.com/item?id=27004599)  
15. [**Why are there so many unfinished buildings in Africa?**](https://www.economist.com/middle-east-and-africa/2021/05/01/why-are-there-so-many-unfinished-buildings-in-africa) `www.economist.com` [`comments`](https://news.ycombinator.com/item?id=27013574)  
16. [**How many engineers does it take to make subscripting work?**](https://erthalion.info/2021/03/03/subscripting/) `erthalion.info` [`comments`](https://news.ycombinator.com/item?id=27006323)  
17. [**Principal Component Analysis Explained Visually**](https://setosa.io/ev/principal-component-analysis/) `setosa.io` [`comments`](https://news.ycombinator.com/item?id=27017675)  
18. [**Bitcoin Core: Bitcoin Core 0.21.1 released with Taproot activation code**](https://bitcoincore.org/en/2021/05/01/release-0.21.1/) `bitcoincore.org` [`comments`](https://news.ycombinator.com/item?id=27020002)  
19. [**What Is the Transparent Material at the End of a Gel Pen Refill?**](https://unsharpen.com/follower-end-of-gel-pen-refill/) `unsharpen.com` [`comments`](https://news.ycombinator.com/item?id=27015267)  
20. [**Bob Cassette Rewinder: Hacking Detergent DRM**](https://github.com/dekuNukem/bob_cassette_rewinder) `github.com` [`comments`](https://news.ycombinator.com/item?id=27013880)  
21. [**Jetoptera VTOL aircraft design features “bladeless fans on steroids”**](https://newatlas.com/aircraft/jetoptera-aircraft-propulsion-system/) `newatlas.com` [`comments`](https://news.ycombinator.com/item?id=27015793)  
22. [**Why are there so many Canadians in India?**](https://chuttenblog.wordpress.com/2021/04/26/data-science-is-interesting-why-are-there-so-many-canadians-in-india/) `chuttenblog.wordpress.com` [`comments`](https://news.ycombinator.com/item?id=27020313)  
23. [**Computer Calculus Reading Group**](https://compcalc.github.io/) `compcalc.github.io` [`comments`](https://news.ycombinator.com/item?id=27004278)  
24. [**What3Words sends legal threat to security researcher for sharing an alternative**](https://techcrunch.com/2021/04/30/what3words-legal-threat-whatfreewords/) `techcrunch.com` [`comments`](https://news.ycombinator.com/item?id=27020810)  
25. [**Substack (YC W18) is hiring to build a better business model for writing**](https://substack.com/jobs) `substack.com` [`comments`](https://news.ycombinator.com/item?id=27018970)",2021-05-03T09:07:02Z,2021-05-03T09:07:02Z,open,0,"Hacker News Daily, resources of dark pattern, government regulation, FTC, workshop discussion",,"regulation, workshop, documentation",Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/185,Daily Hacker News 06-03-2021,https://github.com/xueyuanl/daily-hackernews/issues/185,"
# Daily Hacker News
  
1. [**30k U.S. organizations newly hacked via holes in Microsoft Exchange Server**](https://krebsonsecurity.com/2021/03/at-least-30000-u-s-organizations-newly-hacked-via-holes-in-microsofts-email-software/) `krebsonsecurity.com` [`comments`](https://news.ycombinator.com/item?id=26362178)  
2. [**TROS: How IBM mainframes stored microcode in transformers (2019)**](http://www.righto.com/2019/11/tros-how-ibm-mainframes-stored.html) `www.righto.com` [`comments`](https://news.ycombinator.com/item?id=26365355)  
3. [**Burned House Horizon**](https://en.wikipedia.org/wiki/Burned_house_horizon) `en.wikipedia.org` [`comments`](https://news.ycombinator.com/item?id=26364285)  
4. [**Show HN: Svelte NodeGUI, a lightweight Electron alternative with native UI**](https://github.com/nodegui/svelte-nodegui) `github.com` [`comments`](https://news.ycombinator.com/item?id=26361423)  
5. [**Coursera S-1 IPO**](https://www.sec.gov/Archives/edgar/data/1651562/000119312521071525/d65490ds1.htm) `www.sec.gov` [`comments`](https://news.ycombinator.com/item?id=26362443)  
6. [**Kazuo Ishiguro uses artificial intelligence to reveal the limits of our own**](https://www.newyorker.com/magazine/2021/03/08/kazuo-ishiguro-uses-artificial-intelligence-to-reveal-the-limits-of-our-own) `www.newyorker.com` [`comments`](https://news.ycombinator.com/item?id=26356209)  
7. [**Kalman Filter**](https://en.wikipedia.org/wiki/Kalman_filter) `en.wikipedia.org` [`comments`](https://news.ycombinator.com/item?id=26363347)  
8. [**Opvia (YC S20) Is Hiring Engineers in London to Enable Data Driven Biotechnology**](https://www.notion.so/opvia/Opvia-Jobs-151305ed30a140f29ec9eb7df00deadc) `www.notion.so` [`comments`](https://news.ycombinator.com/item?id=26365907)  
9. [**Fusion startup plans reactor with small but powerful superconducting magnets**](https://www.sciencemag.org/news/2021/03/fusion-startup-plans-reactor-small-powerful-superconducting-magnets) `www.sciencemag.org` [`comments`](https://news.ycombinator.com/item?id=26360005)  
10. [**Do Language Models Know How Heavy an Elephant Is?**](https://ai.stanford.edu/blog/scalar-probing/) `ai.stanford.edu` [`comments`](https://news.ycombinator.com/item?id=26365409)  
11. [**An update on Android's audio latency**](https://android-developers.googleblog.com/2021/03/an-update-on-androids-audio-latency.html) `android-developers.googleblog.com` [`comments`](https://news.ycombinator.com/item?id=26361191)  
12. [**Simulating CRT Monitors with FFmpeg (Pt. 1: Color CRTs)**](https://int10h.org/blog/2021/01/simulating-crt-monitors-ffmpeg-pt-1-color/) `int10h.org` [`comments`](https://news.ycombinator.com/item?id=26355175)  
13. [**Wing Commander III**](https://www.filfre.net/2021/03/wing-commander-iii/) `www.filfre.net` [`comments`](https://news.ycombinator.com/item?id=26359431)  
14. [**Twitter's Dorsey auctions first ever tweet as digital memorabilia**](https://www.reuters.com/article/us-twitter-dorsey-idUSKBN2AY03A) `www.reuters.com` [`comments`](https://news.ycombinator.com/item?id=26365579)  
15. [**Show HN: Relocate.me – get your next tech job abroad**](https://relocate.me) `relocate.me` [`comments`](https://news.ycombinator.com/item?id=26360779)  
16. [**How a game about making zines helped me recapture my creativity in lockdown**](https://www.theguardian.com/games/2021/feb/22/electric-zine-maker-video-game) `www.theguardian.com` [`comments`](https://news.ycombinator.com/item?id=26358259)  
17. [**Dark patterns after the GDPR: consent pop-ups and their influence**](https://dl.acm.org/doi/10.1145/3313831.3376321) `dl.acm.org` [`comments`](https://news.ycombinator.com/item?id=26358882)  
18. [**Data Transfer Project by Apple, Facebook, Google, Microsoft, etc.**](https://datatransferproject.dev/) `datatransferproject.dev` [`comments`](https://news.ycombinator.com/item?id=26360101)  
19. [**Intel Core I7-11700K Review: Blasting Off with Rocket Lake**](https://www.anandtech.com/show/16535/intel-core-i7-11700k-review-blasting-off-with-rocket-lake) `www.anandtech.com` [`comments`](https://news.ycombinator.com/item?id=26363116)  
20. [**FizzBuzz Mario World: Learning Assembly Language and Having Some Fun**](https://computebeauty.com/posts/fbmw/index.html) `computebeauty.com` [`comments`](https://news.ycombinator.com/item?id=26362739)  
21. [**SVG Tetris**](https://www.xul.fr/svgtetris.svg) `www.xul.fr` [`comments`](https://news.ycombinator.com/item?id=26360716)  
22. [**Isadore Singer Bridged Math and Physics**](https://www.quantamagazine.org/isadore-singer-bridged-math-and-physics-20210304/) `www.quantamagazine.org` [`comments`](https://news.ycombinator.com/item?id=26362360)  
23. [**The Zen Anti-Interpretation of Quantum Mechanics**](https://www.scottaaronson.com/blog/?p=5359) `www.scottaaronson.com` [`comments`](https://news.ycombinator.com/item?id=26363004)  
24. [**How to Build a Community: Starting with “Why?”**](https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html) `clrcrl.com` [`comments`](https://news.ycombinator.com/item?id=26363709)  
25. [**Caramel: An OCaml for the Erlang VM**](https://caramel.run) `caramel.run` [`comments`](https://news.ycombinator.com/item?id=26354017)",2021-03-06T09:04:28Z,2021-03-06T09:04:28Z,open,0,"Hacker News Daily, resources of dark pattern, paper title: Dark Patterns after the GDPR: Scraping Consent Pop-ups and Demonstrating their Influence","GDPR, pop-ups, nagging","GDPR, pop-ups, nagging, documentation",Papers/Docs/Sources,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/mastodon/mastodon/issues/15029,"Cannot dismiss large missing notification permission banner without clicking ""Enable…""",https://github.com/mastodon/mastodon/issues/15029,"<!-- Make sure that you are submitting a new bug that was not previously reported or already fixed -->

<!-- Please use a concise and distinct title for the issue -->

### Expected behaviour

When showing the [notification column prompt to enable desktop notifications](https://github.com/tootsuite/mastodon/pull/14985 ), Mastodon provides a clear way to disable desktop notifications or otherwise permanently dismiss the large prompt without first requiring tapping on the `Enable desktop notifications` button.

Given the frequency with which other websites misuse the notification permission and the hassle of adjusting every single toggle, someone who does not wish to receive notifications at all might not trust or want to deal with Mastodon's in-page notification toggles.

Consider the `×` close button provided by Twitter on their notification prompt.

(That said, please don't copy Twitter's hostile behavior of randomly sprinkling the notification request prompt in no matter how many times I dismiss it - it should not show again until a `Desktop notifications` toggle is turned on in the notification column settings or some other clear, less space-consuming option is triggered.)

<!-- What should have happened? -->

### Actual behaviour

After logging into Mastodon, the Notifications column features a banner prompting to ""Enable desktop notifications"" due to the default notification settings including desktop notifications.  However, there's no immediately obvious way to dismiss this prompt as the `Desktop notifications` toggles are disabled when missing the permission, and it can be non-obvious that **to disable** the space-consuming banner you **must first click Enable** to receive the browser level prompt (which can then be denied, though that will leave a smaller banner around as the notification toggles are not disabled).

<!-- What happened? -->

### Steps to reproduce the problem

1.  If notification permissions have been granted to your Mastodon instance, remove them.

2.  Clear local storage (to ensure the default `Desktop notifications` toggles are enabled)

3.  Log into the Mastodon instance and open the notifications column

4.  Observe the banner prompt to enable notifications

5.  Attempt to disable or dismiss this banner without first clicking the `Enable desktop notifications` button (e.g. if one already knows they do not want any desktop notifications for privacy or attention/focus management reasons)

<!-- What were you trying to do? -->

### Specifications

<!-- What version or commit hash of Mastodon did you find this bug in? -->

Mastodon commit hash: [Glitchsoc port](https://github.com/vulpineclub/mastodon/commit/4ae4b0397430230d9d6fdf139ae59e2637859d13 ) of the [Mastodon commit for changing the missing desktop notifications banner](https://github.com/tootsuite/mastodon/commit/a69ca294738dbe22bacaf9f1fc5a551d99797b35 ).

<!-- If a front-end issue, what browser and operating systems were you using? -->

Firefox Nightly 201022 17:03 (Build #2015771211) on Android 11 October 2020 security patch (Pixel 4 XL).

----

*Filing this from my mobile device; if I'm missing information let me know and I can add it soon-ish!*",2020-10-24T10:04:23Z,2023-11-17T18:51:16Z,open,3,"Mastodon, usage of dark pattern in software, enabling desktop notifications, nagging, lack of permanent dismiss option, forced action","notification, enable button, forced action","Mastodon, notification feature, nagging, forced action",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/w3c/strategy/issues/235,Develop safeguards against erroneous online (over)buying by elderly/others vulnerable due to cognitive impairment,https://github.com/w3c/strategy/issues/235,"* https://asia.nikkei.com/Spotlight/Society/Japan-s-elderly-online-shoppers-running-into-trouble-infographic
* https://vdata.nikkei.com/en/newsgraphics/aging-society/e-commerce/

> Unfamiliarity with screen layouts and operating procedures among the elderly leads to a high rate of erroneous orders and other issues… confirmation and warning signs are small and difficult to notice. A system that can detect and limit unusual orders is needed to protect these new “vulnerable shoppers.”  … Safeguards for over-orders are needed.
>
> Internet service providers have developed technology to protect vulnerable consumers, mainly minors, by limiting viewing content, time and billing. However, mechanisms to protect the elderly are still in their infancy.
>
> Technology can provide great benefits to the elderly by giving them access to the market, but it also needs to evolve to protect them from risk … develop technology to detect signs of excessive purchasing based on buying patterns.

_**Note:** The bulleted points below are all verbatim quotations from the articles cited above._

#### Examples of specific problems that occur regularly among elderly users:
* over-ordering **by repeatedly pressing the purchase button even after payment**
* purchases that were **intended to be one-time only, but have turned into subscriptions**
* even if elderly shoppers want to cancel their orders, **they often give up** when they have to do so online

#### Causes:
* cognitive decline… is another reason the elderly are more likely to encounter problems
* many Alzheimer’s patients repeatedly purchase the same product
* people with Alzheimer's disease are at a high risk of forgetting their most recent activities
* especially serious problem for seniors who live alone, where no one can discover the problem and intervene

#### Exacerbated by current pandemic:
* with the outbreak of the new coronavirus, the amount of elderly using the internet is set to increase even faster
* the amount those in their eighties spend online on major everyday items has also jumped since April. In June, spending was more than 6,000 yen, a 56% increase from the same month last year.
* for people aged 60 or older, consultations about health food orders increased particularly sharply … a six-fold jump

#### Data about the scale of the problems, and the rate at which they are increasing:
* consultations related to online shopping at the [Japanese] National Consumer Affairs Center by people aged 60 and older in fiscal 2019 [were] **15 times more than in fiscal 2010**
* that is a sharp increase compared to those aged 59 and younger, which increased less than 6 times.
*  the number of **consultations for internet trouble surpassed those for non-internet issues for the first time**
* the World Health Organization predicts that **the global number of people with dementia will continue to increase by almost 10 million each year**, reaching 150 million people in 2050
* there are nearly 7 million households in Japan which are people aged 65 or older living alone
* those numbers will continue to grow
* the notion that seniors are not familiar with the internet is a thing of the past
  * 50% of those in their sixties were making purchases online
  * even those in their seventies are rapidly shifting to the web, with more than 40% of them making purchases online
  * that number is also close to 20% for those in their 80s
  * for those in their 60s, 70s, and 80 and older, **the numbers of online shopping problems have increased 14-18 times over the past nine years**",2020-10-22T08:10:38Z,2023-10-15T23:16:20Z,open,9,"miscellaneous (FTC workshop, Bringing Dark Patterns to Light: An FTC Workshop)","examples, definitions",documentation,Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/nvuillam/sfdx-essentials/issues/54,Remove Amplitude tracking from this package,https://github.com/nvuillam/sfdx-essentials/issues/54,"**Describe the solution you'd like**
Could you please remove amplitude tracking from this package and remove the `--noinsight` flag? I'm happy to submit a PR to remove it myself if you're ok with it. This behavior is not obvious and a potential security risk for people using this package for private build tools. Npm gives you download statistics which are useful for understanding package usage.
",2021-04-20T04:45:40Z,2021-04-22T03:53:32Z,open,7,"usage of dark pattern in sfdx tool during script execution, data collection by default without explicitly consent","command line flag, default on","data collection, preselection, default, sfdx tool, script execution",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/inukshuk/anystyle/issues/148,"""type"": null isn't valid csl",https://github.com/inukshuk/anystyle/issues/148,"Similar to #110, or rather concerning how that was solved – according to the [CSL-JSON docs](https://citeproc-js.readthedocs.io/en/latest/csl-json/markup.html#type-field), the `type` field is 
> Required. The type field is a simple field containing a string value. CSL-JSON constrains the possible for values of the type field to a limited set of possible values (e.g., “book” or “article”). The type must be a valid CSL type under the schema of the installed style. See the schemata of CSL and CSL-M for their respective lists of valid types.

In terms of potential workflows, I've noticed that some APA7-style references processed into CSL-JSON on anystyle.io therefore fail to import into Zotero, which complains that a csl-json file containing `""type"": null`s is ""not a supported format"". Crudely replacing all of those `null`s with `""book""`s fixes that problem, though.

(Also, thank you for the very valuable software!)
 ",2020-07-20T22:06:30Z,2020-07-22T12:33:16Z,open,4,"miscellaneous (dark pattern sources, docs, report: deceived by Design: How tech companies use dark patterns to discourage us from exercising our rights to privacy)",,"privacy issue, documentation",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Roguelike-Celebration/azure-mud/issues/415,Ask attendees to rate talks in real-time,https://github.com/Roguelike-Celebration/azure-mud/issues/415,,2021-04-19T00:01:42Z,2023-06-24T00:11:31Z,open,5,"usage of dark pattern in software, rating talk system, nagging, notification badge, popups dialog","notificationm rating system, nagging","rating system, notification feature, pop-ups, nagging",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/import-js/eslint-plugin-import/issues/2323,fix: detect case-sensitive filesystems correctly under yarn PnP,https://github.com/import-js/eslint-plugin-import/pull/2323,"yarn in PnP mode uses a virtual filesystem, and adding the `preferUnplugged: true` flag forces it to write this package to the real filesystem. This is needed so the case-sensitive detection logic in `resolve.js` works properly.",2021-12-09T21:07:19Z,2023-12-19T02:35:44Z,open,18,prevention of dark pattern,"dp in coding, metadata, package","metadata, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/seunghyunhan/daily-arxiv-noti/issues/184,"New submissions for Thu, 20 May 21",https://github.com/seunghyunhan/daily-arxiv-noti/issues/184,"## Keyword: recommendation
### RecPipe: Co-designing Models and Hardware to Jointly Optimize  Recommendation Quality and Performance
 - **Authors:** Udit Gupta, Samuel Hsia, Jeff (Jun)Zhang, Mark Wilkening, Javin Pombra, Hsien-Hsin S. Lee, Gu-Yeon Wei, Carole-Jean Wu, David Brooks
 - **Subjects:** Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)
 - **Arxiv link:** https://arxiv.org/abs/2105.08820
 - **Pdf link:** https://arxiv.org/pdf/2105.08820
 - **Abstract**
 Deep learning recommendation systems must provide high quality, personalized content under strict tail-latency targets and high system loads. This paper presents RecPipe, a system to jointly optimize recommendation quality and inference performance. Central to RecPipe is decomposing recommendation models into multi-stage pipelines to maintain quality while reducing compute complexity and exposing distinct parallelism opportunities. RecPipe implements an inference scheduler to map multi-stage recommendation engines onto commodity, heterogeneous platforms (e.g., CPUs, GPUs).While the hardware-aware scheduling improves ranking efficiency, the commodity platforms suffer from many limitations requiring specialized hardware. Thus, we design RecPipeAccel (RPAccel), a custom accelerator that jointly optimizes quality, tail-latency, and system throughput. RPAc-cel is designed specifically to exploit the distinct design space opened via RecPipe. In particular, RPAccel processes queries in sub-batches to pipeline recommendation stages, implements dual static and dynamic embedding caches, a set of top-k filtering units, and a reconfigurable systolic array. Com-pared to prior-art and at iso-quality, we demonstrate that RPAccel improves latency and throughput by 3x and 6x.
### Dark Patterns, Electronic Medical Records, and the Opioid Epidemic
 - **Authors:** Daniel Capurro, Eduardo Velloso
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2105.08870
 - **Pdf link:** https://arxiv.org/pdf/2105.08870
 - **Abstract**
 Dark patterns have emerged as a set of methods to exploit cognitive biases to trick users to make decisions that are more aligned with a third party than to their own. These patterns can have consequences that might range from inconvenience to global disasters. We present a case of a drug company and an electronic medical record vendor who colluded to modify the medical record's interface to induce clinicians to increase the prescription of extended-release opioids, a class of drugs that has a high potential for addiction and has caused almost half a million additional deaths in the past two decades. Through this case, we present the use and effects of dark patterns in healthcare, discuss the current challenges, and offer some recommendations on how to address this pressing issue.
### Where are we in embedding spaces? A Comprehensive Analysis on Network  Embedding Approaches for Recommender Systems
 - **Authors:** Sixiao Zhang, Hongxu Chen, Xiao Ming, Lizhen Cui, Hongzhi Yin, Guandong Xu
 - **Subjects:** Information Retrieval (cs.IR); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2105.08908
 - **Pdf link:** https://arxiv.org/pdf/2105.08908
 - **Abstract**
 Hyperbolic space and hyperbolic embeddings are becoming a popular research field for recommender systems. However, it is not clear under what circumstances the hyperbolic space should be considered. To fill this gap, This paper provides theoretical analysis and empirical results on when and where to use hyperbolic space and hyperbolic embeddings in recommender systems. Specifically, we answer the questions that which type of models and datasets are more suited for hyperbolic space, as well as which latent size to choose. We evaluate our answers by comparing the performance of Euclidean space and hyperbolic space on different latent space models in both general item recommendation domain and social recommendation domain, with 6 widely used datasets and different latent sizes. Additionally, we propose a new metric learning based recommendation method called SCML and its hyperbolic version HSCML. We evaluate our conclusions regarding hyperbolic space on SCML and show the state-of-the-art performance of hyperbolic space by comparing HSCML with other baseline methods.
### Private Hierarchical Clustering in Federated Networks
 - **Authors:** Aashish Kolluri, Teodora Baluta, Prateek Saxena
 - **Subjects:** Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)
 - **Arxiv link:** https://arxiv.org/abs/2105.09057
 - **Pdf link:** https://arxiv.org/pdf/2105.09057
 - **Abstract**
 Analyzing structural properties of social networks, such as identifying their clusters or finding their most central nodes, has many applications. However, these applications are not supported by federated social networks that allow users to store their social links locally on their end devices. In the federated regime, users want access to personalized services while also keeping their social links private. In this paper, we take a step towards enabling analytics on federated networks with differential privacy guarantees about protecting the user links or contacts in the network. Specifically, we present the first work to compute hierarchical cluster trees using local differential privacy. Our algorithms for computing them are novel and come with theoretical bounds on the quality of the trees learned. The private hierarchical cluster trees enable a service provider to query the community structure around a user at various granularities without the users having to share their raw contacts with the provider. We demonstrate the utility of such queries by redesigning the state-of-the-art social recommendation algorithms for the federated setup. Our recommendation algorithms significantly outperform the baselines which do not use social contacts and are on par with the non-private algorithms that use contacts.
### High-Performance FPGA-based Accelerator for Bayesian Neural Networks
 - **Authors:** Hongxiang Fan, Martin Ferianc, Miguel Rodrigues, Hongyu Zhou, Xinyu Niu, Wayne Luk
 - **Subjects:** Hardware Architecture (cs.AR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)
 - **Arxiv link:** https://arxiv.org/abs/2105.09163
 - **Pdf link:** https://arxiv.org/pdf/2105.09163
 - **Abstract**
 Neural networks (NNs) have demonstrated their potential in a wide range of applications such as image recognition, decision making or recommendation systems. However, standard NNs are unable to capture their model uncertainty which is crucial for many safety-critical applications including healthcare and autonomous vehicles. In comparison, Bayesian neural networks (BNNs) are able to express uncertainty in their prediction via a mathematical grounding. Nevertheless, BNNs have not been as widely used in industrial practice, mainly because of their expensive computational cost and limited hardware performance. This work proposes a novel FPGA-based hardware architecture to accelerate BNNs inferred through Monte Carlo Dropout. Compared with other state-of-the-art BNN accelerators, the proposed accelerator can achieve up to 4 times higher energy efficiency and 9 times better compute efficiency. Considering partial Bayesian inference, an automatic framework is proposed, which explores the trade-off between hardware and algorithmic performance. Extensive experiments are conducted to demonstrate that our proposed framework can effectively find the optimal points in the design space.
### On Interpretation and Measurement of Soft Attributes for Recommendation
 - **Authors:** Krisztian Balog, Filip Radlinski, Alexandros Karatzoglou
 - **Subjects:** Information Retrieval (cs.IR)
 - **Arxiv link:** https://arxiv.org/abs/2105.09179
 - **Pdf link:** https://arxiv.org/pdf/2105.09179
 - **Abstract**
 We address how to robustly interpret natural language refinements (or critiques) in recommender systems. In particular, in human-human recommendation settings people frequently use soft attributes to express preferences about items, including concepts like the originality of a movie plot, the noisiness of a venue, or the complexity of a recipe. While binary tagging is extensively studied in the context of recommender systems, soft attributes often involve subjective and contextual aspects, which cannot be captured reliably in this way, nor be represented as objective binary truth in a knowledge base. This also adds important considerations when measuring soft attribute ranking. We propose a more natural representation as personalized relative statements, rather than as absolute item properties. We present novel data collection techniques and evaluation approaches, and a new public dataset. We also propose a set of scoring approaches, from unsupervised to weakly supervised to fully supervised, as a step towards interpreting and acting upon soft attribute based critiques.
### POINTREC: A Test Collection for Narrative-driven Point of Interest  Recommendation
 - **Authors:** Jafar Afzali, Aleksander Mark Drzewiecki, Krisztian Balog
 - **Subjects:** Information Retrieval (cs.IR)
 - **Arxiv link:** https://arxiv.org/abs/2105.09204
 - **Pdf link:** https://arxiv.org/pdf/2105.09204
 - **Abstract**
 This paper presents a test collection for contextual point of interest (POI) recommendation in a narrative-driven scenario. There, user history is not available, instead, user requests are described in natural language. The requests in our collection are manually collected from social sharing websites, and are annotated with various types of metadata, including location, categories, constraints, and example POIs. These requests are to be resolved from a dataset of POIs, which are collected from a popular online directory, and are further linked to a geographical knowledge base and enriched with relevant web snippets. Graded relevance assessments are collected using crowdsourcing, by pooling both manual and automatic recommendations, where the latter serve as baselines for future performance comparison. This resource supports the development of novel approaches for end-to-end POI recommendation as well as for specific semantic annotation tasks on natural language requests.
## Keyword: semi-supervised
### Self-supervised Heterogeneous Graph Neural Network with Co-contrastive  Learning
 - **Authors:** Xiao Wang, Nian Liu, Hui Han, Chuan Shi
 - **Subjects:** Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2105.09111
 - **Pdf link:** https://arxiv.org/pdf/2105.09111
 - **Abstract**
 Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-viewcontrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, two extensions of HeCo are designed to generate harder negative samples with high quality, which further boosts the performance of HeCo. Extensive experiments conducted on a variety of real-world networks show the superior performance of the proposed methods over the state-of-the-arts.
",2021-05-20T17:00:32Z,2021-05-20T17:00:32Z,open,0,"paper/literature of dark pattern, document, paper title: Dark Patterns, Electronic Medical Records, and the Opioid Epidemic",healthcare examples,"Medical Records, documentation",Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/knex/knex-schema-inspector/issues/73,[PostgreSQL] Improve parsing support for postgresql data types,https://github.com/knex/knex-schema-inspector/pull/73,"This PR will add:
* a new property `default_value_raw` to the [types/column.ts](https://github.com/knex/knex-schema-inspector/pull/73/files#diff-671ee2baf4bb6d3fecb4f871a51dedfe229c47563b7e5fbef257e0c7445f6792R35) that will contain the default raw value inspected from schema definitions;
* the dependency [pg-types](https://github.com/brianc/node-pg-types), that contains a good collection of parsers for PostgreSQL data types.

New types parsed:
* timestamps/dates;
* arrays in the format '{}';

#### Caveat

The module pg-types uses the **data type oid** to find the appropriate parser for the column type. In contrast, knex-schema-inspector  uses `information_schema.data_type`. To bridge the pg-types approach to the knex-schema-inspector, this PR uses [this map](https://github.com/knex/knex-schema-inspector/pull/73/files#diff-241a92bc77a6f7efb5e272de443b7ea90213da7142d15ed3b3fe9d27d867511cR12) **that may require to be updated in the future**.

#### Tasks
* [x] add new property `default_raw_value`
* [x] update all dialects to take into account `default_value_raw`; 
* [x] integrate `pg-types` to support pg native data types;
* [x] additional logic to parse arrays;
* [x] update unit tests;

Closes #72 ",2021-10-18T10:05:09Z,2023-02-13T23:44:05Z,open,18,"dark pattern in coding, 'defaultValue' design choice, Javascript object, SQL expression","defaultValue, JavaScript or SQL","UI/UX Design, JavaScript, SQL",DPs in design coding ,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/keesschollaart81/vscode-home-assistant/issues/961,The VSCode settings.json file is getting created on non-HA repos,https://github.com/keesschollaart81/vscode-home-assistant/issues/961,"When I open some random repositories on VSCode, I can see the `.vscode/settings.json` getting created, yet those repos have nothing to do with HA configuration!

A good example if the [zigbee2mqtt](https://github.com/Koenkk/zigbee2mqtt): just clone the repo, open in VS Code (do ensure that this extension is enabled and running first) and observe the file getting created.

Extension runs in:
- [X] VS Code for Desktop 
- [ ] Hassio Add-on 
- [ ] Visual Studio Online
- [ ] Other: 

I'm running VS Code on:
- [X] Windows 
- [ ] Mac 
- [ ] Linux 

I'm accessing my files:
- [X] From local disk 
- [X] Via remote SSH 
- [X] Smb
- [ ] Other:  ",2021-02-02T16:38:30Z,2022-10-31T00:28:43Z,open,19,"usage of dark pattern in software, VSCode, DP in plugin","autocreation of .vscode/settings.json, forced action","VSCode, autocreate, plugin, forced action",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/nextcloud/android/issues/6505,Global auto-upload opt-out,https://github.com/nextcloud/android/issues/6505,"### Is your feature request related to a problem? Please describe.
I'm always frustrated when I am not sure whether an application on my phone is uploading files on the internet without my consent

### Describe the solution you'd like
A global toggle that completely disables any autoupload feature

### Describe alternatives you've considered
Right now, I think (but I am no sure) that the autoupload can be enabled or disabled per folder. This leaves me uneasy: I have thousands of them and no way to check if any of them is enabled

### Additional context
I keep a lot of things on my phone. I don't want that any of this ends up in the internet, unless I am explicitly adding it.",2020-07-21T13:08:25Z,2024-02-26T09:08:00Z,open,14,"NextCloud (free, open-source, safe home to your data storage), usage of dark pattern in software, autoupload feature","upload, auto sync","NextCloud, autoupload feature, forced action",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/81,Should we have a section on authorised agents?,https://github.com/w3ctag/privacy-principles/issues/81,,2021-11-09T20:23:15Z,2022-10-19T16:33:07Z,open,9,miscellaneous (mislead users to authorizing actions without fully understand/consent),,misleading,DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/w3ctag/ethical-web-principles/issues/68,Consider adding a new principle about providing undiscriminating economic opportunity,https://github.com/w3ctag/ethical-web-principles/issues/68,"The web offers incredible economic opportunities, and while a number of the ethical web principles acknowledge the value of empowering individuals or providing equal opportunity, the economic opportunities enabled by the web are barely mentioned in EWP.

I'd be happy to help suggest text once we have agreement that (a) this is worth pursuing and (b) on the direction such a principle would take.",2021-12-04T01:44:56Z,2022-03-08T09:32:35Z,open,4,miscellaneous (opposed/against DPs in marketing),"anticompetitive manipulations of a standards process, vendor lock",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/FILPool520/BPool/issues/2,Project Showcase: OmniLingo,https://github.com/FILPool520/BPool/issues/2,"Language learning apps can give a fun, convenient way to learn a new language. Like many uses of the internet, though, there is an opportunity for dark patterns to sneak in: user data hoarding, targeted presentation, and majority-cultural filter bubbles can have negative social impacts, and properietary or closed-source software and always-connected centralised backends can create unstable infrastructure and restrict user freedom.

We present here Omnilingo (opens new window)- an open project to build language learning protocols, software, and infrastructure that avoids these problems, prioritizing minority language communities and user data sovereignty. Let’s start with a few example stories about Omnilingo’s users.

#Language Activist
A language activist in a minority community wants to add their language to their favourite language learning app. The activist gathers audio samples and transcriptions and designs a curriculum. They contact the company producing the app, which controls what material can be used. The company responds that the language has too few speakers to be worth their time, saying one of:

Their lawyers don’t have time to evaluate whether they can use this material legally.
Their developers don’t have time to add the language to their app.
Their servers don’t have space or bandwidth to host the material for use in the app.
They can’t evaluate the quality of the material, and would rather not allow anyone to use it.
With OmniLingo, the activist can host the material they’ve collected and, through the IPFS decentralised storage network, and users can add the material to their app using the material’s Content ID hash.

#Language Learner
A privacy-conscious language learner wants an app that doesn’t track their abilities or habits; apps with registration and partnerships with advertising surveillance networks are hard to find, and many of them have disappeared along with their data. With OmniLingo, as long as their are users the data remains on the network; the open protocol allows developing clients which store no information on the network, or which allow users to choose who gets access to their data.

#Language Instructor
A language instructor is tired of having to adapt their course to the subscription plastic-wrapped curriculum their school purchased: the curriculum dictates the topics that are covered, the order, the vocabulary, and the variety of voices (gender, dialect, accent) that are used. With OmniLingo, the instructor can create, share and mix their own material.

#Who we are
We’re a pair of computational linguistics researchers and language activists. Fran Tyers is an assistant professor of computational linguistics at Indiana University and Nick Howell is a language technology consultant. We work at all layers of the stack to bring the latest advancements in language technology to minority and under-resourced language communities in ways that support their right to self-determination.

#What is OmniLingo
OmniLingo is a protocol and sample implementation for language-learning applications with a focus on decentralised and self-determined storage, user rights and privacy, and minority and under-represented languages.

                  distributed
                    system
                  developers
                      |
  language -----      |   
  curators      \     |      --------- marginalised language
                 \    |     /          learners
                           /
  language ------   IPFS   ----------- language learning
  instructors              \           researchers
                 /   | |    \
                /    | |     --------- privacy-concious language
  activists ----     | |               learners
                    /   \ 
                   /     \
  language  -------       ------------ experimental language
  community                            task designers
  supporters
#Architecture
language community  ----------
   authors                    \ collection    OmniLingo      publish on IPFS             fetched by any     language
                                --------->  node operators  ----------------->   IPFS   ---------------->    learner
language community            /               (anyone!)       with toolkit                 conformant       
   speakers         ----------                                                               client
OmniLingo language data is stored on IPFS in a hierarchy of JSON and MP3 files. The _root index_of a language data store is a JSON dictionary mapping ISO-639 (opens new window)language codes to language index and language metadata.

{
  ⋮
  ""or"": {
    ""cids"": [
      ""QmXYXMPyCREZCLao7k462rKNAFznxszeshdXqauh63Tet4""
    ],
    ""meta"": ""QmV2SJHieJP1P6RDsSRchTwpWjAMho7ci7HXbkvN4ULuoR""
  },
  ""pa-IN"": {
    ""cids"": [
      ""QmSKHQJdznnaNSNxDw9MXZxNzVNiJC9Fyi5pV1eXD9dWmU""
    ],
    ""meta"": ""QmNT6VGydPEJvcqmMPpp1g3qCqWtBn1WHAmzswL3NqAHMU""
  },
  ""pl"": {
    ""cids"": [
      ""QmSP7E9MFGphEodZuxf73yinGMaKvg8nx3V98bs5HQ4gfT""
    ],
    ""meta"": ""QmQjPam8Nxwu2GckmSfp73iq1BauNm7mNXmKu8odGyRzZN""
  },
  ⋮
}
Language metadata consists of a “display name” for the language and a set of character rewrite rules to make typing easier; an example from Turkish:

{
  ""alternatives"": {
    ""İ"": [
      ""I""
    ]
  },
  ""display"": ""Türkçe""
}
Language indices are JSON lists of audio sample and difficulty metadata, used to generate an appropriate exercise for the learner’s level.

[
  ⋮
  {
    ""chars_sec"": 15.211640211640212,
    ""clip_cid"": ""QmVDBB3qAujxuesvmhKZajxgYZnms3dUb24bBx6rr5hJvg"",
    ""length"": 6.048,
    ""meta_cid"": ""QmZNucpVvYxGiWhyqte9izfoaW79uQHuE7w4fWagWv1LLh"",
    ""sentence_cid"": ""QmR1uoBwNJRHhcPhD2utiNji1J3e4Q2t1nmUie9cJxccYt""
  },
  {
    ""chars_sec"": 15.972222222222223,
    ""clip_cid"": ""QmcjJwcPF5oUX3WPtkAqFU9iCr9NvQAwVQabgBQSuVFMaG"",
    ""length"": 5.76,
    ""meta_cid"": ""QmZNucpVvYxGiWhyqte9izfoaW79uQHuE7w4fWagWv1LLh"",
    ""sentence_cid"": ""QmR1uoBwNJRHhcPhD2utiNji1J3e4Q2t1nmUie9cJxccYt""
  },
  ⋮
]
The sentence_cid field refers to a JSON dictionary of the original transcript, license, and language:

{
  ""content"": ""Tavaliselt ongi nii, et mesinik jääb oma surnud mesilastega ja mitte mingit lahendust ei tule."",
  ""copyright"": ""CC0-1.0"",
  ""language"": ""et""
}
The clip_cid field is the CID of the MP3 file; meta_cid is a link to more detailed sentence metadata, including a tokenised transcript and punctation tags for each token:

{
  ""sentence_cid"": ""QmR1uoBwNJRHhcPhD2utiNji1J3e4Q2t1nmUie9cJxccYt"",
  ""tags"": [ ""X"", ""X"", ""X"", ""PUNCT"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""X"", ""PUNCT"" ],
  ""tokens"": [ ""Tavaliselt"", ""ongi"", ""nii"", "", "", ""et"", ""mesinik"", ""jääb"", ""oma"", ""surnud"", ""mesilastega"", ""ja"", ""mitte"", ""mingit"", ""lahendust"", ""ei"", ""tule"", ""."" ]
}
In summary, the OmniLingo language store looks like this:

root-index
    ├── lang1
    │             ├── lang1-index
    │             │             ├── sent1
    │             │             │             ├── audioclip
    │             │             │             ├── metadata
    │             │             │             └── transcript
    │             │             └── …
    │             └── lang1-metadata
    ├── lang2
    └── …
Root indexes are encouraged to be published to IPNS, so that clients can receive updates.

#Implementation
We have implemented:

a Python toolkit for publishing language data
a Python command-line client demo
a HTML+JS web demo
#Language data publishing toolkit
There are three main steps in adding your data to OmniLingo. The first step is importing the data into IPFS, the second is indexing the data and the final step is publishing the data.

#Import
Import data into your local IPFS node and generate an index:

$ importer.py dataset_dir index_path
e.g.

$ importer.py ./cv-corpus-7.0-2021-07-21/tr/ tr.json
where the dataset_dir is in Common Voice format.

#Index
Index the data, extracting a balanced subset of clips by a complexity metric:

$ indexer.py locale index_path
e.g.

$ indexer.py tr tr.json
This will return a CID that looks like QmXpgcavH2shpBbfnFoymPxEw2zpr4MdAgi1aaoZT4Yeho

#Publish
Publish data to the global index in OmniLingo on IPFS:

$ publisher.py locale cid
e.g.

$ publisher.py tr QmXpgcavH2shpBbfnFoymPxEw2zpr4MdAgi1aaoZT4Yeho
This will return a CID which looks something like QmWAmrGNGkL8N6LfsfAKueYGYLqJ2gqn9EZR2a11fxRos6, which you can
then publish to an IPFS name using the local node ID:

ipfs name publish cid 
e.g.

ipfs name publish QmWAmrGNGkL8N6LfsfAKueYGYLqJ2gqn9EZR2a11fxRos6
#Command-line client demo
The Python command-line client demonstrates how you can build your own local OmniLingo client; users are presented with fill-in-the-blank exercises, but there isn’t any difficulty analysis.

#HTML+JS web demo
Try it out! (opens new window)We wrote a HTML+JS web demo using a browserified copy of js-ipfs (opens new window). It stores a list of root indexes in local storage, and merges their trees.

Users are presented with fill-in-the-blank exercises in order of increasing difficulty, as measured by characters-per-second in the audio. We look forward to developing other measures of difficulty!

One remaining point of centralisation is the IPNS resolution: IPNS names will be resolved through the gateway at ipfs.io.

#What’s next
Omnilingo’s design encourages experimentation; we hope to see expansion along several axes:

New client experiences:
bringing native OmniLingo experiences to platforms
new algorithms for choosing exercises
choosing and customising exercises
New data:
bring more languages to OmniLingo
bring more connections to OmniLingo (e.g., Wikidata for vocabulary learning)
Both:
bring pronunciation assistence to OmniLingo
bring distributed identities to OmniLingo, multi-device or multi-client usage
We have specific plans for pronunciation assistence and distributed identities in the next phase of our OmniLingo development work. Want to help out? Share your ideas and collaborate with us in",2021-12-22T06:22:21Z,2021-12-22T06:22:21Z,open,0,"deceptive design practices in language learning software, oppotunaties for DPs: user data hoarding, targeted presentation, and majority-cultural filter bubbles","OmniLingo, data hoarding, examples","OmniLingo, deceptive design practices, data collection",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/DEFRA/design-discussions/issues/9,Cookies policy and consent,https://github.com/DEFRA/design-discussions/issues/9,"## What
Help users manage their personal data by telling them when you store cookies on their device.

## Why
We must have users consent to store cookies or similar technologies on their device

## How

* Ask users for consent
* Provide information on cookies used
* Allow users to set preferences
* Allow users to change preferences
* Inform users of any changes
",2020-02-26T10:58:58Z,2020-03-30T12:46:52Z,open,20,"cookie policy consent, prevention of dark pattern in design, explicitly opt-in for analytics cookie, ""accept all"" & ""reject all"" & ""manage preference""","cookie consent, privacy policy","cookie consent, privacy issue, opt-in/out, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/nirjan-dev/learning-to-code/issues/185,The Role of Animation and Motion in UX,https://github.com/nirjan-dev/learning-to-code/issues/185,"[link to the post](https://www.nngroup.com/articles/animation-purpose-ux/)

Although animations can be useful and can build user expectations about the UI, they should be used with a light touch — primarily as a tool for providing users with easily noticeable, smooth feedback.

# Purpose of UI Animations
When animation is used in a subtle way, it can help users build mental models about how the system works and how they can interact with it.  Animations are less critical for user experience when they are simply time-filling visual stimulations during moments of transition (in fact, it’s these down-time animations that often frustrate participants in usability testing).  Instead of using animations to provide surface-level delight (that quickly sours), animations can be leveraged for usability: as clues about what is currently happening with the system, as signifiers for how UI elements will behave, and as easily understandable spatial metaphors for the user’s location in the information space.

## Motion for Feedback
Animations are often helpful as a form of noticeable feedback that an action has been recognized by the system.  A ubiquitous example is the animation of a navigation menu sliding over the page when a hamburger icon is tapped.  Because our visual systems are so attuned to motion, a short animation can ensure that users see the feedback.

Sometimes, static visual feedback is ignored due to change blindness. For example, people may not notice the shopping-cart–badge update after clicking the Add to cart button in the Cuisinart example below. An animation increases the chance of noticing that feedback. (Another alternative would be to make the static feedback more prominent — e.g., through a dialog box or using a bigger badge. Both solutions would likely be more intrusive than a simple animation.)

And animations can also be used as a form of feedback before the user commits to an action, such as previewing the new location of an item when using drag-and-drop to reorder a list.
Your browser does not support the video tag.

## Motion to Communicate State Change

Motion can be used to indicate that the interface switched to a different state — for example, because of a mode change. Modes are often a difficult concept to communicate to users, but animation can help in two ways: (1) by making the mode change noticeable; and (2) by providing a conceptual metaphor of the mode transition. For example, morphing a pencil icon into a disk after it was clicked on signals the transition from Edit to Save mode more clearly than swapping one icon out for the other instantly.

In addition to showing a transition between modes or views of data, animations are also helpful for communicating state changes that are not triggered by users’ actions. For example, loading indicators show that the system is not yet ready to accept input.  One form of this is a “skeleton screen” (a placeholder UI that looks like a wireframe of the loading page, with no content) that is animated by a light glare moving across it.  

## Motion for Spatial Metaphors and Navigation

The structure of a complex information space is often challenging to communicate to users without taxing their cognitive resources or taking up too much screen space. Scanning through navigation menus, tree diagrams, or even breadcrumbs to figure out where one is in the information hierarchy is a complex type of cognitive work. While animation alone is not a suitable substitute for visible navigation with clear, unbranded labels, it can signal to users the direction in which they are moving within a process or hierarchy; this supplemental cue can make navigation through a complex IA more intuitive and understandable.

Zooming animations can help users understand the direction of their journey into a hierarchical information space without looking at a tree diagram. Zooming out shows less detail, but more objects, thus suggesting that the user travels up into the hierarchy, whereas zooming in shows more detail, but fewer objects, creating the impression of going deeper into the hierarchy.

Likewise, a slide-over animation helps to establish that a user is moving forward or backward within a process such as checkout.

Animations can also prevent disorientation and telling people if they are on the same page or have moved on — particularly on mobile, where context can be lost due to the small screen size.  Accordions, anchor links, and menu overlays can be disorienting or confusing if the change appears instantaneously; since a menu overlay fills the entire screen, the relationship between the overlay and the underlying page (e.g., “is this content a new page, or is it something else?”) is hard to understand without an animated cue. (Why does it matter if users know where they are? If they think they are on a new page, they are often tempted to use the Back button to navigate to the previous view; unfortunately, in the case of overlays or accordions, that action will take them away from the page instead of simply closing the element.)

## Motion as a Signifier
Animations help users understand how to interact with UI elements. The direction (or other attributes) of the motion signifies the type of acceptable actions. For example, a card that expands from the bottom of the screen towards the top signals to the user that it can be closed by pulling down. A new card that comes from the right of the screen signals that it can be closed by swiping it to the right.

## Attention Grabbing and Attention Hijacking

ecause the human visual system is very sensitive to motion (particularly, to motion that appears to have animacy), animation can be used to grab users’ attention, for better or worse. On the one hand, it can make a subtle signifier obvious, but on the other hand, gratuitous animations distract and annoy the user. Further, using animation to hijack the users’ attention or create a fear of loss is a dark pattern: an unethical application of user-experience principles and cognitive psychology to get users to do something they ordinarily wouldn’t.

",2020-01-27T07:32:06Z,2020-01-27T07:32:06Z,open,0,"animation/motion in UI design, attention-hijacking users in dark pattern, discussion of impact","animate, urgency, attention-hijacking","animation, UI/UX Design, distraction",DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/fireindark707/daily-arxiv-noti/issues/3,"New submissions for Thu,  8 Apr 21",https://github.com/fireindark707/daily-arxiv-noti/issues/3,"## Keyword: social movement
There is no result 
## Keyword: social network
### Ethical User Interfaces: Exploring the Effects of Dark Patterns on  Facebook
 - **Authors:** Thomas Mildner, Gian-Luca Savino
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2104.03010
 - **Pdf link:** https://arxiv.org/pdf/2104.03010
 - **Abstract**
 Many researchers have been concerned with whether social media has a negative impact on the well-being of their audience. With the popularity of social networking sites (SNS) steadily increasing, psychological and social sciences have shown great interest in their effects and consequences on humans. In this work, we investigate Facebook using the tools of HCI to find connections between interface features and the concerns raised by these domains. Using an empirical design analysis, we identify interface interferences impacting users' online privacy. Through a subsequent survey (n=116), we find usage behaviour changes due to increased privacy concerns and report individual cases of addiction and mental health issues. These observations are the results of a rapidly changing SNS creating a gap of understanding between users' interactions with the platform and future consequences. We explore how HCI can help close this gap and work towards more ethical user interfaces in the future.
### HumAID: Human-Annotated Disaster Incidents Data from Twitter
 - **Authors:** Firoj Alam, Umair Qazi, Muhammad Imran, Ferda Ofli
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
 - **Arxiv link:** https://arxiv.org/abs/2104.03090
 - **Pdf link:** https://arxiv.org/pdf/2104.03090
 - **Abstract**
 Social networks are widely used for information consumption and dissemination, especially during time-critical events such as natural disasters. Despite its significantly large volume, social media content is often too noisy for direct use in any application. Therefore, it is important to filter, categorize, and concisely summarize the available content to facilitate effective consumption and decision-making. To address such issues automatic classification systems have been developed using supervised modeling approaches, thanks to the earlier efforts on creating labeled datasets. However, existing datasets are limited in different aspects (e.g., size, contains duplicates) and less suitable to support more advanced and data-hungry deep learning models. In this paper, we present a new large-scale dataset with ~77K human-labeled tweets, sampled from a pool of ~24 million tweets across 19 disaster events that happened between 2016 and 2019. Moreover, we propose a data collection and sampling pipeline, which is important for social media data sampling for human annotation. We report multiclass classification results using classic and deep learning (fastText and transformer) based models to set the ground for future studies. The dataset and associated resources are publicly available.\url{https://crisisnlp.qcri.org/humaid_dataset.html}
## Keyword: recommendation
### The Power of Subsampling in Submodular Maximization
 - **Authors:** Christopher Harshaw, Ehsan Kazemi, Moran Feldman, Amin Karbasi
 - **Subjects:** Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Optimization and Control (math.OC)
 - **Arxiv link:** https://arxiv.org/abs/2104.02772
 - **Pdf link:** https://arxiv.org/pdf/2104.02772
 - **Abstract**
 We propose subsampling as a unified algorithmic technique for submodular maximization in centralized and online settings. The idea is simple: independently sample elements from the ground set, and use simple combinatorial techniques (such as greedy or local search) on these sampled elements. We show that this approach leads to optimal/state-of-the-art results despite being much simpler than existing methods. In the usual offline setting, we present SampleGreedy, which obtains a $(p + 2 + o(1))$-approximation for maximizing a submodular function subject to a $p$-extendible system using $O(n + nk/p)$ evaluation and feasibility queries, where $k$ is the size of the largest feasible set. The approximation ratio improves to $p+1$ and $p$ for monotone submodular and linear objectives, respectively. In the streaming setting, we present SampleStreaming, which obtains a $(4p +2 - o(1))$-approximation for maximizing a submodular function subject to a $p$-matchoid using $O(k)$ memory and $O(km/p)$ evaluation and feasibility queries per element, where $m$ is the number of matroids defining the $p$-matchoid. The approximation ratio improves to $4p$ for monotone submodular objectives. We empirically demonstrate the effectiveness of our algorithms on video summarization, location summarization, and movie recommendation tasks.
### Why? Why not? When? Visual Explanations of Agent Behavior in  Reinforcement Learning
 - **Authors:** Aditi Mishra, Utkarsh Soni, Jinbin Huang, Chris Bryan
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2104.02818
 - **Pdf link:** https://arxiv.org/pdf/2104.02818
 - **Abstract**
 Reinforcement Learning (RL) is a widely-used technique in many domains, including autonomous driving, robotics, stock trading, and video games. Unfortunately, the black box nature of RL agents, combined with increasing legal and ethical considerations, makes it increasingly important that humans understand the reasoning behind the actions taken by an RL agent, particularly in safety-critical domains. To help address this challenge, we introduce PolicyExplainer, a visual analytics interface which lets the user directly query an RL agent. PolicyExplainer visualizes the states, policy, and expected future rewards for an agent, and supports asking and answering questions such as: ""Why take this action? Why not this other action? When is this action taken?"". PolicyExplainer is designed based upon a domain analysis with RL experts, and is evaluated via empirical assessments on a trio of domains: taxi navigation, an inventory application, and the safety-critical domain of drug recommendation for HIV patients.
### Reinforcement Learning with a Disentangled Universal Value Function for  Item Recommendation
 - **Authors:** Kai Wang, Zhene Zou, Qilin Deng, Runze Wu, Jianrong Tao, Changjie Fan, Liang Chen, Peng Cui
 - **Subjects:** Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2104.02981
 - **Pdf link:** https://arxiv.org/pdf/2104.02981
 - **Abstract**
 In recent years, there are great interests as well as challenges in applying reinforcement learning (RL) to recommendation systems (RS). In this paper, we summarize three key practical challenges of large-scale RL-based recommender systems: massive state and action spaces, high-variance environment, and the unspecific reward setting in recommendation. All these problems remain largely unexplored in the existing literature and make the application of RL challenging. We develop a model-based reinforcement learning framework with a disentangled universal value function, called GoalRec. Combining the ideas of world model (model-based), value function estimation (model-free), and goal-based RL, a novel model-based value function formalization is proposed. It can generalize to various goals that the recommender may have, and disentangle the stochastic environmental dynamics and high-variance reward signals accordingly. As a part of the value function, free from the sparse and high-variance reward signals, a high-capacity reward-irrelevant world model is trained to simulate complex environmental dynamics under a certain goal. Based on the predicted environmental dynamics, the disentangled universal value function is related to the user's future trajectory instead of a monolithic state and a scalar reward. We demonstrate the superiority of GoalRec over previous approaches in terms of the above three practical challenges in a series of simulations and a real application.
### Evaluating Medical IoT (MIoT) Device Security using NISTIR-8228  Expectations
 - **Authors:** Thomas P. Dover
 - **Subjects:** Cryptography and Security (cs.CR)
 - **Arxiv link:** https://arxiv.org/abs/2104.03283
 - **Pdf link:** https://arxiv.org/pdf/2104.03283
 - **Abstract**
 How do healthcare organizations (from small Practices to large HDOs) evaluate adherence to the cybersecurity and privacy protection of Medical Internet of Things (MIoT) used in clinical settings? This paper suggests an approach for such evaluation using National Institute of Standards and Technology (NIST) guidance. Through application of NISTIR 8228 Expectations it is possible to quantitatively assess cybersecurity and privacy protection, and determine relative compliance with recommended standards. This approach allows organizations to evaluate the level of risk a MiOT device poses to IT systems and to determine whether or not to permit its use in healthcare/IT environments. This paper reviews the current state of IoT/MiOT cybersecurity and privacy protection using historical and current industry guidance & best-practices; recommendations by federal agencies; NIST publications; and federal law. It then presents similarities and differences between IOT/MiOT devices and ""traditional"" (or classic) Information Technology (IT) hardware, and cites several challenges IoT/MiOT pose to cybersecurity and privacy protection. Finally, a practical approach to evaluating cybersecurity and privacy protection is offered along with enhancements for validating assessment results. In so doing it will demonstrate general compliance with both NIST guidance and HIPAA/HITECH requirements.
## Keyword: graph neural network
### Theoretically Improving Graph Neural Networks via Anonymous Walk Graph  Kernels
 - **Authors:** Qingqing Long, Yilun Jin, Yi Wu, Guojie Song
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2104.02995
 - **Pdf link:** https://arxiv.org/pdf/2104.02995
 - **Abstract**
 Graph neural networks (GNNs) have achieved tremendous success in graph mining. However, the inability of GNNs to model substructures in graphs remains a significant drawback. Specifically, message-passing GNNs (MPGNNs), as the prevailing type of GNNs, have been theoretically shown unable to distinguish, detect or count many graph substructures. While efforts have been paid to complement the inability, existing works either rely on pre-defined substructure sets, thus being less flexible, or are lacking in theoretical insights. In this paper, we propose GSKN, a GNN model with a theoretically stronger ability to distinguish graph structures. Specifically, we design GSKN based on anonymous walks (AWs), flexible substructure units, and derive it upon feature mappings of graph kernels (GKs). We theoretically show that GSKN provably extends the 1-WL test, and hence the maximally powerful MPGNNs from both graph-level and node-level viewpoints. Correspondingly, various experiments are leveraged to evaluate GSKN, where GSKN outperforms a wide range of baselines, endorsing the analysis.
### Optimizing Memory Efficiency of Graph NeuralNetworks on Edge Computing  Platforms
 - **Authors:** Ao Zhou, Jianlei Yang, Yeqi Gao, Tong Qiao, Yingjie Qi, Xiaoyi Wang, Yunli Chen, Pengcheng Dai, Weisheng Zhao, Chunming Hu
 - **Subjects:** Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2104.03058
 - **Pdf link:** https://arxiv.org/pdf/2104.03058
 - **Abstract**
 Graph neural networks (GNN) have achieved state-of-the-art performance on various industrial tasks. However, the poor efficiency of GNN inference and frequent Out-Of-Memory (OOM) problem limit the successful application of GNN on edge computing platforms. To tackle these problems, a feature decomposition approach is proposed for memory efficiency optimization of GNN inference. The proposed approach could achieve outstanding optimization on various GNN models, covering a wide range of datasets, which speeds up the inference by up to 3x. Furthermore, the proposed feature decomposition could significantly reduce the peak memory usage (up to 5x in memory efficiency improvement) and mitigate OOM problems during GNN inference.
",2021-04-08T06:44:05Z,2021-04-08T06:44:05Z,open,0,"paper/literature of dark pattern, document, paper title: Ethical User Interfaces: Exploring the Effects of Dark Patterns on Facebook","Facebook, UI, examples","Facebook, documentation",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tailscale/tailscale/issues/983,FR: Make autostart optional in Windows installer,https://github.com/tailscale/tailscale/issues/983,"Could you please add an option to the Windows Tailscale installer to ask the user whether he / she wants the Tailscale GUI to start on system boot or not? I couldn't find the NSIS configuration in the repo to directly make a pull request, so I assume that's part of the closed source of the GUI clients.
The option can be default on the keep the current behavior.

Thank you!",2020-12-02T16:29:35Z,2023-01-05T06:44:00Z,open,23,"miscellaneous (dark pattern design practices, automatic setup new software, hard to turn off)",start up software?,"deceptive design practices, obstruction",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/top-gg/issues/issues/846,Feedback on new vote-page button behaviour,https://github.com/top-gg/issues/issues/846,"#### New voting page behavior negative feedback

I have negative feedback of the new implementation of voting, where the vote button is blocked if you have already voted ...

Before the update you would be able to activate the button after the advertisement even if you had already voted; if you tried voting before the due time it would then error out.

Now due to this update, you can unlock the vote button only after the due time runs out so for every vote you have the delay of the advertisement (because after the 12 hours elapse, you have to reload the page; you can't just be ready to vote as you could before, because now the button is blocked).

I'm not sure I explained myself. Basically I prefer to still see the ad and have the vote button available for click, even when I have already voted for the bot: the bot will send me a Discord message when I can vote again and in that second I press Vote.

Now I have to reload the page and wait for the ad. Because at the 12th hour mark even if I'm fully ready to press on the vote I now have to reload the page a second time in order to unlock the vote.",2021-11-27T23:23:57Z,2022-04-09T00:29:00Z,open,10,"prevention of dark pattern in software, voting system, avoid waiting ads, ","ads, voting, forced action","ads, voting system, avoid dark pattern, forced action",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ChatTriggers/ChatTriggers/issues/261,Essential should not be a hard dependency,https://github.com/ChatTriggers/ChatTriggers/issues/261,"**Is your feature request related to a problem? Please describe.**
Essential is in my opinion [bloat + probably privacy invading][1], and does not offer any value to developers except the GUI libraries + other (which can be shaded and/or done with a custom implementation).

**Describe the solution you'd like**
Essential should not be a hard dependency. It should be up to CT modules to handle how Essential may be unavailable.

**Describe alternatives you've considered**
None, since Essential is a hard dependency

**Additional context**
I also hold a bit of a grudge against Essential due to how their UI has dark patterns and has taken data collection to in my opinion, an extreme level, so take this with a grain of salt.

  [1]: https://semisol.dev/blog/why-to-not-use-essential/",2021-11-27T15:17:22Z,2023-12-23T15:08:00Z,closed,3,,"Essential, data collection, UI","Essential, data collection, UI/UX design",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/privacycg/proposals/issues/26,Ad Topic Hints,https://github.com/privacycg/proposals/issues/26,"# What if we flipped digital advertising around?
Today, when you visit a website, each ad network roughly follows three steps:
1. Figure out **_who you are_**, 
2. …then look up **_a profile of behavioral data_** about you. Stuff like what other websites you’ve visited.
3. …then, based on this, try to **_infer what ad topics_** you might be interested in seeing.

What if we flipped the script entirely, to make the web more private, but also to put people in control:
1. Visit website
2. Multiple ad networks all ask your web browser: “**_What topics of ads_** should I show to this person for this website visit? Please select a topic they’ll find interesting / relevant.”

This not only skips over the resolution of the user-identity step (which is poised to break in light of browser tracking prevention efforts), it also means the ad networks no longer need to keep a profile of behavioral data about individuals.

But perhaps most interesting of all, it moves that decision of “what ad topics would you be interested in seeing” into a place where people can exert control over the process.

Through a combination of sensible automatic defaults, with the opportunity for people to manually override the system (if they so desire) perhaps we can have both relevant ads about interesting topics, and also preserve user privacy and autonomy.

# Addressing the risk of fingerprinting

People have multiple interests, and these interests change over time. What’s more, people don’t necessarily know what they like. An important function of ads is to help people discover new products and services that they’d love, but didn’t know about before.

As such, the “Ad Topic Hints” returned by the browser should change constantly. Some topics of interest may show up more frequently than others, and the user might express the desire to see other topics less. And finally, there ought to be some randomness thrown in - to mix things up and explore topics they haven’t seen before.

This is great news from a privacy perspective, because it means these “Ad Topic Hints” couldn’t be used as some kind of tracking vector, or fingerprinting surface. If the “Ad Topic Hints” returned by the browser include a lot of random variation and change over time, not only across sites, but even across multiple sessions on the same site, we should be able to ensure they can’t be used for fingerprinting. This is [one of the major points of criticism about FLoC](https://blog.mozilla.org/en/mozilla/privacy-analysis-of-floc/) that this “Ad Topics Hints” proposal seeks to address.

# Addressing the risk of sensitive information disclosure

These ad interests aren’t communicating data about what websites a person has visited, their attributes or characteristics. FLoC indirectly does this (to some extent), and this is another piece of criticism this proposal seeks to address. Since we’ve flipped the script, this proposed API would instead be sending out information about **_characteristics of ads, not people_**.

But perhaps more importantly, this API would, by design, provide the user with the ability to inspect (and if they so desire, override) the set of “Ad Topic Hints” their browser is telling sites to show to them. Any inferences being made about what ad topics their browser thinks they may find interesting would be clearly displayed. Rather than [have the browser vendor determine what is “sensitive” or not](https://github.com/WICG/floc#sensitive-categories), if the person felt that a given “Ad Topic” revealed something they didn’t want revealed, they could ask their browser to stop requesting ads of that topic.

# Ad topics as vectors of numbers

Rather than describe an “Ad Topic” with a categorical label, we propose using a neural network to convert ads into embedding vectors ([introductory explanation here](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526) if you're not familiar with the concept). This has numerous benefits. It’s precise, can be universally applied without the need for human annotation, smoothly captures concepts that don’t have simple names, works across all languages, and allows us to compute the numerical “similarity” of any two ads.

Imagine an open-source ML system into which you feed an ad. It analyses the image / video as well as text, and emits a list of 64 numbers. Like this:

1.56, -3.82, 3.91, -2.27, -7.16, …, 1.81

Anyone can run this code on any ad to instantly get the list of numbers that are the “embedding” for that ad. We can design a system which can deal with all kinds of inputs, so that it works for image ads, video ads, text ads, anything. 

This ML system would be designed so that ads about similar topics result in **_nearby points_**. In this way, we can easily compare any two ads to see how “similar” they are. We just compute the cosine of the angle between these two vectors. It’s as simple as just computing the dot-product of both embedding vectors and dividing by both magnitudes. It’s computationally fast and cheap.

Now that we have a simple, standard way to understand the “topic” of an ad, and a way to compare the similarity of two ads, let’s describe how it would be used.

The browser can select a vector that’s “similar” to other ads the person finds interesting / relevant. It can avoid selecting vectors similar to ads for which the person has expressed dislike. And every now and again, the browser should just pick a random area it hasn’t tried before - to explore, and learn if the person is interested in that topic or not.

# Sensible defaults

Most people will not want to take the time to interact with an interface that asks them about their ad interests. That’s fine, so long as we have a reasonable default for people who don’t bother to configure this themselves.

The browser can collect information about ads the person is shown across the web, ads they click on, and ad conversion events.

Based on this information, the browser can infer what ad topics the person seems to engage with (and what they do not).

# Autonomy through centralized transparency and control

Unlike much behavioural advertising today, where inferences derived from behavioural data are often invisible and unknowable - the browser can make all of this available to the user. It can show them not only the inferred interests it has generated, but also the raw data used to generate that prediction. 

This leads to the second big difference with most forms of behavioural advertising. The user may choose to modify or override these inferred interests.

The fact that these inferences are all centralised within the browser is what makes this a tractable user experience. It’s not realistic for people to identify all the ad networks which may be making inferences about them based on behavioural data. It’s even less realistic to imagine that people will modify / override these inferences across all those networks. Centralisation gives the user a realistic form of control.

This should also address concerns about “autonomy”. When it’s possible to see all the data, and all the inferences, and to override / modify them in one place, we can say that this puts people in control over the ads they want to see and what information their browser transmits about those interests.

What’s more, the browser should allow people to configure how much “exploration” they’d like. Some people might desire more variety, while others might prefer their browser to stick to a narrower range of ad topics.

This proposal isn’t prescriptive about the exact algorithm the browser should use to select the ad interest vector to be sent to a given page, as this should be a great opportunity for browser vendors to compete with one another, in terms of ease of use and relevance of ads, as well as ease of user understanding and control.

# Ideas about ways to incorporate user-stated/controlled interests

Several important proposals about ads and privacy involve labeling ads in a way that the browser can understand. While these proposals are primarily about attribution / measurement use-cases, we could utilize this here as well.

Once a browser understands what pieces of content are ads, it could potentially introduce a universal control that allows people to tell the browser how they feel about the “Ad Topic” of that ad. Perhaps a “right click” or a long-press on mobile could reveal options like “More ads of this topic” or “Fewer ads of this topic”. 

Another idea would be for the browser to have a special UI somewhere with an infinite feed of ads. These could either be a hard-coded list, or could be fetched through ad requests to networks that wanted to participate in such a UI. People could go through this “ad feed” selecting “More ads of this topic” or “Fewer ads of this topic” on each. This would help the browser quickly understand more about what this person did / didn’t want to see ads about.

There are no doubt many other ideas out there which merit experimentation. This is just the beginning of this conversation.

# Concern about centralized browser control

But there are also downsides to this level of centralization within the browser. Browser vendors who operate “Search Ads” that rely on first-party data would be able to personalize ads with or without this “Ad Topic Hints” API. They wouldn’t have much incentive to make this system work particularly well (from the perspective of ad monetization). As such, they might under-invest in this “Ad Topic Hints” API.

How can we stimulate more competition in this space? One possible approach would be to make this API “pluggable”. Such browser plugins would need to be reviewed / vetted to ensure user privacy and stop abuse. Plugins would have access to the ad-interaction data described in the “sensible defaults” section as well as user feedback on ads, and could design their own user-interfaces as well as algorithms to generate the “Ad Topic Hints” returned.

Making “Ad Topic Hints” pluggable is just one idea. There may be even better solutions available.

# Understanding Ad Topic Hints

Advertisers will naturally want to develop some understanding of these “Ad Topic Hints” and map them to concepts they already understand, like the [IAB taxonomy of ad topics](https://iabtechlab.com/blog/tech-lab-adds-new-ad-product-taxonomy-to-portfolio).

The easiest way to understand these “Ad Topic Hints” would be to take a sample of ads that represent all the various categories in the IAB taxonomy of ad topics, and run them through the ML system. Ideally one would produce mappings for multiple examples of each category. 

Then, for any “Ad Topic Hint” vector, one could compare it to these reference points. A simple approach would be to just consider the topic of the ad with the “closest” vector. A more sophisticated approach might consider the actual “distance”. If the closest reference point is sufficiently far away, this may be an unlabelled part of the ad topic spectrum. We may discover that additional categories need to be added to existing taxonomy systems.

To help illustrate this mapping process, imagine these embedding vectors were just two dimensional. By coloring the space which is closest to a given reference point all the same color you’d wind up with a Voroni Diagram like this:

[Image of a Voronoi diagram from Wikipedia](https://en.wikipedia.org/wiki/Voronoi_diagram#/media/File:Euclidean_Voronoi_diagram.svg)

Imagine that each of those black dots represents a “reference ad” deemed to belong to a particular “Ad Topic” in the IAB’s taxonomy. Any “Ad Topic” vector would fall into one of these colored regions. A simple approach would be to deem that topic the same as the reference point within that region.
",2021-06-21T00:38:37Z,2021-07-26T18:04:35Z,open,15,miscellaneous (avoid dark pattern discussion),,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/webcompat/web-bugs/issues/58918,www.reddit.com - see bug description,https://github.com/webcompat/web-bugs/issues/58918,"<!-- @browser: Firefox Mobile 68.0 -->
<!-- @ua_header: Mozilla/5.0 (Android 7.1.2; Mobile; rv:68.0) Gecko/68.0 Firefox/68.0 -->
<!-- @reported_with: mobile-reporter -->
<!-- @public_url: https://github.com/webcompat/web-bugs/issues/58918 -->

**URL**: https://www.reddit.com/r/StonerPhilosophy/

**Browser / Version**: Firefox Mobile 68.0
**Operating System**: Android 7.1.2
**Tested Another Browser**: No 

**Problem type**: Something else
**Description**: Dark Pattern implemented server-side to trick mobile users to install an unnecessary app.
**Steps to Reproduce**:
Reddit randomly denies access to ""subreddits"" to mobile users to force them to install an unnecessary app even though there is a mobile UI available and online on the website. This is a dark pattern because it nudges people to take unwanted actions. Additionaly this practise should be considered harmful because it works against a standardized and interconnected world-wide-web.
<details>
      <summary>View the screenshot</summary>
      <img alt=""Screenshot"" src=""https://webcompat.com/uploads/2020/9/ff398b55-959e-4332-a545-8e27a19801d9.jpg"">
      </details>

<details>
<summary>Browser Configuration</summary>
<ul>
  <li>gfx.webrender.all: false</li><li>gfx.webrender.blob-images: true</li><li>gfx.webrender.enabled: false</li><li>image.mem.shared: true</li><li>buildID: 20200731175902</li><li>channel: default</li><li>hasTouchScreen: true</li><li>mixed active content blocked: false</li><li>mixed passive content blocked: false</li><li>tracking content blocked: false</li>
</ul>
</details>

[View console log messages](https://webcompat.com/console_logs/2020/9/6c4d4d0e-2eb2-4b2b-8d39-1c2129dcb76b)

_From [webcompat.com](https://webcompat.com/) with ❤️_",2020-09-27T11:34:21Z,2023-10-19T19:13:23Z,closed,1,"Reddit, usage of dark pattern in software, nudge users to install app, unwanted action","Reddit, downoad unnecessary app, nagging","Reddit, nagging, app installation",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/webcompat/web-bugs/issues/51690,jevaisvouscuisiner.com - Unable to dismiss subscription popup,https://github.com/webcompat/web-bugs/issues/51690,"<!-- @browser: Firefox Mobile 75.0 -->
<!-- @ua_header: Mozilla/5.0 (Android 10; Mobile; rv:75.0) Gecko/75.0 Firefox/75.0 -->
<!-- @reported_with:  -->
<!-- @public_url: https://github.com/webcompat/web-bugs/issues/51690 -->
<!-- @extra_labels: browser-focus-geckoview -->

**URL**: https://jevaisvouscuisiner.com/griesknepfle-gnocchi-semoule-alsace-recette/09/2017/

**Browser / Version**: Firefox Mobile 75.0
**Operating System**: Android
**Tested Another Browser**: No 

**Problem type**: Design is broken
**Description**: Items are overlapped
**Steps to Reproduce**:
newsletter pop-up unclosable, suspecting a dark pattern...

<details>
<summary>Browser Configuration</summary>
<ul>
  <li>None</li>
</ul>
</details>

_From [webcompat.com](https://webcompat.com/) with ❤️_",2020-04-15T20:51:36Z,2023-10-19T19:41:47Z,closed,3,"jevaisvouscuisiner.com, usage of dark pattern in software, unabled dismiss subscription popup, nagging",pop-up with no close button,"jevaisvouscuisiner.com, modal, pop-up, nagging, obstruction",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/ahmedk92/Blog/issues/27,Thoughts about Clean Architecture™,https://github.com/ahmedk92/Blog/issues/27,"# Thoughts about Clean Architecture™

The clean architecture is an application architecture popularized by [Robert C. Martin](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html). You may be already familiar with it or its name. If not, that's ok. If you know about architectures such as MVVM, you're mostly there. I'll try to organize my thoughts according to the following:

1. Quick overview of the architecture and what is promises to deliver.
2. Promised wins and my personal opinions on how much each of them is achieved.

<br/>
<aside>
💡 Note that I'll be discussing a flavor of it that got popular among mobile developers, iOS and Android alike. That form of the clean architecture may not be 100% in line with what Robert C. Martin originally intended or what he would personally do.
</aside>

<br/><br/>
\<rant>
Before we begin, I must mention that I have a pet peeve with the architecture's name. I really think it wouldn't have been that popular if it was named otherwise. This is why I stylized it as Clean Architecture™ in the title. I believe intuition is king. The word clean works wonders especially with new developers. It can also cause those who don't adopt it to look down on their code because it's not ""clean"".
\</rant>

## Quick overview of the clean architecture

I'll try to tackle this point from the developer's point of view. I think most of us progressed in a similar way with respect to architecture. It was something like this:

1. Apple's MVC. 
    1. AppDelegate was a big deal, and contained so much important logic.
    2. Network calls casually happened in view controllers.
    3. Singletons were convenient and abundant.
    4. No tests.
2. A better MVC.
    1. Things started to move out from the app delegate and view controllers to models (the M in MVC)
    2. Singletons were probably still there, but used in places that made sense.
    3. Tests started to appear. But since a good deal of interaction logic was still in view controllers, tests didn't cover that area.
3. MVVM (or MVP)
    1. Interaction logic also moved out from view controllers to view models (or presenters).
    2. View models and presenters made it easier to test interaction logic.

While at this point things started to look much better than before, to some, there was still some imperfections to say the least. To some they saw it as flaws. Namely, what's known as business logic, or what the clean architecture like to call, domain logic. To be fair, depending on the problem at hand, it's hard to draw clear lines where does domain logic begins or end. It maybe be easy to draw the lines for a shopping cart app, but what about a drawing app, or a JSON processor app? In such apps, domain logic can easily get mixed with UI and data logic respectively. Anyway, based on that reasoning, the clean architecture builds upon that notion of boundaries, and breaks down the app to the following layers (typically represented as modules, but we won't discuss this now):

1. Domain. This is the centerpiece of the architecture. This layer doesn't not depend on any other layer. It also shouldn't expose any 3rd party dependency in its APIs (and ideally nor system APIs as well). It contains business rules represented as models and use cases.
    1. Domain models. A domain model is a plain ""POJO"" that contains just enough data that delivers to the user a specific value. For example, in a shopping cart app, `CartProduct` sounds like a valid domain model. That `CartProduct` can look like this:
        
        ```kotlin
        data class CartProduct(
          val productId: String, 
          val productName: String, 
          val isAvailableInLimitedAmount: Boolean
        )
        ```
        
        In UI, products that are available in limited amounts may be required to be displayed differently, with a different text color for example, to urge the user to checkout quickly (hello dark patterns 👋). The takeaway here is that a domain model shouldn't include something like text color. Instead, it should include what piece of information valuable to the user it's trying to communicate, and presentation (or UI. That's a different debate 😅) should translate that to a text color.
        
    2. Use cases. You can imagine them as functions in suits 🕴️A use case is a function-like object whose a single method (e.g. `execute`or whatever syntactic sugar the language offers like Swift's `callAsFunction`). Each use case returns (or accepts, or both) a domain model. So, for the domain model given an example above, the use case returning it would be something like `GetCart`. 
2. Presentation. Here live view models. They delegate to use cases to pull/push data to/from the UI. Their sole responsibility now is managing temporary state and managing interaction. No ""business logic"" here anymore.
3. UI. 
4. Data. It depends on domain, and shields it from dealing with the intricacies of managing data, be it remote or local. This layer itself is broken down into other layers:
    1. Repository (some call it Gateway). Use cases define their interfaces. They cater the needed domain models to use cases. As a result, it's not unusual for business logic to actually end up in the repositories, rendering use case as pass-throughs. Repositories depend on local and remote data sources to properly construct the required domain models. 
    2. Data Sources. A data source can be thought of as a shell over an actual data source like a web API or a data base. They majorly expose a CRUD kind of an API. A repository is the one that knows who to make meaningful domain models out of data models returned by data sources. A data source can be local or remote.
        1. Local. It can wrap an in-memory structure, a locally persisted file of some popular format (json, xml, ...etc), shared preferences, user defaults, a sqlite database, Core Data, Realm, ..etc. Most of the time it's considered as a cache, but for sure in some cases they are the primary source of truth.
        2. Remote. It can wrap any kind of network-based data sources like REST, RPC, sockets, ...etc.

I think this was enough of an overview. Let's see what the architecture promises.

## Promised wins

There are multiple goals developers usually have in mind when adopting this architecture. In no particular order and no claim of being exhaustive:

1. Domain-driven design.
2. Development parallelism.
3. Testability.
4. Common language (screaming architecture)
5. Decoupling.

### Domain-driven design

As mentioned earlier, the architecture advocates a domain-driven design. Use cases and domain models shouldn't be affected by what kind of UI is being used. The same domain layer can be used in a mobile app and a command line app for example. 

While being the hallmark of the architecture, I think this gets broken quite often. The issue is not with developers doing something wrong I believe as it's with how tricky the concept really is. Take a dashboard feature for example. The concept is naturally heavily UI-driven. Having a use case with the word ""dashboard"" in its name triggers some clean architecture zealots/connoisseurs. The quick remedy is often just a name replacement with a word like ""statistics"". In my opinion, that's just a hack. Why should a particular set of statistics be grouped like that in a single use case unless it's expected to be displayed in a single hard-to-decompose UI component? To raise the argument in a different way, imagine the user interface is a voice-based assistant like Siri. Usually the user asks a question and expects a brief answer, not a dashboard-sized bucket of information. Does it still make sense to reuse the same use case for such interaction?

### Development parallelism

The layer/boundary decomposition works from a task organizing point of view. Since each layer defines their own models and interfaces to interact with other layers, working on implementing multiple layers at once is achievable. For example, once domain models and use cases are defined for a given feature, work on presentation and data can start in parallel.

### Testability

Since logic is now spread across multiple layers, the responsibility of each class becomes smaller. Dependencies represented as interfaces (dependency inversion protocol in action) makes it easier to mock them in unit tests.

However, there's something inconvenient about writing unit tests for heavily broken down code like this. At some point, especially in the data layer, tests become brainless and the amount of mocking vastly outweighs the actual logic being tested, to the extent you sometimes feel you're testing the mocks. Mocking code can outgrow actual code that it might exceed it in bugginess. This may not be a problem with the architecture per se, but maybe of how it become popular to view each class as a unit that must have its own tests.

### Common language

The template nature of the architecture makes it easier for new developers to expect where they can find a particular type of logic. This is usually referred to as a screaming architecture. My only problem with this is that I believe this backfires in terms of creativity. Shoe-horning any application to fit a ui→viewModel→useCase→repository interaction feels absurd and bureaucratic sometimes or most of the time depending on the problem at hand.

### Decoupling

One of the goals of the architecture is to decouple components from each other, and more importantly decouple domain from any framework or library dependency, be it 3rd party or system-provided. This sounds good to everyone most of the time, but it comes with shortcomings. The architecture puts much faith in programming languages. Recall its requirement that domain shouldn't expose a library dependency in its API. This prohibits using something like Rx's `Observable` types in the use case signature for example. However, developers usually solve this problem by simply breaking that rule for Rx. This is one example from a [popular clean architecture sample on Github](https://github.com/sergdort/CleanArchitectureRxSwift/blob/f4e4b74661ad6f0639c39b0d927f153897eda0bb/Domain/UseCases/PostsUseCase.swift):

```swift
import Foundation
import RxSwift

public protocol PostsUseCase {
    func posts() -> Observable<[Post]>
    func save(post: Post) -> Observable<Void>
    func delete(post: Post) -> Observable<Void>
}
```

Domain models being POJOs suffer a similar problem. Take a library like Realm for example. One of its selling points is what they call zero-copy, or what basically means, the object in hand is just a holder of pointers for fast access to data saved on disk. So, a model like this (taken from their [docs](https://docs.mongodb.com/realm/sdk/android/#define-an-object-schema)):

```kotlin
import io.realm.RealmObject

open class Frog(
    var name: String,
    var age: Int = 0,
    var species: String? = null,
    var owner: String? = null
): RealmObject()
```

won't actually store any property of those in memory when fetched, but each property will be a proxy/getter that knows where exactly the needed data in the persisted file and will return it each time it's called. This is cool for some performance-wise. However, having to copy those into plain POJO domain models you simply lose that feature completely. Some may see that's violating the separation of concerns principle and mixing business and data/persistence specificities. That's fair point, but I wouldn't judge this as **wrong**. I believe the architecture being lacking in supporting such features is better admitted than doubling-down and mocking other approaches. That stance of looking down on to conflicting approaches is sadly abundant among this architecture's adherents. 

And to expand more on copying, to construct a domain model, a quite good deal of copying is usually done across layers. First the deserialized object fetched from the API for example is copied to a model that is returned by the remote data source to the repository for further processing. The repository in turn copies that model again to the domain model. Most of the time all these versions look exactly the same, with the exception of the deserialized object having an annotation or is a subclass of a reusable deserializer library object. I haven't seen the architecture applied in a performance-sensitive contexts. I don't know really how this problem can be solved without breaking the architecture's principle.

## Conclusion

The architecture works, but I don't like it. However I can live with it since it's became an industry standard, at least in mobile development. 

I think the architecture has some non-trivial negative impact and shortcomings as demonstrated, but unfortunately its adherents exacerbate its dislikability by alienating the criticizers. The culture around it really triggers some gut alarms. Maybe because it's marketed at developers how feel insecure about their ad-hoc architectures? The populist nature (if you allow me) of its terminology also works well marketing-wise; starting from claiming the word ""clean"" to the liberal use of strong words like right, wrong, good, bad, etc. by its proponents.

I would expand more on the negative cultural impact of it in this article, but I tried to avoid ranting as possible. So, maybe twitter is a more fitting place for such noise :)",2021-12-12T14:06:55Z,2021-12-13T13:03:46Z,open,0,"miscellaneous (dark pattern discussion, fake scarcity, fake urgency)","checkout, urgency","fake urgency, fake scarcity",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/w3c/manifest-app-info/issues/42,Enable developers to know if a web app has been installed,https://github.com/w3c/manifest-app-info/issues/42,"We’ve gotten signal that some developers have an interest in making adjustments to their content and/or resource payload based on installation status. Currently, folks are relying on querying ""display mode"" on the client side as a proxy, but display mode does not indicate installation status (e.g., a ""fullscreen"" display mode is indicated even if the site was put in fullscreen mode via the JavaScript API.

This issue thread is intended to catalog the use cases folks have for wanting to know about installation status.

Related: #32 and https://github.com/w3c/manifest/pull/977",2021-09-10T16:39:07Z,2021-09-29T22:09:36Z,open,11,"deceptive design practices, forced action, sign-in with installation, force to accept ","installation issue, forced action","sign-in with installation, forced action, deceptive design practice",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/freedomofpress/dangerzone/issues/117,Improve Overall UX,https://github.com/freedomofpress/dangerzone/issues/117,"**Purpose**
I have volunteered to develop a plausible (to reasonably implement) and intuitive ux solution to guide implementation of #77, in the GUI. After taking _Dangerzone_ for an initial spin on my Mac, a host of usability quirks emerged that could be improved upon to support both #77 and single-file use of _Dangerzone_. 

This issue is to track and collect feedback against work towards improving _Dangerzone's_ **general** usability, in a light design sprint with occasional follow-up. This work is likely to include my asking some of questions, and my submission of wireframes and interactive proof-of-concept video(s) for review. 

**Scope**
Internews is funding some of my work on the [SecureDrop Worksation](https://workstation.securedrop.org/) project, through its [Usable.Tools](https://usable.tools/) fund. _DangerZone_ has emerged as a relevant tool in Worksation users' workflows, and we (the SecureDrop team) would like to contribute a few of my hours from the usable.tools award, towards making _DangerZone_ more intuitive—and extending that functionality to support bulk file sanitization. ",2021-06-11T22:25:30Z,2023-11-22T18:29:30Z,open,11,"Dangerzone (convert potential danger docs into safe ones), improve UX, Google and Facebag are famous for usage of dark pattern to to ""drive engagement""","Google, Facebag, ""drive engagement, override UI, dangerzone","Dangerzone, Google, Facebag, ""drive engagement"", UI/UX design",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/matrix-org/matrix-spec/issues/797,Controlled accounts,https://github.com/matrix-org/matrix-spec/issues/797,"Hi,

I've been looking for a way for my kid to communicate with their classmates/friends in a responsible way (both privacy and security) but my pursuit ended with the sad conclusion that there currently is no such thing.

I'm not going to introduce my kids to the pests like FB and others. Or rather, I would at least like to keep them away from those platforms for as long as I can since I realize that the social pressure to use them will only grow as kids age.

So before going into much more detail: this idea is targeting a set of features to support communication for children _younger_ than 13 years old. This is a very sensitive subject so if the age target is out of the question due to law restrictions or whatnot, feel free to say so and there's no need to continue reading my ramblings.

So the idea is to create a walled garden for younger children to freely communicate without their parents having to actively setup a communication line using the currently existing platforms (which are all targeted towards adults or >13y) each time that the kid wants to talk (chat/video call/doodle/whatever) with one or more friends, classmates, family members, ...

Child accounts should be restricted in many ways:
- must be created by an existing account (parent account) and cannot be created on their own.
- multiple accounts can be assigned as parent accounts, but each parent account should be notified about other parent account actions concerning the child account.
- all child account communication should be end-to-end encrypted (somewhat, see following point)
- ~~**(controversial)** all parent accounts ~~should~~ (may) be able to access end-to-end encrypted communication (this might be a bit tricky because if all parent accounts are automatically joined in every room, the children will get the feeling of being continuously watched which is not what I want to achieve)~~
- all child account actions are constrained to non-public spaces. (not sure if that's a thing, I should read up on the current spaces spec)
- can't join spaces without parental approval.
- can't accept invites without parental approval (unless specifically allowed in a Space).
- can't join rooms without parental approval (unless specifically allowed in a Space).

There are probably other things that I can't come up with right now, so I might add some later on.

This featureset could also be used to provide safe spaces for elementary schools (class rooms, playground rooms, club rooms), sports clubs and other organizations revolving about children where you want your children to communicate with their peers without fearing harassment by external parties.",2021-04-07T08:12:40Z,2023-01-29T19:50:15Z,open,30,"controlled account, kids (<13 yrds) communication platform, mislead users that they sign up a secure account but less secure in reality","controlled account when a personal account is created, privacy issue","controlled account, privacy issue, misleading",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/extratone/extratone/issues/233,Deurbanising the Web,https://github.com/extratone/extratone/issues/233,"“I’ve migrated to HTML 4.”
- _Mark Pilgrim, January 2003._
“The software industry is currently going through the “disposable plastic” crisis the physical world went through in the mid-20th century (and is still paying down the debt for). You can run software from 1980 or 2005 on a modern desktop without too much hassle, but anything between there and 2-3 years ago? Black hole of fad frameworks and brittle dependencies. Computer Archaeology is going to become a full-time job.”
- _Linux Weekly News, August 2020_
—-
Computing in the 2020s is (still) a user-hostile shifting sand land1. We are drowning in churn and noise. I am fighting back by switching this website from HTML to PDF.
Yes, blasted, accursed PDF, of all things!
“Why? Why?! For the love of all that is holy, why?!” you say!
Certainly not because it’s a great format. PDF has many shortcomings. But in its cold, immutable fixity, it stands in opposition to the mercenary, dynamic web of rubbish. PDF makes a stand against the churn.
“We choose to switch to PDF in this decade, not because it easy, but because it is hard” – John F. Warnock, September 12th 1962
I’m publishing this document in PDF because:
• PDFs are self-contained and offlineable – you can archive them and be confident they will remain stable and readable in the future, with no external dependencies to manage. You can’t kill a PDF by shutting down an API.
• PDFs are files. We must not lose sight of the fact that files are a basic freedom. In a world where information is increasingly locked up behind APIs, files represent control for the user. A file is a sequence of bytes, of a known length. It is completely under the control of the user. A vendor cannot change it sneakily. You can checksum it and
     1 Not an original idea – such complaints are commonplace. Here’s one, and here’s another, and another, and another, and another.
      2
  
manage its integrity. You can sign it and manage its authenticity. You can back it up and distribute it easily. You can sneakernet it and samizdat it. You can parse it and convert it to another format. You can work with it offline. We have 60 years of tooling available to manage files.
• PDFs are decentralised. You may have obtained this PDF from a website, or maybe not! Self-contained static files are liberating! They stand alone and are not dependent on being hosted by any particular web server or under any particular domain. You can publish to one host or to a thousand hosts or to none, and it maintains its identity through content-addressing, not through the blessing of a distributor.
• PDFs are discoverable. Search engines index them as easily as any other format.
• PDFs are independent of browsers – but can still be read easily by most browsers.
• PDFs and a PDF tool ecosystem exist today. No need for another ghost town GitHub repo with a promising README and v0.1 in progress. PoC||GTFO!
• PDF is an open standard, which is freely available2, and stable. It has a version number and many interoperable implementations including free and open source readers and editors.
• PDFs are part of the web, as much as HTML – they support hyperlinks and you can link to specific pages with URL fragments.
• PDFs are page-oriented. This is another fundamental freedom – to know unambiguously which part of the document you are looking at. Compare to infinite-scroll HTML pages which are disorienting by design. This may sound trivial, but seriously: with infinite scrolling, you are fundamentally not in control of the reading experience. Let’s ignore the fact that most infinite scrolling implementations are janky. The problem is that you have no clear notion of when the document will end, whether you will be permitted to reach the end, whether the end will still be available by the time you get there, or what hurdles (adverts) lie in your path. It is harder to reference a section, to share it, to bookmark it, to download it, and to find it again. You are reliant on the site to inform you where you are and where you need to go next. Unsurprisingly, this disorientation is a feature, from the perspective of
   2 Although it is a scandal that ISO want 198 Swiss Francs for a copy of the PDF 2.0 spec, ISO 32000-2:2017
 3
  
the content controller. A page is a physical unit of information just as the paragraph is a logical unit of information. HTML focuses on logical structure and leaves the physical structure to the browser, which ostensibly formats it for optimum viewing by the user, but in practice formats it for optimum “engagement” with the advertiser. Without pages, users are adrift.
PDF’s historical disadvantages are now either resolved or mitigated:
• PDFs used to be large, and although they are still larger than equivalent HTML, they are still an order of magnitude smaller than the torrent of JavaScript sewage pumped down to your browser by most sites3.
• PDFs used to be inaccessible, but now you can tag them.
• PDFs used to be unreadable on small screens, but now you can reflow
them.
• PDFs used to be read-only, but now there are tools to edit them4, or dump their contents to other formats.
• PDFs used to be best consumed as printed pages, but now there is an abundance of PDF tooling for viewing and manipulating them on screens of all sizes.
How did it come to this?
Some say the organic web is dead, but it is still out there. It’s out there in the same sense that the open countryside is still out there: local, boutique, and characterful, but gradually thinning in favour of a great migration away to the cities. Web denizens now spend their online lives in the immense arcologies of Facebook, Google, Twitter, Reddit, the walled gardens of app stores, and the walled fortresses of corporate networks. Basic infrastructure is gloriously taken care of by the City – no need to be concerned with what lies beneath the streets. It’s all just there waiting to serve eager customers. Plush furnishings and smooth highways. All you need to do is go when the light turns green and stop when the light turns red. You’ll never be lost because everywhere is a destination. All this, for only $9̅.99.
The countryside has been paved.
3 The http archive State of the Web report for July 2020 claims the median desktop page size is 2000KB, across 70 requests.
4 But it’s still best if you don’t.
     4
  
In the city, you are free to walk the streets and gawp through the windows, urged not to notice you are on somebody else’s property, subject to their terms of service (you did read them, didn’t you?), consuming that service using devices they approve, at a time they decide, in a format conducive to monetisation, and in an order set by an algorithm tuned by addiction psychologists to maximise your spend. There is a one-way system in force: the downward scroll.
Content marketing has infected the web. Advertising has funded many wonderful things, but with the disastrous side-effect of poisoning the web’s semantics. Every topic has been SEO’d, and everyday searches lead to pages of fake plastic human-interest, the length and shape of which has been designed solely around the multiple megabytes of adverts, distractions, upsells, misdirections, invitations to sign up to newsletters, cookie warnings, GDPR warnings... and maybe some content darting out of view as another ad loads. Is it unfair to blame advertising for the government-mandated cookie warnings? Not at all, because websites don’t need to use tracking cookies, and they only need a GDPR warning if they process personal data. Quit processing my personal data!
Articles are undated in an attempt to stay evergreen. If information architecture had a Geneva Convention, this would be a war crime.
The churn is relentless – content is changed without notice or record of history, or republished under different domains. The search engines5 are choked of their oxygen supply, with every search keyword assailed by a zombie horde of have-a-go algorithmically-generated content farms, trying to out-pagerank each other and exhausting the namespace around those keywords.
The tracking and monitoring is all-pervasive. Sites that failed to get a click out of you try to wring some residual value from your visit through harvesting your personal data, or maybe even by hammering your CPU and battery with some cryptomining JavaScript.
Mobile is the worst, hemmed in by hustlers on all sides, with only a narrow blinkered proprietary viewport to look through, and the bonnet sealed shut.
      5 Both of ‘em!
 5
  
Follow the money
The thermonuclear cash generator at the heart of AdTech is driven by engagement and attention. The more time users spend on your site, the more adverts you can show them. And what should the ad vendors do when every web page is completely saturated by advertising? Easy! Expand the scope of the web to include every possible mode of content creation and consumption and in fact all of computing in its entirety, thereby attracting more eyeballs!
Starting with Web 2.0 techniques such as XMLHttpRequest, which was the key enabling technology for reloadless single-page-applications, we now have a web of applications, not just a web of pages. The web is no longer just HTML, but also Web GL, Web Sockets, Web Assembly, Web RTC, Web NFC, Web Storage, a Vibration API... the catalogue of specs is monstrous.
Drew DeVault demonstrates it hilariously:
“The total word count of the W3C specification catalogue is 114 million words at the time of writing. If you added the combined word counts of the C11, C++17, UEFI, USB 3.2, and POSIX specifications, all 8,754 published RFCs, and the combined word counts of everything on Wikipedia’s list of longest novels, you would be 12 million words short of the W3C specifications.
I conclude that it is impossible to build a new web browser. The complexity of the web is obscene. The creation of a new web browser would be comparable in effort to the Apollo program or the Manhattan project.
It is impossible to:
• Implement the web correctly
• Implement the web securely
• Implement the web at all”
The old web standards have been co-opted; the W3C has capitulated and accepted that HTML is now ruled by the WHATWG. Who are they? The browser vendors!
Now, browsers today are incredibly sophisticated and powerful. The browser engineers deserve immense respect for the technology they have created. We live in a web application paradise thanks primarily to the efforts (and $billions) of Mozilla and Google. Web applications are neat, but the browser has become the all-consuming gatekeeper of interaction and engagement. Driven by this demand to expand its domain of control, the browser is now so complex that it requires web-advertising-scale investment to maintain. The browser vendors have achieved devops apotheosis in their rapid release cadence, but have done so out of
         6
  
necessity, driven by endless scope creep. The recent interest in VR and AR is fuelled by a dollar-signs-for-eyeballs desire for a terra nullius to pave with billboards.
“Every program attempts to expand until it can read mail. Those programs which cannot so expand are replaced by ones which can.”
- Zawinski’s Law
When is a browser finished? ChromeOS’s answer is: not until it has completely taken over all functionality of the OS, and turned the whole computer into a browser appliance!
This complexity creates a vast attack surface, in need of regular patching. It’s so complex that the whole apparatus is de facto fundamentally insecure – why else the need for continual patching? You can’t stay safe without accepting updates, and the updates come with feature churn mixed in alongside the security patches in a mandatory undifferentiated trashstream of updates. (There is an Extended Support Release of Firefox which receives security patches for as long as a whole year!).
You might wonder what the problem is with all these specs growing and browsers getting regular updates. Isn’t it a good thing that we enjoy rapid progress?
To the extent that we get to enjoy things like YouTube and sandspiel, yes! But to the extent that we want the internet to be a place where we can work and live and think and communicate free of malware, surveillance, dark patterns and the insidious influence of advertising, the answer is, empirically, sadly, no. The web has become ad-corrupted hand-in-hand with growth in technological capability, and the symbiotic relationship between web and browser means they feed on each others’ churn. Ads demand new sources of novelty to put themselves on, so the web expands continually, the specs grow in complexity, the browsers grow in sophistication, the barrier to entry grows ever higher, the vast cost of it all demands more ad revenue to fund it... and thus the perpetual motion machine is complete.
There is no baseline, and no stability or clear standard or objective beyond continual expansion. But stable standards are incredibly important. They allow software, at least in theory, to be finished. Why is it important that software be finished? Because it gives us hope that we might end the churn and fix all the bugs! I want to use software whose version number is
     7
  
1.0. I want to use software whose every line of code has been studied, analysed, optimised and punishingly tested. I want every component and subcomponent and every interaction and every configuration to be exquisitely documented, and taught in courses, and painstakingly deconstructed and proven sound. I want an ethnography of computer science whose scripture is this divine code, quoted for wisdom, on which scholars publish volumes of commentaries, and commentaries on the commentaries. I want software that works!
I can dream, right?
The neverending6 churn as the web increases its scope directly drives the “Black hole of fad frameworks and brittle dependencies”. In return for the marvel that is the modern web application, we have struck an awful bargain: it is now almost impossible to read a simple document on the web without signing up to the whole web application contraption, and there is no simple document-oriented subset of HTML for which you could create a simple document-oriented browser. Moreover, the web is now everything (witness the death of the thick client).
I posit no conspiracy theory here. It’s the Systems Razor: Never attribute to malice or stupidity that which is adequately explained by uncontrolled complexity.
Can we fix it?
It’s time to rebuild the web! Let’s define a simplified subset of HTML, CSS and JavaScript that cannot be subverted into AdTech, and a simple, secure browser to consume it. Content will be delivered over a new, modern decentralised protocol...
Haha, only kidding. I can’t be the only one tired of experimental proto- projects which promise revolution if only literally everybody could be persuaded to join their new network and become software technicians.
The ad-browser-social-network-industrial-complex is all but extinguishing the old web, and the foundationless, ad-driven churn driving it is harming the global information ecology and ultimately harming public discourse by making the open web a toxic experience and driving users to centralised platforms. Chaos and banditry force the population into the arms of feudal lords who promise protection.
        6 HTML is now a “living standard”
  8
  
There used to be an internet middle class, of non-commercial users who were not overtly technical, but were still able to self-publish. Much as in the offline world, the middle class has been squeezed, and now the internet population seems sharply polarised, with elite wizard hackers running things like IPFS on one side, and captive non-techies never seeing anything outside the Facebook mobile app.
Ironically, it’s never been easier to set up a website – we have Medium, Wordpress, Wix, Blogger, and ten thousand other services providing infrastructure. But they are mostly used for evil7, being the tools behind the satanic cabal of recipe sites, listicle-pushers, and clickbait merchants. Many genuine bloggers are out there in the web countryside, but drowned out.
I sorely miss the independent online citizenry with publishing sovereignty, but I just don’t trust the browser-oriented web any more. What should we do?
Backwards to the future
“In anything at all, perfection is finally attained not when there is no longer anything to add, but when there is no longer anything to take away, when a <body> has been stripped down to its nakedness.” - Antoine de Saint-Exupéry
Let HTML5 become the web application platform. Let the browser vendors keep developing forever more. We can’t fight them (and besides, we all still want to watch YouTube), but we can escape to the countryside and rebuild something human-scale, human-controlled and human-understandable!
It is true that the PDF spec has suffered feature creep (3D models?!), so we should use PDF/A instead, which forbids interactive content (normal PDFs can contain JavaScript!) and ensures your PDFs are absolutely self- contained, even embedding the fonts.
“But how can you just throw away all of the semantic qualities of HTML?!”
HTML’s semantic capabilities were oversold. Tagged PDF is just as expressive for all practical purposes. Maybe HTML supports richer metadata, but metadata is crap. Stick the right keywords in a document and 99% of semantic use cases are met.
“But why not use a traditional subset of HTML and just avoid JavaScript?!”
HTML encourages document creep. Are you disciplined enough to stick to that subset? Are you sure you won’t be tempted to embed an interactive tweet or some other faustian convenience? How will your users trust that
        7 Counterpoint: Neocities is awesome!
  9
  
your site’s plain-HTML-look doesn’t hide some malicious JavaScript tracking anyway?
PDF/A makes a statement against such shenanigans.
“But what about RSS syndication?!”
You can point to a PDF file in an RSS feed if you wish.
“But how can I automate updates to my site’s look and feel?!”
Same as with HTML – generate your PDFs using scripting. But unless you’re fixing usability issues, do your users a favour and don’t bother – readers are interested in the content and truly don’t care about the headers, footers, sidebar, and whatever.
“But PDFs look so ugly when reading on my phone!”
Eh, they look alright to me. I do acknowledge that fancy spidery tiny text in multi-column layouts is awkward and ugly to read on a small screen, but that’s a layout decision that you can make, and word processors (or DTP software) make it a whole lot easier for lay persons to control layout to suit their audience.
“But it’s just as easy to write self-contained HTML pages!”
Sure, but if you’re going to hide CTF forensics challenges in your publication, a coverdisk allows you to do it in style!
“But how can I implement shiny whizz-bang features that will engage readers and drive conversions?!”
You can’t. PDF is boring. Boring is bad for business. But boring is good for users.
“But how can I add legitimate interactive features to my site, like user comments?!”
Foregoing interactive features is most certainly a sacrifice. But how much of a compromise is it really that commentators must get their own blog instead of commenting on yours? The instant gratification of in-line real- time comments is a double-edged sword. In my view, the great majority of comments are worthless, low-effort, trolling, psy-ops, or malicious. Comments worth making can withstand the friction of having to send an email. Raising the barrier to commentary could do the web some good. Not everything has to be scaled and automated.
I look forward to a new web niche of non-interactive yet richly-linked PDFs, each with a unique style and charm, born of innocent and uncomplicated
   10
  
human desire to be heard, real monkeysphere-scale community, and freed from the dopamine treadmill of checking your likes, comments and engagement metrics.
“What are the thousands of browser engineers going to do all day now that you’ve destroyed HTML?”
Web applications aren’t going anywhere any time soon, but perhaps some of that talent could be put to improving the PDF tool ecosystem. Despite the support I’m expressing here, I do acknowledge that PDF tools have a lot of rough edges and there is much room for improvement (Libreoffice is currently state of the art for open source tools that can generate Tagged PDF!).
PDF: Still Unfit for Human Consumption, 20 Years Later is a recent roast of PDF, but there are many fine counterpoints and rebuttals on Hacker News. I get it, PDF can be ugly. I’m still saying it’s worth it to escape the noise.
“Come on, who are you kidding with all that moaning about infinite scrolling and advertising? If you don’t like infinite scrolling, HTML doesn’t force you to do it! Same goes for advertising.”
Sure, you can write good HTML. I won’t argue with that. And if you’re writing good HTML, good for you. But HTML is a dual-use technology, the bad guys are dual-using it an awful lot, and I feel that the stone age still has a part to play in the progression of the information age

## Call to action
**Publish in static file formats. Date and hash your work. Stop spying on your users**
  
## Colophon
Taking my own advice, this document was written in the world’s greatest web authoring tool: LibreOffice Writer. It was exported to Tagged PDF/A-2b, followed by adding the coverdisk as a PDF attachment, followed by qpdf and sed munging to achieve PDF/A-3b compliance. The coverdisk is a 1.44MB FAT-12 formatted floppy disk image containing a GPG public key which may be used in future crypto ops.
The document’s primary URL is https://lab6.com/0 – although mirrors are welcome.
The document may contain outrageous falsehoods and embarrassing mistakes, unretractable due to it being immutable. Corrections may be published in future issues.
All content is licensed under:
https://creativecommons.org/licenses/by-sa/4.0/
Contributions may be sent to the email address on the last page, or the Bitcoin address on the first page.
This document’s hexadecimal SHA256 hash begins 0x00, identifying the issue number.
250e3f7d581acff115537ba38e89ad31 is a handy random 128-bit integer that will appear in every issue of Lab 6 and can be used to search for copies.",2021-07-21T12:29:13Z,2021-07-21T12:30:29Z,open,0,"discussion of dark pattern on internet techonology, hard to avoid malware, DPs free environment, web has become ad-corrupted, ads demand increased","ads, malware","ads, malware, discussion, ad-corrupted",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/offen/offen/issues/584,Proposal: Interpolate statistics of anonymous visitors,https://github.com/offen/offen/issues/584,"This is a proposal to eliminate the blind spot in the analytics without compromising the Offen concept.

I'm not familiar with the code base, so please understand this as a high level proposal without implementation details.

## Definitions

I really like the Offen approach to privacy. I like the transparency and control it gives to visitors. At the same time, I see solutions like Plausible and Fathom become increasingly popular because they track every visitor in a way that is at least privacy friendly. I like to think of them as *Anonymous Trackers*. Offen is what I, for the purpose of this proposal, would describe as a *Fair Tracker*. Now *Fair Trackers* are opt-in which is gives total control to the users. If users don't give consent, they will not be tracked at all. *Anonymous Trackers* will track every user and even employ methods such as subdomain forwarding to prevent anti-tracking methods. They do, however, go to great lengths to anonymize users. They keep little data and use hashing to protect personal information.

## Background

As a web developer and a member of the open source community, I value the privacy of my users. As a business owner (without unlimited resources for user research, focus groups, A/B testing, etc.) I need actionable usage statistics to understand how users interact with my product in order to improve UX. Users have a right to control their own data, but as a creator, I too have a legitimate interest to learn how many users I have. So I'm looking at solutions like Offen, Plausible and Fathom and try to wage the benefits. *Anonymous Trackers* can only provide limited insight because they need to be technically unable to connect too many dots. Their concept is to track all users, but not individually. *Fair Trackers* can potentially provide deeper insight, but can only track a possibly quite small subsample of users, because they are opt-in only.

Products like Google Analytics are on the extreme end of the privacy spectrum. They care only about the business owners. Offen however, ist also an extreme solution, just on the other end. Google gave full control only to business owners, Offen only to users. Solutions like Plausible and Fathom are somewhere in between, albeit obviously more on the privacy-friendly side. I really like what Offen is building but I'm afraid the approach might be too restrictive to find wide commercial usage. With this proposal, I seek to provide just enough data to satisfy the cravings of business owners without compromising the Offen concept and values.

## Proposal

I would love to see Offen implement a feature that would allow interpolation of actual usage, based on a) the data collected using the opt-in tracking and b) additional, but very limited data about all visitors. 

The additional tracking proposed would be obligatory for all visitors, but would be cookie-less and would only collect:

- a timestamp of the moment a request was made
- the requested domain + path

This is very little and it is not personal data. But this information could be combined with the rich information about consenting users to interpolate actual usage. The way Offen currently collects statistics, I know how many users opt-in to analytics, but I don't know how many users don't. Collecting just this additional data would enable the following example.

### Example

On a given day, I have 1000 users on my page. 70 of which visit a certain subpage. Only 10% of all users opt-in to analytics. So in my auditorium, I will only see 100 users in total on that day and 7 on that subpage. That gives me a false sense of usage. My site is actually 10 times more popular than I think. If I were to sell ads on my page to maybe make my project sustainable – even if I want to do it in the good old-fashioned, zero-tracking way, Offen would make it hard to determine a fair price because I don't know the total number of views.

However, if Offen were to collect the additional tracking data of every user as described in the proposal, the 10% of users that share their statistics with me, could be interpolated to show me an approximation of the real usage. That way Offen could tell me that there were at least 7 visits on that subpage, but based on the additional tracking, there probably were actually 60 - 80 visits.

This could be visualised using a box plot or similar.

## Rough ideas for implementation

1. Many websites collect logfiles for various reasons. When it comes to DDOS protection, logfiles are a valuable tool. Offen could read the logfiles and gather only the information needed. The logfiles could (as they should be anyway) also be anonymised and short-lived. Offen could also further aggregate the data collected.
2. Offen could collect the needed data itself, similar to the way Plausible and Fathom are doing it.

Personally, I would prefer the first idea. Also, the feature should be optional. 

## Advantages

- more accurate statistics that are far closer to the real numbers
- more appeal to businesses
- makes it easier to sell ads without resorting to ad networks which probably always compromise user privacy
- many websites collect logfiles anyway, even if just anonymised, one might even use tools like GoAccess to complement the Offen stats
- only very little additional data would be collected and no personal data

## Disadvantages

- the concept is more difficult to understand for non-technical folks – if not done well, it might appear like a cheap trick
- with either solution, the setup would be a little more complicated (another reason, this feature should be optional)
- analytics are often hosted separately from where the logfiles live, so to grant access, logfiles might be exposed by accident

## Notes

Of course, the interpolation can only yield good results with either a certain amount of users, or an exceptionally high opt-in ratio. Offen would need solid math behind this and might also need to provide some sort of probability score for the interpolated statistics. A cool way to visualise this might be with increasing transparency or bluriness for days with little data. But I'm getting carried away by the design aspect ;)

## Conclusion

I believe this feature would be a great addition and would improve Offen's competitiveness towards the *Anonymous Trackers*. I would even argue that this approach would be fair not only towards users but also towards projects and businesses.",2021-04-01T09:59:50Z,2021-04-08T08:55:46Z,open,8,"Offen (fair web analytics software), anonymous visitors count feature, users privacy concerns, ","cookie consent, feedback frustruting","Offen, privacy issue, cookie consent",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/kleros/gtcr/issues/147,"Fix some ""No new windows"" overshoot",https://github.com/kleros/gtcr/issues/147,"It looks like all the new windows of the dapp were removed even when they are not classic link.
In particular:
- Left click on ""view listing policies"" starts a download but also links to a blank page 
![image](https://user-images.githubusercontent.com/8873352/87182204-31f13200-c2d3-11ea-90eb-e5b8dc0f4d47.png)
(here it's not a link to another page, but a download ""action"" button), so it shouldn't open a new page.
- Pop under about transactions are not open in a new page which can lead to losing the deployment flow (here they are not classic links but some sort of button and users would obviously want to stay on the page, so it's not a dark pattern).
",2020-07-10T17:33:26Z,2023-04-11T14:10:09Z,closed,2,"dark pattern or not, not DP, link prompts to new window",not dp?,"dark pattern or not, discussion",dark pattern or not,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Xmader/musescore-downloader/issues/5,How to respond to the takedown request email?,https://github.com/Xmader/musescore-downloader/issues/5,"> Hi,
I'm Musescore developer. You need to takedown this repository: https://github.com/Xmader/musescore-downloader and any other your public repositories with same code. Because you illegaly use our private API with licensed music content. All not Public domain content on musescore.com is licensed by major music publishers (Alfred, EMI, Sony, etc.). Distribute licensed music content from Musescore.com for free you violate their rights.
Therefore, in pre-trial procedure, I suggest you close the following resources:
•	https://github.com/Xmader/musescore-downloader (and all your forks and mirrors)
•	https://greasyfork.org/en/scripts/391931-musescore-downloader
Otherwise, I will have to transfer information about you to lawyers who will cooperate with github.com and Chinese government to physically find you and stop the illegal use of licensed content.
> 
> Thanks,
> Max Chistyakov 
> 
> P.S. You can always download Public Domain content for free from musescore.com.

2020-02-08T11:03Z",2020-02-08T23:35:01Z,2022-09-01T18:46:56Z,open,288,"Musescore, takedown request email, usage of dark pattern in software, Musicscore pro, trick users to paid version","download button, not free, misleading","Musescore, trick users to buy paid products, misleading",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/microsoft/vscode/issues/115619,All extensions should be required to respect the enableTelemetry setting to be allowed on the marketplace,https://github.com/microsoft/vscode/issues/115619,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Quoting the website: ""VS Code lets you add features to the product by installing Microsoft and third-party extensions. These extensions may be collecting their own usage data and are not controlled by the telemetry.enableTelemetry setting. Consult the specific extension's documentation to learn about its telemetry reporting and whether it can be disabled.""

I see no reason why there's an extension-sized loophole in the telemetry optout. It's unreasonable to expect the user to read the doc of every extension to see what setting they need to disable telemetry (assuming they even provide such a setting). This skirts the line of a dark pattern designed to discourage the user from avoiding telemetry, and getting them used to forceful telemetry. 

If you're serious about allowing the user to opt out of telemetry, then the terms of the extension marketplace should require authors to respect the single enableTelemetry flag, or they don't get approved.",2021-02-02T16:50:08Z,2023-01-27T23:23:59Z,closed,1,"VSCode, extension in VSC, usage of dark pattern, discourages telemetry opt-out, data collection disabled  ","VSCode, Microsoft, extension, forced action, telemetry","VSCode, Microsoft, extension, forced action, telemetry, data collection, opt-in/out",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/dandi/dandi-archive/issues/758,Improve dandiset creation screen with more information for end user,https://github.com/dandi/dandi-archive/issues/758,"* the License (i) icon should offer more helpful hints about the different license types

* ~provide brief instruction on the top:~
	~Red is required~
	~To add funding information, …~ (Roni: I don't think this is still valid; all fields in the form are required, and funding information in particular must be added at a later time; @bendichter, please explain in a new comment if you disagree)

* ~Protocol (i): protocol.io -> protocols.io~ (Roni: this was fixed at some point)",2021-07-14T21:17:13Z,2023-04-11T21:53:58Z,closed,14,"good usage of dark pattern, help users avoid accidently choose CC0, CC0 - Creative Commons Zero and CC-BY -Creative Commons Attribution","dandiset, dp for forced action example","dandiset, forced action, dark pattern to promote good behavior",DPs in design coding ,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/apache/pulsar/issues/9291,Statsd,https://github.com/apache/pulsar/pull/9291,will write it..,2021-01-23T16:18:28Z,2022-12-07T05:05:32Z,closed,3,miscellaneous (dark pattern in Google),,miscellaneous,miscellaneous,dark pattern in Google,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mozilla-mobile/fenix/issues/13120,"""Enable Synchronization"" banner in settings cannot be removed",https://github.com/mozilla-mobile/fenix/issues/13120,"## Steps to reproduce

1. Get Firefox 79.0
1. Go to settings
1. See huge banner half the first settings page ""Enable synchronization""

### Expected behavior

1. There's some way to remove that annoying banner

### Actual behavior

1. ""Enable Synchronization"" banner cannot be removed

### Device information

* Android device: Moto G5 Plus
* Fenix version: 79.0

┆Issue is synchronized with this [Jira Task](https://mozilla-hub.atlassian.net/browse/FNXV2-4218)
",2020-07-30T12:11:05Z,2022-12-22T20:31:59Z,closed,7,"Mozilla, usage of dark pattern in software, ""Enable Synchronization"" banner can't be removed, nagging","sticky banner, obstruction, nagging","Mozilla, sticky banner, nagging",DPs used in software,,,dark pattern or not,dark pattern or not,,,
https://api.github.com/repos/element-hq/element-android/issues/4025,Can't get out of a verification dialog,https://github.com/element-hq/element-android/issues/4025,"### This issue is: Ready to build

This screen should act as a bottom sheet. When the user clicks outside the area of the bottom sheet it should close. We should implement the appropriate close actions suggested by google. Found here: 
 
> Other ways to close the bottom sheet should be:
> https://material.io/components/sheets-bottom#modal-bottom-sheet
> 
> Control
> Modal bottom sheets appear when triggered by a user action, such as tapping a button or an overflow icon. They can be dismissed by:
> 
> - Tapping a menu item or action within the bottom sheet
> - Tapping the scrim
> - Swiping the sheet down

## Original issue

I accidentally clicked on a new session toast as it popped up while I was doing something else.

Now I have this and can't dismiss it:
![Screenshot_20210916-085451~2.png](https://user-images.githubusercontent.com/51663/133573557-73b9bb7b-286f-41f4-824e-cb0db405bb6d.png)

I want to be able to dismiss that dialog by clicking away from it.",2021-09-16T07:58:56Z,2023-01-13T16:50:36Z,closed,11,"usage of dark pattern in software, verification dialog popup, nagging, block users from dismiss, obstructions","users cannot dismiss, pop-up, modal, obstructions, nagging","pop-up, modal, obstructions, nagging, non-dismissable noticed",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Leantime/leantime/issues/145,Feedback for Project Roadmap 2020,https://github.com/Leantime/leantime/issues/145,"(Continued in separate issue, from #139)

I am using LeanTime mainly as a self-hosted, personal lean project environment (some other users only occasionally). I want this server-based, so I can access from multiple devices (mobile: Android, iPad, laptop: Ubuntu), always with Firefox. I am very privacy-focused and FOSS-oriented. I highly value Humane Tech (I am admin of [HTC](https://community.humanetech.com)) and I judge companies in that light (privacy policies, trackers, dark patterns, etc.).

In all my tools I have a strong preference to use (github-flavored) Markdown. Additional support for (UML) diagrams is a big plus (think [Mermaid](https://mermaid-js.github.io/mermaid/#/) or [PlantUML](https://plantuml.com/)).

In LeanTime I'd like to define Epics and User Stories (will use ToDo's for them). There can be relationships between them (will use hyperlinks). Like in github I will have top-level issues with a checklist of sub-issues.

Missing for me is a place where I can have Gitbook-like long-form documentation (in Markdown). I need to have different Categories and a ToC per category with at least 2 levels of nesting (main / sub).

Integrations-wise I'm a big fan of alternative software (alternative to monopolists, centralization), like e.g. Matrix/Riot vs. Slack.

**Edit**: I am no fan of the current HTML editor, with wysiwyg as-you-type, and e.g. all newlines auto-create a paragraph spacing in the text.",2020-03-05T09:10:17Z,2022-08-21T15:39:03Z,closed,6,"judge companies' usage of dark patterns, privacy policies concerns, tracking issues",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tuskyapp/Tusky/issues/1941,[Feature Request] Setting for deactivation of dark patterns,https://github.com/tuskyapp/Tusky/issues/1941,"I'd like to have the possibility to deactive dark patterns like:
- pull to reload
- infinite scroll 

As an alternative to infinite scroll there could be a pagination of toots. 

* * * *
- [x] I searched or browsed the repo’s other issues to ensure this is not a duplicate.
",2020-09-23T08:07:44Z,2022-05-10T20:31:29Z,closed,2,"Tusky, prevention of dark pattern in software, no pull to read, no infinite scroll","pull to reload, infinite scroll, dp features add or not","Tusky, pull to reload, infinite scroll, addictive, dark pattern or not, avoid dark pattern, discussion","DPs prevention in software, DPs or not",,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/opencollective/opencollective/issues/4268,Platform tips UI design might be seen as a dark pattern,https://github.com/opencollective/opencollective/issues/4268,"I'm getting consistent feedback that the Platform Tips design is confusing/misleading. People just hit the blue button without reading the platform tip text and it's not at all clear to them if the tip is going to the platform or the host, etc. I'm seeing big platform tips come it when I'm sure the user did not really intend that. It's great for the platform to get tips, but I don't want to do it through a dark pattern where people aren't aware or understanding what they are doing.

Possible ideas:
* Make platform tip a separate step from the main contribution step.
* Visually separate it into two separate boxes.
* Default the tip to zero and only accept tips when someone means to give one.
* Make it way more obvious it's a tip - the text just says ""thank you for your contribution"" with no strong indication of what it's referring to.

![Screen Shot 2021-05-11 at 9 18 40 AM](https://user-images.githubusercontent.com/5498878/117725968-fc421000-b239-11eb-9919-51aad4aa8946.png)

related: #4153 ",2021-05-10T21:20:59Z,2022-05-23T01:33:48Z,closed,26,"dark pattern or not, prevention of dark pattern in design, platform tips in UI design, users aren't aware of what they are doing","payment, tips being added, hidden costs, dp or not, discussion","dark pattern or not, discussion, hidden costs, deceptive design practices, avoid dark patterns","DPs prevention in software, DPs or not",,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/masakudamatsu/mima/issues/70,Search box,https://github.com/masakudamatsu/mima/issues/70,"## UI Design

Google Maps iOS app turns the whole screen into a white-background page in which a search box is initially shown at the top (with the back button inside the box). As the user types, predictions will be shown as a list below the search box, NOT as a menu ""dropped down"" from the search box. Which is nice.

But it's boring. With the design concept stressing ""from sky"", the background should be a cloud-like: white but the edges are blurred. The search box outline and the divider in the list should be in (dark enough) sky blue, as if it's the sky seen between clouds. For dark mode, use the gray background with moonlight-like white.

## HTML

Use `<input type=""search"">` because it adds the x button to clear text once the user enters some text ([source](https://css-tricks.com/what-do-you-get-for-using-a-search-input-type/))

But it also enables autocomplete suggestions from past text inputs. Find a way to avoid clashing with place search autocomplete suggestions.
- see https://www.notion.so/HTML-forms-201b-autocomplete-ef7f02fe01ea4719984a637210f0d28e#e3c46053496943cdaf7b7cad2f7cfd3f

## Tasks
1. With mock search term and predictions, create an UI that will be shown after the user clicks the search button
2. Replace mock predictions with Google Maps predictions 

## References

### HTML/CSS best practices

https://www.notion.so/HTML-forms-209-Search-753c3be9b1934afe8e6120c861a86919

### HTML/CSS for Google style search box

https://www.notion.so/Google-search-bar-18a87af68f734c6c8e7f51fb66311626
https://codepen.io/masakudamatsu/pen/MWogwZb
https://material.io/design/navigation/search.html

### Privacy

https://www.smashingmagazine.com/2021/10/autofill-dark-pattern/

### design

Material Design: https://www.notion.so/Search-bar-7fdbe8e2aed545679eb072afb00a127f 

Drawing realistic clouds with SVG/CSS: https://css-tricks.com/drawing-realistic-clouds-with-svg-and-css/

From mood board
https://media.milanote.com/p/images/1M2PTV1r9fDJ1G/LUJ/image.png

### coding
Google Maps Place API's Autocomplete feature:  https://developers.google.com/maps/documentation/javascript/places-autocomplete#place_autocomplete_service",2021-10-16T07:03:22Z,2022-09-03T02:44:33Z,closed,0,"miscellaneous (resource to dark pattern, blog post: the autofill dark pattern)","article/website, autofill/autocomplete dp examples","autocomplete, autofill, examples, blog, post",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/aws-samples/aws-cdk-intro-workshop/issues/276,Incomplete cleanup / Cost trap,https://github.com/aws-samples/aws-cdk-intro-workshop/issues/276,"The workshop and CDK itself lack information about how to clean up correctly and which cost may occur.

As stated in #126 and ignored for years in https://github.com/aws/aws-cdk/issues/986, the user is left with a DynamoDB table, S3 bucket, CloudWatch logs and CloudFormation stack after finishing the workshop, without knowing about their existence.

This is a dark pattern (some may call it worse) as the user acts in good faith and in compliance with the cleanup section, yet will be left in an unclean state for redeployment and could be charged for resources he thought were destroyed.

I suggest the following steps:
- add a clear warning about potentially occurring costs (upfront, users may not complete the workshop)
- add description how/where to find an overview about all things which will/might create charges (e.g. in AWS Console)
- extend the code examples about information on the `RemovalPolicy` options
- implement and include the `cdk bootstrap --destroy` command",2021-08-17T16:50:43Z,2022-07-13T21:28:48Z,closed,2,"deceptive design practices, unclear cleanup instructions in AWS CDK workshop",unclean state for redeployment after cleaning?,"UI/UX design, unclear cleanup instructions in AWS CDK workshop",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/35,"Re: Opt-in, Consent, Opt-out, Global Controls",https://github.com/w3ctag/privacy-principles/issues/35,"* First sentence: Change “control” to “express a preference for what processing is done to their data”. 
* Second sentence: “uses” would seem more relevant in this context than “purposes”, or perhaps “uses and/or purposes”.
* Informative website regarding dark patterns: https://darkpatternstipline.org/harms
* For discussion: the default privacy tiers. For example, it does not seem appropriate to require people who are vulnerable to opt-out. Consider also adding text about the privacy implications of choosing to opt-out, especially when the majority of users does not.
* Consider adding text about people rarely changing the default and the consequences that has for their privacy.
* Permissions are relevant to consent. Take a look at Nick Doty’s post here: https://www.w3.org/blog/2019/07/adding-another-permission/. It could be a helpful starting point for recommendations. Would it make sense to add another section under 3 that covers permissions?
",2021-08-17T22:01:23Z,2022-06-27T15:00:11Z,closed,2,"source to dark pattern website, privacy principle, opt-in, consent, opt-out, global controls","website, definitions/examples","opt-in/out, privacy issue, cookie consent, examples",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/semgrep/semgrep/issues/4460,"Ensure users aren't surprised by ""--config=auto will log in to the Semgrep Registry with your project URL""",https://github.com/semgrep/semgrep/issues/4460,"Hi team,

Thanks for the semgrep project, I'm wondering what this notice is when running semgrep with the ``--config=auto`` suggestion refers to:

```semgrep --config=auto```
```
....
Logging in to the Semgrep Registry as project 'git@github.com:...`
```

This felt pretty alarming to read, given I thought semgrep was about to try and upload code somewhere?

What does ""logging in"" refer to? Who sees it? What if the repository on GitHub is private?

Thank you
",2021-12-26T02:21:23Z,2022-12-06T06:30:04Z,closed,19,"Semgrep (cybersecurity company), command line security tool - CLST, usage of dark patterns in CLST, send users data without comfirmation, automatically extract information without consent",dp in coding?,"Semgrep, consent, privacy issue, deceptive design practice",DPs used in software,,,DPs or not,dps or not,,,
https://api.github.com/repos/w3ctag/design-reviews/issues/643,HTMLMediaElement controlsList,https://github.com/w3ctag/design-reviews/issues/643,"Ya ya yawm TAG!

I'm requesting a TAG review of ""HTMLMediaElement controlsList"" to offer a way to control the native controls elements/buttons that are being shown by the user agent in order to be able to remove some features that do not make sense or are not part of the expected user experience or only allowlist a limited amount of features.

  - Explainer¹: [https://github.com/WICG/controls-list/blob/gh-pages/explainer.md](https://github.com/WICG/controls-list/blob/gh-pages/explainer.md)
  - Specification URL: [https://github.com/whatwg/html/pull/6715](https://github.com/whatwg/html/pull/6715) | [https://wicg.github.io/controls-list/html-output/#attr-media-controlslist](https://wicg.github.io/controls-list/html-output/#attr-media-controlslist)
  - Tests: N/A at the time of writing
  - Security and Privacy self-review²: [https://github.com/WICG/controls-list/blob/gh-pages/security-privacy-questionnaire.md](https://github.com/WICG/controls-list/blob/gh-pages/security-privacy-questionnaire.md)
  - GitHub repo: [https://github.com/WICG/controls-list](https://github.com/WICG/controls-list)
  - Primary contacts (and their relationship to the specification):
      - François Beaufort (@beaufortfrancois), Google
      - Tommy Steimel (@steimelchrome), Google
  - Organization(s)/project(s) driving the specification: Google
  - Key pieces of existing multi-stakeholder review or discussion of this specification:
    - [Intent to Prototype and Ship: noplaybackrate in HTMLMediaElement.controlsList](https://groups.google.com/a/chromium.org/g/blink-dev/c/u9jsiarDEOg) in 2021
    - [Intent to Implement and Ship: native media controls customization API](https://groups.google.com/a/chromium.org/g/blink-dev/c/tFuQd3AcsIQ/m/utuGo1FDEgAJ) in 2017
  - External status/issue trackers for this specification (publicly visible, e.g. Chrome Status):
    - [https://www.chromestatus.com/feature/5092414224072704](https://www.chromestatus.com/feature/5092414224072704)
    - [https://www.chromestatus.com/feature/5737006365671424](https://www.chromestatus.com/feature/5737006365671424)

Further details:

  - [x] I have reviewed the TAG's [Web Platform Design Principles](https://w3ctag.github.io/design-principles/)
  - The group where the work on this specification is currently being done: WICG
  - The group where standardization of this work is intended to be done (if current group is a community group or other incubation venue): unknown
  - Major unresolved issues with or opposition to this specification:
    - https://github.com/whatwg/html/issues/2293#issuecomment-275749536
  - This work is being funded by: Google

You should also know that...

- Chrome has shipped ""HTMLMediaElement controlsList"" in 2017.

We'd prefer the TAG provide feedback as:

  🐛 open issues in our GitHub repo for **each point of feedback**",2021-06-03T09:52:39Z,2022-07-28T14:20:32Z,closed,10,"deceptive design practices, restrict users' controls/accessibility/ability on site","disable download image, disable fullscreen, UI/UX design","deceptive design practices, restrict users' controls/accessibility/ability on site, ",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/mastodon/mastodon/issues/17040,Add admin setting to disable trending links separately from trending hashtags,https://github.com/mastodon/mastodon/pull/17040,"I am still unconvinced that #16917—which has been merged without addressing the stated concerns nor with any clear approval from the community—is a good idea.

Thankfully, the way it is implemented means links will not actually be reported as trending to users without moderators taking action first. Unfortunately, it ties the feature to trending hashtags, so moderators who want trending hashtags but not trending links will still get spammed with review requests for the latter.

This PR adds a separate setting to enable trending links independently from trending hashtags.",2021-11-25T20:01:46Z,2022-04-27T15:12:52Z,closed,9,"usage of dark pattern in Twitter to drive engagement, what is dark pattern, DP discussion","Mastodon, dp or not, examples, discussion","Mastodon, Twitter, drive engagement, discussion, dark pattern or not",dark pattern or not,,,DPs or not,dps or not,,,
https://api.github.com/repos/whatwg/html/issues/7113,Proposing a Web Privacy standard?,https://github.com/whatwg/html/issues/7113,"> Hello everyone,
>
> this is my first contribution here, so please be kind if I don't put this in the right way or at the right place or if I propose something, which has already been considered/discussed. Also English isn't my first language, so please ask if something sounds weird or is not understandable.
>
> Paul

In 2018 the European Union General Data Protection Regulation (GDPR) became effective, which introduced more stringent and strict measures to protect the personal identifying information of data subjects. As a consequence of that, a lot of countries have followed up with their own data protection laws. While there are now broad and effective legal frameworks for data protection, I was wondering whether it might be good to accompany those with technical frameworks, which are beneficial to both users and website providers -- for users because they could set general settings in their web browsers and wouldn't need to go through hundreds of thousands of cookie settings modals, but could easily and effectively exercise their decision power; for website owners because they could use a standard API without having to build one of their own.

Such standards would fulfil the promise of *privacy by design* and might help to end frustration on both the users and the providers site. I suppose this HTML standard repository is the best currently matching one, given that it already includes such modules as ""User interaction"", ""Web application APIs"" or ""Communication"". However if you feel like an other standard would be more applicable or this topic deserving a completely new standard, please let me know.

To be a bit more specific, here are two possible features I would consider for such a ""Web Privacy"" standard module:

* Cookie Management

    Cookie setting modals are something, website providers employ because they feel (or are) obligated to do so by the privacy laws. However, in the way they currently are, there are multiple design flaws. First of all, (almost) nobody ever reads through these modals at all. In my experience, there are two types of users: those who immediately click ""I consent"" to get rid of the modal as soon as possible; and those who click ""Manage settings"", then spend half an hour unticking various boxes, then giving up and clicking ""I consent"". This is because of the second flaw: the modals are generally designed in a way that makes it very easy to approve but extremely difficult to reject. Which is not only a so-called ""dark pattern"", but also illegal under many of these privacy laws.

    A possible solution here would be to define in the standard, that website providers could *somehow* inform browsers about the cookies they set, what type of cookies these are (necessary, additional comfort, tracking, advertisement, ...) and other needed information, and browsers allowing users via a browser dialog window (and likely default-settings) to make a choice based on these information.

* Advertisement Control

    Personalized advertisement is a privacy problem of its own. It is suspected to be used for psychological manipulation, including even for election fraud. It allows companies to track users around the whole internet. And it is used everywhere, you can't ""escape"" it.

    To better balance the interests of the advertisers and the users, I had the idea that users should be able to categorize themselves using standardized categories (such as, for example: ""interested in: Web Standards"", ""age: 18-35"") and advertisement providers using only these categories for selecting the shown ad. The categorization would be completely voluntary and 100%-ly up to the user. While there is currently no regulation yet, which would require this, I think having a web standard for that process could be beneficial already, since it would allow companies to voluntarily switch to these standards; their reason for doing that being to be able to advertise themselves as ""fair advertisers"".

(These are just two examples for what might be done here, so please propose other ideas if you have them.)

What do you think about having such a ""Web Privacy"" standard?",2021-09-24T11:21:52Z,2022-09-04T12:55:06Z,closed,9,"web privacy standard, cookie management, gdpr compliance enforced","modals, cookie management, illegal, law, easy to accept, hard to reject","modals, cookie management, GDPR, regulation, hard to canceI, UI/UX design","DPs related regulation, DPs examples/definitions",,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/AnalogJ/scrutiny/issues/31,Should `Power Cycle Count` mark as failed when number is low?,https://github.com/AnalogJ/scrutiny/issues/31,"As per title. Smart stats show Power Cycle Count as `64` and yet this shows as a failure in scrutiny. Is this correct? `load_cycle_count` is `4589` and that's a little on the high side but only a few times a day and doesn't seem hugely unreasonable to me based on past (anecdotal) experience. You are correlating this against backblazes failure data I presume and that's how you're coming up with FAIL?

```
SMART Attributes Data Structure revision number: 16
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
  1 Raw_Read_Error_Rate     0x000b   100   100   016    Pre-fail  Always       -       0
  2 Throughput_Performance  0x0005   134   134   054    Pre-fail  Offline      -       104
  3 Spin_Up_Time            0x0007   138   138   024    Pre-fail  Always       -       474 (Average 477)
  4 Start_Stop_Count        0x0012   100   100   000    Old_age   Always       -       75
  5 Reallocated_Sector_Ct   0x0033   100   100   005    Pre-fail  Always       -       0
  7 Seek_Error_Rate         0x000b   100   100   067    Pre-fail  Always       -       0
  8 Seek_Time_Performance   0x0005   128   128   020    Pre-fail  Offline      -       18
  9 Power_On_Hours          0x0012   098   098   000    Old_age   Always       -       15656
 10 Spin_Retry_Count        0x0013   100   100   060    Pre-fail  Always       -       0
 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       64
 22 Unknown_Attribute       0x0023   100   100   025    Pre-fail  Always       -       100
192 Power-Off_Retract_Count 0x0032   097   097   000    Old_age   Always       -       4589
193 Load_Cycle_Count        0x0012   097   097   000    Old_age   Always       -       4589
194 Temperature_Celsius     0x0002   162   162   000    Old_age   Always       -       37 (Min/Max 19/42)
196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0
197 Current_Pending_Sector  0x0022   100   100   000    Old_age   Always       -       0
198 Offline_Uncorrectable   0x0008   100   100   000    Old_age   Offline      -       0
199 UDMA_CRC_Error_Count    0x000a   200   200   000    Old_age   Always       -       0
```

<img width=""1375"" alt=""image"" src=""https://user-images.githubusercontent.com/2773080/90949044-bd9dc880-e412-11ea-93c9-33b2c7e7cb02.png"">
",2020-08-22T05:00:44Z,2022-05-25T15:26:58Z,closed,5,"Backblaze, deceptive design practices, popup/wizard, ","Backblaze, opt-in/out","Backblaze, opt-in/out, deceptive design practices","DPs examples/definitions, DPs in design coding ",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/orestbida/cookieconsent/issues/135,Color of buttons from a legal perspective,https://github.com/orestbida/cookieconsent/issues/135,"I'm no legal expert, I'm just reading articles and try to understand the situation. On 15th September 2020, the state court Rostock issued a judgement (Az. 3 O 762/19) in a case where the owner of a website had implemented two dark patterns to nudge the visitors into accepting all cookies. 1) unnecessary cookies were pre-selected and 2) the 'accept all' button was green and well visible, while the 'deny all' button was light grey with white font color. Based on this decision, I have read several [articles](https://www.heuking.de/de/news-events/newsletter-fachbeitraege/artikel/aktuelle-handlungsempfehlungen-zur-ausgestaltung-von-cookie-bannern.html) (German, sry...) now that advise to make both buttons visually identical. It is probably okay to style them a little (!) differently, but to be on the safe side (and also – fair to the users) they should be visually equal. 

Obviously, this can be easily addressed using a little CSS. But I was wondering if this shouldn't be the default and the current implementation an exception.",2021-12-08T12:36:32Z,2022-04-09T02:42:14Z,closed,5,"dark pattern design, cookie consent, nudge users to accept all cookies, pre-selected unnecessary cookies, 'accept all' button was green and well visible, while the 'deny all' button was light grey with white font color","consent cookie, nudge, opt-in/out","cookie consent, preselection, nudge, opt-in/out, Ui/UX design",DPs in design coding,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/mastodon/mastodon/issues/13670,Remove all Keybase features from Mastodon,https://github.com/mastodon/mastodon/issues/13670,"### Pitch and Motivation

Because Keybase is acquired by Zoom, a large privacy disrespecting US company, Mastodon's (and all privacy loving Mastodon servers) reputation is at stake.

https://blog.zoom.us/wordpress/2020/05/07/zoom-acquires-keybase-and-announces-goal-of-developing-the-most-broadly-used-enterprise-end-to-end-encryption-offering/

So this is actually not a feature request, but an anti-feature request.",2020-05-07T18:58:35Z,2022-12-08T11:10:26Z,closed,22,"dark pattern design, terms and conditions, atrocious and heavily anti-user","Mastodon, Keybase, anti-user, terms and conditions","Mastodon, Keybase, anti-user, terms and conditions",DPs in design coding,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/TechSolomon/cs371/issues/1,Dark Patterns – Assignment Details,https://github.com/TechSolomon/cs371/issues/1,"###### *Dark Patterns are anything designed to force users to do something they probably don’t want to do, or didn’t intend to do, or making the intended action harder than it should be.*

# Prototyping tools
- [Adobe XD | Fast & Powerful UI/UX Design & Collaboration Tool](https://www.adobe.com/products/xd.html)
- [Figma: the collaborative interface design tool.](https://www.figma.com/)
- [Proto.io - Prototyping for all](https://proto.io/)

# Project instructions
- [x] #2
- [x] #3

# Design document
- [x] #4
- [x] #5
- [x] #6",2021-12-04T02:00:43Z,2021-12-10T02:34:14Z,closed,0,"dark pattern education, cs371, dark pattern-related assignment","assingment, links, examples?","dark pattern education, discussion, examples",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Turing-Complete-Game/Suggestions-and-Issues/issues/153,"[Bug]: Public Stats - Privacy, anyone?",https://github.com/Turing-Complete-Game/Suggestions-and-Issues/issues/153,"### What happened?

Before making players' stats publicly available to scrap for anyone, at least ask players if that's OK. In fact, ask them to opt-in before you collect *any* data, be it stats or ""telemetry"". There's enough exploitation and dark patterns going on in the tech world already. 

No this is not a feature request. It may not be a technical bug, but it's a certainly a bug. 

### Version

Other

### Operating System

any

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct",2021-12-02T20:42:34Z,2022-02-22T10:29:20Z,closed,10,"prevention of dark pattern, ask consent from users before collect data, public stats","opt-in before collection data, telemetry","data collection, telemetry, opt-in/out, avoid dark pattern",DPs prevention in software,,,dark pattern or not,dark pattern or not,,,
https://api.github.com/repos/TechSolomon/cs371/issues/2,Find an example of dark patterns,https://github.com/TechSolomon/cs371/issues/2,"1. New York Times (unsubscribe)
2. Amazon Prime (delete account)
3. Donating to political campaigns (recurring charges)",2021-12-04T02:02:21Z,2021-12-10T02:34:15Z,closed,1,"dark pattern education, cs371, dark pattern-related assignment, New York Times (unsubscribe), Amazon Prime (delete account), Donating to political campaigns (recurring charges)",examples?,"dark pattern education, discussion, examples",DPs examples/definitions,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/TechSolomon/cs371/issues/3,Share the example of dark patterns,https://github.com/TechSolomon/cs371/issues/3,,2021-12-04T02:02:25Z,2021-12-10T02:34:15Z,closed,1,"dark pattern education, cs371, dark pattern-related assignment",examples?,"dark pattern education, discussion, examples",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/TechSolomon/cs371/issues/4,Describes the dark pattern or patterns,https://github.com/TechSolomon/cs371/issues/4,,2021-12-04T02:02:28Z,2021-12-10T02:34:15Z,closed,0,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/clowdr-app/clowdr/issues/282,Tab organization under program overlay,https://github.com/clowdr-app/clowdr/issues/282,The Full Program tab should be next to the Happening Now tab,2021-05-27T20:07:41Z,2022-03-07T20:03:44Z,closed,2,"usage of dark pattern in software, visual interference, make it the least obvious thing to click on","UI/UX design, dp to click less on schedule page, design hierarchy","UI/UX design, design hierarchy, interface interference",DPs used in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/brave/brave-browser/issues/19695,"""Hide Brave Rewards button"" stands out from the other toggles",https://github.com/brave/brave-browser/issues/19695,"The ""Hide Brave Rewards button"" toggle in `brave://settings/appearance` stands out from the rest of the toggles because all of the other ones use ""Show xxxx"" or ""Always show xxxx"":
![Screenshot from 2021-11-23 14-22-25](https://user-images.githubusercontent.com/167821/143138695-0127fa76-d4b9-4375-8583-c240d626b140.png)

We should change that to be ""Show Brave Rewards button"" (default ON) to match the rest of the settings. Otherwise some people may think we're trying to confuse people with a ""dark pattern"", as opposed to the real reason which is that we didn't notice the inconsistency when we originally added that toggle.

(Originally reported in https://neilzone.co.uk/2021/11/brave-browser-less-privacy-respectful-than-i-was-expecting by @neilzone.)",2021-11-23T22:32:55Z,2022-02-25T07:47:57Z,closed,6,"Brave browser, prevention of dark pattern in design, no double-nagation to trick users","UI/UX design, avoid dp","Brave, avoid dark pattern, UI/UX deign, double-negation",DPs prevention in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/DIADesignGuild/events/issues/28,Privacy UX and Dark Patterns,https://github.com/DIADesignGuild/events/issues/28,"
![sgvux28](https://user-images.githubusercontent.com/603924/139000426-45a67497-a86d-4be6-98c2-94fdb0b8b4c5.png)

GDPR, dark patterns, cookies

https://lu.ma/sgvux28
https://www.diadesign.io/events/sgvux-28/",2021-10-08T04:21:41Z,2021-11-30T05:39:32Z,closed,0,"privacy UX, dark patterns, poster, talk",discussion?,"examples, talk","Papers/Docs/Sources, DPs examples/definitions",,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/50,Make Dark Pattern List,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/50,,2021-10-29T12:19:56Z,2021-11-01T22:22:28Z,closed,0,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/signalapp/Signal-Desktop/issues/5164,Undismissable 'Upgrade this Group' message is covering Message entry.,https://github.com/signalapp/Signal-Desktop/issues/5164,"<!--
Our bug tracker is ONLY for bugs. It is not for feature requests, questions, or comments.

Please fill out this template with all the information you have. We can't do much without
both the logs and a detailed description of what you've encountered. Please do your best!

Please note that this tracker is only for bugs. Please try these locations if you have a question or comment:

  https://community.signalusers.org/
  http://support.signal.org/
  support@signal.org

Lastly, be sure to preview your issue before saving. Thanks!
-->

- [X] I have searched open and closed issues for duplicates
<!--
  You can search all issues here:
    https://github.com/signalapp/Signal-Desktop/issues?utf8=%E2%9C%93&q=is%3Aissue
  Replace [ ] with [X] once you've searched
-->

---

### Bug Description

<!-- Give an overall summary of the issue. -->
On my Windows desktop signal, 3 of the 4 groups defined by employer now have a 'Upgrade this group' block message at the bottom and no place to type in a message anymore. 

### Steps to Reproduce

<!-- Using bullet points, list the steps that reproduce the bug. -->

Open a Windows Signal Desktop app with a group defined more than a few months ago?

Actual Result:

<!-- Describe the details of the buggy behaviour. -->

The block message at the bottom hides or replaces the message entry. There is no obvious way to dismiss this, only a 'Continue' button, which if pressed tells me all of the other group members will be dumped if I go ahead (and I did not setup any of these groups).

Restarting does not get rid of these messages, and if there is another way to type messages using the desktop app, I do not know of it. These groups are now useless for sending messages.

Expected Result:

<!-- Describe in detail what the correct behavior should be. -->

I should be able to get rid of this damn message and use the app as normal.

### Screenshots

<!--
How to take screenshots on all OSes: https://www.take-a-screenshot.org/
You can drag and drop images into this text box.
-->

### Platform Info

Signal Version: 1.40.1

<!-- You can see Signal's version number at Help -> About or File -> About Signal Desktop -->

Operating System:
Windows 10
<!-- Instructions for finding your OS version are here: http://whatsmyos.com/ -->
",2021-04-08T12:08:43Z,2022-08-01T15:36:43Z,closed,17,"Signal, usage of dark pattern in software, force to ungrade, forced action","Signal, forced action, paid version to stay in groups ","Signal, forced action, paid version",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/w3ctag/ethical-web-principles/issues/48,"Reference dark patterns, for #25",https://github.com/w3ctag/ethical-web-principles/pull/48,"Expansion on the ""enhance individual control and privacy"" principle to reference dark patterns as suggested by @tantek in #25.

Also slight reword to uncouple centralization issues, for @mnot's concerns in the issue.",2021-09-14T09:01:42Z,2021-10-23T06:12:09Z,closed,0,"ethical web principle, dark pattern examples/education","ethical practices, examples, Github post","Ethical Web Principle, dark pattern education, post","Papers/Docs/Sources, DPs examples/definitions",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/12,Organise dark pattern list,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/12,,2021-10-01T13:02:21Z,2021-10-14T18:13:27Z,closed,1,dark pattern types spreadsheet list,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-chrome-extension/issues/6,Design Highlighting dark pattern UI,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-chrome-extension/issues/6,,2021-10-04T15:39:42Z,2021-10-15T12:33:33Z,closed,0,miscellaneous (design highlighting dark pattern UI),,miscellaneous,miscellaneous,design highlighting dark pattern UI,,DPs used in software,dps used in software,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-node-side/issues/55,Added info on dark patterns home page and table,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-node-side/pull/55,,2021-11-04T02:25:13Z,2021-11-04T14:31:44Z,closed,0,miscellaneous,,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-node-side/issues/64,"Added all the dark pattern pages, with videos and pictures for each +…",https://github.com/TUD-Dark-Pattern-2021/dark-pattern-node-side/pull/64,… description,2021-11-11T23:22:45Z,2021-11-11T23:22:51Z,closed,0,miscellaneous,,,,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-node-side/issues/63,"Added all the dark pattern pages, with videos and pictures for each + description",https://github.com/TUD-Dark-Pattern-2021/dark-pattern-node-side/pull/63,,2021-11-11T23:17:57Z,2021-11-11T23:18:10Z,closed,0,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/w3ctag/design-principles/issues/196,"""Don't Enable Dark Patterns"" Principle?",https://github.com/w3ctag/design-principles/issues/196,"@tantek left an issue on Ethical Web Principles https://github.com/w3ctag/ethical-web-principles/issues/25 suggesting a principle on this topic:

> We will avoid introducing technologies that create new or disproportionately enable, benefit, or amplify existing user interface dark patterns, such as confirm shaming, misdirection, friend spam, permissions pressuring or escalation, threat of data loss etc. We should also avoid new technologies that could be easily abused by existing dark patterns to more easily cause new or worse harms to users. We should design specifications that explicitly plan for and mitigate potential dark pattern abuses.

However I wonder if this should in fact be part of the design principles doc, referring back to the Ethical Principle [enhancing individual control and power](https://www.w3.org/2001/tag/doc/ethical-web-principles/#control)?",2020-05-28T14:47:33Z,2021-10-06T15:49:20Z,closed,1,"design principle, prevention of dark pattern, mitigate potential dark pattern abuses",,"avoid dark pattern, deceptive design practice",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/microsoft/winget-cli/issues/179,Please include ability to opt out of telemetry and clear documentation on how to opt out,https://github.com/microsoft/winget-cli/issues/179,"# Description of the new feature/enhancement

The readme mentions you collect telemetry, but it doesn't include information on how to opt out. Opting out is critical, and understanding how should be provided. 

I might have missed where this is shown, but I'm not sure I see it.

* **UPDATE 21 MAY 2020:** Updated with more clarity on why I don't like telemetry or data collection - https://github.com/microsoft/winget-cli/issues/179#issuecomment-632219209",2020-05-19T15:26:47Z,2022-06-21T15:50:59Z,closed,46,"prevention of dark pattern, no ""submarine-ing consent"", enable opt out of telemetry, clear instructions on how to opt out ","telemetry, opt-out, data collection without consent","telemetry, opt-in/out, data collection, consent, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-node-side/issues/8,Api functions to return number of detected dark patterns,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-node-side/issues/8,,2021-09-26T17:02:26Z,2021-10-15T11:16:58Z,closed,0,API to detect DPs,,"API, detection",DPs detection Tools,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/w3ctag/ethical-web-principles/issues/25,Proposed Ethical Web Principle: Avoid enabling and amplifying dark patterns,https://github.com/w3ctag/ethical-web-principles/issues/25,"The [W3C TAG Ethical Web Principles](https://www.w3.org/2001/tag/doc/ethical-web-principles/) mentions [enhancing individual control and power](https://www.w3.org/2001/tag/doc/ethical-web-principles/#control) and recognizes a few misbehaviors, yet focuses on decentralization, minimizing single points of failure, and enabling individual &amp; DIY developers. All of that is good, however there is the larger class of “dark pattern” harms to be named and explicitly avoided in specification and technology designs.

The Principles should explicitly note (either adding to or splitting off from “The web must enhance individuals' control and power”) the existence of “dark patterns” in web user interfaces (see [WP: Dark pattern](https://en.wikipedia.org/wiki/Dark_patterns) and [darkpatterns.org](https://www.darkpatterns.org/) for examples), with a statement similar to countering misinformation like:

We will avoid introducing technologies that create new or disproportionately enable, benefit, or amplify existing user interface dark patterns, such as confirmshaming, misdirection, friend spam, permissions pressuring or escalation, threat of data loss etc. We should also avoid new technologies that could be easily abused by existing dark patterns to more easily cause new or worse harms to users. We should design specifications that explicitly plan for and mitigate potential dark pattern abuses.

And cite either or both of those above two references. See also [twitter.com/darkpatterns](https://twitter.com/darkpatterns) for many more real world web examples.

We obviously won’t be able to prevent all dark patterns and their harms, but we can at least reduce some of them by calling them out, and avoiding new technologies that would increase the chance of users being harmed by existing and new dark patterns.

(Originally published at: https://tantek.com/2020/066/b2/avoid-enabling-amplifying-dark-patterns)",2020-03-06T20:40:29Z,2021-10-06T15:32:24Z,closed,12,"Ethical Web Principle, discussion of avoid (enabling/amplifying) dark patterns, ","ethical practice, discussion, examples, post","Ethical Web Principle, avoid dark pattern, discussion",DPs examples/definitions,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/56,added documentation about DP detection we do in project,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-python-side/pull/56,added documentation about the Dark Patterns we detect and the techniques used to detect them.,2021-11-01T22:21:55Z,2021-11-01T22:22:28Z,closed,0,"add docs to DP detection, dark pattern detection technique",,miscellaneous,miscellaneous,"DPs detection Tools, Papers/Docs/Sources",,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/TUD-Dark-Pattern-2021/dark-pattern-python-side/issues/37,Fix the bug of empty dp result,https://github.com/TUD-Dark-Pattern-2021/dark-pattern-python-side/pull/37,"The bug comes up when there is no dark pattern detected on the website, the dataset feeding into the second model will be empty, that's when prediction doesn't work.

The condition of the ""no dark pattern detected on the current page"" is added in the code, just returning empty values in JSON file.
",2021-10-19T18:43:55Z,2021-10-19T19:46:28Z,closed,0,"dark pattern detection tool implementation, coding to implement detection tool",detection tool,"detection, coding",DPs detection Tools,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/privacyguides/privacyguides.org/issues/242,Universal search bot for every account's privacy control,https://github.com/privacyguides/privacyguides.org/issues/242,"It was painful when I wanted to verify  gdpr rights around 30 of my online accounts including social, entertainment and so on. But I went ahead and found some of the links which where hidden deep in dark patterns. I wanted to make others life easier by creating a bot on telegram, the one I explored by chance. I intend to crowdsource the data and make the service available to general public on other platforms like WhatsApp.
Kindly check out the bot and leave comments and promote it as beta.
[@datacarebot](https://t.me/datacarebot) 
[Data Privacy care community](https://t.me/protectprivacy)",2021-11-05T02:47:44Z,2021-11-21T13:00:54Z,closed,0,unsure,,,,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/Codeinwp/neve/issues/3272,Update buttons in Neve dashboard.,https://github.com/Codeinwp/neve/issues/3272,"It seems like there are buttons in Neve dashboard that are leading to an external page. We should add the external icon there too, to let the users know that it's an external link.
https://vertis.d.pr/qXWv5q, https://vertis.d.pr/RgPvj9, https://vertis.d.pr/35ZLmZ 

For the feedback link, it doesn't even open a new tab.",2021-12-17T10:00:14Z,2021-12-21T17:29:33Z,closed,2,"Neve, dark pattern in design, button UI design in dashboard","misleading, trick users, UI/UX design","Neve, misleading, trick users, UI/UX design",DPs in design coding ,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/89,Organize the document coherently,https://github.com/w3ctag/privacy-principles/issues/89,"Since our document started as a concatenation of two independent documents, at some point we'll need to refactor the whole thing into a coherent whole. I'm starting to get a picture of how we might do that, which I'll outline here.

1. [Introduction](https://w3ctag.github.io/privacy-principles/#intro)
1. Interesting Definitions
   1. [People](https://w3ctag.github.io/privacy-principles/#people)
   1. [Data](https://w3ctag.github.io/privacy-principles/#data)
   1. [Parties](https://w3ctag.github.io/privacy-principles/#parties)
   1. [Acting on Data](https://w3ctag.github.io/privacy-principles/#acting-on-data)
   1. ""purpose"" and ""means"" definitions, from later sections.
1. [User Agents](https://w3ctag.github.io/privacy-principles/#user-agents)
1. [Identity](https://w3ctag.github.io/privacy-principles/#identity)
   1. [Cross-context recognition](https://w3ctag.github.io/privacy-principles/#hl-recognition-cross-context), possibly mixed together with the Identity section
1. Ethical Data Use
   1. [Personal Control and Autonomy](https://w3ctag.github.io/privacy-principles/#autonomy)
   1. [Contexts](https://w3ctag.github.io/privacy-principles/#contexts-and-privacy)
   1. [Opt-in, Consent, Opt-out, Global Controls](https://w3ctag.github.io/privacy-principles/#opt-in-out)
   1. #73
   1. [Sensitive information disclosure](https://w3ctag.github.io/privacy-principles/#hl-sensitive-information)
   1. [Unexpected profiling](https://w3ctag.github.io/privacy-principles/#hl-unexpected-profiling)
   1. [Collective issues](https://w3ctag.github.io/privacy-principles/#collective)
1. [Intrusive behavior](https://w3ctag.github.io/privacy-principles/#hl-intrusion)
1. [Powerful capabilities](https://w3ctag.github.io/privacy-principles/#hl-capabilities)
1. Boring Definitions

I think we could further reorganize the sections under ""Ethical Data Use"" by thinking about how the grounds for lawful processing, for example from the [GDPR](https://gdpr-info.eu/art-6-gdpr/) map to the principles we'd like organizations to use when deciding how to process data. For example, data use is ok if it's clear to the user that it's necessary to do what they asked; freely-given consent makes data use ok; data use to protect user safety is generally ok; use that's in-line with contextual expectations is generally ok; etc.",2021-11-30T23:49:02Z,2022-01-12T19:19:14Z,closed,4,"privacy principle, documentation about privacy, dark pattern topic","documentation, examples","privacy issue, documentation, discussion","Papers/Docs/Sources, DPs examples/definitions",,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/carforyou/carforyou-components-pkg/issues/410,feat: allow to hide the close icon on modals,https://github.com/carforyou/carforyou-components-pkg/pull/410,,2021-09-03T09:05:06Z,2021-09-07T06:46:01Z,closed,3,"prevention of dark pattern in design, no harder to close model","modals, hide close button","modal, obstruction, avoid dark pattern, UI/UX design",DPs prevention in software,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/privacycg/proposals/issues/11,Registry of Businesses and Domain Name Ownership,https://github.com/privacycg/proposals/issues/11,"## Introduction

This proposal puts forward the need for a single, or number of Authorities/Registrars that businesses can use to register as an entity that intends to control / process personal information on the web within certain jurisdictions, and the entity's ownership of a domain name.

## Goals

 * Provide a more transparent means for the user to govern when and how their personal information is used/stored/shared by businesses.
 * Provide a means for user agents to decide default behaviour in regards to allowing data to be accessed/stored/shared per domain.
 * Provide a means for businesses to register their domain names for the business as an entity that intends to control / process personal information within certain jurisdictions.
 * Provide a means for businesses to register their relationship with service providers, to the extent that a service provider is a separate business, and intends to process shared personal information.
 * Aid in the decline of consent banners

## Non-goals

 * This proposal does not attempt to define the protocol of signals between the user agent and business (e.g. Do Not Sell). Rather, it could help to define the relationship that may be necessary in order for the communication to exist.
 * The ability for client-side data to be shared across domains that have the same business registration, although this could perhaps follow.

## Background and arguments

In regards to CCPA and GDPR, storage/access/control of personal information and personally identifiable information, is not limited to *domain names*, but rather to *businesses*. When a user visits a site, very commonly they will be presented with a consent banner, which gives the user access to the privacy policy of the business that operates the site under the domain name. The privacy policy may also include the third party service providers with whom the business may share the user's personal information. Currently, the user agent is not able to assist the user in a meaningful way when it comes to the proactive acceptance of a privacy policy.

The user agent is also not able to assist very heavily in retroactive control of data; if the user wishes to view/remove data held by the user agent, they are able to only see a list of domain names that the data is partitioned to. There is a likelihood of little understanding of the businesses that have access to the data when browsing the web, and the relationships between those businesses, where third party service providers are concerned.

In order for the user agent to be able to assist the user, I believe it is necessary that information about the owner of the domain name, and the relationship they have with service providers, is accessible to the user agent. A business _could_ publish the data itself, and have that accessible in a .well_known location in relation to the domain name. Indeed this could be a valid first step in achieving the listed goals. However, when it comes to data protection, I believe it should be assumed that a domain is not fully trusted to keep this information correct by itself.

Businesses already have a large responsibility to fulfill data protection requirements, and depending on the jurisdiction, they are obligated to register themselves to a relevant authority<sup>[1]</sup>. This responsibility will no doubt get larger and more complex as laws are introduced in more jurisdictions. By implementing standard authorities on the web, it may help to normalise the process/data.

## Proposal in slightly more detail

 * At the very least, a business registration should include the name of the business, and the information required to communicate with the business for data protection purposes. If a registration for a domain name is being made for a business, there should be a mechanism that acts as sufficient verification that it is the business or an agent of the business performing the registration. At any time, a business can query the domain names that have been registered under its ownership, and flag any issues, with sufficient verification that they have the power to do so.
 * Upon request, most likely at the time of domain name resolution, the user agent is given, or can query, the business registration for the domain name. In order to be deemed valid, the registration must be signed by an authority that the user agent has trusted. The registration may be cached at a number of locations between the user agent and the authority.
 * The user agent can use the existence and data of a business registration, and the preferences set by the user to determine if and how it allows the access/storage of client-side data for the domain by default, and the domains of the business's service providers.
 * Client-side user data can be partitioned to a business registration (or the absence of a business registration) under a domain. If the business registration meaningfully changes, the client-side data can undergo a process of transferral, or removal, controlled by the user agent.
 * For user data stored by the business (i.e. non-client side), the user agent can send signals to the business and its service providers, requesting it to perform certain actions i.e. Opt out, Do Not Sell. This is providing that the business has agreed to comply to a certain standard/protocol, and the registration contains details on the protocol of communication. If the business does not show itself to comply to a certain standard, the user agent will have had the opportunity to deny access to data / prompt the user upfront.

I believe that by having businesses optionally comply to standards, and knowing that access to data can freely be rescinded, user agents have the potential to satisfactorily make decisions on the user's behalf, or prompt the user when necessary. Thus potentially removing the need for consent banners.

To make things more clear, I've put together a mockup to demonstrate how this proposal _could_ open up possibilities for the user agent (I am in no way recommending this is how browsers should decide to implement it 🙂):

![User Privacy Dialogues](https://user-images.githubusercontent.com/634879/79334249-d1429b00-7f17-11ea-978c-9f9f57c1abc1.png)

## Considerations
  This is a rough start at a proposal, and it's purposefully vague both in definitions and technical specification. If there's interest in it, there are many things to be considered. Some that I can think of off-hand:
 * What would the exact definition of a business and domain name be, for the purpose of this proposal?
 * What would a business registration look like? What data would it hold?
 * What constitutes a sufficient verification of a business?
 * Would there be multiple business registrations allowed for a single domain, for the same business/organisation, to cater for different jurisdictions/laws?
 * How about domain names that many different businesses may use?
 * How can a business registration link/relate to registrations in existing authorities<sup>[1]</sup>?
 * What existing mechanisms if any could be used that this registry could piggyback off of? (domain name registrars, certificate authorities etc.).


## How does this compare to similar existing proposals?
[First-Party Sets](https://github.com/krgovind/first-party-sets) and [Domain Boundaries](https://datatracker.ietf.org/wg/dbound/about/) are perhaps similar, in that they offer a mechanism to group domains together under an umbrella, but they serve different goals to this proposal in my opinion. Control and trust over the user's data is the primary goal of this proposal, not the ability for businesses to share client-side data between domains. This proposal puts forward the necessity for an outside authority that the user agent trusts, rather than relying on .well_known locations or DNS records set up by the business. This proposal also provides a means for the registration of relationships to service providers, that the user's information may be shared with, to allow for transparency/control over shared data.

IAB have [published a framework](https://www.iab.com/guidelines/ccpa-framework/) to allow publishers to comply with CCPA legislation, by registering and signing an agreement. This proposal doesn't aim to compete with the framework, but it would be interesting to explore if this could perhaps compliment it.

## Appendix

  <sup>[1]</sup> Existing business registries:
   * UK [ICO](https://ico.org.uk/about-the-ico/what-we-do/register-of-fee-payers/) - mandatory registration
   * GDPR member state [Data Protection Authorities](https://edpb.europa.eu/about-edpb/board/members_en) - non-mandatory registration depending on member state
   * California [Data Broker Registry](https://oag.ca.gov/data-brokers) - mandatory for those that fall under the definition of [_Data Broker_](http://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB1202#id_69D5D2E2-D018-4F7A-B778-8A2DAEFE939F)

---
### Including my comment from April 29th here to improve visibility

---

Thanks a lot for the responses here and in the call. I've put some thought into how this could move along into a more concrete spec for consideration, while hopefully addressing some of the thoughts/concerns made so far.

## Straw man spec

### Data Structure
Upon request, the User Agent can access the following, per domain, which contains data relevant to the processing or control of personal information by the entity that owns the domain:

```
{
  ""policy"": {
    ""type"": """",
    ""version"": """",
    ""clientStorageRequirement"": """",
    ""fullPolicyTextHref"": """",
  },
  ""serviceProviders"": [
    {
      ""entityId"": """",
      ""domainName"": """",
      ""processingCapability"": """"
    }
  ],
  ""interface"": {
    ""type"": """",
    ""version"": """",
    ""signalConformity"": [
      ""opt-in"",
      ""opt-out"",
      ""do-not-sell""
    ]
  },
  ""signed"": {
    ""domainName: """",
    ""entity"": {
      ""uniqueIdentifier: """",
      ""name"": """",
      ""state"": """",
      ""country"": """",
      ""governmentAuthorityRegistrationId"": """"
    },
    ""expires"": """"
  }
  ""authority"": """",
  ""signature"": """"
}
```

### Policy
This details policy information that can be read programmatically. The schema is designed to be extensible, and the different types and standards are not part of this scope, other than what's considered the most basic.

### Service Providers
This is an important aspect of the proposal, which has the potential to allow greater transparency and feed into decisions the User Agent makes regarding sharing of data. Consent Management Platforms currently create an environment where the user agrees (in my opinion unwittingly) to the sharing of their data to hundreds of third party services. This information is usually in the written privacy policy, but I think there's a great advantage to having this exposed to the User Agent.

### Interface
This details how the User Agent is able to communicate with the entity in regards to control of personal data. Again, it is designed to be extensible and contain the standards to which the entity conforms to, with perhaps some flexibility for unique customisation. Applied standards can borrow a lot from learnings elsewhere, including the TCF as mentioned by chrispaterson.

### Signed
This is the portion of the data that is required to be signed by an authority. Here, it is the domain name to business/entity relationship.

### Where should the data be accessed from?
I think the options are:
1. Stored on a server that the entity controls, in a .well_known location relative to the domain
2. Stored as a DNS TXT Record, in a _well_known host relative to the domain

My preference is for a DNS record. It implies a certain amount of elevated priveleges to implement, inherently verifies domain access by the entity, and avoids a potential issue with matching wildcard domains due to upstream proxies.

### How can the data be trusted?
An authority will be responsible for signing some of the data. In this straw man spec, only the domain name to entity relationship is signed, the rest of the data is separate. This is to allow for the easy updating of the policy, service providers and interface. The authority should act as a registry for the business entity, and should verify that the signature request is legitimate. Perhaps a similar process to EV certificates could be used for the validation process.

As far as the trusting of the policy goes, it's a difficult one. How would an authority audit the process, and monitor the process over time? Right now, everything is behind a black box to the User Agent, and this proposal is attempting to bring the processes to light. It was mentioned in the call that attempting to standardise these processes can also have the advantage of businesses having a better sense of how they should be handling the data.

### Revocation
Some mechanism should be in place for the authority to signal that a record is now invalid, without having to wait for the expiry of the record. This needs more thought.

### What can the User Agent do with the data?
Please see the UX mockup in the original post above. An API could be made accessible to JS perhaps for further functionality. To be clear, this proposal does not attempt to define standard behaviour of different browsers, or the API.

One further idea is the concept of the User Agent being in control of both transient and long-lived consent, given either implicitly or explicitly. Going further, there could be an identifier to represent this consent, which the User Agent could use to query the business/entity and its service providers for the existence of personal data associated with this identifier, revealing an audit trail of where and how the data is being used. This, again, is not in scope, but is perhaps made possible by the proposal.

### What incentive does a business have to register and keep the policy up to date?
This was raised by a number of people in the call, and by sammacbeth above. My initial thinking was that, in the event that the User Agent were to become more restrictive for domains that do not provide a policy or business ownership, the incentive for the business will be to not be affected as heavily by these constraints. This will be especially true for non-essential third party service providers, where the User Agent may enact more stringent measures i.e. decide not to load them. This is the main contrast between this proposal and First Party Sets in my opinion, as the goal for that proposal seems to be for the User Agent to be able to treat multiple domains as the same site in terms of privacy, effectively lessening existing restrictions. Having said that, as this proposal's scope does not include the behaviour of the User Agent, a similar lessening of existing restrictions would be possible with this proposal I think, and could certainly provide an incentive if that's what the User Agent decided to allow.

### High-level Questions
  * Is the possible User Agent behaviour valuable? Is this something that would garner interest?
  * If yes, does the presence of this data fulfil the desired behaviour? Are there other ways to achieve the same goal?
  * Is there value in the data even if it isn't signed? Can the hard dependency on an authority be removed?

",2020-04-14T15:13:17Z,2022-05-17T23:10:55Z,closed,17,"dark pattern to achieve higher opt-in rates, site owners, acquiring consent","opt-in, higher opt-in then higher reward","opt-in/out, consent, deceptive design practices",DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/DTS-STN/Data-Patterns/issues/41,Update about-fr.md,https://github.com/DTS-STN/Data-Patterns/pull/41,adding information about dark patterns / ajouter l'information sur les designs trompeurs,2021-08-04T17:58:08Z,2021-08-06T14:34:28Z,closed,0,miscellaneous (add information about dark pattern),,miscellaneous,miscellaneous,add information about dark pattern,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/DTS-STN/Data-Patterns/issues/32,Update about.md,https://github.com/DTS-STN/Data-Patterns/pull/32,Adding draft content and visuals explaining dark patterns.,2021-07-29T20:46:57Z,2021-08-03T18:30:59Z,closed,0,miscellaneous (add draft content and visuals explaining dark patterns),,miscellaneous,miscellaneous,add draft content and visuals explaining dark patterns,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/DIADesignGuild/events/issues/8,Evil by Design,https://github.com/DIADesignGuild/events/issues/8,"![01_FB Event Banner](https://user-images.githubusercontent.com/603924/135217916-8f5092e1-a8e5-4043-9cb3-698a4b2a6eae.png)

**Date**
October 1st, 2019

**Location**
Temple City, CA

Without evil, there is no good. Do you have what it takes to be evil by design?

This October we'll take a look at what it means to be an evil designer. We'll have a short presentation on dark patterns and the various ways that they manifest, do a short workshop to think up some of the best ways we could entrap a user by design, and then wrap up the night with horrible UX stories. Feel free to come dressed as your favorite evil character or concept.

## Agenda
6:00 pm Check-in + food + mingle
6:30 pm Welcome and intros
7:00 pm Presentation
7:30 pm Horror stories + networking
9:30 pm Wrap up

---

### About the Speakers
By day, **Wanda Seto** is a Product Designer at Sauce Labs, specializing in building tools and analytic dashboards for enterprise users. Currently, she is building testing tools for developers to optimize their apps. By night, Wanda stays up late fighting the dark patterns that she finds in her design as Wonder Woman.

Nine to five, **Jesse Lee Despard** is a UX Researcher at PatientPop. She utilizes qualitative and quantitative methodologies and data analysis, and she advocates for the user's needs to be reflected in the product lifecycle. But when the city sleeps, Jesse is a friendly neighborhood Spider UX-er as as a volunteer for SGVUX and lead organizer of WIAD as Spider-Woman.

---
### About the venue
Located in the middle of residential area Temple City, C4 Creative Studio is home to a giant Christmas tree, a fake police car, and a Bat Cave. It is also a production space with production sets and costume making.

You'll find lots of free street parking. A parking lot is also available behind the venue.

### Will there be food?
Of course, there will be food! If you want to make a recommendation as well as look at the menu, let Grace and the planning team know at sangabrielvalleyux@gmail.com or on #planning on Slack.

### Who should come? Can I bring my kids?
Anyone! Bring your kids if you want to and they can join the conversation if they want to. Just let us know if they're coming when you register.

### What does my registration fee include?
Admission helps cover our venue costs, food & drinks, digital & marketing expenses for this volunteer-led community. If you liked this event and want more, please help us support it!

### How can I pay for this event?
We accept all major credit cards, including Visa, MasterCard, and American Express. We also take PayPal and Venmo (payable to @theSGVux) at the door.

### Can I cancel or transfer my registration if I can't attend?
Yes, you can transfer your registration to someone else. Just get in touch (sangabrielvalleyux@gmail.com) and we'll update the ticket information.

### Additional questions?
Reach out to Grace at sangabrielvalleyux@gmail.com
",2021-09-29T06:53:57Z,2021-09-29T06:54:06Z,closed,0,"dark pattern education, talk of evil by design, bad UX design",discussion about dp,"dark pattern education,  discussion, UI/UX design","Papers/Docs/Sources, DPs examples/definitions",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/JetBrains/youtrack-workflows/issues/29,YouTrack not GDPR compliant,https://github.com/JetBrains/youtrack-workflows/issues/29,"I cannot delete my own comments in YouTrack.
Instead there is a fake-delete button that allows me to ""hide"" my own comment.

The administrator cannot give permission to allow someone to delete its own comments.
Instead, there is only a permission to permanently delete **everyones** comment.
The exact naming is: `Delete Not Own and Permanent Comment Delete`.

Please fix YouTrack to let me fully delete my own comments (permanent delete) without allowing to permanent delete someone else comments.

There must be an option to permanently delete my own inputs/comments without being able to delete someone else comments.",2021-09-02T11:05:28Z,2021-09-14T13:23:58Z,closed,7,"YouTrack, usage of dark pattern, violate gdpr compliance, data privacy concerns, fake ""delete"" button, no permission to delete users' comment","YouTrack, del button for comments not working, privacy issue, GDPR","YouTrack, GDPR, privacy issue, data collection, deceptive design practice","DPs used in software, DPs related regulation ",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/microsoft/terminal/issues/10726,Add tracelogging for drag&drop on the new tab button,https://github.com/microsoft/terminal/pull/10726,"As discussed in team sync. Is this a mysterious dark pattern we didn't know about? 

* [x] closes #10721
* [x] I work here
* [x] doesn't need tests
* [x] doesn't need docs
* see also #10160 ",2021-07-20T14:45:28Z,2021-07-20T16:19:51Z,closed,4,unsure,tracelogging?,,,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/17,"""Describe this dark pattern (Optional)"" > Please remove ""optional"" and just leave ""Describe this dark pattern""",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/17,"Upon second glance, it would be great for people to _try_ to include this because it would help a lot on the moderation front for us to understand what we're supposed to be looking at and use as much of their language on what they experienced as possible. ",2021-05-06T01:16:18Z,2021-05-11T00:26:32Z,closed,0,"miscellaneous (content format, remove optional in the ""Describe this dark pattern (Optional)"")",,,,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/103,Dark patterns are being published that are not on the published list,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/103,"
Here are the listed dark patterns that are published on WP: 
https://darkpatterns.kinsta.cloud/wp-admin/edit.php?post_status=publish&post_type=example

We are seeing some of the dark patterns that I changed the Title to: Not a dark pattern, Unverified, etc. (BUT DID NOT PUBLISH) show up in the feed in the website. 

Any idea why this may be happening?
![image](https://user-images.githubusercontent.com/60265274/120495773-006dd300-c38b-11eb-9651-6068f1cb04b4.png)

",2021-06-02T14:12:18Z,2021-06-02T14:54:41Z,closed,8,"dark pattern sources, DP types in published list on WP",,"dark pattern education, examples",DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/darlinghq/darling/issues/1006,xcode-select --install broken because of a potential server issue,https://github.com/darlinghq/darling/issues/1006,"**Expected Result**
Install Xcode CLI tooling

**Actual Result**
The python script that is called pulls files from https://swdistcache.darlinghq.org/api/v1/products/by-tag?tag=DTCommandLineTools but that currently returns a 500. Seems like a potential server issue.

**Steps To Reproduce**
1. Within your Darling shell, execute `xcode-select --install`
",2021-08-06T20:50:16Z,2022-04-19T21:05:54Z,closed,71,"Darling shell, usage of dark pattern in registration dev tool, redirect to the paymeny page without filling out the personnal information ","forced action, registration, payment","Darling shell, forced action, registration, payment",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ScoopInstaller/Main/issues/2190,git: `post_install` command breaks behaviour and creates dark pattern,https://github.com/ScoopInstaller/Main/issues/2190,"The `git` manifest has a `post_install` command (last commit de25ea9d9f1a63ea416a98630f32785a789e9810 by @amaechler) that sets/overwrites the user configuration for the credential manager. It should not be there for several reasons:

First of all, it is incredibly surprising and just plain _wrong_ behavior for a package manager, or anybody else, to touch a user configuration. Let alone on every update just plain _overwrite_ the user choice. On every update I choose my preferred credential helper and the next update overwrites it. The commit justifies it by linking another commit in the git repository, but you will notice that that commit changes the _default_. It does not change anything in the user config (rightfully, as the user config is not part of the package. It is part of the user's environment) but if you have selected a different manager, it respects your choice and doesn't force it on you. (Speaking of which, why was the need for that line even felt, seeing as the default was literally changed upstream?)

Secondly and more importantly, it just trashes the upstream's sane behavior. The upstream git-for-windows comes with a `credential-helper-selector` GUI program set to the default helper. The first time that you push, it is supposed to prompt you to choose the credential helper you want, and it sets your choice in the 'system' config (See? They know not to touch the user config). The problem is, the user config takes rightful priority over the system config, and so the option forced on you by the manifest command takes priority. That command is not expecting to be executed in this way, and you get a loop where the GUI program is launched multiple times per push to ask you but none of the choices you make change anything. Upstream comes with a handy GUI to help newcomers decide their credential helper and because of this command both that behavior and any choice an already-familiar user might have made earlier are ignored.

Worst of all, this leads to a dark pattern. Even if the user, at every point they are asked, having selected any other helper or none, this will force the usage of the `manager-core` helper. Despite github phrasing out passwords, I'm sure many still use it, not to mention other git hosters. Many naive users may not even realize that their passwords are being stored in plaintext, accessible to anybody with an unprivileged shell command, without so much as the OS keychain protecting it.

It's as simple as:
```
printf '%s\n' protocol=https host=github.com | git credential-manager-core get
```

TLDR: I see no need for that command whatsoever. git-for-windows on a fresh install already comes with a GUI to set up your credential helper, and not only does this break that sane behavior and deliberately overwrites user choice for no reason, it opens up a security hole to naive users.",2021-05-18T19:27:56Z,2021-05-20T23:07:50Z,closed,6,"git, post_install, command break behaviors, usage of dark pattern, force usage of manager-core, forced action, ","forced action to select helper, preselction, coding","Git, forced action, preselection, coding",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/28,No source link currently included in the dark pattern specific page,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/28,"Currently, we ask for a source link in the form, but that source is not included in the dark pattern specific page. In order to correctly ""cite"" the source, could we include this please? 

![image](https://user-images.githubusercontent.com/79227044/117600996-1afdb500-b11b-11eb-99b2-b9e50143f858.png)

![image](https://user-images.githubusercontent.com/79227044/117600812-b3476a00-b11a-11eb-9725-5204e295e8f6.png)",2021-05-10T03:07:58Z,2021-05-17T21:54:32Z,closed,12,"dark pattern education, darkpatternstipline.org, dark pattern source/website, error, missing source links",,"examples, dark pattern education",DPs examples/definitions,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/30,"Tagged harms under dark pattern submissions not being aggregated into ""harm overview page""",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/30,"Not all dark patterns that are tagged with ""felt shamed"" seemed to be aggregated into this page: 

Current ""felt shamed page"" only shows one example
![image](https://user-images.githubusercontent.com/60265274/117602070-d293c680-b11d-11eb-9c79-da8cb7fb0afb.png)

This is one dark pattern I submitted with a ""felt shamed"" harm tag: 
![image](https://user-images.githubusercontent.com/60265274/117602132-f3f4b280-b11d-11eb-840b-f88dcf8e5587.png)
",2021-05-10T03:26:50Z,2021-05-11T15:16:23Z,closed,1,"dark pattern education, darkpatternstipline.org, dark pattern source/website, error, ""felt shame"" tagged lack of examples",all features marked with dp not showing up on the final page,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/21,"Add helper text to the ""Describe your dark pattern"" field box ",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/21,"![image](https://user-images.githubusercontent.com/60265274/117240188-4bcda980-adfe-11eb-947e-dbf58a44e7bf.png)

In place of ""Enter your description"" or add somewhere as visible helper text: 
`Please explain what you experienced in detail and what harm it caused you. If possible, please explain how we can try to recreate your experience. `

This is because there will be some people who write ""Other"" as the industry + harm category and we need to encourage that information to live in the ""catch all"" open form field box here.",2021-05-06T04:06:47Z,2021-05-11T00:25:16Z,closed,1,"dark pattern education, darkpatternstipline.org,  dark pattern source/website",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/1Password/1password-teams-open-source/issues/351,Add GDPR WP,https://github.com/1Password/1password-teams-open-source/pull/351,"## GDPR WP ##

#### 1Password Teams URL ####
okiemgrafika.1password.eu

#### Project Name ####
GDRP WP

#### Short Description ####
Simple plugin to load tracking scripts based on user consent. No dark patterns.

#### Project Age ####
2 months since started; only 14 days from public release.

#### Number Of Core Contributors ####
2

#### Project Website ####
https://wordpress.org/plugins/og-gdpr/

#### Repository URL(s) ####
[WordPress public trac](https://plugins.trac.wordpress.org/browser/og-gdpr/)  
[WordPress SVN](https://plugins.svn.wordpress.org/og-gdpr/)

#### Latest Release URL(s) ####
https://plugins.trac.wordpress.org/browser/og-gdpr/tags/1.0.4

#### License Type ####
MIT

#### License URL ####
https://plugins.trac.wordpress.org/browser/og-gdpr/tags/1.0.4/LICENSE.txt


## A Bit About Yourself  ##

#### Name ####
Marcin

#### Email ####
895g6guhu@relay.firefox.com

#### Project Role ####
Core-dev

#### Profile/Website ####
Don't have any.

#### Comments ####
",2021-06-09T10:38:37Z,2021-06-14T11:51:45Z,closed,1,"gdpr wp, prevention of dark pattern in design, plugin to track script witt users consent","GDPR, user consent, pluign, tracking scripts","GDPR, tracking, avoid dark pattern, consent","DPs prevention in design, DPs related regulation ",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/22,Consider using another column for dark pattern to use more screen real estate,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/22,"As this list grows - I think there is a lot of white space that can currently be used to fill the screen a bit more, especially as you're scrolling down. Could there be 3 columns of dark patterns? 

![image](https://user-images.githubusercontent.com/60265274/117241031-2b9eea00-ae00-11eb-8812-f4ed3bf4a820.png)",2021-05-06T04:18:14Z,2021-05-10T19:00:32Z,closed,4,"dark pattern education, darkpatternstipline.org, (DP) website layout design",,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/31,Examples do not tab through with keyboard input,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/31,"navigation for 'dark patterns are everywhere' do not focus with keyboard input

https://gyazo.com/2fa83eee78fd54a0158607f02450d493",2021-05-10T16:27:15Z,2021-05-11T15:35:24Z,closed,0,"dark pattern education, darkpatternstipline.org, (DP) website layout design, focus with keyboard input issue",,,,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/27,Include source link that is provided in form on dark pattern specific page,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/27,"Currently, we ask for a source link in the form, but that source is not included in the dark pattern specific page. In order to correctly ""cite"" the source, could we include this please? 

![image](https://user-images.githubusercontent.com/79227044/117600996-1afdb500-b11b-11eb-99b2-b9e50143f858.png)


![image](https://user-images.githubusercontent.com/79227044/117600812-b3476a00-b11a-11eb-9725-5204e295e8f6.png)",2021-05-10T03:06:07Z,2021-05-10T03:06:32Z,closed,1,"dark pattern education, darkpatterntipline.org, (DP) website layout design, add source link",,,,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/54,"include images for ""dark patterns are everywhere"" carousel on home page for different industries",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/54,"this seems to be being built out as we speak, but wanted to flag the images for each of the industries that are not complete just yet. 

![image](https://user-images.githubusercontent.com/60265274/117911403-b6259480-b2ab-11eb-9bc2-a3a2ec57ddf9.png)
",2021-05-12T02:54:25Z,2021-05-12T23:37:45Z,closed,1,"dark pattern education, darkpatterntipline.org, (DP) website layout design, add image in home page",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/MultiMC/Launcher/issues/3805,NOISSUE Flagged mods system,https://github.com/MultiMC/Launcher/pull/3805,"This pull request introduces a post-installation dialog for getting user consent to have certain mods ('flagged mods') be enabled. At present this intends to cover mods for Tracking and Advertising purposes, and is limited to the modpacks.ch support - but should be rolled out to other platforms with time.

This pull request will disable any flagged mods that have not been explicitly allowed by the user, using the standard MultiMC disable mechanism - note that any disabled mods can always be enabled at a later date (through Instance Settings -> Loader Mods).

![image](https://user-images.githubusercontent.com/5103549/119268912-f01c6200-bbec-11eb-857c-12e11c55e88c.png)

The above is an example dialog from FTB Cotton 1.0.0 where FTB Auxilium has been explictly enabled.",2021-05-23T16:35:07Z,2021-07-22T16:42:48Z,closed,4,"MultiMC, usage of dark pattern, break modpack by default, check by default, preselction","MultiMC, modpacks, default","MultiMC, default, preselection",DPs prevention in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/inthepocket/cookie-though/issues/2,Discourage dark patterns,https://github.com/inthepocket/cookie-though/issues/2,"The default button in a cookie nagger should preferably be ""Enable the strictly necessary"" and not ""Accept all"". 

The sample dialog has a darkish-pattern IMO. A user has to notice that ""Customize"" is a link. It needs to clicked first to see what the customizable options are. That makes for two extra clicks.",2021-03-08T11:44:48Z,2021-03-08T13:22:35Z,closed,6,"prevention of dark pattern, cookie consent options, gdpr guidelines","mutiple clicks for customizing, cookie consent","GDPR, cookie consent, avoid dark pattern, deceptive design practices","DPs prevention in design, DPs related regulation ",,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/59,page meta defaults and management through the CMS,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/59,"@benrito - 
Here are the fields that we are currently accounting for and their default values. Let me know if you think we need to make adjustments. These values get used for page meta including OpenGraph and Twitter specific meta tags. We also have set it up so that meta can be overwritten on a page by page basis in WP (Through the Yoast Plugin)

{
  ""title"": ""Dark Patterns Tipline"",
  ""description"": ""Need copy..."",
  ""url"": ""https://____.com"", // Site domain?
  ""inLanguage"": ""en-US"", // Language Tag on <html> element
  ""logo"": ""/img/logo.png"", // Used for SEO and favicon
  ""ogLanguage"": ""en_US"", // Facebook Language
  ""shareImage"": ""/img/lib-share.png"" // Default social share image
  ""twitter"": """" // Need?
  ""facebook"": """" // Need?
}

1. Should we account for a title pattern? ie... <page.title> | Dark Pattern Tipline
2. What will the domain end up being?
3. Ocupop will create share images and favicons and push these up as soon as possible for testing.

",2021-05-12T18:46:35Z,2021-05-12T23:32:17Z,closed,2,"dark pattern education, darkpatterntipline.org",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3ctag/design-reviews/issues/545,WebXR Device API,https://github.com/w3ctag/design-reviews/issues/545,"Saluton TAG!

I'm requesting a TAG review of the [WebXR Device API](https://immersive-web.github.io/webxr). We have previously requested review [here](https://github.com/w3ctag/design-reviews/issues/403) and incorporated all the feedback; now that we are approaching CR I wanted to request review a second time in case the TAG wanted a chance to provide any final feedback.

The [WebXR Device API](https://immersive-web.github.io/webxr) provides access to input and output capabilities commonly associated with Virtual Reality (VR) and Augmented Reality (AR) devices. It allows you develop and host VR and AR experiences on the web.


  - Explainer¹: https://github.com/immersive-web/webxr/blob/master/explainer.md
  - Specification URL: https://immersive-web.github.io/webxr/
  - Tests: https://github.com/web-platform-tests/wpt/tree/master/webxr
  - Security and Privacy self-review²: We have an [explainer](https://github.com/immersive-web/webxr/blob/master/privacy-security-explainer.md) and a [spec section](https://immersive-web.github.io/webxr/#security) on security and privacy.
  - GitHub repo (if you prefer feedback filed there): github.com/immersive-web/webxr
  - Primary contacts (and their relationship to the specification):
      - @Manishearth (Editor, Mozilla)
      - @toji (Editor, Google)
      - @AdaRoseCannon (WG Chair, Samsung)
      - @cwilso (WG Chair, Google)
      - @yonet (WG Chair, Microsoft)
  - Organization(s)/project(s) driving the specification: Immersive-Web Working Group
  - Key pieces of existing multi-stakeholder review or discussion of this specification: Previous TAG review at https://github.com/w3ctag/design-reviews/issues/403
  - External status/issue trackers for this specification (publicly visible, e.g. Chrome Status): https://www.chromestatus.com/feature/5680169905815552  , https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API#Browser_compatibility , it's also released on some versions of Firefox Reality (which does not have its own status page)

Further details:

  - [x] I have reviewed the TAG's [API Design Principles](https://w3ctag.github.io/design-principles/)
  - Relevant time constraints or deadlines: I'm hoping we can request CR in a month or so, so ideally before that, but I understand if the wide review process takes longer. Review is the main remaining CR blocker.
  - The group where the work on this specification is currently being done: Immersive web Working Group
  - Major unresolved issues with or opposition to this specification: Not that I know of
  - This work is being funded by: ?

You should also know that...

[please tell us anything you think is relevant to this review]

We'd prefer the TAG provide feedback as (please delete all but the desired option):

  ☂️ open a single issue in our GitHub repo **for the entire review**

",2020-08-07T19:26:09Z,2021-09-15T15:24:10Z,closed,6,miscellaneous (some sites use DPs),"price setting, dp examples",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/95,"update text from ""mediation"" > ""help""",https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/95,,2021-05-20T04:08:34Z,2021-05-20T19:18:43Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design",,,,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/60,Develop,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/60,,2021-05-12T21:34:32Z,2021-05-12T21:35:03Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design",examples in code?,,,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/proginosko/LeechBlockNG/issues/195,Is paypal configured incorrectly?,https://github.com/proginosko/LeechBlockNG/issues/195,"According to https://www.salecalc.com/paypal for an international transaction there should be a fee of 4.4% + 30c or $0.74. However, when I try to make a $10 donation from the Czech Republic the fee is $2.28 (which is more than I'm willing to give them). Is paypal configured incorrectly in the donation link?
![paypal](https://user-images.githubusercontent.com/1391608/106128996-27f42b00-6160-11eb-8e5e-85774f9ffa54.png)

",2021-01-28T10:59:15Z,2021-06-02T00:45:28Z,closed,2,"Paypal, usage of dark pattern in software, currency transfer issue","Paypal, prices go up 50 cents automatically, hidden costs","Paypal, hidden costs, currency conversion",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/coderedcorp/wagtail-seo/issues/1,Change help text for amp_pages,https://github.com/coderedcorp/wagtail-seo/issues/1,"The help text currently says: `Generates an alternate AMP version of article pages that are preferred by search engines. See https://amp.dev/`

But AMP is no longer required for top stories: https://www.searchenginejournal.com/googles-top-stories-to-show-more-than-just-amp-pages/370792/

So, would it make sense to remove the part about amp being `preferred by search engines`? AFAIK now it shouldn't directly affect ranking either. And like most developers I'd rather not encourage people to use it.

Also, this option doesn't seem to actually generate an AMP page, only a link to one, so the first half of the help text seems incorrect as well. ",2020-09-28T12:35:32Z,2021-07-31T17:08:22Z,closed,5,"AMP (a web component framework), Google use dark pattern in ranking AMP pages","Google, ranking AMP pages higher than non-AMP, design hierarchy, interface intereference","Google, ranking system, AMP(a web component framework), design hierarchy",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/51,"""Our purpose"" text in home page footer adjustment",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/51,"Replacing the text in ""Our Purpose""

The Dark Patterns Tip Line is a platform people can use to submit deceptive designs they encounter in everyday digital products and services. Through crowdsourcing human stories of digital manipulation and amplifying people’s voices, we will raise awareness of the real-life harms that result from deceptive design.

The submissions reflect the views of the people who submitted them, and not necessarily those of Consumer Reports. They have not been checked by Consumer Reports for accuracy.
",2021-05-11T21:38:04Z,2021-05-12T23:37:05Z,closed,2,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences","The Dark Patterns Tip Lines, examples","The Dark Patterns Tip Lines, https://darkpatternstipline.org/, crowdsourcing",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/46,Develop,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/46,,2021-05-11T15:32:44Z,2021-05-11T15:40:32Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, deploy the app",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/45,Continued development,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/45,,2021-05-11T14:30:42Z,2021-05-11T14:33:37Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, deploy the app",,,,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/29,Updates to OurPurpose text,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/29,,2021-05-10T03:13:25Z,2021-05-10T19:48:07Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, deploy the app",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/32,Develop,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/32,github issues,2021-05-10T18:10:32Z,2021-05-10T18:14:38Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, deploy the app",,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/i3/i3/issues/4400,Enable GitHub Discussions for i3,https://github.com/i3/i3/issues/4400,"TODOs:

- [X] Enable discussions
- [x] Announce on reddit + perma-sticky
- [x] Update contact information (#4482) (https://github.com/i3/i3/pull/4503)
- [x] Update FAQ link (https://github.com/i3/i3/pull/4503)
- [X] Add new button on issue template
- [x] Update contact page on website (https://github.com/i3/i3.github.io/pull/110)
- [ ] Announce this on the next release notes

<details><summary>Original request</summary>

## I'm submitting a…
<!-- Check one of the following options with ""x"" -->
<pre>
[ ] Bug
[x] Feature Request
[ ] Documentation Request
[ ] Other (Please describe in detail)
</pre>

## Current Behavior
<!--
Describe the current behavior,
e.g., »When pressing Alt+j (focus left), the window above the current window is focused.«
-->
Not available.

## Desired Behavior
<!--
Describe the desired behavior you expect after mitigation of the issue,
e.g., »The window left next to the current window should be focused.«
-->
Can you please enable github discussions forum here? So we can use it to discuss i3 not related to feature or a bug?

## Impact
<!--
Please note that at this point we focus on maintaining i3 and fixing bugs, and will rarely consider features which require further configuration or significant complexity.
In such cases you should consider and present specific benefits derived from adding this feature such that it can be weighed against the cost of additional complexity and maintenance.
-->
<pre>
[ ] This feature requires new configuration and/or commands
</pre>

## Environment
<!--
Please include your exact i3 version.
Note that we only support the latest major release and the current development version. If you are using an older version of i3, please first update to the current release version and reproduce the issue there.
-->
Output of `i3 --moreversion 2>&-`:
<pre>
i3 version: 
</pre>

<!--
Please also answer the questions below to help us process your issue faster. If you have any other information to share, please add it here as well.
-->
<pre>
- Linux Distribution & Version:
- Are you using a compositor (e.g., xcompmgr or compton):
</pre>

</details>",2021-04-13T09:18:54Z,2021-11-09T17:46:51Z,closed,29,"dark pattern sources, Hacker News, DP discussion","Reddit, manipulate to install","Reddit, app installation, documentation",Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/38,#20 add link to privacy policy,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/38,,2021-05-10T22:20:42Z,2021-05-11T00:20:34Z,closed,3,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design, add link to privacy policy",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ietf/terminology/issues/9,Suggest: Deception Pattern replaces Dark Pattern,https://github.com/ietf/terminology/pull/9,"Hi @mallory. As per our email exchange, hereby the PR to use 'Deception Pattern' instead of 'Dark Pattern' in UX design docs and elsewhere.",2020-10-06T05:41:59Z,2021-02-22T11:02:29Z,closed,0,miscellaneous (replace dark pattern with deceptive design in docs),,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/brave/brave-browser/issues/13222,Unsolicited Advertisements from Brave Rewards / Respecting the User's Choices,https://github.com/brave/brave-browser/issues/13222,"<!-- Have you searched for similar issues? Before submitting this issue, please check the open issues and add a note before logging a new issue. 

PLEASE USE THE TEMPLATE BELOW TO PROVIDE INFORMATION ABOUT THE ISSUE. 
INSUFFICIENT INFO WILL GET THE ISSUE CLOSED. IT WILL ONLY BE REOPENED AFTER SUFFICIENT INFO IS PROVIDED-->

## Description 
<!--Provide a brief description of the issue-->

[This is getting a little silly now, guys.](https://mastodon.tedomum.net/@resynth1943/105391306346272791)

I appreciate the privacy benefits of Brave, but I don't really want to play whack-a-mole with Brave's forceful corporate advertising on random pages, without me giving any form of consent.

This was enabled shortly after installing an update for Brave; I did not consent to having these enabled.

After disabling your (frankly rather invasive) cryptocurrency features 15 times, I think we need to draw a line: how many more advertisements are you going to add? How many more options?

I've also had advertisements from Brave randomly re-enable themselves, after loading the program.

## Steps to Reproduce
<!--Please add a series of steps to reproduce the issue-->

   1. Go to GitHub.com in Brave
   2. Disable literally every option for Brave Rewards you can find
   3. See 'Tip' buttons!

## Expected result:
<!--Please add screenshots if needed-->

The advertisements do not show after I say 'no' 15 times.

## Actual result

The advertisements appear without user consent.

## Reproduces how often: 
<!--[Easily reproduced/Intermittent issue/No steps to reproduce]-->


## Brave version (brave://version info)
<!--For installed build, please copy Brave, Revision and OS from brave://version and paste here. If building from source please mention it along with brave://version details-->



Brave | 1.18.70 Chromium: 87.0.4280.101 (Official Build) (64-bit)
-- | --
Revision | 9407c80213cda69c2b7abcb4fa8e3f74488f4956-refs/branch-heads/4280@{#1807}
OS | Linux
JavaScript | V8 8.7.220.29
Flash | (Disabled)
User Agent | Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.101 Safari/537.36
Command Line | /opt/brave.com/brave/brave --enable-dom-distiller --disable-domain-reliability --no-pings --extension-content-verification=enforce_strict --extensions-install-verification=enforce --origin-trial-public-key=[redacted] --sync-url=https://sync-v2.brave.com/v2 --lso-url=https://no-thanks.invalid --variations-server-url=https://variations.brave.com/seed --enable-features=WebUIDarkMode,AutoupgradeMixedContent,PrefetchPrivacyChanges,PasswordImport,ReducedReferrerGranularity,LegacyTLSEnforced,DnsOverHttps --disable-features=AutofillServerCommunication,IdleDetection,SignedExchangeSubresourcePrefetch,SafeBrowsingEnhancedProtection,TextFragmentAnchor,PrivacySettingsRedesign,TabHoverCards,NotificationTriggers,SmsReceiver,VideoPlaybackQuality,AllowPopupsDuringPageUnload,AutofillEnableAccountWalletStorage,NetworkTimeServiceQuerying,PasswordCheck --flag-switches-begin --enable-gpu-rasterization --enable-features=WebUIDarkMode,AutoupgradeMixedContent,PrefetchPrivacyChanges,PasswordImport,ReducedReferrerGranularity,LegacyTLSEnforced,DnsOverHttps,ContentSettingsRedesign,LiteVideo --flag-switches-end
Executable Path | /opt/brave.com/brave/brave
Profile Path | /home/resynth/.config/BraveSoftware/Brave-Browser/Default


## Version/Channel Information:
<!--Does this issue happen on any other channels? Or is it specific to a certain channel?-->

- Can you reproduce this issue with the current release? Yes.
- Can you reproduce this issue with the beta channel? 
- Can you reproduce this issue with the nightly channel? 

## Other Additional Information:

- Does the issue resolve itself when disabling Brave Shields? No. 
- Does the issue resolve itself when disabling Brave Rewards? No.
- Is the issue reproducible on the latest version of Chrome? No.

## Miscellaneous Information:
<!--Any additional information, related issues, extra QA steps, configuration or data that might be necessary to reproduce the issue-->

In all respect, I think your company need to respect people's boundaries and listen to the word 'no'. As I've disabled Rewards in every configurable setting option, I'm gobsmacked as to why it continues to appear.

---

*Search keywords: spam; ads; advertising; rewards; tips; github; twitter; reddit; consent; send a tip; advertisement*",2020-12-16T18:48:47Z,2021-10-22T18:07:26Z,closed,18,"Brave browser, usage of dark pattern in software, distory trust, ","Brave Reports default, ""privacy report, examples ","Brave, privacy issue",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/8,Thumbnail images,https://github.com/consumer-reports-innovation-lab/dark-patterns/pull/8,,2021-04-30T18:00:30Z,2021-04-30T18:03:11Z,closed,1,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design, add thumbnail image",,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/18,"Change ""Source Link"" text on form to ""Where did you find this dark pattern? (ex. Include source or link to website, app, tweet or post)"" ",https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/18,"Change ""Source Link"" text on form to ""`Source Link (ex. Link to website, app, tweet or post)`""
![image](https://user-images.githubusercontent.com/60265274/117228550-46189980-ade7-11eb-8e36-866f621d4f74.png)
",2021-05-06T01:17:53Z,2021-05-11T19:22:00Z,closed,4,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design, change textual contents",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/92,Add text edits on form *AND* add text after form is submitted.,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/92,"Hi all. We got some feedback from a federal regulator today and need your help to see if we can make some quick text updates in 2 places: 
1. on the top of the form
2. in the text after you submit a pattern and it says ""successful submission thank you, etc""

We are still getting legal approval so do not make any updates yet, but wanted to highlight this as a heads up. I'll let you know once we get approval from legal to post. after that, it'd be great to get your guidance on how to make text changes asap.

cc: @benrito 

See text in question here for context: 
https://docs.google.com/document/d/1KbVO5ZBlMXRRle0HFpzP7rQMuRWpDeSqoAVSF0V5KT0/edit",2021-05-19T21:32:13Z,2021-05-22T11:29:11Z,closed,4,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design, add text edit of form",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/73,add feedback mechanism (contact or email),https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/73,"Hey guys - I know this is last minute. Talked to @benrito. 

we need a way for people to reach out. there is no way for anyone to get in touch (complain, make a suggestion, journalist outreach, be a partner). 

is there way to add a [contact / feedback] link and have it go somewhere where people can submit comments? 
* can be stored in wordpress
* can be forwarded to me 

Can be simple - we need some / any mechanism to do this. 

OR we can do an email: hi@darkpatternstipline.org  and stick in footer. 

thoughts? @tbeck 
",2021-05-14T21:02:16Z,2021-05-18T21:55:06Z,closed,9,"dark pattern education, darkpatterntipline.org, crowdsourcing of DP experiences, (DP) website layout design, add feedback mechanism (email & contact)","gatsby, Dark patterns tip line, email after feedback",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/userstyles-world/userstyles.world/issues/34,Menu: Add & Import,https://github.com/userstyles-world/userstyles.world/issues/34,"Makes more sense that both links (add and Import) appear only after login.

![image](https://user-images.githubusercontent.com/73315658/113526758-a1a9fa00-9591-11eb-81b0-62cbef671b77.png)


",2021-04-05T01:08:46Z,2021-04-05T13:50:37Z,closed,2,"prevention of dark pattern, avoid misleading/confusion","""Add""/""Import"" button after loggin in, design","UI/UX design, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/AlphaWallet/alpha-wallet-ios/issues/2793,Prompt to rate and review app,https://github.com/AlphaWallet/alpha-wallet-ios/issues/2793,"Linking to the issue in Android repo

https://github.com/AlphaWallet/alpha-wallet-android/issues/1856",2021-05-24T01:09:17Z,2021-05-24T07:13:01Z,closed,2,"AlphaWallet, IOS, App Store, nagging, prompt to rate apps","prompt appearing without control, nagging","AlphaWallat, iOS, App Store, rating system, nagging",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/consumer-reports-innovation-lab/dark-patterns/issues/76,Add Matomo plugin,https://github.com/consumer-reports-innovation-lab/dark-patterns/issues/76,"Hey fellas, we may be able to do ourselves with admin privs but dropping here ahead of Weds: https://matomo.org/installing-matomo-for-wordpress/",2021-05-17T15:12:19Z,2021-05-18T22:06:41Z,closed,4,,"Matomo, user login tracking, cookie disabled","Matomo, login, tracking, cookie consent, disabled",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/dtolnay/proc-macro2/issues/273,Add forbid(unsafe_code),https://github.com/dtolnay/proc-macro2/pull/273,"Hi proc-macro2 Maintainers,
I am developing a safe regular expression library.  Of its dependencies, only `proc_macro2` is lacking a `forbid(unsafe_code)` declaration.  Can we please add it?

Best,
Michael

## Cargo Geiger Safety Report
```

Metric output format: x/y
    x = unsafe code used by the build
    y = total unsafe code found in the crate

Symbols: 
    🔒  = No `unsafe` usage found, declares #![forbid(unsafe_code)]
    ❓  = No `unsafe` usage found, missing #![forbid(unsafe_code)]
    ☢️  = `unsafe` usage found

Functions  Expressions  Impls  Traits  Methods  Dependency

0/0        0/0          0/0    0/0     0/0      🔒  safe-regex 0.1.0
0/0        0/0          0/0    0/0     0/0      🔒  └── safe-regex-macro 0.1.0
0/0        0/0          0/0    0/0     0/0      ❓      ├── proc-macro2 1.0.24
0/0        0/0          0/0    0/0     0/0      🔒      │   └── unicode-xid 0.2.1
0/0        0/0          0/0    0/0     0/0      🔒      └── safe-regex-compiler 0.1.0
0/0        0/0          0/0    0/0     0/0      ❓          ├── proc-macro2 1.0.24
0/0        0/0          0/0    0/0     0/0      🔒          └── quote 1.0.8
0/0        0/0          0/0    0/0     0/0      ❓              └── proc-macro2 1.0.24

0/0        0/0          0/0    0/0     0/0    

```
",2021-02-12T06:32:41Z,2021-04-02T01:39:10Z,closed,7,"miscellaneous (Geiger, usage of dark pattern, mislead users)",,miscellaneous,miscellaneous,"Geiger, usage of dark pattern, mislead users",,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/00-Evan/shattered-pixel-dungeon/issues/743,"Save/Load function (Badge Disabled, no record)",https://github.com/00-Evan/shattered-pixel-dungeon/issues/743,"It would be nice to add a function to write and load a save file. It is provided in the form of a checkbox and can be set in the options, and will be applied from the next game. When I try to use this feature and start the game, I get the following warning message: ""Are you sure you want to save? If you save, you will not be able to earn badges. Also, no records will left. Confirm or cancel."" This warning only appears once and is saved immediately thereafter. Clicking Cancel immediately clears the option. Once a save file is created, the badge earning ability is permanently removed from that file. The save file is saved in a separate directory without being hidden. It can be backed up or shared via a USB connection.

I wish it would be compatible with the PC version, but I don't think it's necessary.

After all, The badge will prove your skills, so I don't think it's completely against the spirit of roguelike.",2021-06-23T00:12:26Z,2021-06-23T18:21:11Z,closed,4,"prevention of dark pattern, gaming","game, run record not saved, frustration","gaming, UI/UX design, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3ctag/design-reviews/issues/636,Pickling for Async Clipboard API,https://github.com/w3ctag/design-reviews/issues/636,"Ya ya yawm TAG!

I'm requesting a TAG review of Pickling for Async Clipboard API.

Powerful web applications would like to exchange data payloads with web and native applications via the OS clipboard (copy-paste).
The existing Web Platform has an API that supports the most popular standardized data types (text, image, rich text) across all platforms. 
However, this API does not scale to the long tail of specialized formats. In particular, custom formats, non-web-standard formats like 
TIFF (a large image format), and proprietary formats like .docx (a document format), are not supported by the current Web Platform.
Pickling for Async Clipboard API aims to provide a solution to this problem, by letting web applications read and write custom, unsanitized, web-originated payloads using a standardized pickling format.

  - Explainer¹ (minimally containing user needs and example code): https://github.com/w3c/editing/blob/gh-pages/docs/clipboard-pickling/explainer.md
  - Security and Privacy self-review²: https://github.com/w3c/editing/blob/gh-pages/docs/clipboard-pickling/security-privacy.md
  - GitHub repo (if you prefer feedback filed there): N/A
  - Primary contacts (and their relationship to the specification):
      - Anupam Snigdha (@snianu), Microsoft
      - Bo Cupp (@BoCupp-Microsoft) Microsoft
      - Darwin Huang (@dway123) Google.
  - Organization/project driving the design: Microsoft in collaboration with Google
  - External status/issue trackers for this feature (publicly visible, e.g. Chrome Status): https://chromestatus.com/feature/5649558757441536

Further details:

  - [X] I have reviewed the TAG's [Web Platform Design Principles](https://w3ctag.github.io/design-principles/)
  - The group where the incubation/design work on this is being done (or is intended to be done in the future): [Editing TF](https://github.com/w3c/editing)
  - The group where standardization of this work is intended to be done (""unknown"" if not known): [Editing TF](https://github.com/w3c/editing)
  - Existing major pieces of multi-stakeholder review or discussion of this design: N/A
  - Major unresolved issues with or opposition to this design: N/A
  - This work is being funded by: Microsoft

You should also know that...

There have been discussions on Pickling Clipboard API during TPAC and also while discussing Raw Clipboard API.
Slides: https://docs.google.com/presentation/d/1_fAgL54D0whQ497G8iL0K2kKpxiWDr3M7gXXSIS76II
Editing TF Minutes: https://lists.w3.org/Archives/Public/public-editing-tf/2020Oct/0017.html

We'd prefer the TAG provide feedback as (please delete all but the desired option):

  💬 leave review feedback as a **comment in this issue** and @-notify @snianu @dway123 @BoCupp-Microsoft
",2021-05-13T15:33:44Z,2021-09-15T22:07:34Z,closed,17,"dark pattern example, discussion, trick users to agree to permission","phishing, getting permission with dp, unethical, zuckering","deceptive design practices, permission, phishing",DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/arp242/goatcounter/issues/472,Circumvent ad-blockers,https://github.com/arp242/goatcounter/issues/472,Is there any way to circumvent ad-blockers automatically (similar to [this](https://github.com/0x11DFE/Matomo-Anti-Adblock) or [this](https://github.com/simonfrey/matomo_circumvent_adblock) approach for Matomo)?,2021-04-09T12:26:15Z,2021-04-10T10:29:48Z,closed,4,"GoatCounter, prevention of dark pattern, no hovering on data, no tricks to override users' blocking preferences","GoatCounter, data collecting example","GoatCounter, data collection, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/signalapp/Signal-Desktop/issues/4684,On Signal Desktop the audio during a call is not heard by the other party,https://github.com/signalapp/Signal-Desktop/issues/4684,"<!--
Please fill out this template with all the information you have. We can't do much without
both the logs and a detailed description of what you've encountered. Please do your best!

Please note that this tracker is only for bugs and feature requests. Please try these
locations if you have a question or comment:

  https://community.signalusers.org/
  http://support.signal.org/
  support@signal.org

Lastly, be sure to preview your issue before saving. Thanks!
-->

- [x] I have searched open and closed issues for duplicates
<!--
  You can search all issues here:
    https://github.com/signalapp/Signal-Desktop/issues?utf8=%E2%9C%93&q=is%3Aissue
  Replace [ ] with [X] once you've searched
-->

---

### Bug Description

When calling on desktop app the microphone doesn't work

### Steps to Reproduce

<!-- Using bullet points, list the steps that reproduce the bug. -->

1.  make a video or audio call

Actual Result: The video works but the audio doesn't, no matter what source is selected

<!-- Describe the details of the buggy behaviour. -->

Expected Result: Audio working

<!-- Describe in detail what the correct behavior should be. -->

### Screenshots

<!--
How to take screenshots on all OSes: https://www.take-a-screenshot.org/
You can drag and drop images into this text box.
-->

### Platform Info

Signal Version:  Signal Desktop 1.38.2

<!-- You can see Signal's version number at Help -> About or File -> About Signal Desktop -->

Operating System: Windows 10

<!-- Instructions for finding your OS version are here: http://whatsmyos.com/ -->

Linked Device Version: MIUI 11.0.2 (Android 8.1.0)

<!-- Android: Settings -> Advanced,  iOS: Settings -> General -> About -->

### Link to Debug Log


https://debuglogs.org/600f4cccbd5f42bbaac58db7267604611b92b16829ab7a1a7f21587804d2f30e 

<!--
Immediately after the bug has happened, submit a debug log via View -> 
https://debuglogs.org/600f4cccbd5f42bbaac58db7267604611b92b16829ab7a1a7f21587804d2f30e


In most cases, a log from your other devices is also useful:
  Android: https://support.signal.org/hc/en-us/articles/360007318591#android_debug
  iOS: https://support.signal.org/hc/en-us/articles/360007318591#ios_debug
-->
",2020-11-30T18:38:48Z,2021-11-22T15:16:16Z,closed,56,"Microsoft, Windows 10, obscure privacy setting, impact on screen sharing and webcam functionality","Microsoft, Windows 10, changing privacy settings automatically turns on microphone, sneaking, unethical","Microsoft, Windows 10, privacy issue, preselection",DPs used in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/squidfunk/mkdocs-material/issues/1914,Feature request: cookie consent,https://github.com/squidfunk/mkdocs-material/issues/1914,"Struggled with adding a cookie consent banner via Google Tag Manager (GTM) injection until a frontend colleague helped. Since I could not find anything about this topic related to mkdocs or mkdocs material I thought I'd open an issue here for others to google. Could maybe be added as a feature if relevant for more people, otherwise feel free to close soon.

HOWTO: Use the [mkdocs theme override functionality](https://www.mkdocs.org/user-guide/styling-your-docs/#using-the-theme-custom_dir) and create a `main.html` file with the following javascript code taken from [here](https://developers.google.com/tag-manager/quickstart). The first, custom part of the code ensures that the GTM is not being active when running `mkdocs serve` locally since this blocks from interacting with the site. Also see this [PR and repository](https://github.com/up42/up42-py/pull/130) as an example for the structure of the overrides.

```
<!-- Elements added to main will be displayed on all pages -->
{% extends ""base.html"" %}

{% block libs %}
<!-- Google Tag Manager -->
<script>
var gtmId = 'GTM-YOURGTMCODE;
if (typeof window !== 'undefined' && window.location.href.includes('127.0.0.1')) {
  gtmId = 'GTM-XXX'
}
(function(w,d,s,l,i){
  w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer', gtmId);
</script>
  <!-- End Google Tag Manager -->
{% endblock %}
```

## Description

If this would be added by default I could imagine it being used similarly to the Google Analytics tag in the mkdocs.yml file. Depending on your GTM configuration adds a cookie banner. However probably not relevant for too many users. Don't know much about cookies and was also told that when using Google Analytics anonymized this would not actually be neccessary (was still decided to add it for the future).

### Screenshots / Mockups

![image](https://user-images.githubusercontent.com/12833517/92646494-d2210280-f2e6-11ea-86a8-66f1d5f41b71.png)


- [x] ... the documentation does not mention anything about my idea
- [x] ... to my best knowledge, my idea wouldn't break something for other users
- [x] ... there are no open or closed issues that are related to my idea
",2020-09-09T20:00:04Z,2021-08-29T14:36:06Z,closed,32,"MKDocs, usage of dark pattern, cookie consent, color psychology on buttons, trick users to click ""accept all""","cookie consent, extra click to deny, obstruction, nagging","MKDocs, cookie consent, UI/UX design",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/gitpod-io/gitpod/issues/4142,Update wording for marketing related notifications in settings,https://github.com/gitpod-io/gitpod/issues/4142,"### Bug description

""Marketing"" has a quite negative connotation, also it's a very general term and doesn't explain the value of the emails. Instead, we should have more descriptive wording.

Right now we are using ""Marketing Notifications -Receive product marketing emails""

Suggestion: ""Product notifications - receive emails about products updates and news""


### Steps to reproduce

https://gitpod.io/notifications

### Expected behavior

_No response_

### Example repository

_No response_

### Anything else?

_No response_",2021-05-04T13:03:51Z,2021-05-18T11:34:10Z,closed,5,"usage of dark pattern in software, newsletter sign up, terms and conditions accept","Gitpod, default emails, preselection","Gitpod, newsletter signup, terms and conditions, preselection",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/designdetails/designdetails/issues/503,Purposefully hard to find features,https://github.com/designdetails/designdetails/issues/503,"Hi, I’m wondering if you have any thoughts on making certain features of a website more difficult to find. For example, if I want to talk or chat with an actual human about an Amazon order, one has to find Customer Service in the app, then step through multiple selection screens to narrow down the topic, issue, specific item, read though the “standard” answers, pick “I need more help”, select a communication preference, confirm multiple times that you want to start a chat.....you get the picture. I assume this does cut down the number of live interactions they need to handle, but if I know for sure I want to talk to someone, the process can be annoying when presumably the buyer is already upset about an issue. Thanks!!",2020-11-10T17:44:53Z,2021-01-24T21:56:43Z,closed,1,"dark pattern in other contexts, hard-to-find in customer service","hard to find features, sneaking","UI/UX design, sneaking",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ooni/probe/issues/1391,F-Droid needs Antifeature Tracking,https://github.com/ooni/probe/issues/1391,"...as usage metrics and send error reports are OPT-OUT

Also, the app connects to `countly.ooni.io` port 443 TCPv4 and `oXXXXXX.ingest.sentry.io` port 443 TCPv4 just by starting the app, no test ever run. 

Making them OPT-IN is better ;)

F-Droid version 2.9.10
",2021-03-11T10:16:41Z,2021-06-14T14:21:27Z,closed,20,"usage of dark pattern in software, opt-in without asking","F-Droid, design","F-Droid, opt-in/out, forced action, preselection",DPs used in software,,,DPs or not,dps or not,,,
https://api.github.com/repos/HabitRPG/habitica/issues/12610,Discussion: darker patterns in game design,https://github.com/HabitRPG/habitica/issues/12610,"Hi all.

Basically, there is a super long list of things MMOs and mobile games do to be addictive and/or feel more rewarding. I was particularly shocked at how good Gacha games are at this stuff. Habitica does very little of these things.

To me, the ideal version of Habitica would implement a lot of these patterns, even ones that are kinda dark. I realize there's a need to balance this against making Habitica itself too distracting. One way to address this is by making these features configurable, since there's no reason all players need to be playing with the same set of rules. 

Here are some patterns other games do:

-  **Progression never stops**: your dude can always be stronger or cooler. This is often achieved with randomly generated modifiers for gear, making it where you'll never acquire the theoretically optimal gearset. 
   - Habitica on the other hand gives players endgame headgear game very early on (Nameless Helm). This should probably be changed, it just means I have no incentive to buy hats. This is even more true if you're playing with a big party.
   - Randomly generated gear is also just fun, it means the game can never just be ""solved"" and you constantly have to evaluate new tradeoffs. May be considered too distracting though.
   - Habitica could also achieve this by giving some incentive to reach level 100 and use an Orb, for example giving you a random piece of special permanent gear when you do so.
- **Vanishingly rare drops / jackpots**. Could be achieved via the enchanted armoire and giving quests randomized loot. related to above but I just want to point out that it can be used for cosmetics not just power-increasing things.
  - Relatedly Hearthstone increases your odds of getting a Legendary card the longer you go without getting one, other gambling games similarly have non-independent odds designed to trigger repeat gambling. 
- **Complicated crafting systems**. A lot of games have a bunch of wacky different resources you can use to combine and craft things. Gacha games are probably best in class at this but even League of Legends has a good example in its crafting system. ""Once I got a 3rd Golden Shard I disenchanted them into Dust which I used to empower my dragon egg so that it could fuse with the other empowered dragon egg to give me a Hyper Dragon Egg"". Another common theme here is exponential requirements- 3 Foos make a Bar, 3 Bars make a Bar+, and so on.
   - These may be too distracting (players spend time understanding the wacky crafting system and optimizing how they craft) but I definitely think it's no accident that they are commonplace. 

I'm not an expert and I don't play a lot of games with dark patterns. I'm sure there are a lot of other things that could be applied. I anticipate some arguments against dark patterns. People do struggle with gaming addiction and there should definitely always be a way to play Habitica without triggering that. That's why this is a discussion ticket and not a feature req. ",2020-09-24T21:25:00Z,2020-09-25T04:58:16Z,closed,1,"Habitica, prevention of dark pattern in gaming","Habitica game, addictive, progression non-stop, jackspot missing, urgency, design hierarchy","Habitica, gaming, fake urgency, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/postmanlabs/postman-app-support/issues/9402,How to disable shared history?,https://github.com/postmanlabs/postman-app-support/issues/9402,"The constant pop-ups about shared history limits are a bit annoying considering I don't really care about sharing history in the first place.

Any way to disable this?",2021-01-06T07:52:57Z,2021-01-06T12:25:51Z,closed,6,"usage of dark pattern in software, nagging, popups, ""upgrade"" for usage limit",,"popups, nagging, tricks users for buying paid products",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/gitcoinco/web/issues/6828,Organize Townsquare By Top Posts,https://github.com/gitcoinco/web/issues/6828,"As an information consuming user, I want a town square which has curated, relevant, and useful content that rises to the top and a default view which doesn't show me *any* content which is low-quality. Curation matters! 

Taking inspiration [from this post](https://twitter.com/mikaelcho/status/1270743622619717632) by @ceresstation in Slack, organize our Town Square by the top 10 posts of the week. 

Reddit / Dev / Twitter all organize their feeds in this manner. 

One step further -- we could consider *only* showing the top 10 posts, with the 'see more' option only if you want to see it later. 

Reduces 'infinite scrolling', which can [be considered a dark pattern.](https://medium.com/simple-human/7-reasons-why-infinite-scrolling-is-probably-a-bad-idea-a0139e13c96b) 

Design wise, I wonder if our Townsquare would be better as a forum (where we encourage people share longer form ideas), rather than posts (some of which are quite low value ATM). ",2020-06-11T06:00:55Z,2020-12-16T15:05:35Z,closed,3,"prevention of dark pattern, no infinite scroll","infinite scrolling, deception, addictive","infinite scroll, avoid dark pattern, addictive",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/socketry/falcon/issues/112,"Add option to suppress ""Server"" header",https://github.com/socketry/falcon/issues/112,"In a recent commit you (re-)added a mandatory `Server` header: https://github.com/socketry/falcon/commit/59bf99bc2d593d35d09bdd39b8019eeac780c55f

I get that it's in the spec, but https://www.ietf.org/rfc/rfc2068.txt strongly recommends to make it a configurable field. Also see https://www.troyhunt.com/shhh-dont-let-your-response-headers/ for a more detailed background on why this is a good idea.",2020-04-08T12:18:14Z,2021-01-07T06:23:02Z,closed,4,dark pattern: security features are only available in commercial/paid product,,privacy issue(features are only available in commercial/paid product),DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/jitsi/jitsi-meet/issues/5779,Mobile link welcome page reverse buttons,https://github.com/jitsi/jitsi-meet/issues/5779,"When you share a link the other person currently get this view:

![XoNlVMdUSlybb2lKiyd2og](https://user-images.githubusercontent.com/2282799/78764657-62dd6600-7976-11ea-8a12-d074a549faad.jpg)

...which looks more like a dark-pattern to always force the user to press download instead of join.

Yes the user might not have the app but, at least on Android, pressing the intent link when you don't have the app will pop-up the Store selector _(F-Droid, Aurora or I guess even Play)_, making the Download button useless somewhat.

Can this be reduced to JOIN or at least reorder and emphasis JOIN as a big blue button and Download as a link?

",2020-04-08T08:54:52Z,2020-11-14T09:49:08Z,closed,7,"Jitsi Meet, prevention of dark pattern in software, no color difference button to trick users to click, ","Jitsi Meet, ""download"" instead of just joining, obstrcution","Jitsi Meet, deceptive design practice, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/AdguardTeam/AdguardFilters/issues/73968,Whitelist a 100% GDPR compliant user experience company,https://github.com/AdguardTeam/AdguardFilters/issues/73968,"[//]: # (***You can delete or ignore strings starting with ""[//]:"" They will not be visible either way.)

***Description***:
* **Current behaviour**: Some GDPR compliant companies like contentsquare are blocked
Hello, thank you for the awesome job, I use ublockOrigin everyday and it would be nothing without your filters list so thank you.
I was just wondering if a company is 100% [GDPR](https://gdpr-info.eu/) compliant can be whitelisted.

Thanks.
",2021-02-03T10:37:29Z,2021-02-15T16:34:13Z,closed,5,"100% gdpr compliance companies, criteria, no dark patterns, etc",good example of no dp,"GDPR, regulation",DPs related regulation ,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/rainbow-me/rainbow/issues/1271,Allow to delete all backups,https://github.com/rainbow-me/rainbow/pull/1271,"Added an option to delete all backups with double confirmation.

PoW - single wallet: http://recordit.co/ZOyLbMTjig
PoW - multiple wallets: http://recordit.co/XqZLVwvzwz",2020-11-04T02:37:20Z,2020-11-05T17:15:25Z,closed,3,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/elliotlepers/Amazon-Killer/issues/22,"webextension : complete refactoring, multiple bookstores and countries",https://github.com/elliotlepers/Amazon-Killer/pull/22,"I took some time of a sunday lockdown to rewrite the Amazon Killer extension. 
It's now a crossbrowser webextension (according to the latest standards)
I tested the extension on Chrome and Firefox, but it should also works on Opera, Safari and Edge. 

And I added a lot of other online bookstores for more countries (UK, US, FR, IT, ES, CA), they are displayed according to the language of the amazon site. 
[The complete list of bookstores is here](https://github.com/elliotlepers/Amazon-Killer/compare/elliotlepers:master...lowwebtech:master#diff-67a2bd337991a87d2f5452929efd639f0ee4ccf22e695a8dbf0ee4ccf22e695a8dbfR26597Rca)
This list need to be worked on to add more independent bookstore, in more countries.

Description of extension and text button are translated in EN, FR, IT, ES

I did not add the click on the icon of the extension. There is usually more than one link per country.
I can display a popup under the icon with the list of stores?
I also hided some html elements on the book pages (when there is the ISBN), like kindle links, price displays, dark patterns, delivery options and buy buttons.

And there is also npm command line tasks to auto-deploy the extension on firefox and chrome stores. 
I will come back to you to configure the credentials.

Let me know if you think of others enhancements ? And take a look at the list of bookstores `datas/urls.js` 

Thanks",2020-11-02T10:23:29Z,2020-11-03T08:25:21Z,closed,0,"usage of dark pattern in software, kindle links, price displays, delivery options, buy buttons",webextension,"Kindle, links, UI/UX Design",DPs used in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/knadh/listmonk/issues/211,Opt-in list requires user to click twice,https://github.com/knadh/listmonk/issues/211,"Hi 

I was wondering if there is a setting which allows to send opt-in mails which result in opt-in action just by clicking once on the button in email?  the below screen grab is from the user's email, now if he clicks on confirm another url opens up where he has to click confirm again.  Question is how can he straight away confirm by clicking only once i.e. the link in the email.

![image](https://user-images.githubusercontent.com/71901268/97088391-1295cf00-164e-11eb-8d94-29417870bf6e.png)
",2020-10-24T17:41:18Z,2020-10-25T06:54:24Z,closed,1,"usage of dark pattern in design, opt-in list, comfirmed twice to once","opt-in requires 2 clicks, obstruction, interface interference","opt-in/out, confirmshaming, UI/UX design",DPs in design coding,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/IQSS/dataverse/issues/7496,Dataverse violates the GDPR by sending user information to Google without consent,https://github.com/IQSS/dataverse/issues/7496,"Dataverse violates the GDPR because it doesn't ask the user for consent before sending visitor information to Google Tag Manager and setting a cookie on the visitor's browser. You should use some kind of popup to ask for consent, and only then load  the Google Tag Manager.

For example, a popup like this works very well: https://github.com/chiiya/haven/

I noticed this behavior in Dataverse 5.2, but I suppose it's the same in all.",2020-12-28T11:03:59Z,2021-01-05T14:27:28Z,closed,7,"data.aussad.at, usage of dark pattern in software, cookie consent design, ""accept all"", ""allow all cookie"", Dataverse violates gdpr compliance, send data to Google without consent","aussdata.at, pop-up, confusing","data.aussad.at, pop-ups, cookie consent, privacy issue, GDPR","DPs used in software, DPs related regulation ",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/Hacktoberfest/hacktoberfest-2020/issues/560,Remove default opt-in for marketing emails,https://github.com/Hacktoberfest/hacktoberfest-2020/pull/560,"# Description

We were opting folks into DigitalOcean marketing by default, which our community did not agree with as it is a dark pattern. This makes the checkbox unchecked by default.

# Test process

Register, no checkboxes are checked by default.

# Requirements to merge

- [x] My code follows the style guidelines of this project
- [x] I have performed a self-review of my own code
- [ ] I have commented my code in hard-to-understand areas
- [x] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [x] New and existing unit tests pass locally with my changes
",2020-09-30T15:26:19Z,2020-09-30T23:45:29Z,closed,0,"prevention of dark pattern in software, marketing email, remove default opt-in","DigitalOcean marketing default, preselection","DigitalOcean, opt-in/out, preselction, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/decidim/decidim/issues/6348,"""None of the above"" option on Election voting process",https://github.com/decidim/decidim/issues/6348,"ref: S-US.10 *(NEW)* 

As a participant, I want a clear way of saying ""I don't like any of these options"". At first, we thought about handling this with an explicit option created by the administrator as a specific option. For instance: 

![](https://i.imgur.com/OcBYhEt.png)

This has problems because it doesn't work for checkboxes kind of elections.

So, going back to #5973: 

> ### About NOTA (None of the above)
> Some elections can have an option called ""None of the above"" (NOTA), also known as ""voto en blanco"" or ""blank ballot"" in Spanish. As far as we know, given the current interface we could implement it in several ways:
> 1. By having another button on ""Back"" / ""Next"" bar
> 2. By not selecting an option, but we should at least give a modal for confirming that's an option (as nvotes/agoravoting already does)
> 3. By having an explicit option configured by default
> 4. By having documentation on the admin Elections configuration panel explaining that she should make it an explicit option
> On Decidim we prefer that this particular decision should be explicit (3rd or 4th options) and as the rest of the software should be an admin decision (4th option). We don't want to apply Dark Patterns here.
> More information on [None of the above](https://en.wikipedia.org/wiki/None_of_the_above)

We should have: 
1. An explicit configuration on the admin panel so the administrator of the participatory space can choose if she wants to have this option on a given question 
2. An explicit button at the UI separated from the rest of the options
3. A modal confirming that the visitor knows what she's doing 

### Mockup 

![](https://i.imgur.com/SaKwNsm.png)

### Acceptance Criteria

- [x] As a participatory process administrator I can configure if I want that a question has the NOTA explicit boolean (checkbox) option 
- [x] As a visitor I can select the NOTA option when configured
- [x] As a visitor if I select the NOTA option, the other options are disabled
",2020-07-28T15:57:27Z,2020-11-24T16:14:54Z,closed,11,"voting system UI, NOTA - none of the above, prevention of dark pattern in design","Decidim, having options for users to decide","Decidim, voting system, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/carpentries/workshop-template/issues/685,Check whether  Git for Windows installation instructions need to be updated,https://github.com/carpentries/workshop-template/issues/685,"there is a new release of Git for Windows: https://github.com/git-for-windows/git/releases/tag/v2.28.0.windows.1

The installation instructions need to be checked to ensure that they are consistent with the installation process of this new version.",2020-07-28T10:35:45Z,2020-10-08T07:43:22Z,closed,4,"usage of dark pattern in software, git for Windows, nano editor as default","scroll bar position, frustrating design","Git, Windows, scroll bar, nano editor default, preselection, UI/UX design, ",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/radix-ui/primitives/issues/204,RFC: Global app providers,https://github.com/radix-ui/primitives/issues/204,"The time has come to visit the pros and cons of exposing one or more context provider that might be helpful for consumers when dealing with higher level state needed by our components. I keep mentioning it in one-off conversations, so I feel like we should bring it up and decide on a path forward once and for all.

### Rationale

There are a number of existing and in-progress components that need to either read or write some state related to other components. We've managed to get around this using DOM APIs for the most part, but there are times when this is going to be insufficient, particularly when the React tree is a closer source of truth than the DOM tree.

In Reach UI we've historically opted to store global state in a property on `window` to simplify matters so things *just work* for consumers. This has obvious shortcomings, and I think by and large React devs are comfortable with the context API these days. It's not as new and mysterious as it was when Reach decided to go that route. That said, there is value in having things *just work* and I think we should keep that goal intact. Context would be opt-in, expose otherwise un-configurable state data (like tooltip timing), and solve some particularly tricky problems that users will likely run into as their app gets more complex.

### Potential use cases

- `Tooltip`: Similar to focus, tooltips are global in the sense that only one tooltip should be visible at a time. Interactions in other components will dictate whether or not tooltips are visible. Further, the delay timing for a tooltip to appear should be configurable, but preferably at the app level as a difference between instances would create a disjointed user experience. Context would likely simplify implementation of these and reduce the likelihood of bugs.
- `Announce`: Currently handled without context, but if we could potentially simplify implementation a bit by keeping announcements in a context tree. It could also be helpful to be able to read whatever is in the global live regions from other components. Not convinced at this stage we need it, but worth exploring if we decide to go this route with other components.
- `DismissableLayer`: I believe we'll keep this as an internal utility and avoid exposing it directly, but we could include a context provider for it in separate providers in the components that use it to simplify stacking. See https://github.com/modulz/interop-ui/pull/191#discussion_r499585862
- `FocusLock`/`FocusScope`: Still a WIP, but I imagine this could benefit greatly with global context as well
- `ScrollArea`: We need to disable pointer events everywhere except for the active scrollbar while a user is interacting with a scroll area. Unsure if context would be better than the current approach, but we could consider this. Also might be good for some props to be configurable globally similar to a the tooltip to encourage better user experiences (i.e., auto-hide timing)

### Implementation and usage

A `MenuButton` component may read `Tooltip` context but need not require `Tooltip` as a dependency. As such, we probably need to expose various contexts as a separate package. I don't think each context should be its own package necessarily, but we could have a `@interop-ui/react-context` package that exposes individual contexts as separate files so that they are tree shakable. Each context could export a provider and a hook with the necessary setters and getters that can be used anywhere in the tree. We would use these internally with default values so ensure components still work without context.

So for a consumer, this might look something like this:

```js
import * as React from 'react';
// import file directly for tree-shaking, but also exposed in an index file
import { TooltipProvider } from '@interop-ui/react-context/dist/tooltip';
import { DismissableLayerProvider } from '@interop-ui/react-context/dist/dismissable-layer';

function GlobalState({ children }) {
  return (
    <DismissableLayerProvider>
      <TooltipProvider appearanceDelay={400}>
        <SomeOtherProvider>{children}</SomeOtherProvider>
      </TooltipProvider>
    </DismissableLayerProvider>
  );
}

// Consuming:

import { useTooltipContext } from '@interop-ui/react-context/dist/tooltip';

function SomeComponent({ children }) {
  const { appearanceDelay } = useTooltipContext();
  React.useEffect(() => {
    // some effect that needs to sync with tooltip's delay for whatever reason
    window.setTimeout(() => {
      //...
    }, appearanceDelay);
    // ...
  }, [appearanceDelay])
  return (
    <div>
      {/* whatever */}
    </div>
  );
}
```",2020-10-07T13:14:52Z,2020-12-09T16:36:48Z,closed,12,"dark pattern or not, prevention of dark pattern in design, tooltip timing","delay prop, example of dp or not, discussion","tooltip timing, dark pattern discussion",DPs or not,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/microsoft/coyote/issues/52,Unreachable side menu on https://microsoft.github.io/coyote/,https://github.com/microsoft/coyote/issues/52,"On both Firefox and Edge, the left side menu is misplaced, sometimes to the point of either not appearing on the screen at all or being mostly unusable. Depending on the screen resolution and the content of the side menu, the menu position moves up and down.

This issue makes part of the documentation undiscoverable/unreachable for visitors if like me there are unlucky enough to hit the wrong browser/resolution combination.

Please see the screenshots below.

![Install page in Firefox](https://user-images.githubusercontent.com/24879810/93891122-5ada6e00-fceb-11ea-884a-39f7b627b49f.png)

![Learn page in Firefox](https://user-images.githubusercontent.com/24879810/93891269-8a897600-fceb-11ea-851a-943262c0cb8e.png)

![Case study page in Firefox-ff](https://user-images.githubusercontent.com/24879810/93891334-99702880-fceb-11ea-943e-39b19feec1a1.png)

![Learn page in Edge: the search box cannot be reached](https://user-images.githubusercontent.com/24879810/93891504-c58ba980-fceb-11ea-9694-6d8fba53a3b8.png)


As a side note: on the last screenshot, notice the UI dark pattern to nudge users to accept all cookies, in particular the lack of a ""Decline all"" button to complement the ""Accept all"" button. It gets even worse if you click the ""Manage cookies"" button. This kind of pattern is understandable (although ethically questionable) on website depending on third-party tracking to monetize, but it is rather puzzling to see that on a Microsoft funded software project documentation page. I'd be grateful if you provide this feedback to whomever can influence that decision.",2020-09-22T14:06:40Z,2020-10-01T20:33:26Z,closed,4,"Coyote, usage of dark pattern in software, privacy statement, cookie consent, ""accept all"" button, lack of ""decline all"" button","menu not reachable, cookie ""accept all"", less options, obstruction, forced action","Coyote, privacy issue, cookie consent, forced action",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/brave/brave-ios/issues/2940,"make the ""X"" more visible on the VPN modal under ""Settings""",https://github.com/brave/brave-ios/issues/2940,"<!-- Have you searched for similar issues on the repository?
Before submitting this issue, please visit our wiki for common ones: https://github.com/brave/browser-ios/wiki
For more, check out our community site: https://community.brave.com/ -->

### Description: 

When using the light theme, the `X` on the `VPN` modal via `Settings` is hard to see and could be perceived as a dark pattern re: making it harder to see on purpose.

### Steps to Reproduce

  1. install `1.21 (20.10.6.20)` from TF (release channel) using the light theme
  2. go into `Settings`

**Actual result:** <!-- Add screenshots if needed -->

<img width=""508"" alt=""Screen Shot 2020-10-06 at 8 31 02 PM"" src=""https://user-images.githubusercontent.com/2602313/95306227-20c5ac00-0855-11eb-96ce-2a717136faf8.png"">

**Expected result:**

<img width=""459"" alt=""Screen Shot 2020-10-06 at 8 33 39 PM"" src=""https://user-images.githubusercontent.com/2602313/95306243-24f1c980-0855-11eb-952c-dc67af60ff59.png"">

**Reproduces how often:** [Easily reproduced, Intermittent Issue]

100% reproducible using the STR mentioned above.

**Brave Version:** <!-- Provide full details Eg: v1.4.2(17.09.08.16) -->

* `1.21 (20.10.6.20)`

**Device details:** <!-- Model type and iOS version Eg: iPhone 6s+ (iOS 10.3.3)-->

* Reproducible on all devices using `light` theme.

**Website problems only:**

- did you check with Brave Shields down? `N/A`
- did you check in Safari/Firefox (WkWebView-based browsers)? `N/A`

### Additional Information

CCing @jamesmudgett @aekeus @srirambv @bsclifton @iccub ",2020-10-07T08:28:04Z,2020-10-09T13:14:17Z,closed,1,"Brace Firewall, VPN, prevention of dark pattern in UI design, no visual interference, clear X button","VPN, settings, hard to see x to cancel modal, design hierarchy","Brace Firewall, VPN, modal, deceptive design practices, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/microsoft/PowerToys/issues/1915,[Launcher] allow use of signal words,https://github.com/microsoft/PowerToys/issues/1915,"We could integrate a function for signal words like in windows search. So the user enter `signalWord: abc` and the app knows for what the user is searching for.

signal words can be:
- window : search for window including browser tabs
- browser : search for browser tab
- app : user want to start apps
- file : search for file or folder
- cmd : to run command on cmd/ps/...
- calc : to calculate math formula
- ...
",2020-04-03T13:59:42Z,2020-10-21T04:12:46Z,closed,7,"Microsoft PowerToys, signal words, deceptive design practices","signal word, suggestions open","Microsoft PowerToys, signal words, deceptive design practices",DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/MetaMask/metamask-extension/issues/9136,Confirmation warnings can appear clipped below the scrollable area,https://github.com/MetaMask/metamask-extension/issues/9136,"On the transaction confirmation screen, we have an area where we render warnings, like ""This transaction will likely run out of gas"".

That area is currently at the bottom of the TX details view, which is scrollable, and prioritizes the ""Confirmation"" button, which is fixed at the bottom of the view.

This means relevant information can be missed by the user who does not scroll, while the confirm button remains prominent.

Possible mitigations (some can combine):
- Add the confirm/cancel buttons to the scrollable region, so they cannot be clicked until all details have been seen.
- Move the warning message to the top of the confirmation view
- Disable the `Confirm` button until scrolling to the bottom, in the style of common terms & conditions views (maybe a ""dark pattern"", as it may encourage not reading closely).

@rachelcope ",2020-08-04T16:52:22Z,2020-08-18T14:10:57Z,closed,1,"MetaMask, good usage of ""dark pattern"" in design, disable the Confirm button until scrolling to the bottom to 'force' useres to read ","""confirm"" button at the butto, so users don't read carefullky, design hierarchy, manipulation","MetaMask, dark pattern to promote good behavior, terms and conditions",DPs in design coding,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mozilla/glean/issues/1049,Setup the Python environment for generating Python documentation,https://github.com/mozilla/glean/pull/1049,"[doc only]

We skip the tests if a patch set is doc-only, but we still need the
environment around to generate docs.
The test and doc tasks don't _need_ to depend on each other.",2020-07-10T13:27:10Z,2020-07-10T13:40:44Z,closed,2,,"Python document, import/not parse",,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/skeleton0/nordvpn-update/issues/1,Is such service worth the cost?,https://github.com/skeleton0/nordvpn-update/issues/1,Do you have this on 24/7?,2020-07-21T01:42:36Z,2020-07-29T06:38:59Z,closed,3,"NordVPN, usage of dark pattern in software","VPN websites, paid, usually have dp","NordVPN, examples",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/electron/electron/issues/22404,feat: MessagePorts in the main process,https://github.com/electron/electron/pull/22404,"#### Description of Change

This adds a new IPC primitive to Electron based on [MessageChannel][], the DOM primitive. MessageChannel already worked fine in the renderer process, and between renderer processes opened through `window.open` (when `nativeWindowOpen` or `sandbox` is enabled). This change allows passing `MessagePort`s from renderer to the main process. From there, the ports can be forwarded on to other renderers, which wouldn't otherwise necessarily be able to communicate with one another.

Communication over `MessagePort` between two renderer processes is not proxied through the main process. (Caveat: if messages are sent on the port before the other end of it is fully set up in the target renderer, those messages may be queued in the main process until the channel is ready.)

Initial proposal: https://hackmd.io/bwzFRWZzRIyewIBc1Vf7DQ?both

This change adds some new APIs:
#### `ipcRenderer.postMessage(channel, message, [options])`

This is similar to the existing `ipcRenderer.send`, with two key differences. First, you can only send a single argument, as opposed to `ipcRenderer.send` which forwards all arguments after the channel name. Secondly, the 3rd argument is an array of ""transferable objects"", i.e. `MessagePort`s. To send a `MessagePort` to the main process, you must _transfer_ it by passing it in the 3rd argument of `postMessage`, like so:

```js
const {port1, port2} = new MessageChannel
ipcRenderer.postMessage(""my-message"", {some: ""message""}, [port1])
```

This is intentionally similar to [`window.postMessage`](https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage).

Currently, the only kind of transferable object that may be passed in the transfer list is `MessagePort`. In future, more kinds of transferable objects such as `SharedArrayBuffer` may be supported.

TODO: currently this function only accepts an array, but we should match `Window.postMessage` and also accept an object of the form `{transfer: [...]}`.

#### `WebContents.postMessage(channel, message, [options])`

This is the same as `ipcRenderer.postMessage` but going in the other direction, from main to renderer.

#### `MessagePortMain`

As the JS context in the main process in Electron is not a Blink context, we do not have access to Blink's implementation of `MessagePort`. Thus, we provide a polyfill, which communicates over the same underlying Mojo pipe.

This has a similar API to [MessagePort][], but instead of `port.addEventListener('message', ...)` or `port.onmessage = ...`, we adopt the Node.js convention and offer the EventEmitter-style `port.on('message', ...)`.

This object can be passed as a transferable to `WebContents.postMessage` in order to transfer ownership of the message port to a renderer.

---

[MessageChannel]: https://developer.mozilla.org/en-US/docs/Web/API/MessageChannel
[MessagePort]: https://developer.mozilla.org/en-US/docs/Web/API/MessagePort

#### Checklist
<!-- Remove items that do not apply. For completed items, change [ ] to [x]. -->

- [x] PR description included and stakeholders cc'd
- [x] `npm test` passes
- [x] tests are [changed or added](https://github.com/electron/electron/blob/master/docs/development/testing.md)
- [x] relevant documentation is changed or added
- [x] PR title follows semantic [commit guidelines](https://github.com/electron/electron/blob/master/docs/development/pull-requests.md#commit-message-guidelines)
- [x] [PR release notes](https://github.com/electron/clerk/blob/master/README.md) describe the change in a way relevant to app developers, and are [capitalized, punctuated, and past tense](https://github.com/electron/clerk/blob/master/README.md#examples).

#### Release Notes

Notes: Added support for `MessagePort` in the main process.",2020-02-27T00:14:18Z,2020-12-21T16:14:22Z,closed,30,"miscellaneous (insecure coding practices, dark pattern in coding, exposing 'ipcRenderer', security of Electron applications)","ContextBridge, StackOverfkow, example","ContextBridge, StackOverfkow, insecure coding practices",DPs in design coding,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/tock/tock/issues/2047,Virtual ADC support,https://github.com/tock/tock/pull/2047,"### Pull Request Overview

This pull request adds support for virtual ADC. It allows using a virtual ADC from a capsule and also provides a virtual ADC for the User Space.

The syscall interface mimics the existing ADC syscalls, so no changes are needed in the User Space.

For now, the virtual ADC supports only single sample requests.

This PR adds a support for the STM integrated ADC MCU temperature sensor.

### Testing Strategy

This pull request was tested using STM32F3discovery and STM32F412G-discovery

### TODO or Help Wanted

N/A

### Documentation Updated

- [X] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [X] Ran `make prepush`.
",2020-07-28T16:07:22Z,2020-09-25T00:15:50Z,closed,14,miscellaneous,"ADC, simultaneous access for userspace and capsule",,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/godotengine/godot-docs/issues/3435,No way to go back to the main website after visiting the documentation,https://github.com/godotengine/godot-docs/issues/3435,"**Operating system, Browser, Browser Version:**
All

**Issue description:**
After navigating to https://docs.godotengine.org (i.e. the ""Learn"" link), there is no way to get to the main project site pages:

- https://godotengine.org/
- https://godotengine.org/news
- https://godotengine.org/community
- https://godotengine.org/contact

Reference:
https://www.darkpatterns.org/types-of-dark-pattern/roach-motel
",2020-04-24T04:40:09Z,2020-04-26T00:40:01Z,closed,0,"GoDot Docs, usage of dark pattern in software, no way to go back",,"GoDot Docs, deceptive design practices, example",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/gatsbyjs/gatsby/issues/24388,issue with Typescript file in gatsby-starter-default,https://github.com/gatsbyjs/gatsby/issues/24388,"## Summary

In Gatsby-starter-default, one of the pages is a TSX file: [src/pages/page-2.tsx](https://github.com/gatsbyjs/gatsby/blob/master/starters/default/src/pages/page-2.tsx)

This feels like a dark pattern. Although yes I believe it is good to tell people you can now use Typescript in Gatsby natively, the default starter may not be a good place for this to exist. if you type in 

```
gatsby new
```

and spin up a new Gatsby site, now there is Typescript files in there by default which could cause some confusion, as the file states `// Gatsby supports TypeScript natively!` at the top of it, but doesn't link anywhere or discuss the ramifications of what that means.

Instead, maybe have a possibility of an official gatsby-starter-default-typescript that core maintains. or link to a page in the gatsby docs to see what ""Native Typescript in Gatsby"" means.

cc: @blainekasten",2020-05-23T14:48:49Z,2020-05-28T13:59:10Z,closed,2,unsure,"gatsby-starter-default, typescript, forced action, preselection","gatsby-starter-default, typescript, preselection",DPs in design coding ,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/servo/servo/issues/26262,Consider making the duplicate package check optional,https://github.com/servo/servo/issues/26262,"From my current understanding, I think the duplicate package check of servo tidy (#7133, #14695, #19306) is _today_ rather a dark pattern that could prevent fixing regular and security bugs (https://github.com/servo/servo/issues/15989#issuecomment-617670889). Dependabot removes duplicates by upgrading all dependencies step by step. I think this check should be changed into an optional command that can be run manually if one wants to notify external repositories like surfman and gfx-rs to keep their dependencies up to date - as long as they haven't adopted dependabot as well.  It is used all across Mozilla and will become a built-in feature of GitHub: https://github.com/pulls?q=is%3Apr+author%3Aapp%2Fdependabot-preview+org%3Amozilla
",2020-04-22T11:59:48Z,2020-05-18T11:55:37Z,closed,4,,"servo tidy, duplicate package not optional, preselection",,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/decidim/decidim/issues/5973,Submit a vote,https://github.com/decidim/decidim/issues/5973,"ref: S-US.02

As a participant I want to vote for candidates during an election, according to the criteria and limitations established in the participation space.

![](https://i.imgur.com/cH0FeSN.png)
![](https://i.imgur.com/jTgXqam.png)
![](https://i.imgur.com/9rNWQM7.png)
![](https://i.imgur.com/UJc5MQK.png)
![](https://i.imgur.com/7xBPzKL.png)

### Alternatives 

As this issue could be potentially huge, we're limiting it to only **one** kind of interface, the ""checkboxes interface"" as it's the one more versatile. That means that the ""buttons interface"" or the ""radios interfaces"" are out of the scope for the moment: 

![](https://i.imgur.com/amhdrgC.png)
![](https://i.imgur.com/9wQNQuH.png)


### Related issues

* #6196 

### About NOTA (None of the above)

Some elections can have an option called ""None of the above"" (NOTA), also known as ""voto en blanco"" or ""blank ballot"" in Spanish. As far as we know, given the current interface we could implement it on several ways:
1. By having another button on ""Back"" / ""Next"" bar
2. By not selecting an option, but we should at least give a modal for confirming that's an option (as nvotes/agoravoting already does)
3. By having an explicit option configured by default
4. By having documentation on the admin Elections configuration panel explaining that she should make it an explicit option

On Decidim we prefer that this particular decision should be explicit (3rd or 4th options) and as the rest of the software should be an admin decision (4th option). We don't want to apply Dark Patterns here.

More information on [None of the above](https://en.wikipedia.org/wiki/None_of_the_above)

### Acceptance criteria

- [x] As a participant I can't vote before the election is open 
- [x] As a participant I can vote while the election is open 
- [x] As a participant I can't vote after the election is closed 
- [x] As a participant I can see a modal with the metadata for that answer (title, summary, description, image, related proposals) without leaving the voting process
- [x] As a participant I can see how many answers I've selected if there's more than one possible answers
- [x] As a participant before confirming my vote I can edit my answers 
- [x] As a participant before confirming I can select the question that I want to change
- [x] As a participant the vote is ""submitted"" when I can see a JSON object on the web dev console tools (with console.log or similar)
- [x] **Given that** I'm a participant 
      **When** there's only a possible answer
      **Then** I see inputs of type ""radio""
- [x] **Given that** I'm a participant 
      **When** there's more than one possible answer
      **Then** I see inputs of type ""checkbox""
- [x] **Given** that I'm a participant 
      **When** the question has configured the option ""random_answers_order""
      **Then** I see the answers of the question randomized.
- [x] **Given** that I'm a participant 
      **When** there's an answer A with weight 20 
      **and** another answer B with weight 10 
      **Then** I see the answer B before the A. ",2020-04-15T08:42:31Z,2020-07-31T12:02:32Z,closed,7,prevention of dark pattern in UI design,"Decidim, having options for users to decide","Decidim, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/forkcms/forkcms/issues/3048,Consent dialog,https://github.com/forkcms/forkcms/pull/3048,"## Type
- Enhancement
- Feature

## Pull request description

This PR enables developers to build GDPR compliant websites. GDPR affects all
website owners that target EU citizens.

In essence it will show a visitor a dialog wherein they can select their privacy
preferences. For example:

![Example of the consent dialog](https://testing.verkoyen.eu/forkcms/consent-dialog/preview_consent_dialog.png)

The preferences are stored in **functional** cookies so they are remembered.

**IMPORTANT**: it is still the responsibility of the developer/marketeer to
respect the visitors choices. Fork gives you the ability to do so.

### Configuration of the consent dialog

In the backend under ""Settings"" there is a new block which allows you to define
different privacy levels. You can add as many as needed. A visitor can agree to
each level separately.

![Configuration of the levels](https://testing.verkoyen.eu/forkcms/consent-dialog/configuration_of_levels.png)

For each level you need to add 2 translations, these translations will be used
in the consent dialog.

* Title, this is used as the label for the checkbox
* Text, this is used as a description for the level. As GDPR states a user needs
to make an informed disscision, so in the description you can describe what the
level means an how you will use the visitors agreement.

The reference code/name of the translation uses the level like explained below:

    {{ ('msg.PrivacyConsentLevel' ~ level|ucfirst ~ 'Title')|trans|raw }}
    {{ ('msg.PrivacyConsentLevel' ~ level|ucfirst ~ 'Text')|trans|raw }}

So for instance if you define the level ""statistics"" you will need to add 2
translations with the names:

* `PrivacyConsentLevelStatisticsTitle`
* `PrivacyConsentLevelStatisticsText`

<small>Remark: If you change the levels the consent dialog will be shown again
to all visitors. Previous choices will not be ticked.</small>

**There is one level that is always available: `functional`, this is always
allowed.** The user can not change this. It is added as it is a good practice to
explain your visitor what you store in these cookies.

### Usage

#### Retrieving choices in JavaScript
The choices of the visitor are available in `jsData` in the `privacyConsent`-object.

* `possibleLevels` contains all the levels that are defined thru the CMS.
* `levelsHash`, this is the hash that is used to determine if the levels are changed.
* `visitorChoices`, this contains the choice a user has made per level. The default is false.

#### Retrieving choices in PHP
A new service is available as `ForkCMS\Privacy\ConsentDialog`. This service
exposes some methods that you can use:

* `getLevels(bool $includeFunctional = false)`, this will return all the defined levels.
* `getVisitorChoices()`: returns an array with the users chosen preferences
* `hasAgreedTo(string $level)`: returns a boolean if the user has agreed to a given level. Returns false per default, also for non existing levels.

So for example if you want to do personalations if the user has agreed to the
`personalisation`-level, you can use the snippet below:

    if ($this->getContainer()->get(ForkCMS\Privacy\ConsentDialog::class)->hasAgreedTo('personalisation')) {
        ... your code ...
    }

#### Anonymize IP
Google Analytics has a feature called anonymizeIp. If you use our Google Analytics-
or Google Tag Manager integration we use the anonymizeIp feature by default.

In this case you need to add a privacy level with the name `statistics`. If you do
so, and the visitor agrees to it we will disable the IP anonymization.

<small>**Warning**: In Belgium this is not correct. The DPA decided that anonymizeIp
is not enough, therefor you should ask permission before tracking! See below how you
can achieve this.</small>

#### Google Tag Manager
If you use Google Tag Manager it is completely up to you to adhere the visitors
preferences. Below is explained on how it can be configured.

##### Create a variables
* Open Variables
* Click ""New"" next to ""User-Defined Variables""
* Name it ""Privacy Consent - DataLayer - Level XXX"", eg: Privacy Consent - DataLayer - Level statistics
* Choose ""Data Layer Variable"" for the type
* Use ""privacyConsentLevelXXXAgreed"" as the value for ""Data Layer Variable Name"", replace XXX with the ucfirst version of you level name
* Enable ""Set Default Value"", and set the Default Value to ""false""

![Example configuration for data layer variables](https://testing.verkoyen.eu/forkcms/consent-dialog/gtm_variable_configuration.png)

Do this for all the levels you defined.

##### Create triggers
* Open Triggers
* Click ""New""
* Name it ""Privacy Consent - Check - Level XXX not allowed"", eg: Privacy Consent - Check - Level statistics not allowed
* Choose ""Custom event"" for the Trigger Type
* Use "".*"" as Event name, and tick ""Use regex matching""
* Select ""Some custom Events""
* Select the relevant variable, something like DataLayer - Privacy Consent - Level XXX""
* Choose ""Equals"" as the condition and ""false"" as the value

![Not allowed trigger configuration](https://testing.verkoyen.eu/forkcms/consent-dialog/gtm_trigger_not_allowed_configuration.png)

* Click ""New""
* Name it ""Privacy Consent - Event - Level XXX - Agreed"", eg: Privacy Consent - Event - Level statistics - Agreed
* Choose ""Custom event"" for the Trigger Type
* Use ""privacyConsentLevelXXXAgreed"" as Event name, replace XXX with the ucfirst name of your level name
* Select ""All Custom Events""

![Event trigger configuration](https://testing.verkoyen.eu/forkcms/consent-dialog/gtm_trigger_event_configuration.png)

Repeat these steps for each level you have defined

##### Load a tag only when it is allowed
* Open the tag you want to configure. For instance Hotjar
* Edit the triggers
* Add ""Privacy Consent - Event - Level XXX - Agreed"" on the Firing Triggers. This will add the tag if the user agrees.
* Add ""Privacy Consent - Check - Level XXX not allowed"" on the Exceptions. This will prevent the tag from loading when the user did not agree.

![Tag configuration](https://testing.verkoyen.eu/forkcms/consent-dialog/gtm_tag_configuration.png)

By adding the exception the Tag won't be fired. This is the case when a visitor
has not agreed to anything. In that case the consent dialog is shown.
When the visitor clicks ""Save my preferences"", we will fire an event per agreed
level: `privacyConsentLevelXXXAgreed`. This will fire the tag, as it is configured
as a Firing trigger.

If the visitor visits another page the exception won't be triggered as the variable
is true. So the tag will be fired by the ""All Pages"" trigger.

### Removed features
Adding new features also means cleaning up non relevant features, so some are removed:

### Cookie bar
This new Consent Dialog replaces the previous Cookie Bar.

This means you can't use the following methods anymore:

* `$this->get('fork.cookie')->hasAllowedCookies()`
* `$this->get('fork.cookie')->hasHiddenCookieBar()`

### Visitor Id
The visitor Id that was generated and stored in a cookie does not exist anymore.
If you rely on it you should build this feature yourself.",2020-02-26T11:50:58Z,2020-08-17T20:00:39Z,closed,11,"prevention of dark pattern in software, consent dialog design, no ""accept all"" buttin","consent, ""accept all"", manipulation","cookie consent, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/arkadiyt/zoom-redirector/issues/6,No video / audio in Firefox,https://github.com/arkadiyt/zoom-redirector/issues/6,"Thank you so much for making this addon to work around this dark pattern!

Obviously this issue is not about your browser extension per se but rather about the Zoom web client as it doesn't appear to work in Firefox (apart from the text-based chat):

> Your browser does not support using the computer’s Audio device. To use Zoom, install the latest version of a standard browser, such as Chrome.

Since this extension is [available for Firefox](https://addons.mozilla.org/en-US/firefox/addon/zoom-redirector/), I am wondering whether there's something I am missing, like another work-around to enable video and audio?",2020-03-24T10:38:50Z,2020-04-01T12:54:24Z,closed,4,"prevention of dark pattern, addon to remove the DP, Zoom, permission to audio/video",Firefox audio/video issue,"Zoom, permission for audio/video, addon, UI/UX design, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/brave/brave-browser/issues/10200,Ability to disable all ads whatsoever in Brave UI,https://github.com/brave/brave-browser/issues/10200,"Hello!

There is people who do not want to suffer the psychological harassement that ads are in any circumstance. Especially when one does install a web browser like Brave that has a builtin ad blocker.

Brave Web Browser is like an ""ungoogled chromium"" with better distribution on all platforms. On Android for example, it's one Chromium-based browser with ad blocking because Chrome on Android does not support extensions. There is reasons you would want to use Chromium-based browsers instead of Firefox because they have better performance.

Some people are not interested *at all* by the ads or earning rewards through ads, they just want the psychological harassement of ads to stop immediatly.

Yesterday I found that I now had crypto currency related ads in my ""New Tab"" pages, and I found no way to disable them in settings.

Thank you",2020-06-10T07:07:45Z,2020-08-07T16:49:47Z,closed,14,"Brave Browser, prevention of dark pattern in design, all button equal, ","ads, design hierarchy, manipuation","Brave, ads, UI/UX design, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/18F/handbook/issues/1784,Google Drive permission error w/ Cloudlock: Rules of Behavior,https://github.com/18F/handbook/issues/1784,"In the [logging in and networks](https://handbook.tts.gsa.gov/equipment/) page it says:

> Applications such as Trello, Zoom, Favro, and Circle.ci can be logged into using your GSA Google account. Just make sure that you don’t grant Google access to anything beyond basic data; “Basic Info” or “Limited Access to Data and Files” are both approved options that are considered basic data.

But people are still providing access to other things such as Google Drive which is causing GSA IT Security CloudLock to active and not allow other TTS employees to login using their GSA Google Accounts.

I suggest we create a specific, TTS Organizational Rules of Behavior, so that people who have Trello boards acknowledge that they are not supposed connect their Google Drive accounts as a Power Up. ",2020-01-24T02:44:26Z,2020-04-22T22:40:14Z,closed,3,"usage of dark pattern in 3rd parties, Google Drive permission errors","third party SAAS, sign in, forced action","third party, SAAS, Google Drive permissions, forced action",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/lightswitch05/hosts/issues/206,Unblock Algolia domains,https://github.com/lightswitch05/hosts/issues/206,"First, thank you for your work! I'm a happy user of your list myself in my Pi-Hole ;)

I've found a few domains that impact the day-to-day work of my team and I'm eager to get your feedback on how to avoid that further. Full disclaimer, I work at Algolia and privacy+security is big part of my work there.

The domains in question are:
- analytics.algolia.com - Analytics service used from backend
- analytics.de.algolia.com - Analytics service used from backend
- analytics.us.algolia.com - Analytics service used from backend
- recommendation.algolia.com - Recommendation service used from backend
- insights.algolia.io - Insights service used from backend and frontend
- telemetry.algolia.com - Performance data collection used from frontend

On a very high level, we provide a hosted search platform to our customers. The primary product is our search API which gets search requests and produces search responses. The ecosystem is accompanied by various other services like Analytics, Recommendation, Insights, Telemetry. Outside of our community projects (like [docSearch](https://docsearch.algolia.com/), we don't runs services where visitors of the website would be our users. Thanks to this we have no interest in user tracking, fingerprinting or anyhow following our users around the web. Considering that Algolia is used on tens of thousands of websites around the world, it would be pretty terrifying to track all the users (and I would have a very hard time sleeping at night). For our systems to work, we're more than comfortable with anonymous identifiers like DB id, UUID and similar, which are provided to us by our customers, but not by us to the customers. (Interestingly, some of them expect us to do it for them and we then explain that we're not doing and won't be doing it)

Considering the reach that Algolia has, we're also strict on not mixing data between customers. Whenever a service is provided to a customer, it's for them, their data and their results. Our customers don't get access to data of other customers and cannot benefit from the data itself. Which means that if you visit two different websites using Algolia, we won't be able to say that you're the same user and the website won't know (from us) that you're the same user.

Some of the services look indeed scary. Our Analytics carries the same name as all-time-largest tracker Google Analytics while the only thing that our Analytics does is to provide an API of top of the application logs helping our customers identify what are their users searching for. The reason why there are multiple domains is because of data locality, allowing us to process data end-to-end in EU or US, without the data crossing the border. [Analytics details](https://www.algolia.com/doc/guides/getting-insights-and-analytics/search-analytics/out-of-the-box-analytics/)

The other scary service is Recommendation, which looks like ads targeting platform where we tell you what you're looking for based on your overall preferences. That is true (if it's enabled), except that the dataset considered is only the website you're on. This makes it more similar to ""search history"" and ""autocomplete"" rather than "" I know what will be your next search query because of your last 30 minutes of web activity"". [Personalization details](https://www.algolia.com/doc/guides/getting-insights-and-analytics/personalization/what-is-personalization/)

Our Insights service then primarily powers search relevancy feedback and A/B testing. Since search is a hard and unsolved problem, this feedback loop helps our customers improve the relevancy of their search results. All that still without tracking across the web. [Insights details](https://www.algolia.com/doc/guides/getting-insights-and-analytics/leveraging-analytics-data/ab-testing/)

The last one on the list is Telemetry. Here we definitely failed in communication and explanation during our first attempts to better understand end-user experience. Since we operate hundreds of endpoints around the world across many data-centres and providers we wanted to find a way to get insights into the real performance, not just what we see on our side. With the rebuild of the system, we've created a [transparency page for our Telemetry project](https://telemetry.algolia.com/) where we explain what we store, what we do with the data and why. We still don't store tracking cooking and we truncate the IPs, since we still have no use for such precise data and /24 is enough. Thanks to this data we're already helping our providers better understand their network performance and improve peering, thus helping all their customers. I’m aware that we’re getting into dangerous waters here and that’s exactly why we’re trying to make it as privacy preserving as possible.

All in all, I wanted to bring this to your attention. I’m very open to feedback about what we can do better on our side because as I mentioned, we have no desire to track people around the Internet. If possible, it would be great to remove the Algolia domains from the list as they're neither serving ads nor tracking.",2020-07-27T12:37:43Z,2020-08-05T13:47:14Z,closed,3,"miscellaneous (A/B tests to optimize dark patterns, usage of dark patterns)","Algolia domains, A&B tests, user experience",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Cookie-AutoDelete/Cookie-AutoDelete/issues/647,[SUPPORT]  Is there a noob's guide to what this actually does (from a user experience perspective) anywhere?,https://github.com/Cookie-AutoDelete/Cookie-AutoDelete/issues/647,"Hi; I'm on here because I couldn't find this info or any other way of contacting the developers. 

I'm interested in this add-on because it's firefox-approved and sounds good, but I'm struggling to find a low/no-context explanation of what it does. 

Specifically, I think my issue is that I don't know what is meant by 'cookies that aren't being used.' 

If what this means is that it will delete cookies that end up on my computer that don't benefit me, and are only there because a combination of dark patterns and my exhausted ADD brain means that I can't always track down or work out exactly what I need to click to make that not happen, then that sounds great.

But (see aforementioned exhausted ADD brain) I am less interested in something that will go around deleting time-saving cookies (I think it's cookies?) that do things like 'mean I don't have to type in my username every time I want to log in to a site'. 

So what I'm looking for, I guess, is how getting this add-on would actually affect my experience as a web user. If there's a simple way to configure it to do the former thing but not the latter, that would be even better.",2020-03-11T09:37:11Z,2020-03-15T21:33:54Z,closed,2,"cookie consent, add-on to manage cookies","extension for cookies, config needed, helps with consent","cookie consent, add-on, extension, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Blackmill/book-club/issues/73,"Nudge: chapters 2, 3, & 4: July 7",https://github.com/Blackmill/book-club/issues/73,"Nudge: Improving Decisions About Health, Wealth, and Happiness
by Richard H. Thaler, Cass R. Sunstein

https://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness-ebook/dp/B00A5DCALY/

Aiming to read:

Chapter 2: Resisting Temptation
Chapter 3: Following the Herd
Chapter 4: When Do We Need a Nudge?

MC: @antoinemacia 
Notes: @HashNotAdam
See you 12 pm Tuesday, July 7th @ https://whereby.com/blackmill

Ping gday@blackmill.co if you want a calendar invite and access to the low-volume Slack beforehand",2020-06-30T05:03:25Z,2020-07-11T07:31:08Z,closed,2,"miscellaneous (Dark pattern, Nudge discussion)",,miscellaneous,miscellaneous,Nudge discussion,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/meatstuff/itstuff/issues/36,Link dump - February 2020,https://github.com/meatstuff/itstuff/issues/36,"# SECURITY / LAW
- [ ] https://www.nytimes.com/2019/12/03/business/china-dna-uighurs-xinjiang.html
- [ ] https://www.fastcompany.com/90440198/san-diegos-massive-7-year-experiment-with-facial-recognition-technology-appears-to-be-a-flop
- [ ] https://nakedsecurity.sophos.com/2020/01/22/big-microsoft-data-breach-250-million-records-exposed/
- [ ] https://www.telegraph.co.uk/news/2020/01/16/tech-companies-launch-legal-action-force-government-bring-18s/
- [x] https://thenextweb.com/artificial-intelligence/2020/01/28/amazon-engineer-ring-should-be-shut-down-immediately-and-not-brought-back/
- [ ] https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/

# LOLWHA
- [ ] https://torrentfreak.com/replica-store-sells-cheap-knock-off-of-e890-pirate-bay-hoodie-200111/
- [ ] Ethical ad blocking https://scroll.com/
- [ ] https://arstechnica.com/gadgets/2020/01/cbs-all-access-serves-ads-but-not-content-to-linux-users/
- [ ] No more keyboards, Long live Blackberry? https://www.bbc.co.uk/news/technology-51358049
- [ ] If only web pages existed this would not be a problem https://www.businessinsider.com/what-we-know-about-app-iowa-caucuses-into-chaos-2020-2

# ECO
- [ ] Microsoft makes 'carbon negative' pledge https://www.bbc.co.uk/news/technology-51133811
- [ ] https://www.theguardian.com/commentisfree/2020/jan/17/selfless-billionaires-earth-burning-elon-musk-mars
- [ ] https://www.creativeboom.com/inspiration/aerial-photographs-of-led-lit-greenhouses-in-the-netherlands/

# MUSIC
- [ ] https://hackaday.com/2020/01/19/play-that-funky-3d-printer/
- [x] The Picard Song https://www.youtube.com/watch?v=gXB84fpWzg8
- [x] https://www.theregister.co.uk/2020/01/31/elon_dont_doubt_ur_vibe/
- [x] https://www.theguardian.com/music/2020/jan/31/elon-musk-edm-artist-first-track-dont-doubt-ur-vibe

# AI
- [ ] https://www.technollama.co.uk/chinese-court-rules-that-ai-article-has-copyright
- [x] https://www.theregister.co.uk/2020/01/27/google_world_economic_forum/
- [ ] https://www.theregister.co.uk/2020/01/30/facebook_illinois_settlement/

# HAX
- [ ] https://www.theguardian.com/technology/2020/jan/21/amazon-boss-jeff-bezoss-phone-hacked-by-saudi-crown-prince
- [ ] https://twitter.com/johnny_makes/status/1218668895655079936 ""Why Google's new search results design is a dark pattern""
- [ ] https://www.vice.com/en_us/article/qjdkq7/avast-antivirus-sells-user-browsing-data-investigation
- [ ] https://www.theregister.co.uk/2020/01/29/canadian_insurer_paid_ransomware_hunt/
- [x] https://www.theregister.co.uk/2020/02/03/google_maps_hack_cartful_phones/

# WORLD OF STUFF
- [x] New x86s https://hackaday.com/2020/02/04/china-x86-chips-hitting-the-market/",2020-02-03T23:40:28Z,2020-04-08T09:48:54Z,closed,1,"miscellaneous (twitter post, Google search results dark pattern discussion)","Google's search is dp, Twitter post, example","Google, search engine, Twitter post, discussion",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/liferay-design/liferay.design/issues/674,Fix Broken Links,https://github.com/liferay-design/liferay.design/issues/674,"A number of the 'View in Clay' links I've come across have been broken...but the pattern looks predictable — as far as I can tell, we need to add `v2.` as a prefix, and they've changed from `_` to `-` in their urls.

See [Bar Chart's](https://liferay.design/lexicon/core-components/charts/chart-stacked-bar/) for example.

(Updated to include broken links across the site — full table below, checklist to track in the comments)

||||||
|--- |--- |--- |--- |--- |
|#|link|Link Text|Page where found|Server response|
|1|https://www.liferay.com/404|404|https://liferay.design/articles/2019/increasing-our-ability-to-convert-prospects/|404|
|2|https://assets-liferaydotdesign.wedeploy.io|web assets repo|https://liferay.design/articles/2019/netlify-vs-zeit-vs-github-pages/|bad host|
|3|https://wedeploy.com/blog/discontinuing-wedeploy/|they were shuttering the service|https://liferay.design/articles/2019/netlify-vs-zeit-vs-github-pages/|404|
|4|https://help.figma.com/category/87-prototyping|documentation|https://liferay.design/articles/2019/how-to-use-any-clicker-with-figma-presentations/|404|
|5|htttp://www.lexicondesign.io|Design Systems|https://liferay.design/articles/2018/year-one-retrospective-cj/|bad url|
|6|https://www.radicalcandor.com/blog/tag/tip/|finer points of strong culture-building|https://liferay.design/articles/2018/new-team-assemble/|404|
|7|https://seths.blog/2018/04/missing-from-your-job-office/|Seth Godin’s list|https://liferay.design/careers/latam/product-designer/|404|
|8|http://www.terremoto.net/pv7|Programa Vostok|https://liferay.design/events/tramontana-presentation-sep-2019/|404|
|9|https://liferay.design/team/jeong-christopher|Christopher JeongSenior Product Designer||404|
|10|https://www.wallpaper.com/%5D|Wallpaper Magazine|https://liferay.design/team/pires-felipe/|404|
|11|https://help.figma.com/article/47-sharing-files-and-projects|see Figma’s documentation|https://liferay.design/handbook/tools/figma/|404|
|12|slack://user|#t-design-github|https://liferay.design/handbook/tools/github/introduction/|bad url|
|13|https://liferay.design/handbook/work/introduction|||404|
|14|https://www.uie.com/brainsparks/2011/10/27/moving-from-critical-review-to-critique/||https://liferay.design/handbook/collaborate/locally/critique/|404|
|15|https://liferay.design/lexicon/news/updates|||404|
|16|https://clayui.com/docs/layout/grid.html|View in Clay|https://liferay.design/lexicon/foundations/grid/|404|
|17|https://liferay.design/team/balbas-cassandra|Cassandra Balbas|https://liferay.design/articles/2018/81-days-of-liferay/|404|
|18|https://liferay.design/team/wood-jon/iempty.tooliphone.net|this site||404|
|19|https://liferay.design/articles/2019/updates-to-rotisserie|Paul&#x27;s blog entry|https://liferay.design/handbook/collaborate/locally/forum/|404|
|20|https://liferay.design/handbook/grow/transversal-skills|transversal skills|https://liferay.design/handbook/grow/introduction/|404|
|21|https://liferay.design/handbook/grow/product-design/introduction|See Product Design Skills|https://liferay.design/handbook/grow/introduction/|404|
|22|https://liferay.design/handbook/grow/transversal-skills/introduction|transversal skills|https://liferay.design/handbook/grow/career-paths/evaluations/|404|
|23|https://liferay.design/handbook/grow/transversal-skills/excellence|Go to all Excellence Milestones|https://liferay.design/handbook/grow/core-skills/|404|
|24|https://liferay.design/handbook/grow/transversal-skills/collaboration|Go to all Collaboration Milestones|https://liferay.design/handbook/grow/core-skills/|404|
|25|https://liferay.design/handbook/grow/transversal-skills/impact|Go to all Impact Milestones|https://liferay.design/handbook/grow/core-skills/|404|
|26|https://liferay.design/handbook/grow/transversal-skills/advocacy|Go to all Advocacy Milestones|https://liferay.design/handbook/grow/core-skills/|404|
|27|https://liferay.design/handbook/grow/transversal-skills/influence|Go to all Influence Milestones|https://liferay.design/handbook/grow/core-skills/|404|
|28|https://liferay.design/handbook/grow/communication-design/strategy|Go to all Strategy Milestones|https://liferay.design/handbook/grow/communication-design/|404|
|29|https://liferay.design/handbook/grow/communication-design/environmental|Go to all Environmental Milestones|https://liferay.design/handbook/grow/communication-design/|404|
|30|https://liferay.design/handbook/grow/communication-design/production|Go to all Production Milestones|https://liferay.design/handbook/grow/communication-design/|404|
|31|https://liferay.design/handbook/grow/communication-design/brand-identity|Go to all Brand Identity Milestones|https://liferay.design/handbook/grow/communication-design/|404|
|32|https://liferay.design/handbook/grow/communication-design/media|Go to all Media Milestones|https://liferay.design/handbook/grow/communication-design/|404|
|33|https://liferay.design/handbook/grow/product-design/strategy|Go to all Strategy Milestones|https://liferay.design/handbook/grow/product-design/|404|
|34|https://liferay.design/handbook/grow/product-design/research|Go to all Research Milestones|https://liferay.design/handbook/grow/product-design/|404|
|35|https://liferay.design/handbook/grow/product-design/interaction|Go to all Interaction Milestones|https://liferay.design/handbook/grow/product-design/|404|
|36|https://liferay.design/handbook/grow/product-design/visual|Go to all Visual Milestones|https://liferay.design/handbook/grow/product-design/|404|
|37|https://liferay.design/handbook/grow/product-design/engineering|Go to all Engineering Milestones|https://liferay.design/handbook/grow/product-design/|404|
|38|https://liferay.design/pull-requests|pull request guidelines|https://liferay.design/handbook/contribute/issues/|404|
|39|https://liferay.design/principles/Am%20I%20using%20the%20correct%20affordances%20to%20solve%20the%20problem?|affordances||404|
|40|https://clayui.com/docs/components/badges.html|View in Clay|https://liferay.design/lexicon/core-components/badges/|404|
|41|https://clayui.com/docs/components/cards.html|View in Clay|https://liferay.design/lexicon/core-components/cards/|404|
|42|https://clayui.com/docs/components/charts/basic/bar_chart.html|View in Clay|https://liferay.design/lexicon/core-components/charts/chart-bar/|404|
|43|https://clayui.com/docs/components/charts/basic/donut_chart.html|View in Clay|https://liferay.design/lexicon/core-components/charts/chart-doughnut/|404|
|44|https://clayui.com/docs/components/charts/advanced/predictive-forecasting.html|View in Clay|https://liferay.design/lexicon/core-components/charts/chart-forecast/|404|
|45|https://clayui.com/docs/components/charts/basic/pie_chart.html|View in Clay|https://liferay.design/lexicon/core-components/charts/chart-pie/|404|
|46|https://clayui.com/docs/components/dataset-display.html|View in Clay|https://liferay.design/lexicon/core-components/dataset-display/|404|
|47|https://clayui.com/docs/components/dropdowns.html|View in Clay|https://liferay.design/lexicon/core-components/dropdowns/|404|
|48|https://clayui.com/docs/components/forms/form-elements.html|View in Clay|https://liferay.design/lexicon/core-components/forms/|404|
|49|https://clayui.com/docs/components/forms/forms-hierarchy.html|View in Clay|https://liferay.design/lexicon/core-components/forms/forms-hierarchy/|404|
|50|https://clayui.com/docs/components/forms/forms-navigation.html|View in Clay|https://liferay.design/lexicon/core-components/forms/forms-navigation/|404|
|51|https://clayui.com/docs/components/forms/radio-check-toggle.html|View in Clay|https://liferay.design/lexicon/core-components/forms/radio-check-toggle/|404|
|52|https://clayui.com/docs/components/forms/multi-step-form.html|View in Clay|https://liferay.design/lexicon/core-components/forms/multi-step-form/|404|
|53|https://clayui.com/docs/components/forms/multi-step-form-simplified.html|View in Clay|https://liferay.design/lexicon/core-components/forms/multi-step-form-simplified/|404|
|54|https://clayui.com/docs/components/forms/selector.html|View in Clay|https://liferay.design/lexicon/core-components/forms/selector/|404|
|55|https://clayui.com/docs/components/forms/text-input.html|View in Clay|https://liferay.design/lexicon/core-components/forms/text-input/|404|
|56|https://clayui.com/docs/components/forms/text-input-group.html|View in Clay|https://liferay.design/lexicon/core-components/forms/text-input-group/|404|
|57|https://clayui.com/docs/components/forms/text-input-localizable.html|View in Clay|https://liferay.design/lexicon/core-components/forms/text-input-localizable/|404|
|58|https://clayui.com/docs/components/forms/text-input-variations.html|View in Clay|https://liferay.design/lexicon/core-components/forms/text-input-variations/|404|
|59|https://clayui.com/docs/components/icons.html|View in Clay|https://liferay.design/lexicon/core-components/icons/|404|
|60|https://clayui.com/docs/components/labels.html|View in Clay|https://liferay.design/lexicon/core-components/labels/|404|
|61|https://clayui.com/docs/components/modals.html|View in Clay|https://liferay.design/lexicon/core-components/modals/|404|
|62|https://clayui.com/docs/components/navigation/navbar.html|View in Clay|https://liferay.design/lexicon/core-components/navigation/horizontal-nav/|404|
|63|https://clayui.com/docs/components/popovers.html|View in Clay|https://liferay.design/lexicon/core-components/popovers-tooltips/|404|
|64|https://clayui.com/docs/components/progress-bars.html|View in Clay|https://liferay.design/lexicon/core-components/progress-bars/|404|
|65|https://clayui.com/docs/components/stickers.html|View in Clay|https://liferay.design/lexicon/core-components/stickers/|404|
|66|https://clayui.com/docs/components/table/table.html|View in Clay|https://liferay.design/lexicon/core-components/table/|404|
|67|https://clayui.com/docs/css-framework/satellites/timelines.html|View in Clay|https://liferay.design/lexicon/core-components/timelines/|404|
|68|https://clayui.com/docs/components/toolbars/management-toolbar.html|View in Clay|https://liferay.design/lexicon/core-components/toolbars/management-bar/|404|
|69|https://clayui.com/docs/css-framework/satellites/navigation/header.html|View in Clay|https://liferay.design/lexicon/satellite-components/navigation/control-bar/|404|
|70|https://clayui.com/docs/components/sidebar/info-panel.html|View in Clay|https://liferay.design/lexicon/satellite-components/sidebar/infopanel/|404|
|71|https://github.com/liferay-design/lexicon/issues|GitHub repo||404|
|72|https://liferay.design/articles/2019/gestalt-principles/|Gestalt Principles|https://liferay.design/articles/best-practices/measured-vs-optical-alignment/|404|
|73|https://liferay.design/articles/ethics-in-design|post on Ethics|https://liferay.design/articles/best-practices/dark-patterns/|404|
|74|https://liferay.design/team/kolodziej-karolina|Karolina Kolodziej|https://liferay.design/articles/best-practices/service-design/|404|
|75|https://liferay.design/web/guest/home/-/loop/people/_patrick.pentz|Patrick Pentz|https://liferay.design/articles/best-practices/illusion-of-completeness/|404|
|76|https://liferay.design/tags/ResearchAndDevelopment|#ResearchAndDevelopment|https://liferay.design/articles/best-practices/introducing-designbestpractices/|404|
|77|https://liferay.design/tags/Design|#Design|https://liferay.design/articles/best-practices/introducing-designbestpractices/|404|
|78|https://liferay.design/tags/VisualDesign|#VisualDesign|https://liferay.design/articles/best-practices/introducing-designbestpractices/|404|
|79|https://liferay.design/tags/InsideEngineering|#InsideEngineering|https://liferay.design/articles/best-practices/introducing-designbestpractices/|404|
|80|https://liferay.design/tags/BugbeeFeedback|#BugbeeFeedback|https://liferay.design/articles/best-practices/introducing-designbestpractices/|404|
|81|https://liferay.design/lexicon/core-components/chart-stacked-bar|Stacked Bar Chart|https://liferay.design/lexicon/core-components/charts/|404|
|82|https://liferay.design/lexicon/core-components/navigation/breadcrub.html|breadcrumb|https://liferay.design/lexicon/core-components/navigation/|404|
|83|https://liferay.design/lexicon/core-components/navigation/.vertical-nav.html|vertically|https://liferay.design/lexicon/core-components/navigation/|404|
|84|https://liferay.design/lexicon/core-components/navigation/.horizontal-nav.html|bars|https://liferay.design/lexicon/core-components/navigation/|404|
|85|https://liferay.design/lexicon/satellite-components/sites/buttons/assetToolbar|Asset Toolbar|https://liferay.design/lexicon/satellite-components/sites/buttons/|404|
|86|https://liferay.design/lexicon/satellite-components/sites/buttons/assetTitleBar|Asset Title Bar documentation|https://liferay.design/lexicon/satellite-components/sites/buttons/|404|
|87|https://liferay.design/handbook/grow/career-paths/overview/|Read about it in our Handbook||404|
|88|https://liferay.design/lexicon-1/patterns/management_bar|management bars|https://liferay.design/lexicon-1/patterns/buttons/|404|
|89|https://liferay.design/lexicon-1/patterns/list|list|https://liferay.design/lexicon-1/patterns/dataset-display/|404|
|90|https://liferay.design/lexicon-1/patterns/card|card|https://liferay.design/lexicon-1/patterns/dataset-display/|404|
",2020-02-11T18:17:34Z,2020-08-31T17:35:09Z,closed,5,"Liferay.design, dark pattern design practices","article, definition","liferay.design, example",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/woocommerce/woocommerce-admin/issues/4579,Store Profiler - Business details step: install free extensions in 1 click,https://github.com/woocommerce/woocommerce-admin/issues/4579,"**Description:** we're going to experiment with a new approach to install free extensions in the Store Profiler flow, including WCPay. We should start with a small subset of new users - it seems that the easiest way can be filtering the segment by the store location and industry. Eg: stores with the location in the US and Electronics & Computers as industry. 

Final segmentation: Stores that selected the US as country and Fashion, Apparel, Accessories or Health & Beauty as Industry. It gives ~2.5% of the total number of new users and ~30% of the total number of new users from US


![features-3.png](https://images.zenhubusercontent.com/5d84fe8e1201de0001b6ab61/6183de02-628d-4471-a57b-723079c465c0)

**Acceptance Criteria:**
- [ ] display the changes in the flow just to a specific segment (segmentation tbd)
- [ ] display just one checkbox to install all the free extensions. The checkbox should be toggled on by default
- [ ] show a popover with more info about the extensions when the user hovers the info icon
- [ ] install the following extensions if the user clicked ""continue"" with the checkbox togged on: Jetpack, WooCommerce Services, Facebook, Mailchimp, Google Ads, WCPay 
- [ ] remove the JP/WCS step for this segment, as they're going to be installed in the Business details step
- [ ] the redirect to the Jetpack account creation flow should only happen after the theme step 

**Event tracking:**
It will be better to add a new event for this step's alternative version:

Event name: `wcadmin_storeprofiler_store_business_details_continue_alternative`
Event prop: `extensions_installed` (value: Yes/No)
Event description: When the user clicks on ""Continue"" on the alternative version of the Business step
 
Event name: `wcadmin_storeprofiler_store_business_details_popover_alternative`
Event prop: NA
Event description: When the user clicks on the popover

It will be necessary to update `wcadmin_storeprofiler_step_view` to include this alternative step as the value of the `step` prop. It can be named business-details-alternative

**Additional links:**
[Design mockup](https://www.figma.com/file/JH9XMFUCOjfXdr3N09AHRD/On-boarding-iterations-June-'20?node-id=1%3A3)",2020-06-15T10:49:07Z,2020-07-15T14:52:22Z,closed,17,"WooCommerce (open source commerce platform for WordPress), usage of dark pattern in design, hidden information","Store Profiler, hiding steps, sneaking","Store Profiler, WooCommerce, WordPress, hidden information, sneaking",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tom-james-watson/old-reddit-redirect/issues/25,old.reddit.com no longer displays links to join/subscribe to subreddits.,https://github.com/tom-james-watson/old-reddit-redirect/issues/25,"I'm thinking this is more of an issue with a dark pattern that Reddit has implemented, rather than an issue with the add-on itself, but I figured this would probably be a good place to raise the question.

The join or subscribe link for subreddits no longer appears in the sidebar on old.reddit.com. Not sure of any way to get it back. As a work around I've been doing the following:

1. Temporarily disable the add-on.
1. Visit the subreddit using www.reddit.com.
1. Click the link to join/subscribe.
1. Re-enable the add-on.

Would it be possible to implement a workaround in the add-on itself to address this issue?",2020-01-14T00:53:39Z,2020-01-22T01:34:35Z,closed,2,"old.reddit.com, remove dark pattern, link to join, subscribe button to subreddit","uBlock Origin, Reddit issue, ""add-on"" button disable","Reddit, deceptive design practices, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/bloom-housing/bloom/issues/133,Build out User/Authentication Service v0,https://github.com/bloom-housing/bloom/issues/133,"**Infrastructure:**

- [ ] Database + ORM
- [ ] Schema create migrations
    - users (history only in v0)
    - permissions
- [ ] Object versioning

**User Endpoints:**

- [ ] /authenticate => returns JWT

**Admin Endpoints:**

- [ ] /user/{ID}/permissions => shows permissions for userID
- [ ] /user/{ID}/setPermission => sets a permission for userID",2020-01-10T01:07:20Z,2020-06-17T22:03:19Z,closed,10,miscellaneous (phising easier),"verification, phishing, security issue","verification, phishing, privacy issue",DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/sheodox/alexandrite/issues/40,Disable infinite scroll,https://github.com/sheodox/alexandrite/issues/40,"Infinite scroll is an additive dark pattern. It should be possible to disable it, preferably even by default.

",2023-08-01T15:19:07Z,2023-10-24T23:32:12Z,open,1,"Alexandrite (desktop-first alternative web UI), prevention of dark pattern, no infinite scrolling","infinite scroll, option to disable, addictive, emotional manipulation, interface interference","Alexandrite, infinite scroll, addictive, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/pluriversewtf/season0-projects/issues/19,Conduct a comparative analysis of ponzis/MLMs,https://github.com/pluriversewtf/season0-projects/issues/19,"The goal is to identify and extract flows that can be applied towards our regenerative ends, or to reverse engineer traditional dark patterns to explore new regen patterns. Specifically applicable to NFT designs for the pluriverse.",2022-10-26T13:18:56Z,2022-10-26T13:18:56Z,open,0,dark pattern designs by Ponzi schemes and Multi-Level Marketing (MLM),,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/bulwarkid/bulwark-passkey/issues/8,Accidental delete of Key is possible,https://github.com/bulwarkid/bulwark-passkey/issues/8,"Adding a verification for Key deletion because accidental use of the delete button as an close button in the key info is possible.

![grafik](https://github.com/bulwarkid/bulwark-passkey/assets/25664766/859061b2-d589-4d1f-a1c9-66b68039503a)",2023-06-28T08:04:34Z,2023-10-31T09:22:10Z,open,1,"comfirmation for important information deletion, not dark pattern but like a DP concept","key delete button where usually cancel is, UI manipulation, interface intereference","deceptive design practices, discussion",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/damus-io/damus/issues/962,Plebstr breaks damus contact lists [bug],https://github.com/damus-io/damus/issues/962,"> Yeah unfortunately they encode contact lists in a non-standard way, so if you login into plebstr it will make it incompatible with most other clients. Sorry, I can’t provide support if you login to other clients that do dark patterns like this.  

https://damus.io/note1xh6ttazmxr7avq6tlwjwtk5rrrrh4pzc3wxe8sxygzrnyatefr4q6872c7",2023-04-18T02:20:13Z,2023-06-25T18:27:45Z,open,1,"Plebstr, usage of dark pattern, break contact list",,,,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/osoc22/project-knowledge-impact/issues/2,Research Dark Patterns for Good - How Infinity Pools can be beneficial for academic repositories #infinitypools,https://github.com/osoc22/project-knowledge-impact/issues/2,,2022-07-11T10:04:35Z,2022-07-11T13:26:55Z,open,1,"“research dark pattern for good”, infinity pool for academic repositories",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/collective/volto-gdpr-privacy/issues/16,feature request: disable 'accept all' in settings,https://github.com/collective/volto-gdpr-privacy/issues/16,"The 'accept all' button on the *detailed* privacy settings modal is a bit of a dark pattern: if visitors have clicked on the 'change settings' in the previous step, it is very unlikely that they want to accept all settings again.   'Update my preferences'  and 'only necessary cookies'  would be enough. 


If would be cool if that 'accept all button' can be make optional in the add'on settings.",2022-12-11T16:28:31Z,2022-12-11T16:28:31Z,open,0,"prevention of dark pattern in design, gdpr compliance, privacy setting, remove ""accept all"" button ","modal, ""accept all"" button after cutomization, obstruction","modal, privacy issue, GDPR, avoid dark pattern, obstruction",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/your-digital-rights/yourdigitalrights.org/issues/381,Data Protection Laws Cheat Sheet,https://github.com/your-digital-rights/yourdigitalrights.org/issues/381,"Create a one page cheat sheet / infographic containing the dark patterns & counter measures we shared on our Good Tech Fest talk.

There are additional patterns that we have not shared in the talk. 

Report: https://docs.google.com/presentation/d/1YEfxy8zlLqjxeC1FvjptjJdO0xstOOOd4WtsBIzW4tk/edit#slide=id.g1283a6c91ed_0_8",2022-07-15T09:39:28Z,2022-08-02T07:47:34Z,open,0,"dark pattern education, Good Tech Fast talk, data protection law cheat sheet",,miscellaneous,miscellaneous,"dark pattern education, talk, data protection law",,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/EthicalSource/hippocratic-license-3/issues/75,"infitnite scroll, load more, and autoplay and dark patterns and algorithm switch off and ability to include external algorithms etc",https://github.com/EthicalSource/hippocratic-license-3/issues/75,"inclusion in the hippocratic license to not include addictive features like infinite scroll (even the cheeky stuff), load more button, dark patterns, autoplay, to only include algorithmic reccomendations or whatever stuff if consented and also provide the ability to withdraw consent and ability use external algorithms instead, perhaps also mandate that the service should have a competitor who is not getting maliciouslly funding or whatever from the original service (basiclly what google is doing with mozilla) and other stuff that original company can do to open a puppet competitor and ability export data base of the user or what everhtml file data or stuff (i am no tech genius). and ability to store data locally only and not on the servers of the service, ability to self host the service and or run it locally. and perhaps the ability to not have any user identifier at all like simplex-chat does(https://simplex.chat/), also add ability of end to end encryption and the ability to encrypt the database
i understand all might not be possible but think for a second if a service owns servers don't you think they can provide the ability to self host, and other stuff i mentioned, plus there could be exceptions and or some conditions only apply during specific scenarios.
i request that more features like these are added, i am 19 now and have ruined my life on youtube and serch engine, i have become an information addict and i also have to mental help because of all my life problems(some of which is caused by the stuff i mentioned). i also hope that the readers of this make their own tweeks to better the stuff i mentioned and perhaps add more features. thank you",2023-08-31T01:03:46Z,2023-08-31T01:04:30Z,open,0,"prevention of dark pattern in design, infinite scrolling, load more button, autoplay, addictive features","infinite scroll, load more, examples of dp","infinite scroll, addictive, autoplay, load more button, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/jcoombes/commonsensecode/issues/9,cs-interface,https://github.com/jcoombes/commonsensecode/issues/9,"Imagine you were a user who was going to test the resultant code generated by running this file, which parts of the interface might be too complicated or contain dark-patterns? Where in the user interface are we breaking the laws of good ui and ux?

Testset:
A CLI tool py file with e.g. Typer for now

Out of Scope:
Flask app.",2023-04-05T14:46:31Z,2023-04-05T14:48:50Z,open,0,check weather the UI contains dark patterns,,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mastodon/mastodon-ios/issues/808,Option to disable See New Posts popup,https://github.com/mastodon/mastodon-ios/issues/808,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current Behavior

A popup that never dissapears feels like a dark pattern to incentivize refreshing for one new post and then causing you to scroll infinitely instead of finishing read the older posts

### Expected Behavior

pop up should dissapear after a second by default and have an option to never appear.

```markdown
- Device: Iphone
",2022-12-22T19:39:47Z,2022-12-22T19:40:36Z,open,0,"Mastodon, prevention of dark pattern in software, nagging, see new posts popup, disable popup","pop-up doesn't disappear, obstruction, interface interference","Mastodon, pop-ups, nagging, obstruction, avoid dark pattern",DPs prevention in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/psf/requests-html/issues/514,Lazily installing Chromium is an anti-pattern,https://github.com/psf/requests-html/issues/514,"This ""feature"" makes naive assumptions about portability, permissions, and hides silently automated installation of software from users.

This is a feature borrowed from malware. While I understand it's not used maliciously here, it's an absolute mess for folks managing tool-chains and packages in an enterprise or security conscious environment.

You don't think you should get authorization or feedback about preferences from users before you install software on their system? Why would that be okay? ",2022-07-29T02:40:42Z,2022-10-18T02:15:10Z,open,3,"usage of dark pattern in software, installing software without users consent","auto installation of software, unethical, forced action","app installation, forced action",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/w3c/permissions/issues/418,One time permissions: exposing and specifying grant type,https://github.com/w3c/permissions/issues/418,"We've received feedback on the two following items, and wanted to share our view as well as request others' view on them.

> Should we expose whether the user decided to grant ephemerally or persistently?

We are worried about potential dark patterns that exposing this information would enable. For example, a website may decide to not accept an ephemeral grant at all. This would negatively impact the privacy benefits that one-time permissions provide. While there may be use cases where a site can use this information to improve the user experience, we believe that the risks outweigh the benefits.

> Should navigator.permissions.request() allow specification of grant type?

Supporting the ability to request one-time grants only (i.e. showing no permanent grant option on the prompt), is privacy-positive, and something that we would be open to support. In case of API changes here, we believe only grant type restrictions towards more privacy preserving should be explored.",2023-08-14T11:41:15Z,2023-09-15T12:47:04Z,open,1,"prevention of dark pattern, users granted permissions ephemerally or persistently, privacy concerns","one-time permission, example","privacy issue, deceptive design practices, one-time permission, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/themotte/rDrama/issues/671,Move or get rid of the Install The Webapp popup,https://github.com/themotte/rDrama/issues/671,"> When accessing the site on mobile, there is an ""Install the Motte webapp!"" nagware banner with a tiny close button neatly covering up the top right controls, including the notification bell that would tell me about any post responses. Do we really need that, and does it need to be in that location for any non-dark-pattern reasons?

At the very least it shouldn't be covering things up; anyone have a solid feeling on whether it actually encourages people to bookmark the site? (we don't have analytics for this or anything)",2023-08-07T00:09:27Z,2023-08-09T08:30:02Z,open,3,"prevention of dark pattern, webapp installation popups, nagging","pop-up, obstruction","pop-ups, nagging, obstruction, avoid dark pattern",DPs prevention in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/computer-ethics/computer-ethics.github.io/issues/21,Proposed Readings,https://github.com/computer-ethics/computer-ethics.github.io/issues/21,"## Ethical Principles for Human Subject Research:
The Nuremberg Code (1947)
The Declaration of Helsinki (1964)
The Belmont Report (1979)
The Menlo Report (2012)
EU Horizon 2020 Ethics Appraisal Procedure

## Passwords and Authentication:
Ethical Requirements for Responsible Research with Hacked Data, Nature
Machine Intelligence 2021,
https://www.nature.com/articles/s42256-021-00389-w (I can provide a PDF)

Ethical Issues in Research Using Datasets of Illicit Origin, IMC 2017,
https://www.cl.cam.ac.uk/~drt24/papers/2017-ethical-issues.pdf

It's Not Stealing If You Need It: A Panel on the Ethics of Performing
Research Using Public Data of Illicit Origin, WECSR 2012
https://www.guanotronic.com/~serge/papers/fc12.pdf

## Case Studies:

Princeton-Radboud Study on Privacy Law Implementation:
https://www.mishcon.com/news/data-ethics-concerns-halt-academic-study-into-subject-access-requests

The “Hypocrite Commits” Paper
https://www.ieee-security.org/TC/SP2021/downloads/2021_PC_Statement.pdf

Ashley Madison Hack:
https://www.forbes.com/sites/zakdoffman/2020/02/01/ashley-madison-hack-returns-to-haunt-its-victims-32-million-users-now-have-to-watch-and-wait/
https://www.theguardian.com/technology/2016/feb/28/what-happened-after-ashley-madison-was-hacked

LinkedIn Dark Patterns:
https://medium.com/@danrschlosser/linkedin-dark-patterns-3ae726fe1462

LinkedIn Hacked:
https://arstechnica.com/information-technology/2016/06/how-linkedins-password-sloppiness-hurts-us-all/
https://s3.documentcloud.org/documents/6793888/Nikulin-pre-trial-filing-alleging-Ieremenko.pdf",2023-01-03T16:38:38Z,2023-01-03T16:38:39Z,open,0,"miscellaneous (Linkedin, source)",,miscellaneous,miscellaneous,"Linkedin, source",,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/gitcoinco/passport/issues/143,"🚗 [GRANTS] As a Grants Contributor, I want to know before I leave the Trust Bonus page if I have not saved my passport",https://github.com/gitcoinco/passport/issues/143,"GIVEN I have signed into the gitcoin.co/trust
WHEN I have created a passport
AND I have connected my passport
AND I have scored my passport but not saved it
WHEN I try to leave the site
THEN I receive a message informing me that my passport is not saves and asks me if I wanted to save my passport

**Note**
Rethink experience pattern",2022-06-03T00:59:05Z,2023-01-25T14:59:29Z,open,1,"Gitcoin passort, deceptive design practices, intercept user's action ","does not save, extra step, obstrction, nagging","Gitcoin, deceptive design practices, obstrcution",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/darkreader/darkreader/issues/11638,[Bug] Export Dynamic Theme is broken on Firefox,https://github.com/darkreader/darkreader/issues/11638,"### Prerequisites

- [X] I [searched for any existing report](https://github.com/darkreader/darkreader/issues?q=is%3Aissue) about this bug to avoid opening a duplicate.
- [X] I can reproduce this bug in a new, unmodified web browser profile with Dark Reader installed as the only extension.
- [X] I understand I need to use the [Broken Website Report template](https://github.com/darkreader/darkreader/issues/new?assignees=&labels=Broken+Website&template=broken-website-report.yml&title=%5BBroken+Website%5D+Replace+with+title) if this bug I am reporting occurs on a single website.

### Bug Description

When I click 'Export Dynamic Theme' while in Firefox, nothing happens. It works on other browsers.

### Website Address

https://example.com

### Steps To Reproduce

1. Open Dark Reader Dev Tools
a. `Settings > Dev Tools` on the new design
2. `Preview new design`
a. _I pressed `Switch to old design` first to refresh it (if that's even something that ever needs to be done)_
3. `Settings > Manage Settings > Export Dynamic Theme`
a. Nothing happens.

### Expected Behavior

Dynamic theme should be downloaded/saved.

### Actual Behavior

However, no download ever starts or save prompt ever pops up. I checked the download history (Ctrl+J) and my default Downloads folder.

### Operating System

Windows 10

### Web Browser name and version

Firefox 115.1.0esr (64-bit)

### Dark Reader version

4.9.65",2023-08-26T21:11:05Z,2024-02-24T18:32:29Z,open,6,"Firefox, browsers, usage of dark pattern, back button issues in setting to trick users to hit donation button","back button placement, UI design, interface interefernce","Firefox, UI/UX design, misleading, deceptive design practice, ",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mastodon/mastodon/issues/23081,[Poll results] Let's have 'correct answer' marked in quiz-like polls.,https://github.com/mastodon/mastodon/issues/23081,"### Pitch

**I experienced** an interesting quiz started by @lofty@chaos.social:
https://chaos.social/@lofty/109673495214057621 (thread)
Now that it ended, we have insight what everybody guessed and compare to one's own guess.
**What is missing** is the ""solution"" mark, i.e., the correct answer.
**My suggestion** is that an author marks a poll as ""quiz-like"" (label to be defined) which makes it mandatory to mark one or multiple answer/s as ""correct"". 

### Motivation

I think this case shows what happens when the majoritie's opinion is published in a manner that suggests Truth(tm).
We should definitely meet this dark pattern in mastodon, I reckon.",2023-01-13T19:02:47Z,2023-01-15T22:14:20Z,open,1,,"quiz, preselction after quiz is done",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/sipb/uplink/issues/37,Consent/terms and conditions,https://github.com/sipb/uplink/issues/37,"Original comment: https://github.com/sipb/uplink/issues/7#issuecomment-1382676450

## Terms and conditions when signing up

Moving from https://github.com/sipb/uplink/issues/7

Matrix/Synapse have an optional feature where users have to accept terms and conditions when signing up:

![image](https://user-images.githubusercontent.com/24363938/212614313-a6787f2e-2b5b-41f3-b6dc-470ea25e918e.png)

Write those terms and conditions. These should probably not be legal terms, just some general guidelines like don't harass people, respect MIT policies, end-to-end encryption is a thing and use it otherwise we can't guarantee the privacy of your messages:

> Welcome to Matrix. This is how Matrix works.
> This service is provided ""as-is"" with no warranty. We will try our best to keep it running smoothly and you should feel free to reach out if you have any issues. The maintainers plan to rely on it, so it should be available 24/7 or really close. However, we also can't legally guarantee there won't be hiccups.
> You agree that your username will be set to your kerberos/athena username (i.e. your email). If you wish to use a different username, please do not accept and instead email us at [insert email] here so we can manually create your account with the desired username.
> Your messages are only end-to-end encrypted, and hence protected, if they say so. Public channels are not end-to-end encrypted because it wouldn't make sense to do so (also clients expect only private channels to be so).
> If a conversation isn't end to end encrypted, just like Messenger and Discord ones, we can't guarantee it's private. We promise not to look at it, and we promise to have a good security that guarantees we won't get hacked. But we can't guarantee it won't get hacked or that someone won't break into the SIPB office and steal your non-end-to-end encrypted messages.
> If you use bridges, we are not responsible if your account gets banned, since they may violate their terms of service.

This is tied to #6.

## Consenting to Moira list integration

In the linked terms and conditions, add that you agree to give permissions to the moira list integration.

I was originally thinking 2 things: agree to being added for the other moira lists, and one for the Canvas lists. But now I think the former isn't needed for 2 reasons:

1. if the mailing list is not hidden, other people can already see the list of members through WebMoira, so this doesn't change anything
2. when using Slack, ~~people just add you to workspaces and no one asks you if you want to be in them (i.e. Orientation workspace). We are simply allowing mass-adding based on Moira lists, so the feature is still the same.~~ nvm apparently you do get email invites. Either way, if they are sent as Matrix invites, it should be equivalent. The matrix invites are public, but this isn't an issue because of 1.

So I would just add one more checkbox: ""Automatically add me to the group chats of the classes I'm in"", and make it OFF by default.

Now for implementation, there are 2 options, both by editing the [sso_new_user_consent.html](https://github.com/matrix-org/synapse/blob/master/synapse/res/templates/sso_new_user_consent.html) template:

❌ ~~1. Send the opt-in via JavaScript~~
✅ 2. Change the POST endpoint, and write some code that captures the consent and saves it somewhere. I think this is more reliable, because the JavaScript may fail (unlikely, but what if the user clicks the checkbox and then instantly submits before the JS runs? or if there is a JS error it will just go to the console and silent etc). Then do a 307 redirect to the original endpoint.

❌ ~~a) Use PHP~~
❌ ~~b) Use some Python CGI thing~~
✅ c) Synapse plug-ins are allowed to get their own endpoints. This would require knowing how to use Twisted (the framework that Synapse uses for web stuff)

3. Record it from the Synapse source code itself (I'd rather avoid forking the source code at all costs because I am not willing to maintain a fork)

^ Still on the question because we don't know if we'll be able to change the display name from the plug in... (can combine with previous method)

**Hmmm what if:** Make an event spam checker and if the user changed their name, mark the _initial_ name set event as spam. Might not work necessarily tho. If the source code must be changed, it is best to do so but make a pull request so that everyone can have this. As a test pull request but also helpful, it should not be hard to do one that lets you change the name ""SAML"" into something like ""Touchstone"" or ""kerb"" or ""MIT account"", and set an icon, and set confirm_localpart because it is customizable for OIDC but not SAML or CAS.",2023-01-16T07:11:05Z,2023-01-19T03:04:21Z,open,1,"Matrix, Moira list integration, prevention of dark pattern, consent form, terms and conditions, no preselection","definitions, examples","Matrix, terms and conditions, avoid dark pattern, cookie consent","DPs prevention in software, DPs examples/definitions",,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/ConsumerDataStandardsAustralia/standards/issues/321,Design Paper: Consumer Data Right Consent Review,https://github.com/ConsumerDataStandardsAustralia/standards/issues/321,"### Overview
Treasury and the Data Standards Body are exploring opportunities to simplify the CDR Rules and standards to support better consumer experiences while maintaining key consumer protections.

The design paper seeks stakeholder feedback on a number of change proposals relating to rules and standards for CDR consents. Topics for feedback include:

- bundling of consents
- selection of key consent terms
- withdrawal of consent information
- notifications
- consents for de‑identification
- dark patterns.

It also seeks feedback on topics for future consideration.

Consultation documents can be found on Treasury's consultation page [here](https://treasury.gov.au/consultation/c2023-434434-consent), and versions of the design paper can be accessed below:
[Consent Review Design Paper - PDF](https://github.com/ConsumerDataStandardsAustralia/standards/files/12435176/c2023-434434-consent-design-paper.pdf)
[Consent Review Design Paper - DOCX](https://github.com/ConsumerDataStandardsAustralia/standards/files/12435184/c2023-434434-consent-design-paper-0.docx)



### Stakeholder forums
A stakeholder forum will be conducted on 6 September from 11am-12pm to assist stakeholder understandings of the proposed changes and to provide the opportunity for discussion and feedback.

If you would like to participate in this stakeholder forum, please register your interest at [CDRRules@treasury.gov.au](mailto:CDRRules@treasury.gov.au).

### Feedback
You can submit responses to this consultation **up until 06 October 2023**. Feedback may be provided by [email](mailto:CDRRules@treasury.gov.au) and on this Data Standards [GitHub respository](https://github.com/ConsumerDataStandardsAustralia/standards/issues/321). Stakeholders are encouraged to use GitHub for ongoing discussions regarding the Consent Review, which may help inform the development of feedback.

Feedback posted on GitHub is public by nature at the time of submission. Content posted on GitHub should be made according to the community engagement rules published by the DSB.

Further details regarding submissions can be found on Treasury's main consultation page for the Consent Review, [here](https://treasury.gov.au/consultation/c2023-434434-consent).",2023-07-26T04:04:49Z,2023-10-08T22:57:07Z,open,9,"Consumer Data Right (CDR) consent review, dark pattern topic discussion","consent, CDR Rules","Consumer Data Right (CDR), cookie consent, discussion",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/letsencrypt/website/issues/1440,"Rate Limit Focus Pages (Duplicate, Failed) should link back to All Rate Limits page",https://github.com/letsencrypt/website/issues/1440,"The two rate limit focus pages:

* https://letsencrypt.org/docs/duplicate-certificate-limit/
* https://letsencrypt.org/docs/failed-validation-limit/

Should have a link back to https://letsencrypt.org/docs/rate-limits/

I suggest something like the following (markdown):

    # Learn More About Rate Limits

    Let’s Encrypt provides rate limits to ensure fair usage by as many people as possible.
    To learn more about rate limits, best practices, and what other limits you should expect, please visit /rate-limits.

",2022-08-02T19:23:55Z,2022-08-10T22:23:40Z,open,3,"Let's Encrypt (a free, automated, and open certificate authority), usage of dark pattern in software, obstructions, isolate users from overriding the rate limit","isolate users through feature, emotional manipulation, interface interference","Let's Encrypt, isolate users, obstruction",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/kaupunginnaiset/alman-akka/issues/30,Add pagination/infinite scrolling to event list,https://github.com/kaupunginnaiset/alman-akka/issues/30,,2022-03-25T19:42:11Z,2022-03-28T04:06:22Z,open,1,"prevention of dark pattern in software, no infinite scrolling, use pagination instead ","infinite scrolling, pagination suggested, scroll position, UI design manioulation","inifinite scroll, pagination, UI/UX design, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/trufi-association/trufi-core/issues/656,Implement App Install/Conversion Tracking,https://github.com/trufi-association/trufi-core/issues/656,"Description:
The ability to identify which clicks and actions from marketing campaigns turn into conversions – app installs.
We need to find an application that can do what Ted requires.

+ ongoing issue!",2023-01-23T18:16:52Z,2023-06-23T14:23:55Z,open,4,"Medium, post, Booking.com",Mobile Deep Linking - dp examples in article,"Medium, post, UI/UX design, documentation",Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/jacky1234/blogPages/issues/147,HackerNews Top 10 @2023-08-15,https://github.com/jacky1234/blogPages/issues/147,"1. **[Show HN: LLMs can generate valid JSON 100% of the time](https://github.com/normal-computing/outlines)**
494 points by [remilouf](https://news.ycombinator.com/user?id=remilouf) 5 hours ago | [153 comments](https://news.ycombinator.com/item?id=37125118)

2. **[Show HN: Little Rat – Chrome extension monitors network calls of all extensions](https://github.com/dnakov/little-rat)**
376 points by [npace12](https://news.ycombinator.com/user?id=npace12) 12 hours ago | [76 comments](https://news.ycombinator.com/item?id=37119942)

3. **[Discord.io breached, 760k user accounts for sale on darknet](https://stackdiary.com/the-data-of-760000-discord-io-users-was-put-up-for-sale-on-the-darknet/)**
340 points by [skilled](https://news.ycombinator.com/user?id=skilled) 6 hours ago | [123 comments](https://news.ycombinator.com/item?id=37124187)

4. **[Backward Compatibility, Go 1.21, and Go 2](https://go.dev/blog/compat)**
297 points by [philosopher1234](https://news.ycombinator.com/user?id=philosopher1234) 8 hours ago | [238 comments](https://news.ycombinator.com/item?id=37122871)

5. **[I built a garbage collector for a language that doesn’t need one](https://claytonwramsey.github.io/2023/08/14/dumpster.html)**
249 points by [claytonwramsey](https://news.ycombinator.com/user?id=claytonwramsey) 10 hours ago | [111 comments](https://news.ycombinator.com/item?id=37120967)

6. **[The 2002 Überlingen midair collision](https://admiralcloudberg.medium.com/tears-in-the-rain-the-2002-%C3%BCberlingen-midair-collision-591232d0c51e)**
209 points by [vinnyglennon](https://news.ycombinator.com/user?id=vinnyglennon) 12 hours ago | [78 comments](https://news.ycombinator.com/item?id=37120372)

7. **[JWST spots giant black holes all over the early universe](https://www.quantamagazine.org/jwst-spots-giant-black-holes-all-over-the-early-universe-20230814/)**
204 points by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) 7 hours ago | [77 comments](https://news.ycombinator.com/item?id=37123792)

8. **[Elixir – Why the dot when calling anonymous functions?](https://dashbit.co/blog/why-the-dot)**
194 points by [weatherlight](https://news.ycombinator.com/user?id=weatherlight) 9 hours ago | [130 comments](https://news.ycombinator.com/item?id=37122006)

9. **[The anesthetic effect of air at atmospheric pressure](https://pubmed.ncbi.nlm.nih.gov/1130736/)**
126 points by [luu](https://news.ycombinator.com/user?id=luu) 7 hours ago | [94 comments](https://news.ycombinator.com/item?id=37117818)

10. **[Caught by MuseScore's Dark Patterns (2021)](https://gadanidis.ca/posts/2021-11-09-musescore.html)**
119 points by [saltwatercowboy](https://news.ycombinator.com/user?id=saltwatercowboy) 10 hours ago | [73 comments](https://news.ycombinator.com/item?id=37121458)

",2023-08-15T00:45:10Z,2023-08-15T00:45:10Z,open,0,"Hacker News Daily, resources of dark pattern, blog post","MuseScore, examples","MuseScore, blog, post, discussion",Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/django/django-localflavor/issues/473,"French local : Use class Validators for SIRET and SIREN model fields, do not format output",https://github.com/django/django-localflavor/issues/473,"Hello,

Right now the SIRET and SIREN model fields use SIRET and SIREN form fields that do the validation.
I prefer the architecture of the IBAN and BIC fields in generic that use class Validators,
since you can call the validators without using form fields.
Would you accept if I submit a PR with a new file validators.py in fr/
and add in it SIRENValidator and SIRETValidator classes ?
I would use them as is done for IBANValidator and BICValidator.

There is also an annoying thing : 
SIRET is max length 14
but it is formatted with spaces.
Thus if in Django admin you modify a form with a valid SIRET in it you get this error : 
""Ensure this value has at most 14 characters (it has 17).""
![image](https://user-images.githubusercontent.com/4527928/185925221-e9a3f1ee-7c3d-412a-8463-f2545278b23e.png)
I don't know what is the nicest way to avoid this :
- remove formatting in https://github.com/django/django-localflavor/blob/80c6584adf59c992c1d30b06be9e4f9b6eceb376/localflavor/fr/forms.py#L251-L255  ?
- change maxlength from 14 to 17 ?
Modifying a SIRET each time you submit a form because of this is an unvolontary ""dark pattern"" ;)

Thanks, best regards,
    Laurent Lyaudet


",2022-08-22T12:53:30Z,2022-08-23T13:40:00Z,open,2,"prevention of dark pattern, SIRET modification needed everytime","form submission modifies SIRET, forced action","SIRET modification, avoid dark pattern, forced action",DPs prevention in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/krysokyon/bp_alerts/issues/253,[tag found] linux,https://github.com/krysokyon/bp_alerts/issues/253,"
There's been another instance of `linux` on a Hacker News comment.
You can see the details bellow:

> - user: ehnto
> - date: 2022-03-16 15:43:24
> - article Google seems to have signed me up for Google Pay w...
> - comment:
>
>> This flag in chrome://flags might be relevant.chrome://flags/#enable-autofill-credit-card-upload""Enables a new option to upload credit cards to Google Payments for sync to all Chrome devices. – Mac, Windows, Linux, Chrome OS, Android, Fuchsia""They've really ramped up the ""Google"" in Google Chrome these last few years. The ""save payment"" nag box was annoying before, now I'd move it firmly into the dark pattern region, as it attempts to convince you to move your payment into their payment services not just saved locally.The fact that there is no ""never ask me again"" option for that save payment dialog seems like nefarious UI 101. How could a billion dollar company make such a rudimentary UI mistake in a flagship product? Well, they probably didn't make a mistake, they're just getting worse as a company.
",2022-03-16T15:44:02Z,2022-03-16T15:44:02Z,open,0,"Google Chrome, usage of dark pattern in software, nagging, persistent prompts, push users to use Google Pay, no ""never ask me again"" option","""save payment"", nagging","Google Chrome, Google Pay, prompt, nagging",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/headllines/hackernews-daily/issues/972,Hacker News Daily Top 10 @2023-03-14,https://github.com/headllines/hackernews-daily/issues/972,"1. **[Launch HN: Electric Air (YC W23) – Heat pump sold directly to homeowners](https://news.ycombinator.com/item?id=35138319)**
582 points by [cmui](https://news.ycombinator.com/user?id=cmui) 7 hours ago | [538 comments](https://news.ycombinator.com/item?id=35138319)

2. **[Advanced Compilers: Self-Guided Online Course](https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/)**
573 points by [macrolocal](https://news.ycombinator.com/user?id=macrolocal) 20 hours ago | [77 comments](https://news.ycombinator.com/item?id=35130975)

3. **[Google Reader shut down announced ten years ago today](https://googleblog.blogspot.com/2013/03/a-second-spring-of-cleaning.html)**
504 points by [satvikpendem](https://news.ycombinator.com/user?id=satvikpendem) 20 hours ago | [315 comments](https://news.ycombinator.com/item?id=35130764)

4. **[Changes at YC](https://www.ycombinator.com/blog/changes-at-yc/)**
339 points by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) 3 hours ago | [322 comments](https://news.ycombinator.com/item?id=35142245)

5. **[Launch HN: Pynecone (YC W23) – Web Apps in Pure Python](https://news.ycombinator.com/item?id=35136827)**
333 points by [picklelo](https://news.ycombinator.com/user?id=picklelo) 9 hours ago | [183 comments](https://news.ycombinator.com/item?id=35136827)

6. **[Audiophile forum debating which versions of memcpy had the highest sound quality (2013)](https://discuss.systems/@dan/110008052977994607)**
332 points by [Paul_S](https://news.ycombinator.com/user?id=Paul_S) 8 hours ago | [473 comments](https://news.ycombinator.com/item?id=35137327)

7. **[Experian is a pile of dark pattern garbage](https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage)**
291 points by [stanleydrew](https://news.ycombinator.com/user?id=stanleydrew) 3 hours ago | [61 comments](https://news.ycombinator.com/item?id=35142787)

8. **[SVB shows that there are few libertarians in a financial foxhole](https://www.ft.com/content/ebba73d9-d319-4634-aa09-bbf09ee4a03b)**
268 points by [CaliforniaKarl](https://news.ycombinator.com/user?id=CaliforniaKarl) 7 hours ago | [370 comments](https://news.ycombinator.com/item?id=35138341)

9. **[Alpaca: A strong open-source instruction-following model](https://crfm.stanford.edu/2023/03/13/alpaca.html)**
267 points by [jcklie](https://news.ycombinator.com/user?id=jcklie) 9 hours ago | [23 comments](https://news.ycombinator.com/item?id=35136624)

10. **[HSBC to Buy UK Arm of Silicon Valley Bank](https://www.bbc.co.uk/news/business-64937251)**
255 points by [concerto](https://news.ycombinator.com/user?id=concerto) 17 hours ago | [140 comments](https://news.ycombinator.com/item?id=35132181)


<p  align=""right""><a href=""https://github.com/sponsors/timqian""> <i>❤️ Sponsor the author</i></a> </p>
",2023-03-14T00:37:07Z,2023-03-14T00:37:08Z,open,0,"Hacker News Daily, resources of dark pattern, blog post","Experian CreditLock, examples","Experian CreditLock, blog, post, discussion",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/codemirror/dev/issues/752,Chrome/Android - when editor has an horizontal scrollbar it scrolls to the right even when the caret is within the viewport,https://github.com/codemirror/dev/issues/752,"Sorry for the long title but it's hard to explain!
Here's a short screencast to showcase this issue:

![scroll](https://user-images.githubusercontent.com/333276/155283325-01d94b0f-3741-4b6b-b472-d1de85f6d34b.gif)

As you can see, when I click on an empty line (line 4), it scrolls to the right.
As a result the cursor is underneath the gutter (line numbers).

And when I click on the first line just after the word ""long"", it also scrolls to the right even though the caret was within the viewport.

I'm using Chrome 98.0.4758.101 on Android 12. The video was recorded using remote debug and the text editor on the https://codemirror.net/6/ page.

It seems that Chrome somehow ignores the gutter and tries to align the text to the left edge.",2022-02-25T12:30:43Z,2022-05-27T11:23:06Z,open,5,unsure,"Chrome,/Andriod, editable element in center to avoid dp",,,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/tijlleenders/ZinZen/issues/1152,Display confirmation Popup of exiting the app,https://github.com/tijlleenders/ZinZen/issues/1152,"As soon as #1151 is done, I think we should allow this mechanism that **Only** if the user reaches the home page by repetitively pressing the native back button then we should display a popup on the exit of the app. So   ",2023-04-19T06:26:40Z,2023-04-19T07:24:36Z,open,2,"prevention of dark pattern in design, no popup design","pop-ups, obstruction, confirm shaming","pop-ups, avoid dark pattern",DPs prevention in software,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/ValveSoftware/Dota2-Gameplay/issues/2552,Character Select PRoblem,https://github.com/ValveSoftware/Dota2-Gameplay/issues/2552,"### Description

I am unable to lock in a specific character that I want to play. I am instead given a blank loading screen that informs me to lock in a character but none of the characters pop up and I am forced to Randomize just to get a character.

### Example Match ID (and possibly Timestamp)

_No response_

### Screenshots

![unknown](https://user-images.githubusercontent.com/112574781/187735702-b117f674-1f02-4d3e-bd51-2eefcd9fbd27.png)
",2022-08-31T16:55:06Z,2022-09-01T19:17:14Z,open,4,"Dota, usage of dark pattern in gaming, visual interference","""Subscribe"" button confuses user about the free trial options, sneaking, obstruction","Dota, gaming, sneaking",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/918,Daily Hacker News 14-03-2023,https://github.com/xueyuanl/daily-hackernews/issues/918,"
# Daily Hacker News
  
1. [**Ring LLC home security company ransomed by ALPHV ransomware**](https://web.archive.org/web/20230314015249/https://twitter.com/vxunderground/status/1635427567271329792) `web.archive.org` [`comments`](https://news.ycombinator.com/item?id=35148221)  
2. [**Launch HN: Electric Air (YC W23) – Heat pump sold directly to homeowners**](https://news.ycombinator.com/item?id=35138319) [`comments`](https://news.ycombinator.com/item?id=35138319)  
3. [**Alpaca: A strong open-source instruction-following model**](https://crfm.stanford.edu/2023/03/13/alpaca.html) `crfm.stanford.edu` [`comments`](https://news.ycombinator.com/item?id=35136624)  
4. [**Launch HN: Pynecone (YC W23) – Web Apps in Pure Python**](https://news.ycombinator.com/item?id=35136827) [`comments`](https://news.ycombinator.com/item?id=35136827)  
5. [**Russian Assets Reportedly Seized at Baikonur Cosmodrome by Kazakh Authorities**](https://tlpnetwork.com/news/2023/03/russian-assets-seized-at-the-baikonur-cosmodrome) `tlpnetwork.com` [`comments`](https://news.ycombinator.com/item?id=35148131)  
6. [**Audiophile forum debating which versions of memcpy had the highest sound quality (2013)**](https://discuss.systems/@dan/110008052977994607) `discuss.systems` [`comments`](https://news.ycombinator.com/item?id=35137327)  
7. [**Generating aerial imagery with your iPhone's Lidar sensor**](https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/) `jakecoppinger.com` [`comments`](https://news.ycombinator.com/item?id=35142588)  
8. [**Using a Mac without a network connection**](https://eclecticlight.co/2023/03/14/using-a-mac-without-a-network-connection/) `eclecticlight.co` [`comments`](https://news.ycombinator.com/item?id=35148534)  
9. [**Augmenting Human Intellect: A Conceptual Framework (1962) [pdf]**](https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf) `www.dougengelbart.org` [`comments`](https://news.ycombinator.com/item?id=35131164)  
10. [**Can Pachinko be Skill-based? Taking a look at Hanemono**](https://nicole.express/2023/whats-hanemono-precious.html) `nicole.express` [`comments`](https://news.ycombinator.com/item?id=35121271)  
11. [**Show HN: Counter – Simple and free web analytics**](https://counter.dev/) `counter.dev` [`comments`](https://news.ycombinator.com/item?id=35143052)  
12. [**Microsoft lays off one of its responsible AI teams**](https://www.platformer.news/p/microsoft-just-laid-off-one-of-its) `www.platformer.news` [`comments`](https://news.ycombinator.com/item?id=35145189)  
13. [**Changes at YC**](https://www.ycombinator.com/blog/changes-at-yc/) `www.ycombinator.com` [`comments`](https://news.ycombinator.com/item?id=35142245)  
14. [**Touchpad Blocker: Disable touch-pad while typing**](https://touchpad-blocker.com/) `touchpad-blocker.com` [`comments`](https://news.ycombinator.com/item?id=35132039)  
15. [**Crab crisis in Bering Sea a sign of ‘borealization’**](https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/) `alaskabeacon.com` [`comments`](https://news.ycombinator.com/item?id=35146566)  
16. [**Experian is a pile of dark pattern garbage**](https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage) `blog.benton.io` [`comments`](https://news.ycombinator.com/item?id=35142787)  
17. [**Just Ask for Generalization (2021)**](https://evjang.com/2021/10/23/generalization.html) `evjang.com` [`comments`](https://news.ycombinator.com/item?id=35134219)  
18. [**PostgreSQL 14 Internals**](https://postgrespro.com/blog/pgsql/5969985) `postgrespro.com` [`comments`](https://news.ycombinator.com/item?id=35141155)  
19. [**LinPEAS**](https://github.com/carlospolop/PEASS-ng/tree/master/linPEAS) `github.com` [`comments`](https://news.ycombinator.com/item?id=35133851)  
20. [**US court rules Uber and Lyft workers are contractors**](https://www.bbc.com/news/business-64947695) `www.bbc.com` [`comments`](https://news.ycombinator.com/item?id=35147384)  
21. [**Relationship Hero (YC S17) Is Hiring Sales Associates (Remote)**](https://relationshiphero.com/careers?role=salesAssociate) `relationshiphero.com` [`comments`](https://news.ycombinator.com/item?id=35145810)  
22. [**LNER Peppercorn Class A1 60163 Tornado**](https://en.wikipedia.org/wiki/LNER_Peppercorn_Class_A1_60163_Tornado) `en.wikipedia.org` [`comments`](https://news.ycombinator.com/item?id=35142991)  
23. [**Switching from C++ to Rust**](https://laplab.me/posts/switching-from-cpp-to-rust/) `laplab.me` [`comments`](https://news.ycombinator.com/item?id=35143573)  
24. [**Baldwin Lee on his rediscovered images of the deep south**](https://www.theguardian.com/artanddesign/2023/mar/11/it-stunned-me-that-people-had-to-live-like-this-baldwin-lee-rediscovered-images-deep-south-southern-portrait) `www.theguardian.com` [`comments`](https://news.ycombinator.com/item?id=35119136)  
25. [**High-Throughput Generative Inference of Large Language Models with a Single GPU**](https://arxiv.org/abs/2303.06865) `arxiv.org` [`comments`](https://news.ycombinator.com/item?id=35146081)",2023-03-14T09:04:38Z,2023-03-14T09:04:38Z,open,0,"Hacker News Daily, resources of dark pattern, blog post","Experian CreditLock, examples","Experian CreditLock, blog, post, discussion",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/xueyuanl/daily-hackernews/issues/698,Daily Hacker News 04-08-2022,https://github.com/xueyuanl/daily-hackernews/issues/698,"
# Daily Hacker News
  
1. [**Botspam apocalypse**](https://memex.marginalia.nu/log/61-botspam-apocalypse.gmi) `memex.marginalia.nu` [`comments`](https://news.ycombinator.com/item?id=32339314)  
2. [**What’s the strangest thing you ever found in a book?**](https://noctslackv2.wordpress.com/2022/08/02/whats-the-strangest-thing-you-ever-found-in-a-book/) `noctslackv2.wordpress.com` [`comments`](https://news.ycombinator.com/item?id=32334552)  
3. [**OmnesViae: Roman Routeplanner**](https://omnesviae.org/) `omnesviae.org` [`comments`](https://news.ycombinator.com/item?id=32340430)  
4. [**Productivity porn**](https://calebschoepp.com/blog/2022/productivity-porn/) `calebschoepp.com` [`comments`](https://news.ycombinator.com/item?id=32335165)  
5. [**Who do we spend time with across our lifetime? (2020)**](https://ourworldindata.org/time-with-others-lifetime) `ourworldindata.org` [`comments`](https://news.ycombinator.com/item?id=32339424)  
6. [**Infineon chip flaws to disrupt IONIQ 5 EV production**](https://www.kedglobal.com/automobiles/newsView/ked202208030010) `www.kedglobal.com` [`comments`](https://news.ycombinator.com/item?id=32339556)  
7. [**Sending spammers to password purgatory**](https://www.troyhunt.com/sending-spammers-to-password-purgatory-with-microsoft-power-automate-and-cloudflare-workers-kv/) `www.troyhunt.com` [`comments`](https://news.ycombinator.com/item?id=32338186)  
8. [**My lab went from 4000 kg to 130 kg of waste a year**](https://www.nature.com/articles/d41586-022-02092-1) `www.nature.com` [`comments`](https://news.ycombinator.com/item?id=32338478)  
9. [**New open source project: Common Lisp 3D graphics system**](https://old.reddit.com/r/lisp/comments/weocc5/new_open_source_common_lisp_3d_graphics_project/) `old.reddit.com` [`comments`](https://news.ycombinator.com/item?id=32337538)  
10. [**Generally Intelligent (YC S17) Is Hiring Machine Learning Engineers**](https://news.ycombinator.com/item?id=32340023) [`comments`](https://news.ycombinator.com/item?id=32340023)  
11. [**Alpine Linux is reducing dependencies on Busybox**](https://gitlab.alpinelinux.org/alpine/tsc/-/issues/52) `gitlab.alpinelinux.org` [`comments`](https://news.ycombinator.com/item?id=32336190)  
12. [**Things I Have Drawn is a site in which the things kids draw are real**](https://www.thingsihavedrawn.com) `www.thingsihavedrawn.com` [`comments`](https://news.ycombinator.com/item?id=32335818)  
13. [**Run FreeBSD 13.1 for ARM64 in QEMU on Apple Silicon Mac with HVF Acceleration**](https://gist.github.com/ctsrc/a1f57933a2cde9abc0f07be12889f97f) `gist.github.com` [`comments`](https://news.ycombinator.com/item?id=32337023)  
14. [**I Am a Spammer. AMA (2009)**](https://old.reddit.com/r/IAmA/comments/9dw73/i_am_a_spammer_ama/) `old.reddit.com` [`comments`](https://news.ycombinator.com/item?id=32340392)  
15. [**Launch HN: Iollo (YC S22) – At-home metabolomics test to extend healthy lifespan**](https://news.ycombinator.com/item?id=32333417) [`comments`](https://news.ycombinator.com/item?id=32333417)  
16. [**How prestige outlets like The Guardian get away with copypasta**](https://erikhoel.substack.com/p/how-prestige-outlets-like-the-guardian) `erikhoel.substack.com` [`comments`](https://news.ycombinator.com/item?id=32340061)  
17. [**Let's Encrypt has updated their Subscriber Agreement (v1.2 – v1.3)**](https://letsencrypt.org/repository/) `letsencrypt.org` [`comments`](https://news.ycombinator.com/item?id=32339222)  
18. [**Private, organization-owned repository FAQ**](https://www.netlify.com/pricing/private-org-repo-faq/) `www.netlify.com` [`comments`](https://news.ycombinator.com/item?id=32338447)  
19. [**SQLite-HTML: A SQLite extension for querying, manipulating, and creating HTML**](https://github.com/asg017/sqlite-html) `github.com` [`comments`](https://news.ycombinator.com/item?id=32335295)  
20. [**Cut the cutesy errors**](https://alexwlchan.net/2022/08/no-cute/) `alexwlchan.net` [`comments`](https://news.ycombinator.com/item?id=32337520)  
21. [**The Feynman Technique**](https://dsebastien.net/blog/2022-08-03-the-feynman-technique) `dsebastien.net` [`comments`](https://news.ycombinator.com/item?id=32340216)  
22. [**Ask HN: What's up with these DoorDash dark patterns?**](https://news.ycombinator.com/item?id=32338779) [`comments`](https://news.ycombinator.com/item?id=32338779)  
23. [**Ask HN: ZFS native encryption vs LUKS**](https://news.ycombinator.com/item?id=32340433) [`comments`](https://news.ycombinator.com/item?id=32340433)  
24. [**A simple guide to quadratic voting**](https://blog.tally.xyz/a-simple-guide-to-quadratic-voting-327b52addde1) `blog.tally.xyz` [`comments`](https://news.ycombinator.com/item?id=32337705)  
25. [**How to support open-source software and stay sane (2019)**](https://www.nature.com/articles/d41586-019-02046-0) `www.nature.com` [`comments`](https://news.ycombinator.com/item?id=32336010)",2022-08-04T09:08:08Z,2022-08-04T09:08:08Z,open,0,"Hacker News Daily, resources of dark pattern, HN News","DoorDash, examples","Doordash, blog, post, discussion",Papers/Docs/Sources,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/cavi-au/Consent-O-Matic/issues/79,Is this extension too complicated?,https://github.com/cavi-au/Consent-O-Matic/issues/79,"I'm sorry if this is a really stupid issue, but I feel like this extension is way overcomplicated. Why would anyone need support for specifically selecting cookies to allow? Doesn't everyone just deny all of them? Making a consent handler that goes through the entire dialogue clicking buttons and settings sliders and stuff doesn't seem logical when most (or at least most that I come across) simply contain a button to deny everything. I understand that these measures are still needed for the more annoying popups that don't feature such option, yet I believe this procedure is currently also employed for a few popups that _do_ in fact have one.

On a related note, I'm curious as to why there are seperate matchers for detecting when the popup exists on the page and when it is actually showing. Wouldn't it be enough to only account for the latter?",2022-06-27T20:31:24Z,2022-07-07T05:59:07Z,open,2,"usage of dark pattern, coerce users to accept the cookie consent, gdpr-enforced","pop-ups, personal imformation, data collection without consent","GDPR, cookie consent, privacy issue, data collection","DPs used in software, DPs related regulation ",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/509,"【CS-part1】New submissions for Mon, 14 Aug 23",https://github.com/Yukeaaa/arxiv-daily/issues/509,"## Keyword: volume render
There is no result 
## Keyword: volumetric render
There is no result 
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
### A matrix-free parallel solution method for the three-dimensional  heterogeneous Helmholtz equation
 - **Authors:** Jinqiang Chen, Vandana Dwarka, Cornelis Vuik
 - **Subjects:** Numerical Analysis (math.NA)
 - **Arxiv link:** https://arxiv.org/abs/2308.06085
 - **Pdf link:** https://arxiv.org/pdf/2308.06085
 - **Abstract**
 The Helmholtz equation is related to seismic exploration, sonar, antennas, and medical imaging applications. It is one of the most challenging problems to solve in terms of accuracy and convergence due to the scalability issues of the numerical solvers. For 3D large-scale applications, high-performance parallel solvers are also needed. In this paper, a matrix-free parallel iterative solver is presented for the three-dimensional (3D) heterogeneous Helmholtz equation. We consider the preconditioned Krylov subspace methods for solving the linear system obtained from finite-difference discretization. The Complex Shifted Laplace Preconditioner (CSLP) is employed since it results in a linear increase in the number of iterations as a function of the wavenumber. The preconditioner is approximately inverted using one parallel 3D multigrid cycle. For parallel computing, the global domain is partitioned blockwise. The matrix-vector multiplication and preconditioning operator are implemented in a matrix-free way instead of constructing large, memory-consuming coefficient matrices. Numerical experiments of 3D model problems demonstrate the robustness and outstanding strong scaling of our matrix-free parallel solution method. Moreover, the weak parallel scalability indicates our approach is suitable for realistic 3D heterogeneous Helmholtz problems with minimized pollution error.
### A matrix-free parallel two-level deflation preconditioner for the  two-dimensional Helmholtz problems
 - **Authors:** Jinqiang Chen, Vandana Dwarka, Cornelis Vuik
 - **Subjects:** Numerical Analysis (math.NA)
 - **Arxiv link:** https://arxiv.org/abs/2308.06152
 - **Pdf link:** https://arxiv.org/pdf/2308.06152
 - **Abstract**
 We propose a matrix-free parallel two-level-deflation preconditioner combined with the Complex Shifted Laplacian preconditioner(CSLP) for the two-dimensional Helmholtz problems. The Helmholtz equation is widely studied in seismic exploration, antennas, and medical imaging. It is one of the hardest problems to solve both in terms of accuracy and convergence, due to scalability issues of the numerical solvers. Motivated by the observation that for large wavenumbers, the eigenvalues of the CSLP-preconditioned system shift towards zero, deflation with multigrid vectors, and further high-order vectors were incorporated to obtain wave-number-independent convergence. For large-scale applications, high-performance parallel scalable methods are also indispensable. In our method, we consider the preconditioned Krylov subspace methods for solving the linear system obtained from finite-difference discretization. The CSLP preconditioner is approximated by one parallel geometric multigrid V-cycle. For the two-level deflation, the matrix-free Galerkin coarsening as well as high-order re-discretization approaches on the coarse grid are studied. The results of matrix-vector multiplications in Krylov subspace methods and the interpolation/restriction operators are implemented based on the finite-difference grids without constructing any coefficient matrix. These adjustments lead to direct improvements in terms of memory consumption. Numerical experiments of model problems show that wavenumber independence has been obtained for medium wavenumbers. The matrix-free parallel framework shows satisfactory weak and strong parallel scalability.
## Keyword: medical visualization
There is no result 
## Keyword: interactive volume
There is no result 
## Keyword: rendering
### VERF: Runtime Monitoring of Pose Estimation with Neural Radiance Fields
 - **Authors:** Dominic Maggio, Courtney Mario, Luca Carlone
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2308.05939
 - **Pdf link:** https://arxiv.org/pdf/2308.05939
 - **Abstract**
 We present VERF, a collection of two methods (VERF-PnP and VERF-Light) for providing runtime assurance on the correctness of a camera pose estimate of a monocular camera without relying on direct depth measurements. We leverage the ability of NeRF (Neural Radiance Fields) to render novel RGB perspectives of a scene. We only require as input the camera image whose pose is being estimated, an estimate of the camera pose we want to monitor, and a NeRF model containing the scene pictured by the camera. We can then predict if the pose estimate is within a desired distance from the ground truth and justify our prediction with a level of confidence. VERF-Light does this by rendering a viewpoint with NeRF at the estimated pose and estimating its relative offset to the sensor image up to scale. Since scene scale is unknown, the approach renders another auxiliary image and reasons over the consistency of the optical flows across the three images. VERF-PnP takes a different approach by rendering a stereo pair of images with NeRF and utilizing the Perspective-n-Point (PnP) algorithm. We evaluate both methods on the LLFF dataset, on data from a Unitree A1 quadruped robot, and on data collected from Blue Origin's sub-orbital New Shepard rocket to demonstrate the effectiveness of the proposed pose monitoring method across a range of scene scales. We also show monitoring can be completed in under half a second on a 3090 GPU.
### Focused Specific Objects NeRF
 - **Authors:** Yuesong Li, Feng Pan, Helong Yan, Xiuli Xin, Xiaoxue Feng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2308.05970
 - **Pdf link:** https://arxiv.org/pdf/2308.05970
 - **Abstract**
 Most NeRF-based models are designed for learning the entire scene, and complex scenes can lead to longer learning times and poorer rendering effects. This paper utilizes scene semantic priors to make improvements in fast training, allowing the network to focus on the specific targets and not be affected by complex backgrounds. The training speed can be increased by 7.78 times with better rendering effect, and small to medium sized targets can be rendered faster. In addition, this improvement applies to all NeRF-based models. Considering the inherent multi-view consistency and smoothness of NeRF, this paper also studies weak supervision by sparsely sampling negative ray samples. With this method, training can be further accelerated and rendering quality can be maintained. Finally, this paper extends pixel semantic and color rendering formulas and proposes a new scene editing technique that can achieve unique displays of the specific semantic targets or masking them in rendering. To address the problem of unsupervised regions incorrect inferences in the scene, we also designed a self-supervised loop that combines morphological operations and clustering.
### MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain  Adaption in 3D Object Detection
 - **Authors:** Darren Tsai, Julie Stephany Berrio, Mao Shan, Eduardo Nebot, Stewart Worrall
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.05988
 - **Pdf link:** https://arxiv.org/pdf/2308.05988
 - **Abstract**
 Deploying 3D detectors in unfamiliar domains has been demonstrated to result in a drastic drop of up to 70-90% in detection rate due to variations in lidar, geographical region, or weather conditions from their original training dataset. This domain gap leads to missing detections for densely observed objects, misaligned confidence scores, and increased high-confidence false positives, rendering the detector highly unreliable. To address this, we introduce MS3D++, a self-training framework for multi-source unsupervised domain adaptation in 3D object detection. MS3D++ provides a straightforward approach to domain adaptation by generating high-quality pseudo-labels, enabling the adaptation of 3D detectors to a diverse range of lidar types, regardless of their density. Our approach effectively fuses predictions of an ensemble of multi-frame pre-trained detectors from different source domains to improve domain generalization. We subsequently refine the predictions temporally to ensure temporal consistency in box localization and object classification. Furthermore, we present an in-depth study into the performance and idiosyncrasies of various 3D detector components in a cross-domain context, providing valuable insights for improved cross-domain detector ensembling. Experimental results on Waymo, nuScenes and Lyft demonstrate that detectors trained with MS3D++ pseudo-labels achieve state-of-the-art performance, comparable to training with human-annotated labels in Bird's Eye View (BEV) evaluation for both low and high density lidar.
## Keyword: cinematic rendering
There is no result 
## Keyword: volume data
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: retrieval
### LittleMu: Deploying an Online Virtual Teaching Assistant via  Heterogeneous Sources Integration and Chain of Teach Prompts
 - **Authors:** Shangqing Tu, Zheyuan Zhang, Jifan Yu, Chunyang Li, Siyu Zhang, Zijun Yao, Lei Hou, Juanzi Li
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
 - **Arxiv link:** https://arxiv.org/abs/2308.05935
 - **Pdf link:** https://arxiv.org/pdf/2308.05935
 - **Abstract**
 Teaching assistants have played essential roles in the long history of education. However, few MOOC platforms are providing human or virtual teaching assistants to support learning for massive online students due to the complexity of real-world online education scenarios and the lack of training data. In this paper, we present a virtual MOOC teaching assistant, LittleMu with minimum labeled training data, to provide question answering and chit-chat services. Consisting of two interactive modules of heterogeneous retrieval and language model prompting, LittleMu first integrates structural, semi- and unstructured knowledge sources to support accurate answers for a wide range of questions. Then, we design delicate demonstrations named ""Chain of Teach"" prompts to exploit the large-scale pre-trained model to handle complex uncollected questions. Except for question answering, we develop other educational services such as knowledge-grounded chit-chat. We test the system's performance via both offline evaluation and online deployment. Since May 2020, our LittleMu system has served over 80,000 users with over 300,000 queries from over 500 courses on XuetangX MOOC platform, which continuously contributes to a more convenient and fair education. Our code, services, and dataset will be available at https://github.com/THU-KEG/VTA.
### Uncertainty-Aware Cross-Modal Transfer Network for Sketch-Based 3D Shape  Retrieval
 - **Authors:** Yiyang Cai, Jiaming Lu, Jiewen Wang, Shuang Liang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.05948
 - **Pdf link:** https://arxiv.org/pdf/2308.05948
 - **Abstract**
 In recent years, sketch-based 3D shape retrieval has attracted growing attention. While many previous studies have focused on cross-modal matching between hand-drawn sketches and 3D shapes, the critical issue of how to handle low-quality and noisy samples in sketch data has been largely neglected. This paper presents an uncertainty-aware cross-modal transfer network (UACTN) that addresses this issue. UACTN decouples the representation learning of sketches and 3D shapes into two separate tasks: classification-based sketch uncertainty learning and 3D shape feature transfer. We first introduce an end-to-end classification-based approach that simultaneously learns sketch features and uncertainty, allowing uncertainty to prevent overfitting noisy sketches by assigning different levels of importance to clean and noisy sketches. Then, 3D shape features are mapped into the pre-learned sketch embedding space for feature alignment. Extensive experiments and ablation studies on two benchmarks demonstrate the superiority of our proposed method compared to state-of-the-art methods.
### Identification of the Relevance of Comments in Codes Using Bag of Words  and Transformer Based Models
 - **Authors:** Sruthi S, Tanmay Basu
 - **Subjects:** Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2308.06144
 - **Pdf link:** https://arxiv.org/pdf/2308.06144
 - **Abstract**
 The Forum for Information Retrieval (FIRE) started a shared task this year for classification of comments of different code segments. This is binary text classification task where the objective is to identify whether comments given for certain code segments are relevant or not. The BioNLP-IISERB group at the Indian Institute of Science Education and Research Bhopal (IISERB) participated in this task and submitted five runs for five different models. The paper presents the overview of the models and other significant findings on the training corpus. The methods involve different feature engineering schemes and text classification techniques. The performance of the classical bag of words model and transformer-based models were explored to identify significant features from the given training corpus. We have explored different classifiers viz., random forest, support vector machine and logistic regression using the bag of words model. Furthermore, the pre-trained transformer based models like BERT, RoBERT and ALBERT were also used by fine-tuning them on the given training corpus. The performance of different such models over the training corpus were reported and the best five models were implemented on the given test corpus. The empirical results show that the bag of words model outperforms the transformer based models, however, the performance of our runs are not reasonably well in both training and test corpus. This paper also addresses the limitations of the models and scope for further improvement.
## Keyword: video retrieval
There is no result 
## Keyword: mobile
### Slicing the Network: Maintaining Neutrality, Protecting Privacy, and  Promoting Competition
 - **Authors:** Nick Doty, Mallory Knodel
 - **Subjects:** Networking and Internet Architecture (cs.NI); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2308.05829
 - **Pdf link:** https://arxiv.org/pdf/2308.05829
 - **Abstract**
 The principles of net neutrality have been essential for maintaining the diversity of services built on top of the internet and for maintaining some competition between small and large providers of those online services. That diversity and competition, in turn, provide users with a broader array of choices for seeking online content and disseminating their own speech. Furthermore, in order for the internet to be used to its full potential and to protect the human rights of internet users, we need privacy from surveillance and unwarranted data collection by governments, network providers, and edge providers. The transition to 5G mobile networks enables network operators to engage in a technique called network slicing. The portion of a network that is sliced can be used to provide a suite of different service offerings, each tailored to specific purposes, instead of a single, general-purpose subscription for mobile voice and data. This requires a careful approach. Our report describes the technologies used for network slicing and outlines recommendations -- for both operators and regulators -- to enable network slicing while maintaining network neutrality, protecting privacy, and promoting competition.
### Shared Memory-contention-aware Concurrent DNN Execution for Diversely  Heterogeneous System-on-Chips
 - **Authors:** Ismet Dagli, Mehmet Belviranli
 - **Subjects:** Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Performance (cs.PF)
 - **Arxiv link:** https://arxiv.org/abs/2308.05869
 - **Pdf link:** https://arxiv.org/pdf/2308.05869
 - **Abstract**
 Two distinguishing features of state-of-the-art mobile and autonomous systems are 1) there are often multiple workloads, mainly deep neural network (DNN) inference, running concurrently and continuously; and 2) they operate on shared memory system-on-chips (SoC) that embed heterogeneous accelerators tailored for specific operations. State-of-the-art lacks efficient performance and resource management techniques necessary to either maximize total system throughput or minimize end-to-end workload latency. In this work, we propose HaX-CoNN, a novel scheme that characterizes and maps layers in concurrently executing DNN inference workloads to a diverse set of accelerators within a SoC. Our scheme uniquely takes per-layer execution characteristics, shared memory (SM) contention, and inter-accelerator transitions into account to find optimal schedules. We evaluate HaX-CoNN on NVIDIA Orin, NVIDIA Xavier, and Qualcomm Snapdragon 865 SoCs. Our experimental results indicate that HaX-CoNN minimizes memory contention by up to 45% and can improve latency and total throughput by up to 32% and 29%, respectively, compared to the state-of-the-art approaches.
### PrivacyLens: A Framework to Collect and Analyze the Landscape of Past,  Present, and Future Smart Device Privacy Policies
 - **Authors:** Aamir Hamid, Hemanth Reddy Samidi, Tim Finin, Primal Pappachan, Roberto Yus
 - **Subjects:** Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2308.05890
 - **Pdf link:** https://arxiv.org/pdf/2308.05890
 - **Abstract**
 As the adoption of smart devices continues to permeate all aspects of our lives, concerns surrounding user privacy have become more pertinent than ever before. While privacy policies define the data management practices of their manufacturers, previous work has shown that they are rarely read and understood by users. Hence, automatic analysis of privacy policies has been shown to help provide users with appropriate insights. Previous research has extensively analyzed privacy policies of websites, e-commerce, and mobile applications, but privacy policies of smart devices, present some differences and specific challenges such as the difficulty to find and collect them. We present PrivacyLens, a novel framework for discovering and collecting past, present, and future smart device privacy policies and harnessing NLP and ML algorithms to analyze them. PrivacyLens is currently deployed, collecting, analyzing, and publishing insights about privacy policies to assist different stakeholders of smart devices, such as users, policy authors, and regulators. We show several examples of analytical tasks enabled by PrivacyLens, including comparisons of devices per type and manufacturing country, categorization of privacy policies, and impact of data regulations on data practices. At the time of submitting this paper, PrivacyLens had collected and analyzed more than 1,200 privacy policies for 7,300 smart device
### Unveiling the Tricks: Automated Detection of Dark Patterns in Mobile  Applications
 - **Authors:** Jieshan Chen, Jiamou Sun, Sidong Feng, Zhenchang Xing, Qinghua Lu, Xiwei Xu, Chunyang Chen
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2308.05898
 - **Pdf link:** https://arxiv.org/pdf/2308.05898
 - **Abstract**
 Mobile apps bring us many conveniences, such as online shopping and communication, but some use malicious designs called dark patterns to trick users into doing things that are not in their best interest. Many works have been done to summarize the taxonomy of these patterns and some have tried to mitigate the problems through various techniques. However, these techniques are either time-consuming, not generalisable or limited to specific patterns. To address these issues, we propose UIGuard, a knowledge-driven system that utilizes computer vision and natural language pattern matching to automatically detect a wide range of dark patterns in mobile UIs. Our system relieves the need for manually creating rules for each new UI/app and covers more types with superior performance. In detail, we integrated existing taxonomies into a consistent one, conducted a characteristic analysis and distilled knowledge from real-world examples and the taxonomy. Our UIGuard consists of two components, Property Extraction and Knowledge-Driven Dark Pattern Checker. We collected the first dark pattern dataset, which contains 4,999 benign UIs and 1,353 malicious UIs of 1,660 instances spanning 1,023 mobile apps. Our system achieves a superior performance in detecting dark patterns (micro averages: 0.82 in precision, 0.77 in recall, 0.79 in F1 score). A user study involving 58 participants further shows that \tool{} significantly increases users' knowledge of dark patterns.
### Spatial-information Guided Adaptive Context-aware Network for Efficient  RGB-D Semantic Segmentation
 - **Authors:** Yang Zhang, Chenyun Xiong, Junjie Liu, Xuhui Ye, Guodong Sun
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.06024
 - **Pdf link:** https://arxiv.org/pdf/2308.06024
 - **Abstract**
 Efficient RGB-D semantic segmentation has received considerable attention in mobile robots, which plays a vital role in analyzing and recognizing environmental information. According to previous studies, depth information can provide corresponding geometric relationships for objects and scenes, but actual depth data usually exist as noise. To avoid unfavorable effects on segmentation accuracy and computation, it is necessary to design an efficient framework to leverage cross-modal correlations and complementary cues. In this paper, we propose an efficient lightweight encoder-decoder network that reduces the computational parameters and guarantees the robustness of the algorithm. Working with channel and spatial fusion attention modules, our network effectively captures multi-level RGB-D features. A globally guided local affinity context module is proposed to obtain sufficient high-level context information. The decoder utilizes a lightweight residual unit that combines short- and long-distance information with a few redundant computations. Experimental results on NYUv2, SUN RGB-D, and Cityscapes datasets show that our method achieves a better trade-off among segmentation accuracy, inference time, and parameters than the state-of-the-art methods. The source code will be at https://github.com/MVME-HBUT/SGACNet
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
",2023-08-15T01:05:11Z,2023-08-15T01:05:11Z,open,0,"paper/literature of dark pattern, document, paper title: Unveiling the Tricks: Automated Detection of Dark Patterns in Mobile Applications","definition, example, detection",documentation,Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/504,"【CS-part1】New submissions for Mon, 14 Aug 23",https://github.com/Yukeaaa/arxiv-daily/issues/504,"## Keyword: volume render
There is no result 
## Keyword: volumetric render
There is no result 
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
### A matrix-free parallel solution method for the three-dimensional  heterogeneous Helmholtz equation
 - **Authors:** Jinqiang Chen, Vandana Dwarka, Cornelis Vuik
 - **Subjects:** Numerical Analysis (math.NA)
 - **Arxiv link:** https://arxiv.org/abs/2308.06085
 - **Pdf link:** https://arxiv.org/pdf/2308.06085
 - **Abstract**
 The Helmholtz equation is related to seismic exploration, sonar, antennas, and medical imaging applications. It is one of the most challenging problems to solve in terms of accuracy and convergence due to the scalability issues of the numerical solvers. For 3D large-scale applications, high-performance parallel solvers are also needed. In this paper, a matrix-free parallel iterative solver is presented for the three-dimensional (3D) heterogeneous Helmholtz equation. We consider the preconditioned Krylov subspace methods for solving the linear system obtained from finite-difference discretization. The Complex Shifted Laplace Preconditioner (CSLP) is employed since it results in a linear increase in the number of iterations as a function of the wavenumber. The preconditioner is approximately inverted using one parallel 3D multigrid cycle. For parallel computing, the global domain is partitioned blockwise. The matrix-vector multiplication and preconditioning operator are implemented in a matrix-free way instead of constructing large, memory-consuming coefficient matrices. Numerical experiments of 3D model problems demonstrate the robustness and outstanding strong scaling of our matrix-free parallel solution method. Moreover, the weak parallel scalability indicates our approach is suitable for realistic 3D heterogeneous Helmholtz problems with minimized pollution error.
### A matrix-free parallel two-level deflation preconditioner for the  two-dimensional Helmholtz problems
 - **Authors:** Jinqiang Chen, Vandana Dwarka, Cornelis Vuik
 - **Subjects:** Numerical Analysis (math.NA)
 - **Arxiv link:** https://arxiv.org/abs/2308.06152
 - **Pdf link:** https://arxiv.org/pdf/2308.06152
 - **Abstract**
 We propose a matrix-free parallel two-level-deflation preconditioner combined with the Complex Shifted Laplacian preconditioner(CSLP) for the two-dimensional Helmholtz problems. The Helmholtz equation is widely studied in seismic exploration, antennas, and medical imaging. It is one of the hardest problems to solve both in terms of accuracy and convergence, due to scalability issues of the numerical solvers. Motivated by the observation that for large wavenumbers, the eigenvalues of the CSLP-preconditioned system shift towards zero, deflation with multigrid vectors, and further high-order vectors were incorporated to obtain wave-number-independent convergence. For large-scale applications, high-performance parallel scalable methods are also indispensable. In our method, we consider the preconditioned Krylov subspace methods for solving the linear system obtained from finite-difference discretization. The CSLP preconditioner is approximated by one parallel geometric multigrid V-cycle. For the two-level deflation, the matrix-free Galerkin coarsening as well as high-order re-discretization approaches on the coarse grid are studied. The results of matrix-vector multiplications in Krylov subspace methods and the interpolation/restriction operators are implemented based on the finite-difference grids without constructing any coefficient matrix. These adjustments lead to direct improvements in terms of memory consumption. Numerical experiments of model problems show that wavenumber independence has been obtained for medium wavenumbers. The matrix-free parallel framework shows satisfactory weak and strong parallel scalability.
## Keyword: medical visualization
There is no result 
## Keyword: interactive volume
There is no result 
## Keyword: rendering
### VERF: Runtime Monitoring of Pose Estimation with Neural Radiance Fields
 - **Authors:** Dominic Maggio, Courtney Mario, Luca Carlone
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2308.05939
 - **Pdf link:** https://arxiv.org/pdf/2308.05939
 - **Abstract**
 We present VERF, a collection of two methods (VERF-PnP and VERF-Light) for providing runtime assurance on the correctness of a camera pose estimate of a monocular camera without relying on direct depth measurements. We leverage the ability of NeRF (Neural Radiance Fields) to render novel RGB perspectives of a scene. We only require as input the camera image whose pose is being estimated, an estimate of the camera pose we want to monitor, and a NeRF model containing the scene pictured by the camera. We can then predict if the pose estimate is within a desired distance from the ground truth and justify our prediction with a level of confidence. VERF-Light does this by rendering a viewpoint with NeRF at the estimated pose and estimating its relative offset to the sensor image up to scale. Since scene scale is unknown, the approach renders another auxiliary image and reasons over the consistency of the optical flows across the three images. VERF-PnP takes a different approach by rendering a stereo pair of images with NeRF and utilizing the Perspective-n-Point (PnP) algorithm. We evaluate both methods on the LLFF dataset, on data from a Unitree A1 quadruped robot, and on data collected from Blue Origin's sub-orbital New Shepard rocket to demonstrate the effectiveness of the proposed pose monitoring method across a range of scene scales. We also show monitoring can be completed in under half a second on a 3090 GPU.
### Focused Specific Objects NeRF
 - **Authors:** Yuesong Li, Feng Pan, Helong Yan, Xiuli Xin, Xiaoxue Feng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2308.05970
 - **Pdf link:** https://arxiv.org/pdf/2308.05970
 - **Abstract**
 Most NeRF-based models are designed for learning the entire scene, and complex scenes can lead to longer learning times and poorer rendering effects. This paper utilizes scene semantic priors to make improvements in fast training, allowing the network to focus on the specific targets and not be affected by complex backgrounds. The training speed can be increased by 7.78 times with better rendering effect, and small to medium sized targets can be rendered faster. In addition, this improvement applies to all NeRF-based models. Considering the inherent multi-view consistency and smoothness of NeRF, this paper also studies weak supervision by sparsely sampling negative ray samples. With this method, training can be further accelerated and rendering quality can be maintained. Finally, this paper extends pixel semantic and color rendering formulas and proposes a new scene editing technique that can achieve unique displays of the specific semantic targets or masking them in rendering. To address the problem of unsupervised regions incorrect inferences in the scene, we also designed a self-supervised loop that combines morphological operations and clustering.
### MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain  Adaption in 3D Object Detection
 - **Authors:** Darren Tsai, Julie Stephany Berrio, Mao Shan, Eduardo Nebot, Stewart Worrall
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.05988
 - **Pdf link:** https://arxiv.org/pdf/2308.05988
 - **Abstract**
 Deploying 3D detectors in unfamiliar domains has been demonstrated to result in a drastic drop of up to 70-90% in detection rate due to variations in lidar, geographical region, or weather conditions from their original training dataset. This domain gap leads to missing detections for densely observed objects, misaligned confidence scores, and increased high-confidence false positives, rendering the detector highly unreliable. To address this, we introduce MS3D++, a self-training framework for multi-source unsupervised domain adaptation in 3D object detection. MS3D++ provides a straightforward approach to domain adaptation by generating high-quality pseudo-labels, enabling the adaptation of 3D detectors to a diverse range of lidar types, regardless of their density. Our approach effectively fuses predictions of an ensemble of multi-frame pre-trained detectors from different source domains to improve domain generalization. We subsequently refine the predictions temporally to ensure temporal consistency in box localization and object classification. Furthermore, we present an in-depth study into the performance and idiosyncrasies of various 3D detector components in a cross-domain context, providing valuable insights for improved cross-domain detector ensembling. Experimental results on Waymo, nuScenes and Lyft demonstrate that detectors trained with MS3D++ pseudo-labels achieve state-of-the-art performance, comparable to training with human-annotated labels in Bird's Eye View (BEV) evaluation for both low and high density lidar.
## Keyword: cinematic rendering
There is no result 
## Keyword: volume data
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: retrieval
### LittleMu: Deploying an Online Virtual Teaching Assistant via  Heterogeneous Sources Integration and Chain of Teach Prompts
 - **Authors:** Shangqing Tu, Zheyuan Zhang, Jifan Yu, Chunyang Li, Siyu Zhang, Zijun Yao, Lei Hou, Juanzi Li
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
 - **Arxiv link:** https://arxiv.org/abs/2308.05935
 - **Pdf link:** https://arxiv.org/pdf/2308.05935
 - **Abstract**
 Teaching assistants have played essential roles in the long history of education. However, few MOOC platforms are providing human or virtual teaching assistants to support learning for massive online students due to the complexity of real-world online education scenarios and the lack of training data. In this paper, we present a virtual MOOC teaching assistant, LittleMu with minimum labeled training data, to provide question answering and chit-chat services. Consisting of two interactive modules of heterogeneous retrieval and language model prompting, LittleMu first integrates structural, semi- and unstructured knowledge sources to support accurate answers for a wide range of questions. Then, we design delicate demonstrations named ""Chain of Teach"" prompts to exploit the large-scale pre-trained model to handle complex uncollected questions. Except for question answering, we develop other educational services such as knowledge-grounded chit-chat. We test the system's performance via both offline evaluation and online deployment. Since May 2020, our LittleMu system has served over 80,000 users with over 300,000 queries from over 500 courses on XuetangX MOOC platform, which continuously contributes to a more convenient and fair education. Our code, services, and dataset will be available at https://github.com/THU-KEG/VTA.
### Uncertainty-Aware Cross-Modal Transfer Network for Sketch-Based 3D Shape  Retrieval
 - **Authors:** Yiyang Cai, Jiaming Lu, Jiewen Wang, Shuang Liang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.05948
 - **Pdf link:** https://arxiv.org/pdf/2308.05948
 - **Abstract**
 In recent years, sketch-based 3D shape retrieval has attracted growing attention. While many previous studies have focused on cross-modal matching between hand-drawn sketches and 3D shapes, the critical issue of how to handle low-quality and noisy samples in sketch data has been largely neglected. This paper presents an uncertainty-aware cross-modal transfer network (UACTN) that addresses this issue. UACTN decouples the representation learning of sketches and 3D shapes into two separate tasks: classification-based sketch uncertainty learning and 3D shape feature transfer. We first introduce an end-to-end classification-based approach that simultaneously learns sketch features and uncertainty, allowing uncertainty to prevent overfitting noisy sketches by assigning different levels of importance to clean and noisy sketches. Then, 3D shape features are mapped into the pre-learned sketch embedding space for feature alignment. Extensive experiments and ablation studies on two benchmarks demonstrate the superiority of our proposed method compared to state-of-the-art methods.
### Identification of the Relevance of Comments in Codes Using Bag of Words  and Transformer Based Models
 - **Authors:** Sruthi S, Tanmay Basu
 - **Subjects:** Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2308.06144
 - **Pdf link:** https://arxiv.org/pdf/2308.06144
 - **Abstract**
 The Forum for Information Retrieval (FIRE) started a shared task this year for classification of comments of different code segments. This is binary text classification task where the objective is to identify whether comments given for certain code segments are relevant or not. The BioNLP-IISERB group at the Indian Institute of Science Education and Research Bhopal (IISERB) participated in this task and submitted five runs for five different models. The paper presents the overview of the models and other significant findings on the training corpus. The methods involve different feature engineering schemes and text classification techniques. The performance of the classical bag of words model and transformer-based models were explored to identify significant features from the given training corpus. We have explored different classifiers viz., random forest, support vector machine and logistic regression using the bag of words model. Furthermore, the pre-trained transformer based models like BERT, RoBERT and ALBERT were also used by fine-tuning them on the given training corpus. The performance of different such models over the training corpus were reported and the best five models were implemented on the given test corpus. The empirical results show that the bag of words model outperforms the transformer based models, however, the performance of our runs are not reasonably well in both training and test corpus. This paper also addresses the limitations of the models and scope for further improvement.
## Keyword: video retrieval
There is no result 
## Keyword: mobile
### Slicing the Network: Maintaining Neutrality, Protecting Privacy, and  Promoting Competition
 - **Authors:** Nick Doty, Mallory Knodel
 - **Subjects:** Networking and Internet Architecture (cs.NI); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2308.05829
 - **Pdf link:** https://arxiv.org/pdf/2308.05829
 - **Abstract**
 The principles of net neutrality have been essential for maintaining the diversity of services built on top of the internet and for maintaining some competition between small and large providers of those online services. That diversity and competition, in turn, provide users with a broader array of choices for seeking online content and disseminating their own speech. Furthermore, in order for the internet to be used to its full potential and to protect the human rights of internet users, we need privacy from surveillance and unwarranted data collection by governments, network providers, and edge providers. The transition to 5G mobile networks enables network operators to engage in a technique called network slicing. The portion of a network that is sliced can be used to provide a suite of different service offerings, each tailored to specific purposes, instead of a single, general-purpose subscription for mobile voice and data. This requires a careful approach. Our report describes the technologies used for network slicing and outlines recommendations -- for both operators and regulators -- to enable network slicing while maintaining network neutrality, protecting privacy, and promoting competition.
### Shared Memory-contention-aware Concurrent DNN Execution for Diversely  Heterogeneous System-on-Chips
 - **Authors:** Ismet Dagli, Mehmet Belviranli
 - **Subjects:** Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Performance (cs.PF)
 - **Arxiv link:** https://arxiv.org/abs/2308.05869
 - **Pdf link:** https://arxiv.org/pdf/2308.05869
 - **Abstract**
 Two distinguishing features of state-of-the-art mobile and autonomous systems are 1) there are often multiple workloads, mainly deep neural network (DNN) inference, running concurrently and continuously; and 2) they operate on shared memory system-on-chips (SoC) that embed heterogeneous accelerators tailored for specific operations. State-of-the-art lacks efficient performance and resource management techniques necessary to either maximize total system throughput or minimize end-to-end workload latency. In this work, we propose HaX-CoNN, a novel scheme that characterizes and maps layers in concurrently executing DNN inference workloads to a diverse set of accelerators within a SoC. Our scheme uniquely takes per-layer execution characteristics, shared memory (SM) contention, and inter-accelerator transitions into account to find optimal schedules. We evaluate HaX-CoNN on NVIDIA Orin, NVIDIA Xavier, and Qualcomm Snapdragon 865 SoCs. Our experimental results indicate that HaX-CoNN minimizes memory contention by up to 45% and can improve latency and total throughput by up to 32% and 29%, respectively, compared to the state-of-the-art approaches.
### PrivacyLens: A Framework to Collect and Analyze the Landscape of Past,  Present, and Future Smart Device Privacy Policies
 - **Authors:** Aamir Hamid, Hemanth Reddy Samidi, Tim Finin, Primal Pappachan, Roberto Yus
 - **Subjects:** Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2308.05890
 - **Pdf link:** https://arxiv.org/pdf/2308.05890
 - **Abstract**
 As the adoption of smart devices continues to permeate all aspects of our lives, concerns surrounding user privacy have become more pertinent than ever before. While privacy policies define the data management practices of their manufacturers, previous work has shown that they are rarely read and understood by users. Hence, automatic analysis of privacy policies has been shown to help provide users with appropriate insights. Previous research has extensively analyzed privacy policies of websites, e-commerce, and mobile applications, but privacy policies of smart devices, present some differences and specific challenges such as the difficulty to find and collect them. We present PrivacyLens, a novel framework for discovering and collecting past, present, and future smart device privacy policies and harnessing NLP and ML algorithms to analyze them. PrivacyLens is currently deployed, collecting, analyzing, and publishing insights about privacy policies to assist different stakeholders of smart devices, such as users, policy authors, and regulators. We show several examples of analytical tasks enabled by PrivacyLens, including comparisons of devices per type and manufacturing country, categorization of privacy policies, and impact of data regulations on data practices. At the time of submitting this paper, PrivacyLens had collected and analyzed more than 1,200 privacy policies for 7,300 smart device
### Unveiling the Tricks: Automated Detection of Dark Patterns in Mobile  Applications
 - **Authors:** Jieshan Chen, Jiamou Sun, Sidong Feng, Zhenchang Xing, Qinghua Lu, Xiwei Xu, Chunyang Chen
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2308.05898
 - **Pdf link:** https://arxiv.org/pdf/2308.05898
 - **Abstract**
 Mobile apps bring us many conveniences, such as online shopping and communication, but some use malicious designs called dark patterns to trick users into doing things that are not in their best interest. Many works have been done to summarize the taxonomy of these patterns and some have tried to mitigate the problems through various techniques. However, these techniques are either time-consuming, not generalisable or limited to specific patterns. To address these issues, we propose UIGuard, a knowledge-driven system that utilizes computer vision and natural language pattern matching to automatically detect a wide range of dark patterns in mobile UIs. Our system relieves the need for manually creating rules for each new UI/app and covers more types with superior performance. In detail, we integrated existing taxonomies into a consistent one, conducted a characteristic analysis and distilled knowledge from real-world examples and the taxonomy. Our UIGuard consists of two components, Property Extraction and Knowledge-Driven Dark Pattern Checker. We collected the first dark pattern dataset, which contains 4,999 benign UIs and 1,353 malicious UIs of 1,660 instances spanning 1,023 mobile apps. Our system achieves a superior performance in detecting dark patterns (micro averages: 0.82 in precision, 0.77 in recall, 0.79 in F1 score). A user study involving 58 participants further shows that \tool{} significantly increases users' knowledge of dark patterns.
### Spatial-information Guided Adaptive Context-aware Network for Efficient  RGB-D Semantic Segmentation
 - **Authors:** Yang Zhang, Chenyun Xiong, Junjie Liu, Xuhui Ye, Guodong Sun
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2308.06024
 - **Pdf link:** https://arxiv.org/pdf/2308.06024
 - **Abstract**
 Efficient RGB-D semantic segmentation has received considerable attention in mobile robots, which plays a vital role in analyzing and recognizing environmental information. According to previous studies, depth information can provide corresponding geometric relationships for objects and scenes, but actual depth data usually exist as noise. To avoid unfavorable effects on segmentation accuracy and computation, it is necessary to design an efficient framework to leverage cross-modal correlations and complementary cues. In this paper, we propose an efficient lightweight encoder-decoder network that reduces the computational parameters and guarantees the robustness of the algorithm. Working with channel and spatial fusion attention modules, our network effectively captures multi-level RGB-D features. A globally guided local affinity context module is proposed to obtain sufficient high-level context information. The decoder utilizes a lightweight residual unit that combines short- and long-distance information with a few redundant computations. Experimental results on NYUv2, SUN RGB-D, and Cityscapes datasets show that our method achieves a better trade-off among segmentation accuracy, inference time, and parameters than the state-of-the-art methods. The source code will be at https://github.com/MVME-HBUT/SGACNet
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
",2023-08-14T01:05:09Z,2023-08-14T01:05:09Z,open,0,"paper/literature of dark pattern, document, paper title: Unveiling the Tricks: Automated Detection of Dark Patterns in Mobile Applications","definition, example, detection",,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/tijlleenders/ZinZen/issues/605,Create a Privacy page,https://github.com/tijlleenders/ZinZen/issues/605,"Create a page that can be viewed from Dashbaord => ZinZen => Legal => Privacy.

The text (initial proposal - comments from community welcome) should be the following:
```
<b>ZinZen&reg; honors your trust.</b><br /> Feel free to contact us about anything.<br />
                <br /> You can use ZinZen&reg; in pure
                offline mode - or create an anonymous account.<br />We can't (be
                required to)
                share any personal data if we don't
                receive any!<br />
                <br />
                <b>How ZinZen&reg; protects (personal) data:</b><br /> We <b>minimally</b> abide by the laws of the countries
                we operate in - and we only operate in countries that have acceptable laws.<br /> We <b>go further</b>
                by applying the strong(est)
                General Data Protection Regulation (GDPR) - even when not required.
                <br /> We <b>go even further</b> by applying any other reasonable privacy or security measures.<br />
                <br />
                <b>By default, ZinZen&reg; promises:</b><br /> - Login options: no login / anonymous / email
                (alias) /
                <s>social</s>).
                <br /> - ALL your personal data is safe and private - FOREVER.<br />
                - You don't get ANY dark patterns or
                advertisements - EVER.
                <br /> - ANYTHING you choose to send over the internet to us is protected and encrypted - in
                transit and at rest.<br /> - You don't get ANY cookies. If
                you choose to login you get a cookie that only stores an anonymous access token.<br />
                <br>
                <b>Storage on your device</b><br />
                Virtually all apps store data on your device without encrypting it. Even the most secure messaging apps
                don't have an extra password lock. They rely on your phone protection.<br />For the truly paranoid we'll
                provide an option to password-protect ZinZen&reg; at the app-level.<br />
                <br />
                <b>What (personal) data ZinZen&reg; collects - and if/why we use it:</b><br /> ""Personal data"" is any data
                about you or your behavior that can be traced back to you without disproportionate effort.
                <br /> The rest is just ""data"".<br />
                <b>By default, all personal data is stored FOR YOUR EYES ONLY.</b><br />
                <b>For ZinZen&reg; to share any personal data - any personal data at all - YOU need to ask us EXPLICITLY,
                    even when
                    you want to share your data with us, ZinZen.</b><br /> Only then will ZinZen&reg; share what you chose to
                share - and only that - to only those you chose to share with.
                <br /> If you choose to share your personal data with ZinZen&reg; by clicking the button 'share with ZinZen
                anonymously' - any connection to you as a person will be removed; turning it into data.<br /> This data
                helps ZinZen&reg; improve your experience
                and that of others, as well as develop new services.<br />
                <br />
                <b>To update/manage/export/delete your personal data : ZinZen&reg; => My settings.</b><br />
```",2022-08-19T07:47:36Z,2023-09-28T06:07:56Z,open,0,"ZinZen, prevention of dark pattern in design, privacy page, cookie consent form, gdpr compliance",,"ZinZen, privacy issue, GDPR, avoid dark pattern","DPs prevention in software, DPs related regulation ",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/pimoroni/picosystem/issues/74,Ease onboarding with Gitpod,https://github.com/pimoroni/picosystem/pull/74,"[Gitpod](https://gitpod.io) is a tool allowing to have workspace in the cloud with anything you need to work on any specific task.
I configured everything to allow building and contributing to picosystem project.
I hope this will ease contribution and work with picosystem.",2022-01-11T16:56:58Z,2022-01-24T17:21:17Z,open,5,"GitPod (standardized and automated development environments), deceptive design practices, 'always free"", trick wording","SAAS industry, ""always free"". marketing, hidden costs","Gitpod, trick wording, hidden costs, deceptive design practices","DPs in design coding, DPs examples/definitions",,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/relikd/baRSS/issues/11,Allow Apple to scan for malware,https://github.com/relikd/baRSS/issues/11,,2022-11-17T17:32:29Z,2022-11-17T18:57:27Z,open,11,"Apple, IOS, AppStore, dark pattern in software, publish only if you pay, closed garden","Apple, pay to publish, obstruction, forced action","Apple, iOS, App Store, forced action",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/nextcloud/desktop/issues/5396,"[Bug]: Invalid SSL cert pops warning every minute, encouraging unsafe choice",https://github.com/nextcloud/desktop/issues/5396,"### ⚠️ Before submitting, please verify the following: ⚠️

- [X] This is a **bug**, not a question or a configuration issue.
- [X] This issue is **not** already reported on Github (I've searched it).
- [X] Nextcloud Server and Desktop Client are **up to date**. See [Server Maintenance and Release Schedule](https://github.com/nextcloud/server/wiki/Maintenance-and-Release-Schedule) and [Desktop Releases](https://nextcloud.com/install/#install-clients) for supported versions.
- [X] I agree to follow Nextcloud's [Code of Conduct](https://nextcloud.com/contribute/code-of-conduct/)

### Bug description

Hello, 

I was a bit torn on whether to post here on the form, but I think this matter deserves to be discussed among developers and should ultimately result in a change to code. I also know that the root cause for my problem is not necessarily the Nextcloud client itself. But I think we can make a small change that will make NC more secure for everyone, so please hear me out. :) 

My Situation is as follows: 
I have my client connected to multiple NC servers, a few private ones and a few for work. This seems to be a common use-case among a lot of people that I know. It so happens that one of the server I am connected to for reasons of work has administrators that occasionally let a the SSL certificate expire. Of course that always happens when they are on vacation for the next few days and no one else can address it. ;)  This causes an ""invalid certificate"" warning to be raised by the nextcloud client **every minute**.

I have tried to ""pause sync"" for that server. and it appears that I was already ""signed out"" from it automatically, but still: The warning shows up every minute. After trying around for a bit, I have concluded that the only ways I can ""make the warning go away"" are:
- quitting the nextcloud client entirely - which cuts me off from my private servers 
- completely disconnect the offending server from my client - which means I have to set it up later again.
Both are a major nuisance...

Now I personally, am a security-professional, so I naturally opt for the more secure options, even if its annoying. But talking to my coworkers, I discovered that a lot of them will just tick `[ ] Trust this certificate anyway` to get on with their lives. I know its kinda sad but lets be honest, that's how people work. :shrug: 
Of course, on one hand that is ""their problem"" now, but in another way it is like the NC Client is almost nudging them towards this course of action with the annoying repeated prompt. Which leads me to my proposal, see ""Expected behavior"".






 






### Steps to reproduce

1. Add a nextcloud server with an expired ssl certificate to your client
2. Get spammed with pop-up notifications...


### Expected behavior

Since expired certificates are a rather common problem, I think NC Client should handle the interaction with the user more ""constructively"". I.e.: Not nudging the user into making an insecure choice (""Trust this cert anyway""). 

The easiest fix would be to reduce the frequency with which this warning pops up. 
An even better way might be offering the user a better explanation of what is happening, what he can/should do and clearly mark the consequences of each, something like:


-------

Cannot connect securely to `<servername>`:
`<Short reason>`

`<Button to show details of the certificate>`

You should contact the adminstrator of your server to get this problem fixed. If you are the administrator see <link> for common causes of this Problem. 

For now you may choose to:
1. Pause sync for this server and suppress this warning for some time. (This warning might come up again when you resume sync and the problem was not fixed.)
    - 1 Hr 
    - 1 Day
2. Trust this certificate anyway. WARNING THIS IS DANGEROUS, NC CLient can not ensure that it is communicating with the correct server! You might be under attack.


---------

I believe this would do a lot to prevent people from trusting potentially bad certificates and it is probably not very hard to implement. :) 

### Which files are affected by this bug

?

### Operating system

Linux

### Which version of the operating system you are running.

Arch Linux

### Package

Distro package manager

### Nextcloud Server version

24.0.7

### Nextcloud Desktop Client version

3.6.6-1

### Is this bug present after an update or on a fresh install?

Fresh desktop client install

### Are you using the Nextcloud Server Encryption module?

Encryption is Disabled

### Are you using an external user-backend?

- [ ] Default internal user-backend
- [ ] LDAP/ Active Directory
- [ ] SSO - SAML
- [ ] Other

### Nextcloud Server logs

_No response_

### Additional info

_No response_",2023-02-05T13:09:52Z,2023-08-28T19:48:57Z,open,4,"NextCloud, nagging, popup, prompts","SSL cert, pop-ups, nagging","NextCloud, pop-ups, nagging, prompt",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/meixger/hackernews-daily/issues/332,Hacker News Daily Top 30 @2023-08-15,https://github.com/meixger/hackernews-daily/issues/332,"1. [**Show HN: LLMs can generate valid JSON 100% of the time** <code>github.com</code>](https://togithub.com/normal-computing/outlines) - [204 comments 664 points](https://news.ycombinator.com/item?id=37125118)
2. [**Writing about what you learn pushes you to understand topics better** <code>addyosmani.com</code>](https://addyosmani.com/blog/write-learn/) - [153 comments 626 points](https://news.ycombinator.com/item?id=37118883)
3. [**Show HN: Little Rat – Chrome extension monitors network calls of all extensions** <code>github.com</code>](https://togithub.com/dnakov/little-rat) - [86 comments 449 points](https://news.ycombinator.com/item?id=37119942)
4. [**Discord.io breached, 760k user accounts for sale on darknet** <code>stackdiary.com</code>](https://stackdiary.com/the-data-of-760000-discord-io-users-was-put-up-for-sale-on-the-darknet/) - [130 comments 374 points](https://news.ycombinator.com/item?id=37124187)
5. [**Following pushback, Zoom says it won't use customer data to train AI models** <code>www.darkreading.com</code>](https://www.darkreading.com/analytics/following-pushback-zoom-says-it-won-t-use-customer-data-to-train-ai-models) - [171 comments 351 points](https://news.ycombinator.com/item?id=37123572)
6. [**Police raid of a Kansas newsroom raises alarms about violations of press freedom** <code>www.npr.org</code>](https://www.npr.org/2023/08/14/1193676139/newspaper-marion-county-kansas-police-raid-first-amendment) - [135 comments 350 points](https://news.ycombinator.com/item?id=37120350)
7. [**Backward Compatibility, Go 1.21, and Go 2** <code>go.dev</code>](https://go.dev/blog/compat) - [253 comments 346 points](https://news.ycombinator.com/item?id=37122871)
8. [**Software Engineering at Google (2020)** <code>abseil.io</code>](https://abseil.io/resources/swe-book/html/toc.html) - [319 comments 317 points](https://news.ycombinator.com/item?id=37121180)
9. [**I built a garbage collector for a language that doesn’t need one** <code>claytonwramsey.github.io</code>](https://claytonwramsey.github.io/2023/08/14/dumpster.html) - [122 comments 289 points](https://news.ycombinator.com/item?id=37120967)
10. [**OpenFarm – a free and open database and web application for gardening knowledge** <code>openfarm.cc</code>](https://openfarm.cc) - [19 comments 277 points](https://news.ycombinator.com/item?id=37125830)
11. [**JWST spots giant black holes all over the early universe** <code>www.quantamagazine.org</code>](https://www.quantamagazine.org/jwst-spots-giant-black-holes-all-over-the-early-universe-20230814/) - [102 comments 273 points](https://news.ycombinator.com/item?id=37123792)
12. [**Show HN: AI-town, run your own custom AI world SIM with JavaScript** <code>github.com</code>](https://togithub.com/a16z-infra/ai-town) - [54 comments 243 points](https://news.ycombinator.com/item?id=37128293)
13. [**The 2002 Überlingen midair collision** <code>admiralcloudberg.medium.com</code>](https://admiralcloudberg.medium.com/tears-in-the-rain-the-2002-%C3%BCberlingen-midair-collision-591232d0c51e) - [97 comments 229 points](https://news.ycombinator.com/item?id=37120372)
14. [**Bankman-Fried used $100M in stolen FTX funds for political donations, US says** <code>www.reuters.com</code>](https://www.reuters.com/legal/bankman-fried-used-customer-funds-100-mln-us-political-donations-prosecutors-say-2023-08-14/) - [96 comments 217 points](https://news.ycombinator.com/item?id=37128392)
15. [**Judge rules in favor of Montana youths in landmark climate decision** <code>www.washingtonpost.com</code>](https://www.washingtonpost.com/climate-environment/2023/08/14/youths-win-montana-climate-trial/) - [139 comments 216 points](https://news.ycombinator.com/item?id=37123755)
16. [**Python: Just Write SQL** <code>joaodlf.com</code>](https://joaodlf.com/python-just-write-sql) - [248 comments 212 points](https://news.ycombinator.com/item?id=37118633)
17. [**Elixir – Why the dot when calling anonymous functions?** <code>dashbit.co</code>](https://dashbit.co/blog/why-the-dot) - [135 comments 211 points](https://news.ycombinator.com/item?id=37122006)
18. [**Internet Archive responds to recording industry lawsuit targeting obsolete media** <code>blog.archive.org</code>](https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/) - [109 comments 202 points](https://news.ycombinator.com/item?id=37128044)
19. [**Tell HN: t.co is adding a five-second delay to some domains** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=37130060) - [121 comments 191 points](https://news.ycombinator.com/item?id=37130060)
20. [**The anesthetic effect of air at atmospheric pressure** <code>pubmed.ncbi.nlm.nih.gov</code>](https://pubmed.ncbi.nlm.nih.gov/1130736/) - [140 comments 182 points](https://news.ycombinator.com/item?id=37117818)
21. [**Veilid is an open-source, P2P, mobile-ﬁrst, networked application framework** <code>veilid.com</code>](https://veilid.com/) - [59 comments 166 points](https://news.ycombinator.com/item?id=37118124)
22. [**Testing on production** <code>marcochiappetta.medium.com</code>](https://marcochiappetta.medium.com/yes-you-should-test-on-production-61f6dc61908b) - [92 comments 162 points](https://news.ycombinator.com/item?id=37118983)
23. [**Caught by MuseScore's Dark Patterns (2021)** <code>gadanidis.ca</code>](https://gadanidis.ca/posts/2021-11-09-musescore.html) - [81 comments 142 points](https://news.ycombinator.com/item?id=37121458)
24. [**Small Kansas newspaper says co-owner, 98, collapsed and died after police raid** <code>www.cbsnews.com</code>](https://www.cbsnews.com/news/kansas-newspaper-police-raid-marion-county-record-joan-meyer-dies/) - [32 comments 139 points](https://news.ycombinator.com/item?id=37120188)
25. [**Bomb threat causes mass evacuation at DEF CON hacking convention** <code>www.theregister.com</code>](https://www.theregister.com/2023/08/14/def_con_roundup/) - [45 comments 137 points](https://news.ycombinator.com/item?id=37120697)
26. [**Inside The Decline of Stack Exchange** <code>www.thediff.co</code>](https://www.thediff.co/archive/inside-the-decline-of-stack-exchange/) - [160 comments 136 points](https://news.ycombinator.com/item?id=37120982)
27. [**Montana loses fight against youth climate activists in landmark ruling** <code>arstechnica.com</code>](https://arstechnica.com/tech-policy/2023/08/montana-loses-fight-against-youth-climate-activists-in-landmark-ruling/) - [108 comments 133 points](https://news.ycombinator.com/item?id=37127606)
28. [**Java 21: First Release Candidate** <code>openjdk.org</code>](https://openjdk.org/projects/jdk/21/) - [79 comments 132 points](https://news.ycombinator.com/item?id=37126530)
29. [**Autospam and Naive Bayes** <code>pixelfed.blog</code>](https://pixelfed.blog/p/2023/feature/autospam-and-naive-bayes-the-grandfather-of-spam-filters-still-making-waves) - [33 comments 128 points](https://news.ycombinator.com/item?id=37118081)
30. [**Is Venus in some way tidally locked to Earth? (2020)** <code>astronomy.stackexchange.com</code>](https://astronomy.stackexchange.com/questions/36488/is-venus-in-some-way-tidally-locked-to-earth) - [20 comments 124 points](https://news.ycombinator.com/item?id=37118114)",2023-08-15T06:11:07Z,2023-08-15T06:11:07Z,open,0,miscellaneous (source/blog),"article, examples","documentation, blog, post",Papers/Docs/Sources,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/withfig/fig/issues/2162,bug: apt update gives: runuser: user ubuntu ubuntu does not exist or the user entry does not contain all the required fields,https://github.com/withfig/fig/issues/2162,"### Checks

- [X] I have searched [github.com/withfig/fig/issues](https://github.com/withfig/fig/issues?q=) and there are no duplicates of my issue
- [X] I have run `fig doctor` in the affected terminal session
- [X] I have run `fig restart` and replicated the issue again

### Operating system

Ubuntu 22.04

### Expected behaviour

I expected `apt-get update` to update fig without errors.

### Actual behaviour

Error shown as follows:

Preparing to unpack .../0-fig-headless_2.10.1_arm64.deb ...
Uninstalling additional components...
runuser: user ubuntu ubuntu does not exist or the user entry does not contain all the required fields
runuser: user ubuntu ubuntu does not exist or the user entry does not contain all the required fields
error: Failed to uninstall properly
Unpacking fig-headless (2.10.1) over (2.10.0) ...

### Steps to reproduce

_No response_

### Environment

```yaml
fig-details:
  - 2.10.1
hardware-info:
  - model: 
  - model-id: 
  - chip-id: 
  - cores: 2
  - mem: 0.90 GB
os-info:
  - kernel: 5.15.0-1026-aws
  - distro: ""Ubuntu""
  - distro-version: ""22.04.1 LTS (Jammy Jellyfish)""
environment:
  - shell: /usr/bin/bash
  - terminal: <unknown>
  - cwd: /home/ubuntu
  - exe-path: /usr/bin/fig
  - install-method: unknown
  - env-vars:
    - SHELL: /bin/bash
    - FIG_SET_PARENT_CHECK: 1
    - XDG_SESSION_TYPE: tty
    - TERM: xterm-256color
    - FIG_PID: 1064
    - PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/.local/bin:/home/ubuntu/.fig/bin
    - FIG_PARENT: 96b6db4f-0457-41fa-b4ea-b68d3a8b2b79
```
",2022-12-18T02:50:44Z,2024-03-19T11:23:46Z,open,5,"ubuntu, usage of dark pattern in command shell, preselection, ""yes be default""","yes as default for install, ubuntu, preselection","Ubuntu, preselection, default",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/grafana/k6/issues/2952,Expand usage collection to include extension versions in use,https://github.com/grafana/k6/issues/2952,"### Feature Description

Currently, k6 reports anonymous usage data as described in the [docs](https://k6.io/docs/misc/usage-collection/). Thanks to #1741 in v0.43.0, we can now access version info for bundled extensions with the `k6 version` output. To help determine priority for certain extensions, having this version information included in the payload of the usage reports would be nice. I want to discuss bringing this additional metadata to the usage collection payload.

Of course, anonymity and the ability to opt-out are paramount. The only scenario I can think of which could break anonymity would be if someone is creating/using an extension within a private repository. Their Github organization would be ""leaked,"" but we would not have any insight into the extension other than what could be implied by its name.

*Why would we want this information?*
The number of extensions available is continually increasing. Many are proof-of-concept, experimental, or just ""because we can."" Some are hosted here in Grafana and will be officially supported, but most are not. The extensions API has had some breaking changes recently, and many extensions no longer work. By having some metrics to show which extensions are ""popular,"" we can proactively submit patches to repository owners as changes are proposed/made to the underlying module API. We could prioritize based on the amount of usage.
",2023-03-02T14:31:11Z,2023-10-05T12:19:48Z,open,6,"k6 (unit testing platform), usage of dark pattern in software, collect users data without consent, violate gdpr compliance ","k6, data collection without consent","k6 (unit testing platform), GDPR, data collection, privacy issue",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/meixger/hackernews-daily/issues/229,Hacker News Daily Top 30 @2023-05-05,https://github.com/meixger/hackernews-daily/issues/229,"1. [**Google “We have no moat, and neither does OpenAI”** <code>www.semianalysis.com</code>](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) - [723 comments 1599 points](https://news.ycombinator.com/item?id=35813322)
2. [**Scaling up the Prime Video audio/video monitoring service and reducing costs** <code>www.primevideotech.com</code>](https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90) - [484 comments 904 points](https://news.ycombinator.com/item?id=35811741)
3. [**So this guy is now S3. All of S3** <code>chaos.social</code>](https://chaos.social/@jonty/110307532009155432) - [295 comments 472 points](https://news.ycombinator.com/item?id=35820368)
4. [**Facebook has not been doing enough to comply with a 2020 privacy order: FTC** <code>arstechnica.com</code>](https://arstechnica.com/tech-policy/2023/05/ftc-says-facebook-violated-privacy-order-proposes-ban-on-monetizing-youth-data/) - [270 comments 467 points](https://news.ycombinator.com/item?id=35814081)
5. [**EARN IT Act undermines the privacy, security, and safety of law-abiding users** <code>techfreedom.org</code>](https://techfreedom.org/earn-it-act-remains-a-threat-to-liberty-security-safety-of-children/) - [175 comments 337 points](https://news.ycombinator.com/item?id=35814113)
6. [**The seven programming ur-languages (2021)** <code>madhadron.com</code>](https://madhadron.com/programming/seven_ur_languages.html) - [181 comments 334 points](https://news.ycombinator.com/item?id=35813496)
7. [**Shopify will be smaller by about 20% and Flexport will buy Shopify Logistics** <code>news.shopify.com</code>](https://news.shopify.com/important-team-and-business-changes) - [303 comments 299 points](https://news.ycombinator.com/item?id=35813763)
8. [**Googlers angry about CEO’s $226M pay after cuts in perks and 12,000 layoffs** <code>arstechnica.com</code>](https://arstechnica.com/tech-policy/2023/05/googlers-angry-about-ceos-226m-pay-after-cuts-in-perks-and-12000-layoffs/) - [262 comments 288 points](https://news.ycombinator.com/item?id=35821927)
9. [**Heavy marijuana use increases schizophrenia in men, study finds** <code>www.bloomberg.com</code>](https://www.bloomberg.com/news/articles/2023-05-04/heavy-marijuana-use-increases-schizophrenia-in-men-study-finds) - [233 comments 272 points](https://news.ycombinator.com/item?id=35817213)
10. [**Europeans drain billions from banks, fed up with shrinking savings** <code>www.reuters.com</code>](https://www.reuters.com/business/finance/fed-up-with-shrinking-savings-europeans-drain-billions-banks-2023-05-04/) - [268 comments 270 points](https://news.ycombinator.com/item?id=35815538)
11. [**How companies use dark patterns to keep you subscribed** <code>pudding.cool</code>](https://pudding.cool/2023/05/dark-patterns/) - [168 comments 263 points](https://news.ycombinator.com/item?id=35815765)
12. [**New Yorkers want to stop landlords from using facial recognition** <code>gizmodo.com</code>](https://gizmodo.com/nyc-msg-facial-recognition-landlords-ban-law-hearing-1850401997) - [167 comments 255 points](https://news.ycombinator.com/item?id=35814043)
13. [**Google Introduces Passkey Authentication** <code>security.googleblog.com</code>](https://security.googleblog.com/2023/05/so-long-passwords-thanks-for-all-phish.html) - [137 comments 237 points](https://news.ycombinator.com/item?id=35815939)
14. [**America’s first high-volume ‘PFAS Annihilator’ is up and running in W. Michigan** <code>www.woodtv.com</code>](https://www.woodtv.com/news/kent-county/americas-first-high-volume-pfas-annihilator-is-up-and-running-in-west-michigan/) - [126 comments 235 points](https://news.ycombinator.com/item?id=35821128)
15. [**The “baseline” scene in bladerunner 2049 was written by Ryan Gosling (2022)** <code>cohost.org</code>](https://cohost.org/mcc/post/178201-the-baseline-scene) - [139 comments 228 points](https://news.ycombinator.com/item?id=35813595)
16. [**Vim Keybindings Everywhere – The Ultimate List** <code>github.com</code>](https://github.com/erikw/vim-keybindings-everywhere-the-ultimate-list) - [86 comments 202 points](https://news.ycombinator.com/item?id=35816361)
17. [**New C features in GCC 13** <code>developers.redhat.com</code>](https://developers.redhat.com/articles/2023/05/04/new-c-features-gcc-13) - [236 comments 193 points](https://news.ycombinator.com/item?id=35813821)
18. [**Heisting $20M of Magic: The Gathering Cards in a Single Request** <code>www.mayer.cool</code>](https://www.mayer.cool/writings/Heisting-20-Million-in-Magic-Cards/) - [44 comments 192 points](https://news.ycombinator.com/item?id=35824115)
19. [**JEP 450: Compact Object Headers** <code>openjdk.org</code>](https://openjdk.org/jeps/450) - [92 comments 183 points](https://news.ycombinator.com/item?id=35816900)
20. [**Pynecone – Performant, customizable web apps in pure Python** <code>pynecone.io</code>](https://pynecone.io/) - [72 comments 183 points](https://news.ycombinator.com/item?id=35820289)
21. [**Hue Light Hack** <code>www.atomic14.com</code>](https://www.atomic14.com/2023/05/04/hue-light-hacking.html) - [108 comments 177 points](https://news.ycombinator.com/item?id=35814575)
22. [**Colorado kills law that made it harder for cities to offer Internet service** <code>arstechnica.com</code>](https://arstechnica.com/tech-policy/2023/05/colorado-kills-law-that-made-it-harder-for-cities-to-offer-internet-service/) - [92 comments 175 points](https://news.ycombinator.com/item?id=35816577)
23. [**OpenAI Personal Data Removal Request Form** <code>share.hsforms.com</code>](https://share.hsforms.com/1UPy6xqxZSEqTrGDh4ywo_g4sk30) - [146 comments 162 points](https://news.ycombinator.com/item?id=35814480)
24. [**Re-implementing LangChain in 100 lines of code** <code>blog.scottlogic.com</code>](https://blog.scottlogic.com/2023/05/04/langchain-mini.html) - [51 comments 158 points](https://news.ycombinator.com/item?id=35820931)
25. [**BigCode Project Releases StarCoder: A 15B Code LLM** <code>huggingface.co</code>](https://huggingface.co/bigcode) - [34 comments 155 points](https://news.ycombinator.com/item?id=35819305)
26. [**Westinghouse announces a new small modular nuclear reactor** <code>www.cnbc.com</code>](https://www.cnbc.com/2023/05/04/westinghouse-announces-a-small-nuclear-reactor.html) - [119 comments 151 points](https://news.ycombinator.com/item?id=35816789)
27. [**Gitlab and Google Cloud Partner to Expand AI-Assisted Capabilities** <code>www.googlecloudpresscorner.com</code>](https://www.googlecloudpresscorner.com/2023-05-02-GitLab-and-Google-Cloud-Partner-to-Expand-AI-Assisted-Capabilities-with-Customizable-Gen-AI-Foundation-Models) - [107 comments 151 points](https://news.ycombinator.com/item?id=35812378)
28. [**Public Money, Public Code** <code>publiccode.eu</code>](https://publiccode.eu/en/) - [55 comments 141 points](https://news.ycombinator.com/item?id=35824320)
29. [**Shopify to cut 20% of its workforce, beats quarterly revenue estimates** <code>www.reuters.com</code>](https://www.reuters.com/business/retail-consumer/shopify-reports-first-quarter-revenue-above-estimates-2023-05-04/) - [180 comments 136 points](https://news.ycombinator.com/item?id=35813989)
30. [**AI is just someone else's intelligence** <code>www.zdziarski.com</code>](https://www.zdziarski.com/blog/?p=12001) - [140 comments 130 points](https://news.ycombinator.com/item?id=35815982)",2023-05-05T06:11:40Z,2023-05-05T06:11:40Z,open,0,miscellaneous (source/blog),"definitions, examples, COOL WEBSITE","documentation, blog, post",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/meixger/hackernews-daily/issues/177,Hacker News Daily Top 30 @2023-03-14,https://github.com/meixger/hackernews-daily/issues/177,"1. [**Launch HN: Electric Air (YC W23) – Heat pump sold directly to homeowners** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=35138319) - [672 comments 767 points](https://news.ycombinator.com/item?id=35138319)
2. [**Experian is a pile of dark pattern garbage** <code>blog.benton.io</code>](https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage) - [113 comments 492 points](https://news.ycombinator.com/item?id=35142787)
3. [**Changes at YC** <code>www.ycombinator.com</code>](https://www.ycombinator.com/blog/changes-at-yc/) - [405 comments 479 points](https://news.ycombinator.com/item?id=35142245)
4. [**Alpaca: A strong open-source instruction-following model** <code>crfm.stanford.edu</code>](https://crfm.stanford.edu/2023/03/13/alpaca.html) - [43 comments 449 points](https://news.ycombinator.com/item?id=35136624)
5. [**Launch HN: Pynecone (YC W23) – Web Apps in Pure Python** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=35136827) - [230 comments 437 points](https://news.ycombinator.com/item?id=35136827)
6. [**Audiophile forum debating which versions of memcpy had the highest sound quality (2013)** <code>discuss.systems</code>](https://discuss.systems/@dan/110008052977994607) - [506 comments 374 points](https://news.ycombinator.com/item?id=35137327)
7. [**SVB shows that there are few libertarians in a financial foxhole** <code>www.ft.com</code>](https://www.ft.com/content/ebba73d9-d319-4634-aa09-bbf09ee4a03b) - [417 comments 293 points](https://news.ycombinator.com/item?id=35138341)
8. [**HSBC to Buy UK Arm of Silicon Valley Bank** <code>www.bbc.co.uk</code>](https://www.bbc.co.uk/news/business-64937251) - [142 comments 256 points](https://news.ycombinator.com/item?id=35132181)
9. [**Influencer parents and the kids who had their childhood made into content** <code>www.teenvogue.com</code>](https://www.teenvogue.com/story/influencer-parents-children-social-media-impact) - [218 comments 254 points](https://news.ycombinator.com/item?id=35134484)
10. [**Ask HN: Any solo game developers here?** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=35134805) - [136 comments 249 points](https://news.ycombinator.com/item?id=35134805)
11. [**California cancels salmon fishing season** <code>www.cbsnews.com</code>](https://www.cbsnews.com/sanfrancisco/news/california-cancels-salmon-fishing-season/) - [164 comments 245 points](https://news.ycombinator.com/item?id=35142469)
12. [**Switching from C++ to Rust** <code>laplab.me</code>](https://laplab.me/posts/switching-from-cpp-to-rust/) - [150 comments 241 points](https://news.ycombinator.com/item?id=35143573)
13. [**Medicare Advantage plans use algorithms to cut off care** <code>www.statnews.com</code>](https://www.statnews.com/2023/03/13/medicare-advantage-plans-denial-artificial-intelligence/) - [186 comments 239 points](https://news.ycombinator.com/item?id=35135937)
14. [**Tiny-C Compiler (2001)** <code>www.iro.umontreal.ca</code>](http://www.iro.umontreal.ca/~felipe/IFT2030-Automne2002/Complements/tinyc.c) - [61 comments 218 points](https://news.ycombinator.com/item?id=35133708)
15. [**Our production servers were suspended by Google Cloud** <code>www.onvoard.com</code>](https://www.onvoard.com/blog/our-production-servers-was-suspended-by-google-cloud) - [175 comments 200 points](https://news.ycombinator.com/item?id=35133917)
16. [**An end to typographic widows on the web** <code>clagnut.com</code>](https://clagnut.com/blog/2424) - [83 comments 199 points](https://news.ycombinator.com/item?id=35134098)
17. [**Singapore software vendor says own hardware in colo costs $400M less than cloud** <code>www.theregister.com</code>](https://www.theregister.com/2023/03/13/ahrefs_on_prem_savings/) - [187 comments 196 points](https://news.ycombinator.com/item?id=35133510)
18. [**Things I learned after getting users** <code>basementcommunity.bearblog.dev</code>](https://basementcommunity.bearblog.dev/things-i-learned/) - [108 comments 196 points](https://news.ycombinator.com/item?id=35132223)
19. [**Facebook confirms it will drop news sharing in Canada under bill C-18** <code>www.michaelgeist.ca</code>](https://www.michaelgeist.ca/2023/03/the-consequence-of-mandated-payments-for-links-facebook-confirms-it-will-drop-news-sharing-in-canada-under-bill-c-18/) - [140 comments 195 points](https://news.ycombinator.com/item?id=35134751)
20. [**SVB collapse: Peter Thiel’s role scrutinized as spark of bank run** <code>www.washingtonexaminer.com</code>](https://www.washingtonexaminer.com/news/business/svb-collapse-peter-thiel-silicon-valley-) - [231 comments 191 points](https://news.ycombinator.com/item?id=35141775)
21. [**Gitlab loses one-third of its value after company issues weak forecast** <code>www.cnbc.com</code>](https://www.cnbc.com/2023/03/13/gitlab-gtlb-earnings-q4-2023.html) - [179 comments 189 points](https://news.ycombinator.com/item?id=35142777)
22. [**Framework 12th gen laptop review** <code>anarc.at</code>](https://anarc.at/hardware/laptop/framework-12th-gen/) - [146 comments 186 points](https://news.ycombinator.com/item?id=35133336)
23. [**Stanford Alpaca, and the acceleration of on-device LLM development** <code>simonwillison.net</code>](https://simonwillison.net/2023/Mar/13/alpaca/) - [53 comments 183 points](https://news.ycombinator.com/item?id=35141531)
24. [**Alpaca: An Instruct Tuned LLaMA 7B – Responses on par with txt-DaVinci-3** <code>crfm.stanford.edu</code>](https://crfm.stanford.edu/alpaca/) - [164 comments 177 points](https://news.ycombinator.com/item?id=35139450)
25. [**Generating aerial imagery with your iPhone's Lidar sensor** <code>jakecoppinger.com</code>](https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/) - [31 comments 173 points](https://news.ycombinator.com/item?id=35142588)
26. [**SVB insider says employees are angry with CEO** <code>www.cnn.com</code>](https://www.cnn.com/2023/03/13/business/svb-employees-angry-at-ceo/index.html) - [135 comments 171 points](https://news.ycombinator.com/item?id=35142628)
27. [**Overhead of Returning Optional Values in Java and Rust (2021)** <code>pkolaczk.github.io</code>](https://pkolaczk.github.io/overhead-of-optional/) - [153 comments 169 points](https://news.ycombinator.com/item?id=35132586)
28. [**Microsoft lays off an ethical AI team as it doubles down on OpenAI** <code>techcrunch.com</code>](https://techcrunch.com/2023/03/13/microsoft-lays-off-an-ethical-ai-team-as-it-doubles-down-on-openai/) - [142 comments 154 points](https://news.ycombinator.com/item?id=35146076)
29. [**Ipmitool Repository Archived, Developer Suspended by GitHub** <code>www.phoronix.com</code>](https://www.phoronix.com/news/ipmitool-GitHub-Suspended) - [44 comments 148 points](https://news.ycombinator.com/item?id=35137213)
30. [**Instagram Is Disabling Its NFT Features** <code>nftnow.com</code>](https://nftnow.com/news/breaking-instagram-is-sunsetting-digital-collectibles-nfts/) - [135 comments 147 points](https://news.ycombinator.com/item?id=35144140)",2023-03-14T07:09:31Z,2023-03-14T07:09:31Z,open,0,miscellaneous (source/blog),"Experian CreditLock, examples","Experian CreditLock, documentation, blog, post",Papers/Docs/Sources,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/gradio-app/gradio/issues/4226,Ensure that analytics collection is compliant with GDPR,https://github.com/gradio-app/gradio/issues/4226,"- [x] I have searched to see if a similar issue already exists.

**Is your feature request related to a problem? Please describe.**  

I was surprised to see that an open source project running locally as a demo was sending analytics data to Google.

**Describe the solution you'd like**  

`enable_analytics` should be an option that defaults to **do not track analytics**. A user should explicitly opt-into this behavior rather than have to opt out.

**Additional context**  

The opt-in default is implemented here:

https://github.com/gradio-app/gradio/blob/v3.30.0/gradio/blocks.py#L686-L687

Apart from the unconventional use of `True` as an environment variable to signal true/yes/on (it's more common to use `1`), environment variables should default to ""user did not specify this value"".

I think it's perfectly acceptable and to enable the collection of data by way of a public server (e.g. a hosted version of a gradio app) but it is not acceptable IMO to track data running locally without an explicit opt-in from the user.",2023-05-15T22:24:39Z,2024-03-13T18:28:58Z,open,9,"Gradio (open-source Python package), gdpr compliance, privacy regulation, users consent of data collection, avoid dark pattern in telemetry","disable telemetry, alternate ways for feedback","Gradio, GDPR, disable telemetry, privacy issue, data collection, avoid dark pattern","DPs prevention in software, DPs related regulation ",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/aws/aws-cdk/issues/23759,Automatically push updated snapshots for PRs,https://github.com/aws/aws-cdk/issues/23759,"### Describe the feature

Small CDK contributions would be much easier if a [Github action could run `cdk-integ --dry-run` and push updated snapshots](https://peterevans.dev/posts/github-actions-how-to-automate-code-formatting-in-pull-requests/), especially for PRs that are only failing those

### Use Case

I mostly send drive-by PRs and haven't been able to get CDK building in Gitpod lately:
https://github.com/aws/aws-cdk/pull/21914

Even when I had CDK building successfully in Gitpod, it took hours to spin up the environment on Gitpod, build everything, and figure out Github auth in Gitpod",2023-01-19T19:00:11Z,2023-12-13T17:20:43Z,open,10,"Gitpod (cloud development environment), usage of dark pattern in software, billing feature, trick users to get paid version","Gitpod, billing, confusing, hidden costs","Gitpod, billing, hidden costs, trick users to buy paid products",,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/71,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/71,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:44:36Z,2023-03-02T07:44:36Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services","definitions, examples","documentation, detection",Papers/Docs/Sources,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/69,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/69,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:43:55Z,2023-03-02T07:43:55Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/65,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/65,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:43:13Z,2023-03-02T07:43:13Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/67,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/67,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:43:27Z,2023-03-02T07:43:27Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/65,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/65,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:43:13Z,2023-03-02T07:43:13Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/62,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/62,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:42:10Z,2023-03-02T07:42:10Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/60,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/60,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:40:35Z,2023-03-02T07:40:35Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/58,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/58,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:38:14Z,2023-03-02T07:38:14Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/57,"【CS】New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/57,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T07:37:36Z,2023-03-02T07:37:36Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/52,"New submissions for Thu,  2 Mar 23",https://github.com/Yukeaaa/arxiv-daily/issues/52,"## Keyword: volume render
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
## Keyword: volumetric render
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
## Keyword: remote render
There is no result 
## Keyword: hybrid render
There is no result 
## Keyword: raycast
There is no result 
## Keyword: medical imaging
There is no result 
## Keyword: medical visualization
There is no result 
## Keyword: remote visualization
There is no result 
## Keyword: direct volume rendering
There is no result 
## Keyword: mobile device
There is no result 
## Keyword: video retrieval
There is no result 
## Keyword: transfer function
There is no result 
## Keyword: mobile
### Online On-Demand Multi-Robot Coverage Path Planning
 - **Authors:** Ratijit Mitra, Indranil Saha
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00047
 - **Pdf link:** https://arxiv.org/pdf/2303.00047
 - **Abstract**
 We present an online centralized path planning algorithm to cover a large, complex, unknown workspace with multiple homogeneous mobile robots. Our algorithm is horizon-based, synchronous, and on-demand. The recently proposed horizon-based synchronous algorithms compute the paths for all the robots in each horizon, significantly increasing the computation burden in large workspaces with many robots. As a remedy, we propose an algorithm that computes the paths for a subset of robots that have traversed previously computed paths entirely (thus on-demand) and reuses the previously computed paths for the other robots. We formally prove that the algorithm guarantees the complete coverage of the unknown workspace. Experimental results show that our algorithm scales to hundreds of robots in large workspaces and consistently outperforms a state-of-the-art online multi-robot centralized coverage path planning algorithm.We also perform ROS+Gazebo simulations in five $2$D grid benchmark workspaces with 10 Quadcopters and one real experiment with two Quadcopters in an outdoor experiment, to establish the practical feasibility of our algorithm.
### UAV Tracking with Lidar as a Camera Sensors in GNSS-Denied Environments
 - **Authors:** Ha Sier, Xianjia Yu, Iacopo Catalano, Jorge Pena Queralta, Zhuo Zou, Tomi Westerlund
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00277
 - **Pdf link:** https://arxiv.org/pdf/2303.00277
 - **Abstract**
 LiDAR has become one of the primary sensors in robotics and autonomous system for high-accuracy situational awareness. In recent years, multi-modal LiDAR systems emerged, and among them, LiDAR-as-a-camera sensors provide not only 3D point clouds but also fixed-resolution 360{\deg}panoramic images by encoding either depth, reflectivity, or near-infrared light in the image pixels. This potentially brings computer vision capabilities on top of the potential of LiDAR itself. In this paper, we are specifically interested in utilizing LiDARs and LiDAR-generated images for tracking Unmanned Aerial Vehicles (UAVs) in real-time which can benefit applications including docking, remote identification, or counter-UAV systems, among others. This is, to the best of our knowledge, the first work that explores the possibility of fusing the images and point cloud generated by a single LiDAR sensor to track a UAV without a priori known initialized position. We trained a custom YOLOv5 model for detecting UAVs based on the panoramic images collected in an indoor experiment arena with a MOCAP system. By integrating with the point cloud, we are able to continuously provide the position of the UAV. Our experiment demonstrated the effectiveness of the proposed UAV tracking approach compared with methods based only on point clouds or images. Additionally, we evaluated the real-time performance of our approach on the Nvidia Jetson Nano, a popular mobile computing platform.
### AI-Based Multi-Object Relative State Estimation with Self-Calibration  Capabilities
 - **Authors:** Thomas Jantos, Christian Brommer, Eren Allak, Stephan Weiss, Jan Steinbrener
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00371
 - **Pdf link:** https://arxiv.org/pdf/2303.00371
 - **Abstract**
 The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.
### Low-level Online Control of the Formula 1 Power Unit with Feedforward  Cylinder Deactivation
 - **Authors:** Marc-Philippe Neumann, Giona Fieni, Camillo Balerna, Pol Duhr, Alberto Cerofolini, Christopher H. Onder
 - **Subjects:** Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00372
 - **Pdf link:** https://arxiv.org/pdf/2303.00372
 - **Abstract**
 Since 2014, the F\'ed\'eration Internationale de l'Automobile has prescribed a parallel hybrid powertrain for the Formula 1 race cars. The complex low-level interactions between the thermal and the electrical part represent a non-trivial and challenging system to be controlled online. We present a novel controller architecture composed of a supervisory controller for the energy management, a feedforward cylinder deactivation controller, and a track region-dependent low-level nonlinear model predictive controller to optimize the engine actuators. Except for the nonlinear model predictive controller, the proposed controller subsystems are computationally inexpensive and are real time capable. The framework is tested and validated in a simulation environment for several realistic scenarios disturbed by driver actions or grip conditions on the track. In particular, we analyze how the control architecture deals with an unexpected gearshift trajectory during an acceleration phase. Further, we demonstrate how an increased maximum velocity trajectory impacts the online low-level controller. Our results show a suboptimality over an entire lap with respect to the benchmark solution of 49 ms and 64 ms, respectively, which we deem acceptable. Compared to the same control architecture with full knowledge of the disturbances, the suboptimality amounted to only 2 ms and 17 ms. For all case studies we show that the cylinder deactivation capability decreases the suboptimality by 7 to 8 ms.
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: smartphone
There is no result 
## Keyword: medical volume data
There is no result 
## Keyword: volume data
There is no result 
## Keyword: cinematic rendering
There is no result 
## Keyword: webgpu
There is no result 
## Keyword: webgl2
There is no result 
## Keyword: rendering
### Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface
 - **Authors:** Decai Chen, Haofei Lu, Ingo Feldmann, Oliver Schreer, Peter Eisert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00050
 - **Pdf link:** https://arxiv.org/pdf/2303.00050
 - **Abstract**
 Reconstructing general dynamic scenes is important for many computer vision and graphics applications. Recent works represent the dynamic scene with neural radiance fields for photorealistic view synthesis, while their surface geometry is under-constrained and noisy. Other works introduce surface constraints to the implicit neural representation to disentangle the ambiguity of geometry and appearance field for static scene reconstruction. To bridge the gap between rendering dynamic scenes and recovering static surface geometry, we propose a template-free method to reconstruct surface geometry and appearance using neural implicit representations from multi-view videos. We leverage topology-aware deformation and the signed distance field to learn complex dynamic surfaces via differentiable volume rendering without scene-specific prior knowledge like template models. Furthermore, we propose a novel mask-based ray selection strategy to significantly boost the optimization on challenging time-varying regions. Experiments on different multi-view video datasets demonstrate that our method achieves high-fidelity surface reconstruction as well as photorealistic novel view synthesis.
### P$^2$SDF for Neural Indoor Scene Reconstruction
 - **Authors:** Jing Li, Jinpeng Yu, Ruoyu Wang, Zhengxin Li, Zhengyu Zhang, Lina Cao, Shenghua Gao
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00236
 - **Pdf link:** https://arxiv.org/pdf/2303.00236
 - **Abstract**
 Given only a set of images, neural implicit surface representation has shown its capability in 3D surface reconstruction. However, as the nature of per-scene optimization is based on the volumetric rendering of color, previous neural implicit surface reconstruction methods usually fail in low-textured regions, including the floors, walls, etc., which commonly exist for indoor scenes. Being aware of the fact that these low-textured regions usually correspond to planes, without introducing additional ground-truth supervisory signals or making additional assumptions about the room layout, we propose to leverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for indoor scene reconstruction. Specifically, we consider adjacent pixels with similar colors to be on the same pseudo planes. The plane parameters are then estimated on the fly during training by an efficient and effective two-step scheme. Then the signed distances of the points on the planes are regularized by the estimated plane parameters in the training phase. As the unsupervised plane segments are usually noisy and inaccurate, we propose to assign different weights to the sampled points on the plane in plane estimation as well as the regularization loss. The weights come by fusing the plane segments from different views. As the sampled rays in the planar regions are redundant, leading to inefficient training, we further propose a keypoint-guided rays sampling strategy that attends to the informative textured regions with large color variations, and the implicit network gets a better reconstruction, compared with the original uniform ray sampling strategy. Experiments show that our P$^2$SDF achieves competitive reconstruction performance in Manhattan scenes. Further, as we do not introduce any additional room layout assumption, our P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.
### Renderable Neural Radiance Map for Visual Navigation
 - **Authors:** Obin Kwon, Jeongho Park, Songhwai Oh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00304
 - **Pdf link:** https://arxiv.org/pdf/2303.00304
 - **Abstract**
 We propose a novel type of map for visual navigation, a renderable neural radiance map (RNR-Map), which is designed to contain the overall visual information of a 3D environment. The RNR-Map has a grid form and consists of latent codes at each pixel. These latent codes are embedded from image observations, and can be converted to the neural radiance field which enables image rendering given a camera pose. The recorded latent codes implicitly contain visual information about the environment, which makes the RNR-Map visually descriptive. This visual information in RNR-Map can be a useful guideline for visual localization and navigation. We develop localization and navigation frameworks that can effectively utilize the RNR-Map. We evaluate the proposed frameworks on camera tracking, visual localization, and image-goal navigation. Experimental results show that the RNR-Map-based localization framework can find the target location based on a single query image with fast speed and competitive accuracy compared to other baselines. Also, this localization framework is robust to environmental changes, and even finds the most visually similar places when a query image from a different environment is given. The proposed navigation framework outperforms the existing image-goal navigation methods in difficult scenarios, under odometry and actuation noises. The navigation framework shows 65.7% success rate in curved scenarios of the NRNS dataset, which is an improvement of 18.6% over the current state-of-the-art.
### AR-Assisted Surgical Care via 5G networks for First Aid Responders
 - **Authors:** Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis
 - **Subjects:** Graphics (cs.GR)
 - **Arxiv link:** https://arxiv.org/abs/2303.00458
 - **Pdf link:** https://arxiv.org/pdf/2303.00458
 - **Abstract**
 Surgeons should play a central role in disaster planning and management due to the overwhelming number of bodily injuries that are typically involved during most forms of disaster. In fact, various types of surgical procedures are performed by emergency medical teams after sudden-onset disasters, such as soft tissue wounds, orthopaedic traumas, abdominal surgeries, etc. HMD-based Augmented Reality (AR), using state-of-the-art hardware such as the Magic Leap or the Microsoft HoloLens, have long been foreseen as a key enabler for clinicians in surgical use cases, especially for procedures performed outside of the operating room. This paper describes the Use Case (UC) ""AR-assisted emergency surgical care"", identified in the context of the 5G-EPICENTRE EU-funded project. Specifically, the UC will experiment with holographic AR technology for emergency medical surgery teams, by overlaying deformable medical models directly on top of the patient body parts, effectively enabling surgeons to see inside (visualizing bones, blood vessels, etc.) and perform surgical actions following step-by-step instructions. The goal is to combine the computational and data-intensive nature of AR and Computer Vision algorithms with upcoming 5G network architectures deployed for edge computing so as to satisfy real-time interaction requirements and provide an efficient and powerful platform for the pervasive promotion of such applications. By developing the necessary Virtual Network Functions (VNFs) to manage data-intensive services (e.g., prerendering, caching, compression) and by exploiting available network resources and Multi-access Edge Computing (MEC) support, provided by the 5G-EPICENTRE infrastructure, this UC aims to provide powerful AR-based tools, usable on site, to first-aid responders.
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: incremental learning
There is no result 
## Keyword: svm incremental
There is no result 
## Keyword: nerf
### S-NeRF: Neural Radiance Fields for Street Views
 - **Authors:** Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00749
 - **Pdf link:** https://arxiv.org/pdf/2303.00749
 - **Abstract**
 Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, 'floaters' and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7% to 40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering.
## Keyword: multiorgan
There is no result 
## Keyword: multi-organ
There is no result 
## Keyword: multi organ
There is no result 
## Keyword: segmentation
### Applying Plain Transformers to Real-World Point Clouds
 - **Authors:** Lanxiao Li, Michael Heizmann
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00086
 - **Pdf link:** https://arxiv.org/pdf/2303.00086
 - **Abstract**
 Due to the lack of inductive bias, transformer-based models usually require a large amount of training data. The problem is especially concerning in 3D vision, as 3D data are harder to acquire and annotate. To overcome this problem, previous works modify the architecture of transformers to incorporate inductive biases by applying, e.g., local attention and down-sampling. Although they have achieved promising results, earlier works on transformers for point clouds have two issues. First, the power of plain transformers is still under-explored. Second, they focus on simple and small point clouds instead of complex real-world ones. This work revisits the plain transformers in real-world point cloud understanding. We first take a closer look at some fundamental components of plain transformers, e.g., patchifier and positional embedding, for both efficiency and performance. To close the performance gap due to the lack of inductive bias and annotated data, we investigate self-supervised pre-training with masked autoencoder (MAE). Specifically, we propose drop patch, which prevents information leakage and significantly improves the effectiveness of MAE. Our models achieve SOTA results in semantic segmentation on the S3DIS dataset and object detection on the ScanNet dataset with lower computational costs. Our work provides a new baseline for future research on transformers for point clouds.
### DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on  Adaptive Affinity
 - **Authors:** Kun Yang, Jun Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00199
 - **Pdf link:** https://arxiv.org/pdf/2303.00199
 - **Abstract**
 The proposed method in this paper proposes an end-to-end unsupervised semantic segmentation architecture DMSA based on four loss functions. The framework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature extraction. At the same time, a dynamic dilation strategy is designed to better capture multi-scale context information. Secondly, a Pixel-Adaptive Refinement (PAR) module is introduced, which can adaptively refine the initial pseudo labels after feature fusion to obtain high quality pseudo labels. Experiments show that the proposed DSMA framework is superior to the existing methods on the saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and the accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the MIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the convergence speed of the model is also greatly improved after the introduction of the PAR module.
### RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training
 - **Authors:** Lianyu Zhou, Dong Wei, Donghuan Lu, Wei Xue, Liansheng Wang, Yefeng Zheng
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00205
 - **Pdf link:** https://arxiv.org/pdf/2303.00205
 - **Abstract**
 As an essential indicator for cancer progression and treatment response, tumor size is often measured following the response evaluation criteria in solid tumors (RECIST) guideline in CT slices. By marking each lesion with its longest axis and the longest perpendicular one, laborious pixel-wise manual annotation can be avoided. However, such a coarse substitute cannot provide a rich and accurate base to allow versatile quantitative analysis of lesions. To this end, we propose a novel weakly supervised framework to exploit the existing rich RECIST annotations for pixel-wise lesion segmentation. Specifically, a pair of under- and over-segmenting masks are constructed for each lesion based on its RECIST annotation and served as the label for co-training a pair of subnets, respectively, along with the proposed label-space perturbation induced consistency loss to bridge the gap between the two subnets and enable effective co-training. Extensive experiments are conducted on a public dataset to demonstrate the superiority of the proposed framework regarding the RECIST-based weakly supervised segmentation task and its universal applicability to various backbone networks.
### ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution
 - **Authors:** Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00246
 - **Pdf link:** https://arxiv.org/pdf/2303.00246
 - **Abstract**
 Existing 3D instance segmentation methods are predominated by the bottom-up design -- manually fine-tuned algorithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clusters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected regions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as kernels and decodes instance masks via dynamic convolution. To efficiently generate high-recall and discriminative kernels, we propose a simple strategy named Instance-aware Farthest Point Sampling to sample candidates and leverage the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that predicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance. Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on ScanNetV2).
### BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex  Prediction
 - **Authors:** Mingming Zhang, Ye Du, Zhenghui Hu, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00300
 - **Pdf link:** https://arxiv.org/pdf/2303.00300
 - **Abstract**
 Extracting building footprints from remote sensing images has been attracting extensive attention recently. Dominant approaches address this challenging problem by generating vectorized building masks with cumbersome refinement stages, which limits the application of such methods. In this paper, we introduce a new refinement-free and end-to-end building footprint extraction method, which is conceptually intuitive, simple, and effective. Our method, termed as BiSVP, represents a building instance with ordered vertices and formulates the building footprint extraction as predicting the serialized vertices directly in a bidirectional fashion. Moreover, we propose a cross-scale feature fusion (CSFF) module to facilitate high resolution and rich semantic feature learning, which is essential for the dense building vertex prediction task. Without bells and whistles, our BiSVP outperforms state-of-the-art methods by considerable margins on three building instance segmentation benchmarks, clearly demonstrating its superiority. The code and datasets will be made public available.
### Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision
 - **Authors:** Fangqiang Ding, Andras Palffy, Dariu M. Gavrila, Chris Xiaoxuan Lu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2303.00462
 - **Pdf link:** https://arxiv.org/pdf/2303.00462
 - **Abstract**
 This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on \url{https://github.com/Toytiny/CMFlow.}
### Multimodal Industrial Anomaly Detection via Hybrid Fusion
 - **Authors:** Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Yabiao Wang, Chengjie Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00601
 - **Pdf link:** https://arxiv.org/pdf/2303.00601
 - **Abstract**
 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detection based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the multimodal features, which leads to a strong disturbance between features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the interaction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point feature alignment operation to better align the point cloud and RGB features. Extensive experiments show that our multimodal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and segmentation precision on MVTec-3D AD dataset. Code is available at https://github.com/nomewang/M3DM.
### Unsupervised Pathology Detection: A Deep Dive Into the State of the Art
 - **Authors:** Ioannis Lagogiannis, Felix Meissen, Georgios Kaissis, Daniel Rueckert
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00609
 - **Pdf link:** https://arxiv.org/pdf/2303.00609
 - **Abstract**
 Deep unsupervised approaches are gathering increased attention for applications such as pathology detection and segmentation in medical images since they promise to alleviate the need for large labeled datasets and are more generalizable than their supervised counterparts in detecting any kind of rare pathology. As the Unsupervised Anomaly Detection (UAD) literature continuously grows and new paradigms emerge, it is vital to continuously evaluate and benchmark new methods in a common framework, in order to reassess the state-of-the-art (SOTA) and identify promising research directions. To this end, we evaluate a diverse selection of cutting-edge UAD methods on multiple medical datasets, comparing them against the established SOTA in UAD for brain MRI. Our experiments demonstrate that newly developed feature-modeling methods from the industrial and medical literature achieve increased performance compared to previous work and set the new SOTA in a variety of modalities and datasets. Additionally, we show that such methods are capable of benefiting from recently developed self-supervised pre-training algorithms, further increasing their performance. Finally, we perform a series of experiments in order to gain further insights into some unique characteristics of selected models and datasets. Our code can be found under https://github.com/iolag/UPD_study/.
### Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis
 - **Authors:** Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2303.00703
 - **Pdf link:** https://arxiv.org/pdf/2303.00703
 - **Abstract**
 Performances on standard 3D point cloud benchmarks have plateaued, resulting in oversized models and complex network design to make a fractional improvement. We present an alternative to enhance existing deep neural networks without any redesigning or extra parameters, termed as Spatial-Neighbor Adapter (SN-Adapter). Building on any trained 3D network, we utilize its learned encoding capability to extract features of the training dataset and summarize them as prototypical spatial knowledge. For a test point cloud, the SN-Adapter retrieves k nearest neighbors (k-NN) from the pre-constructed spatial prototypes and linearly interpolates the k-NN prediction with that of the original 3D network. By providing complementary characteristics, the proposed SN-Adapter serves as a plug-and-play module to economically improve performance in a non-parametric manner. More importantly, our SN-Adapter can be effectively generalized to various 3D tasks, including shape classification, part segmentation, and 3D object detection, demonstrating its superiority and robustness. We hope our approach could show a new perspective for point cloud analysis and facilitate future research.
### WhisperX: Time-Accurate Speech Transcription of Long-Form Audio
 - **Authors:** Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman
 - **Subjects:** Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2303.00747
 - **Pdf link:** https://arxiv.org/pdf/2303.00747
 - **Abstract**
 Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, their application to long audio transcription via buffered or sliding window approaches is prone to drifting, hallucination & repetition; and prohibits batched transcription due to their sequential nature. Further, timestamps corresponding each utterance are prone to inaccuracies and word-level timestamps are not available out-of-the-box. To overcome these challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut & Merge strategy improves transcription quality and enables a twelve-fold transcription speedup via batched inference.
## Keyword: medical image segmentation
There is no result 
## Keyword: unet
### About Engaging and Governing Strategies: A Thematic Analysis of Dark  Patterns in Social Networking Services
 - **Authors:** Thomas Mildner, Gian-Luca Savino, Philip R. Doyle, Benjamin R. Cowan, Rainer Malaka
 - **Subjects:** Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2303.00476
 - **Pdf link:** https://arxiv.org/pdf/2303.00476
 - **Abstract**
 Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as ``dark patterns''. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users' self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook's, Instagram's, TikTok's, and Twitter's mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies - engaging and governing - with five dark patterns undiscovered before.
## Keyword: u-net
### Can representation learning for multimodal image registration be  improved by supervision of intermediate layers?
 - **Authors:** Elisabeth Wetzer, Joakim Lindblad, Nataša Sladoje
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2303.00403
 - **Pdf link:** https://arxiv.org/pdf/2303.00403
 - **Abstract**
 Multimodal imaging and correlative analysis typically require image alignment. Contrastive learning can generate representations of multimodal images, reducing the challenging task of multimodal image registration to a monomodal one. Previously, additional supervision on intermediate layers in contrastive learning has improved biomedical image classification. We evaluate if a similar approach improves representations learned for registration to boost registration performance. We explore three approaches to add contrastive supervision to the latent features of the bottleneck layer in the U-Nets encoding the multimodal images and evaluate three different critic functions. Our results show that representations learned without additional supervision on latent features perform best in the downstream task of registration on two public biomedical datasets. We investigate the performance drop by exploiting recent insights in contrastive learning in classification and self-supervised learning. We visualize the spatial relations of the learned representations by means of multidimensional scaling, and show that additional supervision on the bottleneck layer can lead to partial dimensional collapse of the intermediate embedding space.
## Keyword: interactive segmentation
There is no result 
",2023-03-02T06:56:48Z,2023-03-02T06:56:48Z,open,0,"paper/literature of dark pattern, document, paper title: About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/jgaa/RESTinCurl/issues/2,Are there plans still to port this to Windows? Or is this project dead?,https://github.com/jgaa/RESTinCurl/issues/2,"Title says all, I'd really like to use this for a project I'm working on on Windows. I tried to use the restc-cpp library, but I couldn't figure out how to get it up and running. I appreciate the simplicity of this version.",2022-12-25T00:54:14Z,2024-01-23T15:27:26Z,open,20,"Microsoft, usage of dark pattern, trick users to use Edge web browser","Windows, Microsoft Edge, forced action","Microsoft, Edge, nagging",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/LeeKyungwook/get-arxiv-noti/issues/256,"New submissions for Wed, 27 Apr 22",https://github.com/LeeKyungwook/get-arxiv-noti/issues/256,"## Keyword: detection
### Machine learning identification of organic compounds using visible light
 - **Authors:** Authors: Thulasi Bikku, Rubén A. Fritz, Yamil J. Colón, Felipe Herrera
 - **Subjects:** Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Optics (physics.optics)
 - **Arxiv link:** https://arxiv.org/abs/2204.11832
 - **Pdf link:** https://arxiv.org/pdf/2204.11832
 - **Abstract**
 Identifying chemical compounds is essential in several areas of science and engineering. Laser-based techniques are promising for autonomous compound detection because the optical response of materials encodes enough electronic and vibrational information for remote chemical identification. This has been exploited using the fingerprint region of infrared absorption spectra, which involves a large number of absorption peaks that are unique to individual molecules, thus facilitating chemical identification. However, optical identification using visible light has not been realized. Using decades of experimental refractive index data in the scientific literature of pure organic compounds and polymers over a broad range of frequencies from the ultraviolet to the far-infrared, we develop a machine learning classifier that can accurately identify organic species based on a single-wavelength dispersive measurement in the visible spectral region, away from absorption resonances. The optical classifier proposed here could be applied to autonomous material identification protocols or applications.
### Automated detection of dark patterns in cookie banners: how to do it  poorly and why it is hard to do it any other way
 - **Authors:** Authors: Than Htut Soe, Cristiana Teixeira Santos, Marija Slavkovik
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2204.11836
 - **Pdf link:** https://arxiv.org/pdf/2204.11836
 - **Abstract**
 Cookie banners, the pop ups that appear to collect your consent for data collection, are a tempting ground for dark patterns. Dark patterns are design elements that are used to influence the user's choice towards an option that is not in their interest. The use of dark patterns renders consent elicitation meaningless and voids the attempts to improve a fair collection and use of data. Can machine learning be used to automatically detect the presence of dark patterns in cookie banners? In this work, a dataset of cookie banners of 300 news websites was used to train a prediction model that does exactly that. The machine learning pipeline we used includes feature engineering, parameter search, training a Gradient Boosted Tree classifier and evaluation. The accuracy of the trained model is promising, but allows a lot of room for improvement. We provide an in-depth analysis of the interdisciplinary challenges that automated dark pattern detection poses to artificial intelligence. The dataset and all the code created using machine learning is available at the url to repository removed for review.
### Real or Virtual: A Video Conferencing Background Manipulation-Detection  System
 - **Authors:** Authors: Ehsan Nowroozi, Yassine Mekdad, Mauro Conti, Simone Milani, Selcuk Uluagac, Berrin Yanikoglu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Multimedia (cs.MM)
 - **Arxiv link:** https://arxiv.org/abs/2204.11853
 - **Pdf link:** https://arxiv.org/pdf/2204.11853
 - **Abstract**
 Recently, the popularity and wide use of the last-generation video conferencing technologies created an exponential growth in its market size. Such technology allows participants in different geographic regions to have a virtual face-to-face meeting. Additionally, it enables users to employ a virtual background to conceal their own environment due to privacy concerns or to reduce distractions, particularly in professional settings. Nevertheless, in scenarios where the users should not hide their actual locations, they may mislead other participants by claiming their virtual background as a real one. Therefore, it is crucial to develop tools and strategies to detect the authenticity of the considered virtual background. In this paper, we present a detection strategy to distinguish between real and virtual video conferencing user backgrounds. We demonstrate that our detector is robust against two attack scenarios. The first scenario considers the case where the detector is unaware about the attacks and inn the second scenario, we make the detector aware of the adversarial attacks, which we refer to Adversarial Multimedia Forensics (i.e, the forensically-edited frames are included in the training set). Given the lack of publicly available dataset of virtual and real backgrounds for video conferencing, we created our own dataset and made them publicly available [1]. Then, we demonstrate the robustness of our detector against different adversarial attacks that the adversary considers. Ultimately, our detector's performance is significant against the CRSPAM1372 [2] features, and post-processing operations such as geometric transformations with different quality factors that the attacker may choose. Moreover, our performance results shows that we can perfectly identify a real from a virtual background with an accuracy of 99.80%.
### DArch: Dental Arch Prior-assisted 3D Tooth Instance Segmentation
 - **Authors:** Authors: Liangdong Qiu, Chongjie Ye, Pei Chen, Yunbi Liu, Xiaoguang Han, Shuguang Cui
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.11911
 - **Pdf link:** https://arxiv.org/pdf/2204.11911
 - **Abstract**
 Automatic tooth instance segmentation on 3D dental models is a fundamental task for computer-aided orthodontic treatments. Existing learning-based methods rely heavily on expensive point-wise annotations. To alleviate this problem, we are the first to explore a low-cost annotation way for 3D tooth instance segmentation, i.e., labeling all tooth centroids and only a few teeth for each dental model. Regarding the challenge when only weak annotation is provided, we present a dental arch prior-assisted 3D tooth segmentation method, namely DArch. Our DArch consists of two stages, including tooth centroid detection and tooth instance segmentation. Accurately detecting the tooth centroids can help locate the individual tooth, thus benefiting the segmentation. Thus, our DArch proposes to leverage the dental arch prior to assist the detection. Specifically, we firstly propose a coarse-to-fine method to estimate the dental arch, in which the dental arch is initially generated by Bezier curve regression, and then a graph-based convolutional network (GCN) is trained to refine it. With the estimated dental arch, we then propose a novel Arch-aware Point Sampling (APS) method to assist the tooth centroid proposal generation. Meantime, a segmentor is independently trained using a patch-based training strategy, aiming to segment a tooth instance from a 3D patch centered at the tooth centroid. Experimental results on $4,773$ dental models have shown our DArch can accurately segment each tooth of a dental model, and its performance is superior to the state-of-the-art methods.
### Robust Dual-Graph Regularized Moving Object Detection
 - **Authors:** Authors: Jing Qin, Ruilong Shen, Ruihan Zhu, Biyun Xie
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO); Numerical Analysis (math.NA)
 - **Arxiv link:** https://arxiv.org/abs/2204.11939
 - **Pdf link:** https://arxiv.org/pdf/2204.11939
 - **Abstract**
 Moving object detection and its associated background-foreground separation have been widely used in a lot of applications, including computer vision, transportation and surveillance. Due to the presence of the static background, a video can be naturally decomposed into a low-rank background and a sparse foreground. Many regularization techniques, such as matrix nuclear norm, have been imposed on the background. In the meanwhile, sparsity or smoothness based regularizations, such as total variation and $\ell_1$, can be imposed on the foreground. Moreover, graph Laplacians are further imposed to capture the complicated geometry of background images. Recently, weighted regularization techniques including the weighted nuclear norm regularization have been proposed in the image processing community to promote adaptive sparsity while achieving efficient performance. In this paper, we propose a robust dual-graph regularized moving object detection model based on the weighted nuclear norm regularization, which is solved by the alternating direction method of multipliers (ADMM). Numerical experiments on body movement data sets have demonstrated the effectiveness of this method in separating moving objects from background, and the great potential in robotic applications.
### PLOD: An Abbreviation Detection Dataset for Scientific Documents
 - **Authors:** Authors: Leonardo Zilio, Hadeel Saadany, Prashant Sharma, Diptesh Kanojia, Constantin Orasan
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2204.12061
 - **Pdf link:** https://arxiv.org/pdf/2204.12061
 - **Abstract**
 The detection and extraction of abbreviations from unstructured texts can help to improve the performance of Natural Language Processing tasks, such as machine translation and information retrieval. However, in terms of publicly available datasets, there is not enough data for training deep-neural-networks-based models to the point of generalising well over data. This paper presents PLOD, a large-scale dataset for abbreviation detection and extraction that contains 160k+ segments automatically annotated with abbreviations and their long forms. We performed manual validation over a set of instances and a complete automatic validation for this dataset. We then used it to generate several baseline models for detecting abbreviations and long forms. The best models achieved an F1-score of 0.92 for abbreviations and 0.89 for detecting their corresponding long forms. We release this dataset along with our code and all the models publicly in https://github.com/surrey-nlp/AbbreviationDetRepo.
### U-Net with ResNet Backbone for Garment Landmarking Purpose
 - **Authors:** Authors: Khay Boon Hong
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2204.12084
 - **Pdf link:** https://arxiv.org/pdf/2204.12084
 - **Abstract**
 We build a heatmap-based landmark detection model to locate important landmarks on 2D RGB garment images. The main goal is to detect edges, corners and suitable interior region of the garments. This let us re-create 3D garments in modern 3D editing software by incorporate landmark detection model and texture unwrapping. We use a U-net architecture with ResNet backbone to build the model. With an appropriate loss function, we are able to train a moderately robust model.
### PyGOD: A Python Library for Graph Outlier Detection
 - **Authors:** Authors: Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang, Kaize Ding, Canyu Chen, Hao Peng, Kai Shu, George H. Chen, Zhihao Jia, Philip S. Yu
 - **Subjects:** Machine Learning (cs.LG); Social and Information Networks (cs.SI)
 - **Arxiv link:** https://arxiv.org/abs/2204.12095
 - **Pdf link:** https://arxiv.org/pdf/2204.12095
 - **Abstract**
 PyGOD is an open-source Python library for detecting outliers on graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for node-, edge-, subgraph-, and graph-level outlier detection, under a unified, well-documented API designed for use by both researchers and practitioners. To overcome the scalability issue in large graphs, we provide advanced functionalities for selected models, including mini-batch and sampling. PyGOD is equipped with best practices to foster code reliability and maintainability, including unit testing, continuous integration, and code coverage. To foster accessibility, PyGOD is released under a permissive BSD-license at https://github.com/pygod-team/pygod/ and the Python Package Index (PyPI).
### Reformulating Speaker Diarization as Community Detection With Emphasis  On Topological Structure
 - **Authors:** Authors: Siqi Zheng, Hongbin Suo
 - **Subjects:** Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2204.12112
 - **Pdf link:** https://arxiv.org/pdf/2204.12112
 - **Abstract**
 Clustering-based speaker diarization has stood firm as one of the major approaches in reality, despite recent development in end-to-end diarization. However, clustering methods have not been explored extensively for speaker diarization. Commonly-used methods such as k-means, spectral clustering, and agglomerative hierarchical clustering only take into account properties such as proximity and relative densities. In this paper we propose to view clustering-based diarization as a community detection problem. By doing so the topological structure is considered. This work has four major contributions. First it is shown that Leiden community detection algorithm significantly outperforms the previous methods on the clustering of speaker-segments. Second, we propose to use uniform manifold approximation to reduce dimension while retaining global and local topological structure. Third, a masked filtering approach is introduced to extract ""clean"" speaker embeddings. Finally, the community structure is applied to an end-to-end post-processing network to obtain diarization results. The final system presents a relative DER reduction of up to 70 percent. The breakdown contribution of each component is analyzed.
### Where and What: Driver Attention-based Object Detection
 - **Authors:** Authors: Yao Rong, Naemi-Rebecca Kassautzki, Wolfgang Fuhl, Enkelejda Kasneci
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2204.12150
 - **Pdf link:** https://arxiv.org/pdf/2204.12150
 - **Abstract**
 Human drivers use their attentional mechanisms to focus on critical objects and make decisions while driving. As human attention can be revealed from gaze data, capturing and analyzing gaze information has emerged in recent years to benefit autonomous driving technology. Previous works in this context have primarily aimed at predicting ""where"" human drivers look at and lack knowledge of ""what"" objects drivers focus on. Our work bridges the gap between pixel-level and object-level attention prediction. Specifically, we propose to integrate an attention prediction module into a pretrained object detection framework and predict the attention in a grid-based style. Furthermore, critical objects are recognized based on predicted attended-to areas. We evaluate our proposed method on two driver attention datasets, BDD-A and DR(eye)VE. Our framework achieves competitive state-of-the-art performance in the attention prediction on both pixel-level and object-level but is far more efficient (75.3 GFLOPs less) in computation.
### Urban Change Detection Using a Dual-Task Siamese Network and  Semi-Supervised Learning
 - **Authors:** Authors: Sebastian Hafner, Yifang Ban, Andrea Nascetti
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.12202
 - **Pdf link:** https://arxiv.org/pdf/2204.12202
 - **Abstract**
 In this study, a Semi-Supervised Learning (SSL) method for improving urban change detection from bi-temporal image pairs was presented. The proposed method adapted a Dual-Task Siamese Difference network that not only predicts changes with the difference decoder, but also segments buildings for both images with a semantics decoder. First, the architecture was modified to produce a second change prediction derived from the semantics predictions. Second, SSL was adopted to improve supervised change detection. For unlabeled data, we introduced a loss that encourages the network to predict consistent changes across the two change outputs. The proposed method was tested on urban change detection using the SpaceNet7 dataset. SSL achieved improved results compared to three fully supervised benchmarks.
### Brain Tumor Detection and Classification Using a New Evolutionary  Convolutional Neural Network
 - **Authors:** Authors: Amin Abdollahi Dehkordi, Mina Hashemi, Mehdi Neshat, Seyedali Mirjalili, Ali Safaa Sadiq
 - **Subjects:** Neural and Evolutionary Computing (cs.NE)
 - **Arxiv link:** https://arxiv.org/abs/2204.12297
 - **Pdf link:** https://arxiv.org/pdf/2204.12297
 - **Abstract**
 A definitive diagnosis of a brain tumour is essential for enhancing treatment success and patient survival. However, it is difficult to manually evaluate multiple magnetic resonance imaging (MRI) images generated in a clinic. Therefore, more precise computer-based tumour detection methods are required. In recent years, many efforts have investigated classical machine learning methods to automate this process. Deep learning techniques have recently sparked interest as a means of diagnosing brain tumours more accurately and robustly. The goal of this study, therefore, is to employ brain MRI images to distinguish between healthy and unhealthy patients (including tumour tissues). As a result, an enhanced convolutional neural network is developed in this paper for accurate brain image classification. The enhanced convolutional neural network structure is composed of components for feature extraction and optimal classification. Nonlinear L\'evy Chaotic Moth Flame Optimizer (NLCMFO) optimizes hyperparameters for training convolutional neural network layers. Using the BRATS 2015 data set and brain image datasets from Harvard Medical School, the proposed model is assessed and compared with various optimization techniques. The optimized CNN model outperforms other models from the literature by providing 97.4% accuracy, 96.0% sensitivity, 98.6% specificity, 98.4% precision, and 96.6% F1-score, (the mean of the weighted harmonic value of CNN precision and recall).
### Performance Analysis of Out-of-Distribution Detection on Trained Neural  Networks
 - **Authors:** Authors: Jens Henriksson, Christian Berger, Markus Borg, Lars Tornberg, Sankar Raman Sathyamoorthy, Cristofer Englund
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2204.12378
 - **Pdf link:** https://arxiv.org/pdf/2204.12378
 - **Abstract**
 Several areas have been improved with Deep Learning during the past years. Implementing Deep Neural Networks (DNN) for non-safety related applications have shown remarkable achievements over the past years; however, for using DNNs in safety critical applications, we are missing approaches for verifying the robustness of such models. A common challenge for DNNs occurs when exposed to out-of-distribution samples that are outside of the scope of a DNN, but which result in high confidence outputs despite no prior knowledge of such input. In this paper, we analyze three methods that separate between in- and out-of-distribution data, called supervisors, on four well-known DNN architectures. We find that the outlier detection performance improves with the quality of the model. We also analyse the performance of the particular supervisors during the training procedure by applying the supervisor at a predefined interval to investigate its performance as the training proceeds. We observe that understanding the relationship between training results and supervisor performance is crucial to improve the model's robustness and to indicate, what input samples require further measures to improve the robustness of a DNN. In addition, our work paves the road towards an instrument for safety argumentation for safety critical applications. This paper is an extended version of our previous work presented at 2019 SEAA (cf. [1]); here, we elaborate on the used metrics, add an additional supervisor and test them on two additional datasets.
### Understanding the Impact of Edge Cases from Occluded Pedestrians for ML  Systems
 - **Authors:** Authors: Jens Henriksson, Christian Berger, Stig Ursing
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.12402
 - **Pdf link:** https://arxiv.org/pdf/2204.12402
 - **Abstract**
 Machine learning (ML)-enabled approaches are considered a substantial support technique of detection and classification of obstacles of traffic participants in self-driving vehicles. Major breakthroughs have been demonstrated the past few years, even covering complete end-to-end data processing chain from sensory inputs through perception and planning to vehicle control of acceleration, breaking and steering. YOLO (you-only-look-once) is a state-of-the-art perception neural network (NN) architecture providing object detection and classification through bounding box estimations on camera images. As the NN is trained on well annotated images, in this paper we study the variations of confidence levels from the NN when tested on hand-crafted occlusion added to a test set. We compare regular pedestrian detection to upper and lower body detection. Our findings show that the two NN using only partial information perform similarly well like the NN for the full body when the full body NN's performance is 0.75 or better. Furthermore and as expected, the network, which is only trained on the lower half body is least prone to disturbances from occlusions of the upper half and vice versa.
### A review of Federated Learning in Intrusion Detection Systems for IoT
 - **Authors:** Authors: Aitor Belenguer, Javier Navaridas, Jose A. Pascual
 - **Subjects:** Cryptography and Security (cs.CR); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2204.12443
 - **Pdf link:** https://arxiv.org/pdf/2204.12443
 - **Abstract**
 Intrusion detection systems are evolving into intelligent systems that perform data analysis searching for anomalies in their environment. The development of deep learning technologies opened the door to build more complex and effective threat detection models. However, training those models may be computationally infeasible in most Internet of Things devices. Current approaches rely on powerful centralized servers that receive data from all their parties -- violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. To mitigate these issues, Federated Learning emerged as a promising approach where different agents collaboratively train a shared model, neither exposing training data to others nor requiring a compute-intensive centralized infrastructure. This paper focuses on the application of Federated Learning approaches in the field of Intrusion Detection. Both technologies are described in detail and current scientific progress is reviewed and categorized. Finally, the paper highlights the limitations present in recent works and presents some future directions for this technology.
### Understanding The Robustness in Vision Transformers
 - **Authors:** Authors: Daquan Zhou, Zhiding Yu, Enze Xie, Chaowei Xiao, Anima Anandkumar, Jiashi Feng, Jose M. Alvarez
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.12451
 - **Pdf link:** https://arxiv.org/pdf/2204.12451
 - **Abstract**
 Recent studies show that Vision Transformers(ViTs) exhibit strong robustness against various corruptions. Although this property is partly attributed to the self-attention mechanism, there is still a lack of systematic understanding. In this paper, we examine the role of self-attention in learning robust representations. Our study is motivated by the intriguing properties of the emerging visual grouping in Vision Transformers, which indicates that self-attention may promote robustness through improved mid-level representations. We further propose a family of fully attentional networks (FANs) that strengthen this capability by incorporating an attentional channel processing design. We validate the design comprehensively on various hierarchical backbones. Our model achieves a state of-the-art 87.1% accuracy and 35.8% mCE on ImageNet-1k and ImageNet-C with 76.8M parameters. We also demonstrate state-of-the-art accuracy and robustness in two downstream tasks: semantic segmentation and object detection. Code will be available at https://github.com/NVlabs/FAN.
### Event Detection Explorer: An Interactive Tool for Event Detection  Exploration
 - **Authors:** Authors: Wenlong Zhang, Bhagyashree Ingale, Hamza Shabir, Tianyi Li, Tian Shi, Ping Wang
 - **Subjects:** Computation and Language (cs.CL); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2204.12456
 - **Pdf link:** https://arxiv.org/pdf/2204.12456
 - **Abstract**
 Event Detection (ED) is an important task in natural language processing. In the past few years, many datasets have been introduced for advancing ED machine learning models. However, most of these datasets are under-explored because not many tools are available for people to study events, trigger words, and event mention instances systematically and efficiently. In this paper, we present an interactive and easy-to-use tool, namely ED Explorer, for ED dataset and model exploration. ED Explorer consists of an interactive web application, an API, and an NLP toolkit, which can help both domain experts and non-experts to better understand the ED task. We use ED Explorer to analyze a recent proposed large-scale ED datasets (referred to as MAVEN), and discover several underlying problems, including sparsity, label bias, label imbalance, and debatable annotations, which provide us with directions to improve the MAVEN dataset. The ED Explorer can be publicly accessed through this http URL The demonstration video is available here https://www.youtube.com/watch?v=6QPnxPwxg50.
### Focal Sparse Convolutional Networks for 3D Object Detection
 - **Authors:** Authors: Yukang Chen, Yanwei Li, Xiangyu Zhang, Jian Sun, Jiaya Jia
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2204.12463
 - **Pdf link:** https://arxiv.org/pdf/2204.12463
 - **Abstract**
 Non-uniformed 3D sparse data, e.g., point clouds or voxels in different spatial positions, make contribution to the task of 3D object detection in different ways. Existing basic components in sparse convolutional networks (Sparse CNNs) process all sparse data, regardless of regular or submanifold sparse convolution. In this paper, we introduce two new modules to enhance the capability of Sparse CNNs, both are based on making feature sparsity learnable with position-wise importance prediction. They are focal sparse convolution (Focals Conv) and its multi-modal variant of focal sparse convolution with fusion, or Focals Conv-F for short. The new modules can readily substitute their plain counterparts in existing Sparse CNNs and be jointly trained in an end-to-end fashion. For the first time, we show that spatially learnable sparsity in sparse convolution is essential for sophisticated 3D object detection. Extensive experiments on the KITTI, nuScenes and Waymo benchmarks validate the effectiveness of our approach. Without bells and whistles, our results outperform all existing single-model entries on the nuScenes test benchmark at the paper submission time. Code and models are at https://github.com/dvlab-research/FocalsConv.
## Keyword: face recognition
### Evolutionary latent space search for driving human portrait generation
 - **Authors:** Authors: Benjamín Machín, Sergio Nesmachnow, Jamal Toutouh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
 - **Arxiv link:** https://arxiv.org/abs/2204.11887
 - **Pdf link:** https://arxiv.org/pdf/2204.11887
 - **Abstract**
 This article presents an evolutionary approach for synthetic human portraits generation based on the latent space exploration of a generative adversarial network. The idea is to produce different human face images very similar to a given target portrait. The approach applies StyleGAN2 for portrait generation and FaceNet for face similarity evaluation. The evolutionary search is based on exploring the real-coded latent space of StyleGAN2. The main results over both synthetic and real images indicate that the proposed approach generates accurate and diverse solutions, which represent realistic human portraits. The proposed research can contribute to improving the security of face recognition systems.
## Keyword: augmentation
### Reprint: a randomized extrapolation based on principal components for  data augmentation
 - **Authors:** Authors: Jiale Wei, Qiyuan Chen, Pai Peng, Benjamin Guedj, Le Li
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2204.12024
 - **Pdf link:** https://arxiv.org/pdf/2204.12024
 - **Abstract**
 Data scarcity and data imbalance have attracted a lot of attention in many fields. Data augmentation, explored as an effective approach to tackle them, can improve the robustness and efficiency of classification models by generating new samples. This paper presents REPRINT, a simple and effective hidden-space data augmentation method for imbalanced data classification. Given hidden-space representations of samples in each class, REPRINT extrapolates, in a randomized fashion, augmented examples for target class by using subspaces spanned by principal components to summarize distribution structure of both source and target class. Consequently, the examples generated would diversify the target while maintaining the original geometry of target distribution. Besides, this method involves a label refinement component which allows to synthesize new soft labels for augmented examples. Compared with different NLP data augmentation approaches under a range of data imbalanced scenarios on four text classification benchmark, REPRINT shows prominent improvements. Moreover, through comprehensive ablation studies, we show that label refinement is better than label-preserving for augmented examples, and that our method suggests stable and consistent improvements in terms of suitable choices of principal components. Moreover, REPRINT is appealing for its easy-to-use since it contains only one hyperparameter determining the dimension of subspace and requires low computational resource.
### Modeling the Noticeability of User-Avatar Movement Inconsistency for  Sense of Body Ownership Intervention
 - **Authors:** Authors: Zhipeng Li, Yu Jiang, Yihao Zhu, Ruijia Chen, Ruolin Wang, Yuntao Wang, Yukang Yan, Yuanchun Shi
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2204.12071
 - **Pdf link:** https://arxiv.org/pdf/2204.12071
 - **Abstract**
 An avatar mirroring the user's movement is commonly adopted in Virtual Reality(VR). Maintaining the user-avatar movement consistency provides the user a sense of body ownership and thus an immersive experience. However, breaking this consistency can enable new interaction functionalities, such as pseudo haptic feedback or input augmentation, at the expense of immersion. We propose to quantify the probability of users noticing the movement inconsistency while the inconsistency amplitude is being enlarged, which aims to guide the intervention of the users' sense of body ownership in VR. We applied angular offsets to the avatar's shoulder and elbow joints and recorded whether the user identified the inconsistency through a series of three user studies and built a statistical model based on the results. Results show that the noticeability of movement inconsistency increases roughly quadratically with the enlargement of offsets and the offsets at two joints negatively affect the probability distributions of each other. Leveraging the model, we implemented a technique that amplifies the user's arm movements with unnoticeable offsets and then evaluated implementations with different parameters(offset strength, offset distribution). Results show that the technique with medium-level and balanced-distributed offsets achieves the best overall performance. Finally, we demonstrated our model's extendability in interventions in the sense of body ownership with three VR applications including stroke rehabilitation, action game and widget arrangement.
### Deeper Insights into ViTs Robustness towards Common Corruptions
 - **Authors:** Authors: Rui Tian, Zuxuan Wu, Qi Dai, Han Hu, Yugang Jiang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.12143
 - **Pdf link:** https://arxiv.org/pdf/2204.12143
 - **Abstract**
 Recent literature have shown design strategies from Convolutions Neural Networks (CNNs) benefit Vision Transformers (ViTs) in various vision tasks. However, it remains unclear how these design choices impact on robustness when transferred to ViTs. In this paper, we make the first attempt to investigate how CNN-like architectural designs and CNN-based data augmentation strategies impact on ViTs' robustness towards common corruptions through an extensive and rigorous benchmarking. We demonstrate that overlapping patch embedding and convolutional Feed-Forward Network (FFN) boost performance on robustness. Furthermore, adversarial noise training is powerful on ViTs while fourier-domain augmentation fails. Moreover, we introduce a novel conditional method enabling input-varied augmentations from two angles: (1) Generating dynamic augmentation parameters conditioned on input images. It conduces to state-of-the-art performance on robustness through conditional convolutions; (2) Selecting most suitable augmentation strategy by an extra predictor helps to achieve the best trade-off between clean accuracy and robustness.
### Context-Aware Sequence Alignment using 4D Skeletal Augmentation
 - **Authors:** Authors: Taein Kwon, Bugra Tekin, Siyu Tang, Marc Pollefeys
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2204.12223
 - **Pdf link:** https://arxiv.org/pdf/2204.12223
 - **Abstract**
 Temporal alignment of fine-grained human actions in videos is important for numerous applications in computer vision, robotics, and mixed reality. State-of-the-art methods directly learn image-based embedding space by leveraging powerful deep convolutional neural networks. While being straightforward, their results are far from satisfactory, the aligned videos exhibit severe temporal discontinuity without additional post-processing steps. The recent advancements in human body and hand pose estimation in the wild promise new ways of addressing the task of human action alignment in videos. In this work, based on off-the-shelf human pose estimators, we propose a novel context-aware self-supervised learning architecture to align sequences of actions. We name it CASA. Specifically, CASA employs self-attention and cross-attention mechanisms to incorporate the spatial and temporal context of human actions, which can solve the temporal discontinuity problem. Moreover, we introduce a self-supervised learning scheme that is empowered by novel 4D augmentation techniques for 3D skeleton representations. We systematically evaluate the key components of our method. Our experiments on three public datasets demonstrate CASA significantly improves phase progress and Kendall's Tau scores over the previous state-of-the-art methods.
### Disambiguation of morpho-syntactic features of African American English  -- the case of habitual be
 - **Authors:** Authors: Harrison Santiago, Joshua Martin, Sarah Moeller, Kevin Tang
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2204.12421
 - **Pdf link:** https://arxiv.org/pdf/2204.12421
 - **Abstract**
 Recent research has highlighted that natural language processing (NLP) systems exhibit a bias against African American speakers. The bias errors are often caused by poor representation of linguistic features unique to African American English (AAE), due to the relatively low probability of occurrence of many such features in training data. We present a workflow to overcome such bias in the case of habitual ""be"". Habitual ""be"" is isomorphic, and therefore ambiguous, with other forms of ""be"" found in both AAE and other varieties of English. This creates a clear challenge for bias in NLP technologies. To overcome the scarcity, we employ a combination of rule-based filters and data augmentation that generate a corpus balanced between habitual and non-habitual instances. With this balanced corpus, we train unbiased machine learning classifiers, as demonstrated on a corpus of AAE transcribed texts, achieving .65 F$_1$ score disambiguating habitual ""be"".
",2022-04-27T17:00:10Z,2022-04-27T17:00:10Z,open,0,"paper/literature of dark pattern, document, paper title: Automated detection of dark patterns in cookie banners: how to do it poorly and why it is hard to do it any other way","examples, detection","documentation, detection","Papers/Docs/Sources, DPs detection Tools",,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/DataDog/browser-sdk/issues/2119,👿 Dark Pattern in RUM Script,https://github.com/DataDog/browser-sdk/issues/2119,"**What are you trying to achieve and what is your issue? Please describe.**
As shown on your [documentation page](https://docs.datadoghq.com/real_user_monitoring/browser/#npm) when you run the init command for the RUM script depending version used the property name may vary but the behavior is the same. 

If you don’t include or set the (sessionReplaySampleRate, premiumSampleRate or replaySampleRate) it defaults to 100%. When implementing a script for any other platform this is very unexpected behavior. Typically if you omit a property it disables the functionality and defaults to a falsy value. Opt in vs. explicit opt out especially when it comes to something that is billable.

To make things worse, you have changed the name of this property 3 times since May of 2022 further exacerbating this dark pattern and making it feel like an intentional way to generate revenue from customers. With each of these version changes if someone upgrades and doesn’t notice this specific change you are billing them for 100% of sessions vs whatever they had set previously. 

**Describe the solution you'd like**
When sessionReplaySampleRate, premiumSampleRate or replaySampleRate are omitted default value should be 0%, disabling the feature.",2023-03-28T16:15:02Z,2023-11-08T08:46:16Z,closed,3,"usage of dark pattern (in RUM script), default 100% billable feature, preselection, functionality disabled","opt-in for billables, preselection, nagging","opt-in/out, billing, preselection, disabled feature",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/iteles/blw-baby/issues/25,Chia Eggs: How to Replace Poultry Eggs with a Plant-based Alternative,https://github.com/iteles/blw-baby/issues/25,"This is a _micro_ piece of content that we can create in around **`T1h`**.

# Todo

## Research

+ [ ] Take a look at the existing web pages/sites listed on the first page of Google results (max 8)
  + [ ] Use an incognito Chrome (or Brave) window to avoid any cookies/trackers
  + [ ] Screenshot the _first_ thing you see when you open the page e.g. the annoying cookie modal/prompt below.
    > See: https://www.take-a-screenshot.org/mac.html
  + [ ] Once you've dismissed the cookie noise, take _another_ screenshot of actual content to show the layout, any Ads, and show how much cruft there is on the page. i.e. do they get straight to the point or is there a lot of noise?

## Create!

Once you have looked at the available top recipes for a Chia Egg and uploaded all the screenshots for the research.

+ [ ] Plan the photograph we are going to take for our recipe:
  + [ ] What background do you want to use, do you want anything else in the frame?
+ [ ] Take the photos of raw ingredients, process and final result
+ [ ] Do any necessary post-processing of images e.g. PhotoShop/LightRoom
+ [ ] Upload photos to GitHub (this issue/thread)
+ [ ] Write up the recipe!
  + [ ] Ingredients list
  + [ ] Process/steps
  + [ ] Any insightful tips/tricks

Once we have the content, we can figure out how to host it in the most SEO friendly way. 💭 
Currently considering WordPress: https://github.com/nelsonic/learn-wordpress/issues/5

## Context

At present, if we search for ""how to make chia egg"" on Google:
https://www.google.com/search?q=how+to+make+chia+egg
![image](https://user-images.githubusercontent.com/194400/165979391-207cc2bd-bf21-4075-b2c6-33093bb19dbc.png)

The top result is: https://minimalistbaker.com/make-chia-egg/
![image](https://user-images.githubusercontent.com/194400/165979253-4da5e3a2-d813-4e7d-bb20-97fd0ca3fb06.png)

But if you want actually _view_ the content, you first need to either ""Accept All: 
![image](https://user-images.githubusercontent.com/194400/166079625-e67e9de7-659e-4029-83aa-8c4f5595ee8b.png)

The **Green** **`Accept All`** Call to Action (CTA) button in the Pop-up/Modal is a [Dark Pattern](https://usercentrics.com/knowledge-hub/dark-patterns-and-how-they-affect-consent/) designed to erode your privacy. 
If you click the button they want you click you will be agreeing to share your browser data with **133 3<sup>rd</sup> Parties** (see below).

You can see the list by clicking on ""Manage Your Privacy"" > ""VENDORS"":

![image](https://user-images.githubusercontent.com/194400/166079614-6eb96f39-07a4-4fbe-87f3-f4172493ede2.png)

1. 33Across
1. A.Mob
1. Active Agent (ADITION technologies GmbH)
1. AcuityAds Inc.
1. Ad360
1. ADARA MEDIA UNLIMITED
1. AdElement
1. Adform
1. Adobe Advertising Cloud
1. Adobe Advertising Cloud
1. Adobe Audience Manager, Adobe Experience Platform
1. Adobe Business Catalyst
1. Adobe Spark
1. AdTheorent, Inc
1. Akamai
1. Amazon
1. Amazon A9
1. Amazon Advertising
1. Amobee Inc.
1. AnyClip
1. Axel Springer Teaser Ad GmbH
1. BeeswaxIO Corporation
1. BIDSWITCH GmbH
1. Bidtellect, Inc
1. BidTheatre AB
1. Bing
1. Blis Media Limited
1. BritePool Inc
1. Carbon (AI) Limited
1. Centro
1. Centro
1. Chocolate Platform
1. Cloud Technologies S.A.
1. CMI Marketing, Inc. d/b/a CafeMedia
1. Comscore B.V.
1. Crimtan Holdings Limited
1. Criteo SA
1. DeepIntent, Inc.
1. Delta Air Lines
1. Delta Projects AB
1. DeltaX
1. Dentsu London Limited
1. Digital East GmbH
1. DoubleVerify Inc.​
1. dunnhumby Germany GmbH
1. DynAdmic
1. Emerse Sverige AB
1. EMX Digital LLC
1. Epsilon
1. Exponential Interactive, Inc d/b/a VDX.tv
1. Facebook
1. GetIntent
1. Google (non TCF)
1. Google Advertising Products 
1. Google Analytics
1. Google Analytics (Privacy Friendly)
1. Google Maps
1. Google Optimize
1. Google ReCaptcha
1. Google Tag Manager 
1. GumGum, Inc.
1. HUMAN
1. ID5 Technology Ltd
1. Index Exchange, Inc.
1. Integral Ad Science, Inc.
1. IPONWEB GmbH
1. Kargo Global Inc.
1. Kayzen
1. Knorex
1. Liftoff Mobile, Inc.
1. LinkedIn
1. LinkedIn Ireland Unlimited Company
1. LiquidM Technology GmbH
1. LiquidM Technology GmbH
1. LiveIntent 
1. LiveRamp, Inc.
1. LoopMe Limited
1. Magnite CTV, Inc.
1. Magnite, Inc.
1. Magnite, Inc. (Outstream)
1. Market Resource Partners LLC
1. Media.net Advertising FZ-LLC
1. Mediakeys Platform
1. MediaMath, Inc.
1. mediarithmics SAS
1. Mobile Professionals BV
1. Nativo, Inc.
1. NeuStar, Inc.
1. NextRoll, Inc.
1. Nielsen DAR 
1. Nielsen Marketing Cloud
1. OpenX
1. Oracle Data Cloud
1. Outbrain UK Ltd
1. PadSquad
1. Parrable
1. Platform161
1. Platform161 B.V.
1. Platform360
1. PubMatic, Inc.
1. PulsePoint
1. Quantcast International Limited
1. Rakuten Marketing LLC
1. remerge GmbH
1. Roxot
1. RTB House S.A.
1. Sharethrough, Inc
1. Sift Media, Inc
1. Simplifi Holdings Inc
1. Sizmek by Amazon
1. Smart Adserver
1. Sociomantic
1. Sonobi, Inc
1. Sovrn Holdings Inc
1. SpotX, Inc
1. StackAdapt
1. TabMo SAS
1. Taboola Europe Limited
1. TAPTAP Digital SL
1. Teads
1. The MediaGrid Inc.
1. The Procter & Gamble Company
1. The Trade Desk
1. travel audience GmbH
1. TripleLift, Inc.
1. Undertone
1. Unruly Group LLC
1. Xandr, Inc.
1. Yahoo
1. Yahoo EMEA Limited
1. Yieldmo, Inc.
1. Zemanta, Inc.
1. Zeta Global

I _wish_ I was making this up.  But I'm not. The default choice they want you to click ""**Accept All**"" will add so many trackers and share your data with so many [Data Brokers](https://www.youtube.com/watch?v=wqn3gR1WTcA) that will then monitor your activities across the web. You might not _care_ that other people know you have viewed a random recipe ... 
But ... you absolutely _should_ care about your own privacy and that of other people!

### SEO

Google _likes_ these websites because they all use Google Analytics and display Ads.
It will be interesting to see if we can ""compete"" with them given that we won't _ever_ have Ads.

Anyway, let's create this recipe and piece of content so we can link to it! 🙏 ",2022-04-29T23:26:55Z,2022-06-08T14:43:02Z,open,22,"usage of dark pattern in software, ""accept all"" CTA (call to action) button, erode privacy","minimalistbaker.com, modal, nagging, obstruction","minimalistbaker.com, modal, nagging, obstruction, privacy issue",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/organicmaps/organicmaps/issues/5686,Make it known that places and map data is contributed by people in the community,https://github.com/organicmaps/organicmaps/issues/5686,"When looking at a map or searching for a place, not all places are in [OpenStreetMap](osm.org). People should be able to discover that map data comes from OSM and not Organic Maps. As this is a community app, a missing business can be addressed by adding it, and it will be added to OSM for everyone.

**Problem Statement**
Most people don't know why they can't find a place they are looking for, and assume the issue is with Organic Maps.

**Main goals**
1. Improve experience for people using OM.
2. Reduce the number of support requests to our small team (""please add this place to the map"", ""fix this invalid address"", or ""why is this route wrong?"").
3. Improve OSM map data quality.
4. Reduce users' disappointment and the number of bad ratings in stores.

**Criteria**
- Place page
      - Existing Place: update ""Edit Place"" button to be ""Edit Place [ OSM logo ] OpenStreetMap"".
      - Unknown Place: update ""Add Place"" button to be ""Add Place [ OSM logo ] OpenStreetMap"", and make the button solid blue, not just outlined in blue.
- Search Result page: directly below search field, display a button called ""Add Place"", followed by the OpenStreetMap logo and ""OpenStreetMap "".  When clicking on the button, this opens the 'Add a place to OpenStreetMap' functionality.
- Main page
      - Display text: in the bottom right corner showing small text ""Map Data: OpenStreetMap"".  Text color: grey.  Text size: 10. Text display time: 30 seconds and then fades away.

**Design**
Place page
https://www.figma.com/file/4IJ7QbJ207Z66OQTXRuBlF?node-id=45:1017&mode=design#675140364
https://www.figma.com/file/4IJ7QbJ207Z66OQTXRuBlF?node-id=146:444&mode=design#675143809

Search Results page
https://www.figma.com/file/u9l4ytCVy3UFIyniAJLAy5?node-id=5:4800&mode=design#675138990
",2023-08-09T22:31:42Z,2024-01-20T00:30:35Z,open,34,miscellaneous,location feature?,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/aeharding/voyager/issues/334,Option to turn off infinite scrolling,https://github.com/aeharding/voyager/issues/334,"This was one of my favorite features of Apollo. Instead of scrolling forever, posts would stop after a certain number, similar to how the reddit website works on mobile. It makes it much easier to avoid getting stuck scrolling for hours at a time. ",2023-07-09T00:58:39Z,2023-11-15T03:22:54Z,closed,1,"Apollo, prevention of dark pattern in software, infinite scrolling disable","infinite scrolling turn off, addictive","Apollo, infinite scrolling, addictive, avoid dark pattern",DPs prevention in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/porscheofficial/cookie-consent-banner/issues/20,Dark patterns are present in example image,https://github.com/porscheofficial/cookie-consent-banner/issues/20,"[Dark patterns](https://cookieinformation.com/resources/blog/what-are-dark-patterns-in-cookie-banners/) are present in the example image.

* 2) Pre-ticked checkboxes
* 4) Deceptive button contrast colors

I did not check to see how the banner is actively being used in the wild and that might differ.",2023-08-10T16:43:38Z,2023-08-11T12:13:38Z,closed,3,"dark pattern examples, pre-ticked checkboxes, button contrast colors ","examples, preselection, design hierarchy, UI manipulation","auto-check boxes, preselection, UI/UX design",DPs examples/definitions,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/breezy-weather/breezy-weather/issues/207,QWeather api （和风天气api）,https://github.com/breezy-weather/breezy-weather/issues/207,"### Link to publicly available documentation of the API

https://dev.qweather.com/en/docs/start/

### Available and not available data

**Available**
1000request/per day

Real-time weather
Hourly forecast(24h)
Daily forecast(3-7d)
grid weather also

Minutely-Precipitation

Warning
Indices
Air Quality
Sun and Moon

**Not available**

Time Machine
Tropical Cyclone
Solar Radiation

Please note that this source is for Chinese especially, people in other countries are suggested to use Accuweather or Openweather as substitute.


### Are you going to develop yourself the new provider for the app?

Yes, I'd like to assist but need some help as a noob maybe.

### Give a bit more details or context about this source

Reasons
Accuweather allow only 50 requests per day.
Current China data api do not support Minutely-Precipitation also

### Acknowledgements

- [X] I have searched the existing issues and this is a new ticket, **NOT** a duplicate or related to another open or closed issue.
- [X] I have written the name of the source as the title of this issue.
- [x] I have updated the app to **[latest version](https://github.com/breezy-weather/breezy-weather/releases/latest)** and this source is not part of it.",2023-07-22T06:51:05Z,2024-02-15T08:54:25Z,open,37,"miscellaneous (forced action, phone number required)","registration requires phone number after email, China","forced action, phone number required, registration",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/matrix-nio/matrix-nio/issues/403,Propagate asyncio.CancelledError in `sync_forever()`.,https://github.com/matrix-nio/matrix-nio/pull/403,"The current behaviour of silently ignoring `asyncio.CancelledError` and returning normally is counter to the intention of `CancelledError`, and breaks some standard asyncio utilities that don't expect it.

From the [Python docs](https://docs.python.org/3/library/asyncio-task.html#task-cancellation):
> In case [asyncio.CancelledError](https://docs.python.org/3/library/asyncio-exceptions.html#asyncio.CancelledError) is explicitly caught, it should generally be propagated when clean-up is complete.

This is my motivating example of where this causes problems:
```python
try:
    await asyncio.wait_for(asyncio.create_task(client.sync_forever()), timeout = 10)
    print(""normal"")
except asyncio.TimeoutError:
    # Would expect to get here, as sync_forever() will obviously run for longer 
    # than 10 seconds.
    print(""timeout"")
```
This counterintuitively prints out `normal` after 10  seconds, as when `wait_for()` discovers the task is still running, it cancels it, then waits for the CancelledError to propagate, and raises a TimeoutError. However, since `sync_forever()` handles the CancelledError and returns normally, no TimeoutError is raised, and the code continues from the return site.

My fix is simply to replace the `break` statement in the handling of CancelledError with a `raise`, to re-throw the exception. This could feasibly break programs that rely on the existing behaviour; I'm not sure how you deal with such things in this project.",2023-04-19T08:53:40Z,2023-11-15T08:20:05Z,closed,4,prevention of dark pattern ,TimeoutError code change for final version,avoid dark pattern,DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/mattermost/mattermost/issues/21710,Switching from Team Edition to Enterprise edition should ask for a confirmation,https://github.com/mattermost/mattermost/issues/21710,"#### Summary
Free trial button does not ask for confirmation.

#### Steps to reproduce
1. Install the Team Edition.
1. Browse to `/admin_console/about/license`.
1. Click on the free trial button.
1. It immediately starts downloading the Enterprise Edition.

#### Expected behavior
The best would be to have an option to hide this banner entirely. But at least the button should ask for a confirmation.
It should also display a clear way to cancel the download after it started.

#### Observed behavior (that appears unintentional) 
The button does not ask for any confirmation before it starts to download a binary replace the running version of Mattermost Server.
We discovered this after a misclick and it kind of looks like a dark pattern.
The fact that this page is the homepage for the admin console makes it especially easy to click the button by mistake.
We are self-hosting the Team Edition and have no intention to switch to the Enterprise Edition.
",2022-11-22T19:56:26Z,2023-11-17T19:07:26Z,closed,6,"MatterMost (open source platform for secure collaboration), usage of dark pattern  in software, free trial button processed without permission","hide banner to avoid confusion, misclick, UI issue, interface intereference","MatterMost, consent, interface interference, UI/UX design",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/jiacai2050/hot-posts/issues/169,2023-01-20 Hot Posts,https://github.com/jiacai2050/hot-posts/issues/169,"# Hacker News


#### [Google to reduce workforce by 12k](https://blog.google/inside-google/message-ceo/january-update/)

437 points by [colesantiago](https://news.ycombinator.com/user?id=colesantiago) at 18:21:01 | [463 comments](https://news.ycombinator.com/item?id=34451051)


#### [A first person shooter in 571 lines of GNU Awk (2016)](https://github.com/TheMozg/awk-raycaster)

312 points by [nequo](https://news.ycombinator.com/user?id=nequo) at 00:55:10 | [65 comments](https://news.ycombinator.com/item?id=34442528)


#### [Stock market charts you never saw (2021)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3050736)

305 points by [dot1x](https://news.ycombinator.com/user?id=dot1x) at 02:07:31 | [171 comments](https://news.ycombinator.com/item?id=34443471)


#### [I&#39;ve procrastinated working on my thesis for more than a year](https://thoughtsbyaashiq.bearblog.dev/ive-procrastinated-working-on-my-thesis-for-over-a-year/)

275 points by [memorable](https://news.ycombinator.com/user?id=memorable) at 13:35:24 | [140 comments](https://news.ycombinator.com/item?id=34449626)


#### [CarSized: A way to visualise car dimensions](https://www.carsized.com/en/)

256 points by [kennybrea](https://news.ycombinator.com/user?id=kennybrea) at 10:46:20 | [83 comments](https://news.ycombinator.com/item?id=34448576)


#### [How to own an airline in 3 easy steps and grab the TSA nofly list along the way](https://maia.crimew.gay/posts/how-to-hack-an-airline/)

230 points by [half-kh-hacker](https://news.ycombinator.com/user?id=half-kh-hacker) at 06:39:12 | [124 comments](https://news.ycombinator.com/item?id=34446673)


#### [ChatRWKV, like ChatGPT but powered by the RWKV (RNN-based, open) language model](https://github.com/BlinkDL/ChatRWKV)

180 points by [maraoz](https://news.ycombinator.com/user?id=maraoz) at 05:29:32 | [55 comments](https://news.ycombinator.com/item?id=34445873)


#### [The Art of Money Getting or Golden Rules for Making Money by P. T. Barnum (1880)](https://www.gutenberg.org/files/8581/8581-h/8581-h.htm)

123 points by [splatzone](https://news.ycombinator.com/user?id=splatzone) at 09:13:46 | [28 comments](https://news.ycombinator.com/item?id=34447945)


#### [Launch HN: Odigos (YC W23) – Instant distributed tracing for Kubernetes clusters]()

113 points by [edenfed](https://news.ycombinator.com/user?id=edenfed) at 00:59:52 | [27 comments](https://news.ycombinator.com/item?id=34442603)


#### [Exploiting null-dereferences in the Linux kernel](https://googleprojectzero.blogspot.com/2023/01/exploiting-null-dereferences-in-linux.html)

102 points by [kuter](https://news.ycombinator.com/user?id=kuter) at 02:37:18 | [34 comments](https://news.ycombinator.com/item?id=34443813)


#### [Simulation Intelligence: Towards a New Generation of Scientific Methods (2022)](https://arxiv.org/abs/2112.03235)

85 points by [fastneutron](https://news.ycombinator.com/user?id=fastneutron) at 03:19:30 | [12 comments](https://news.ycombinator.com/item?id=34444377)


#### [Ultibo – Bare-Metal Pascal for Raspberry Pi](https://ultibo.org/make/)

69 points by [Fr0styMatt88](https://news.ycombinator.com/user?id=Fr0styMatt88) at 04:45:12 | [14 comments](https://news.ycombinator.com/item?id=34445367)


#### [ZeroSSL: XSS to session hijacking, stealing a private key (and password hash)](https://groups.google.com/a/ccadb.org/g/public/c/kqtoGeEv5Fc)

65 points by [kkm](https://news.ycombinator.com/user?id=kkm) at 04:40:02 | [10 comments](https://news.ycombinator.com/item?id=34445305)


#### [Sudoedit can edit arbitrary files](https://seclists.org/oss-sec/2023/q1/42)

60 points by [accessvector](https://news.ycombinator.com/user?id=accessvector) at 05:05:26 | [32 comments](https://news.ycombinator.com/item?id=34445602)


#### [Nuclear explosion impact on humans indoors (2022)](https://aip.scitation.org/doi/10.1063/5.0132565)

57 points by [jnord](https://news.ycombinator.com/user?id=jnord) at 06:22:31 | [43 comments](https://news.ycombinator.com/item?id=34446513)


#### [Deep Learning Tuning Playbook](https://github.com/google-research/tuning_playbook)

56 points by [tehnub](https://news.ycombinator.com/user?id=tehnub) at 13:17:12 | [3 comments](https://news.ycombinator.com/item?id=34449527)


#### [Show HN: Music Audio Search Engine Using OpenAI&#39;s Embeddings on GPT Descriptions](https://muzic-sage.vercel.app/)

48 points by [jmiran15](https://news.ycombinator.com/user?id=jmiran15) at 10:07:59 | [18 comments](https://news.ycombinator.com/item?id=34448334)


#### [Getting Started with Property-Based Testing in Python with Hypothesis and Pytest](https://semaphoreci.com/blog/property-based-testing-python-hypothesis-pytest)

46 points by [BerislavLopac](https://news.ycombinator.com/user?id=BerislavLopac) at 17:28:12 | [5 comments](https://news.ycombinator.com/item?id=34450736)


#### [The Myth of the Myth of the 10x Programmer (2020)](https://payne.org/blog/the-myth-of-the-myth-of-the-10x-programmer/)

44 points by [nsoonhui](https://news.ycombinator.com/user?id=nsoonhui) at 19:21:25 | [36 comments](https://news.ycombinator.com/item?id=34451566)


#### [SSHD: Random boot time relinking, OpenBSD](https://undeadly.org/cgi?action=article;sid=20230119075627)

44 points by [codesniperjoe](https://news.ycombinator.com/user?id=codesniperjoe) at 15:14:53 | [25 comments](https://news.ycombinator.com/item?id=34450059)


#### [Choosing a Postgres Primary Key](https://supabase.com/blog/choosing-a-postgres-primary-key)

39 points by [awalias](https://news.ycombinator.com/user?id=awalias) at 18:55:30 | [14 comments](https://news.ycombinator.com/item?id=34451344)


#### [FYI: Fastly&#39;s down, which is why so many sites are down]()

32 points by [mattweinberg](https://news.ycombinator.com/user?id=mattweinberg) at 07:05:56 | [6 comments](https://news.ycombinator.com/item?id=34446883)


#### [Interesting Facts about Bell Labs and 2001: A Space Odyssey (2001)](https://sites.psu.edu/comm150honors/2016/05/03/interesting-facts-about-bell-labs-and-the-odyssey-from-an-archivist-at-bell-labs-my-dad/)

31 points by [ecliptik](https://news.ycombinator.com/user?id=ecliptik) at 14:04:21 | [15 comments](https://news.ycombinator.com/item?id=34449740)


#### [Not worried about AI that passes Turing test, but AI that fails it on purpose](https://old.reddit.com/r/C_S_T/comments/ae288t/im_not_worried_about_the_ai_that_can_pass_the/)

29 points by [undopamine](https://news.ycombinator.com/user?id=undopamine) at 19:34:15 | [17 comments](https://news.ycombinator.com/item?id=34451679)


#### [So why a News Feed?](https://post.news/article/2KYjMzTY05WmEZmxJnG3PGqyVpz)

25 points by [tokenadult](https://news.ycombinator.com/user?id=tokenadult) at 05:30:32 | [6 comments](https://news.ycombinator.com/item?id=34445888)


#### [Revisiting Apple’s ill-fated Lisa computer, 40 years on](https://arstechnica.com/gadgets/2023/01/revisiting-apples-ill-fated-lisa-computer-40-years-on/)

23 points by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) at 18:38:54 | [0 comments](https://news.ycombinator.com/item?id=34451178)


#### [Unusual compound found in Rembrandt’s The Night Watch](https://www.esrf.fr/home/news/general/content-news/general/unusual-compound-found-in-rembrandts-the-night-watch.html)

22 points by [gmays](https://news.ycombinator.com/user?id=gmays) at 05:43:58 | [20 comments](https://news.ycombinator.com/item?id=34446053)


#### [Runlike: Given an existing Docker container, prints the command line to run it](https://github.com/lavie/runlike)

19 points by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) at 17:51:48 | [0 comments](https://news.ycombinator.com/item?id=34450880)


#### [The Foonly F1 Computer (2011)](http://dave.zfxinc.net/f1.html)

15 points by [dcminter](https://news.ycombinator.com/user?id=dcminter) at 02:18:49 | [6 comments](https://news.ycombinator.com/item?id=34443602)


#### [Wait, what? Wyoming lawmakers push to ban all electric vehicles by 2035](https://financialpost.com/commodities/energy/electric-vehicles/wyoming-lawmakers-bill-ban-electric-vehicles-2035)

15 points by [ranit](https://news.ycombinator.com/user?id=ranit) at 02:28:43 | [3 comments](https://news.ycombinator.com/item?id=34443702)


#### [Lights kept on at a Mass. school for a year because no one can turn them off](https://www.nbcnews.com/news/us-news/lights-massachusetts-school-year-no-one-can-turn-rcna65611)

14 points by [slapshot](https://news.ycombinator.com/user?id=slapshot) at 05:30:11 | [6 comments](https://news.ycombinator.com/item?id=34445882)


#### [A different approach to building C++ projects](https://rachelbythebay.com/bb/)

11 points by [kimmk](https://news.ycombinator.com/user?id=kimmk) at 19:06:15 | [7 comments](https://news.ycombinator.com/item?id=34451454)


#### [TitleMax Makes Sure Customers Can Never Pay Off Their Car Loans](https://jalopnik.com/how-titlemax-makes-sure-customers-can-never-pay-off-the-1850006898)

9 points by [t23](https://news.ycombinator.com/user?id=t23) at 12:40:48 | [0 comments](https://news.ycombinator.com/item?id=34449332)


#### [Ask HN: Do you prefer Powershell?]()

7 points by [nodra](https://news.ycombinator.com/user?id=nodra) at 09:38:59 | [10 comments](https://news.ycombinator.com/item?id=34448138)


#### [Peter Thiel’s fund wound down 8-year Bitcoin bet before market crash](https://www.ft.com/content/0a1d5597-7145-4035-987b-ff033bba3d75)

7 points by [mancerayder](https://news.ycombinator.com/user?id=mancerayder) at 03:56:48 | [0 comments](https://news.ycombinator.com/item?id=34444815)


#### [EMAG2: Earth Magnetic Anomaly Grid (2-arc-minute resolution)](https://www.ngdc.noaa.gov/geomag/emag2.html)

6 points by [graderjs](https://news.ycombinator.com/user?id=graderjs) at 00:32:37 | [0 comments](https://news.ycombinator.com/item?id=34442158)


#### [Gen Z and millennials are leading ‘the big quit’ in 2023](https://www.cnbc.com/2023/01/18/70percent-of-gen-z-and-millennials-are-considering-leaving-their-jobs-soon.html)

6 points by [hker](https://news.ycombinator.com/user?id=hker) at 14:29:47 | [1 comments](https://news.ycombinator.com/item?id=34449849)


#### [Dark Patterns](https://link.springer.com/article/10.1007/s12599-022-00783-7)

5 points by [rntn](https://news.ycombinator.com/user?id=rntn) at 03:40:09 | [2 comments](https://news.ycombinator.com/item?id=34444623)


#### [J&amp;J to discontinue HIV vaccine trial](https://www.reuters.com/business/healthcare-pharmaceuticals/jj-discontinue-hiv-vaccine-trial-2023-01-18/)

5 points by [Jimmc414](https://news.ycombinator.com/user?id=Jimmc414) at 03:48:38 | [2 comments](https://news.ycombinator.com/item?id=34444712)


#### [Keyline Design](https://en.wikipedia.org/wiki/Keyline_design)

4 points by [raptorraver](https://news.ycombinator.com/user?id=raptorraver) at 03:16:39 | [0 comments](https://news.ycombinator.com/item?id=34444340)


#### [FTX’s new CEO says there’s possibility for exchange to restart](https://techcrunch.com/2023/01/19/ftxs-new-ceo-says-theres-possibility-for-exchange-to-restart/)

4 points by [danielrm26](https://news.ycombinator.com/user?id=danielrm26) at 03:10:00 | [0 comments](https://news.ycombinator.com/item?id=34444265)


#### [The Paradox of Goals](https://nesslabs.com/the-paradox-of-goals)

4 points by [gardenfelder](https://news.ycombinator.com/user?id=gardenfelder) at 03:08:52 | [1 comments](https://news.ycombinator.com/item?id=34444245)


#### [Microsoft still offers MSN premium dial-up](https://get.msn.com/)

4 points by [WorldPeas](https://news.ycombinator.com/user?id=WorldPeas) at 08:36:05 | [0 comments](https://news.ycombinator.com/item?id=34447679)


#### [Emerge (YC W21) is hiring engineers to build the future of mobile development](https://www.ycombinator.com/companies/emerge-tools/jobs/5Y3MCJi-senior-mobile-engineer-remote)

1 points by [jshchnz](https://news.ycombinator.com/user?id=jshchnz) at 05:00:35 | [ comments](https://news.ycombinator.com/item?id=34445538)


#### [Lago (YC S21), open source usage based billing, is hiring a cloud engineer](https://www.ycombinator.com/companies/lago/jobs/kDbtSIO-cloud-engineer)

1 points by [Rafsark](https://news.ycombinator.com/user?id=Rafsark) at 20:02:01 | [ comments](https://news.ycombinator.com/item?id=34451887)



# V2EX


  <details>
    <summary>
      <strong>听说今天还在上班的不是年薪百把万就是月薪千把块</strong>
    </summary>
    我是那个月薪千把块😭😭😭
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/909990"">79 comments</a> by <a href=""https://www.v2ex.com/u/wjx0912"">wjx0912</a>
    at 08:58:29
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>自制的兔年红包封面，欢迎 v 友们使用</strong>
    </summary>
    <p>1 月 20 日 12 点，800 份</p>
<p><img alt=""红包封面"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.imgur.com/GUFUnZM.jpg""></p>
<p>或者跳转到： <a href=""https://mp.weixin.qq.com/s/Xr3vyNTrD4o_EPVc18Q9dA"" rel=""nofollow"">https://mp.weixin.qq.com/s/Xr3vyNTrD4o_EPVc18Q9dA</a></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910007"">72 comments</a> by <a href=""https://www.v2ex.com/u/billyu"">billyu</a>
    at 10:40:29
    in <a href=""https://www.v2ex.com/go/promotions"">推广</a>
    </p>


  <details>
    <summary>
      <strong>过年回家电脑上三个远程没有一个可以使用 有什么稳定好用的远程推荐吗？</strong>
    </summary>
    <p>过年回家电脑上挂着三个远程软件 没有一个能够使用  简直要被气死
1.Todesk   电脑上一直挂着这个软件 之前帮助同事解决过一些问题就没有管过 回到家后发现需要远程连接密码，试遍了我所有密码都不正确。 我就知道这个密码肯定不是我设置的 我就想问问产品经理怎么想的？ 我现在再坐飞机过去取看一下密码是多少吗？
客服工单无人回复 打电话也没人接 去他们论坛看了下  还有很多人密码明明正确连接不上 客服给的解决方案是让重新设置下密码 或者重新下载软件  我要是能控制电脑要你们干什么？？？ 真的 NT</p>
<p>2.Parsec 回到家后本地 parsec 登录相同账号远程主机直接不显示，临走前局域网内测试了下无问题 </p>
<p>3.moonlight 临走前下载了下就没有管过 想着映射了 ip 端口 知道公网 ip 应该无问题， 回家后连接不上调研了下还得去设置英伟达的参数  真的无语 这是给普通用户去用的？？？？？</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910028"">65 comments</a> by <a href=""https://www.v2ex.com/u/willwon1"">willwon1</a>
    at 12:54:50
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>刚知道有某雅(Alist)这个东西,再看我的威联通有点不香了...</strong>
    </summary>
    <p>我 NAS 七成的功能是看片<br>
当初 NAS+硬盘+UPS 将近 1W 块了,还费劲巴拉的蹲 PT 站开放注册...<br>
昨天发现某雅啥都有啊...<br>
心塞啊,我是 49 年入国军了吗?<br>
V 友们能说一说 Alist 的劣势让我舒心一下吗?<br>
或者...你们扔几块石头下来?<br>
我不换不锈钢盆,谢谢</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/909991"">49 comments</a> by <a href=""https://www.v2ex.com/u/gezimonkey"">gezimonkey</a>
    at 09:09:44
    in <a href=""https://www.v2ex.com/go/nas"">NAS</a>
    </p>


  <details>
    <summary>
      <strong>春节档电影该看哪一部？🤔️🤔️</strong>
    </summary>
    <p>春节档，该看哪部？</p>
<p>妙记多<a href=""https://www.mojidoc.com/04dbc-eoivpkemyrb3xc2nrtnkkd7dmi-00b/?utm_medium=referral&amp;utm_source=V2ex&amp;utm_content=0120%C2%A0"" rel=""nofollow"">十年最强春节档</a>观影小贴士奉上，点击查看👈，祝大家新春快乐</p>
<p><img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://pic.imgdb.cn/item/63ca26a4be43e0d30e5bf39e.png"">
<img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://pic.imgdb.cn/item/63ca2781be43e0d30e5d4d61.png"">
<img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://pic.imgdb.cn/item/63ca27f2be43e0d30e5ddc92.png"">
<img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://pic.imgdb.cn/item/63ca284cbe43e0d30e5e5bce.png""></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910035"">47 comments</a> by <a href=""https://www.v2ex.com/u/MojiDOc"">MojiDOc</a>
    at 13:39:22
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>2023 年了，有什么性价比高、既要又要还要的路由器推荐？</strong>
    </summary>
    <p>想给出租房扔一台。</p>
<p>性能越高越好，支持特性越多越好（什么 WiFi6 、万兆网络、typec 接口应上尽上，当然没有也行🐶）</p>
<p>价格千元以内，越便宜越好。（市场能买到的价格，包括二手价格和水货价格）</p>
<p>没有 mesh 、跨层 ap 等需求。</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/909995"">47 comments</a> by <a href=""https://www.v2ex.com/u/clearc"">clearc</a>
    at 09:57:46
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>学费生活费预算 20w，现在还有合适的水硕项目吗</strong>
    </summary>
    <p>本人基本情况 目前从事运维工程师  全日制专科+成人非全本科学历+学位证 英语水平目前只有三级，努把力应该能够到雅思 5.5<br></p>
<p>需要一个 qs200 内 中留服认证  和 IT 行业只要沾点边的专业  好毕业（授课型硕无需论文） 的一年制水硕<br></p>
<p>有什么推荐的吗<br></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910025"">43 comments</a> by <a href=""https://www.v2ex.com/u/nigga"">nigga</a>
    at 12:37:37
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>有没有好吃 吃起来方便 饱肚子 健康的食物推荐？</strong>
    </summary>
    rt 靴靴各位
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910081"">39 comments</a> by <a href=""https://www.v2ex.com/u/angcz"">angcz</a>
    at 20:19:49
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>wCaptcha, 一个基于工作量证明的 CAPTCHA</strong>
    </summary>
    <p>CAPTCHA 就是所谓的验证码，不过这个基于工作量证明的验证码可以不要求用户进行操作，在后台就可以默默地完成。</p>
<p>这个验证码的核心在于，用工作量证明的方式取代了要求用户进行一些操作，来证明客户端是一个人类。不过这个验证码其实并不能区分客户端是不是人类，它的主要目的是防止大量的恶意请求，比如爆破用户名密码、爬虫之类。</p>
<p>对于一个普通用户来说，花几秒钟的时间做一个计算，然后再提交表单，这是完全可以接受的，可是对于爬虫或者登录接口爆破之类的机器人来说，如果每发一个请求就要花两三秒的 CPU 时间，这就完全不可接受了。</p>
<p>工作量证明算法使用了不可并行加速的算法，也就是说，显卡加速是废的，多核计算也是废的（除非同时对一个接口发送多个请求，但这样的请求是非正常的，很容易过滤掉）。</p>
<p>网站在这里： <a href=""https://wcaptcha.pingflash.com"" rel=""nofollow"">https://wcaptcha.pingflash.com</a>
如果担心数据安全，可以直接用源码私有化部署。</p>
<p>至于算法细节之类的东西，都可以在网站上找到，我就不在这里废话了。</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910042"">31 comments</a> by <a href=""https://www.v2ex.com/u/greensea"">greensea</a>
    at 14:39:06
    in <a href=""https://www.v2ex.com/go/create"">分享创造</a>
    </p>


  <details>
    <summary>
      <strong>服务最好是无状态的是什么意思</strong>
    </summary>
    <p>有懂的大哥吗</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/910002"">28 comments</a> by <a href=""https://www.v2ex.com/u/spr1ngs"">spr1ngs</a>
    at 10:20:36
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>



",2023-01-21T00:48:20Z,2023-01-21T00:48:21Z,open,0,"Hacker News Daily, resources of dark pattern, paper/literature","definitions, examples",documentation,Papers/Docs/Sources,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/Extended-Thunder/send-later/issues/611,remove all anonymous data collection from Send Later extension,https://github.com/Extended-Thunder/send-later/issues/611,"Anonymous data collection in a plugin that has full access to Thunderbird state is a dark pattern and should be removed. Please stop taking on the bad habits of trillion-dollar surveillance capitalists. The vast number of data breaches, data leaks, and ransomware attacks we see on a daily basis should give anyone pause before sharing data with a third party--even one with deep pockets and a dedicated information security staff. This extension should not be adopting these dangerous data collection practices.

I removed the Send Later extension because of this change in the latest release, and I will not even consider re-installing it until all telemetry and other data collection, no matter whether it's opt-in or opt-out, is removed.",2023-08-29T16:32:31Z,2023-08-29T22:36:21Z,closed,1,"prevention of dark pattern, anonymous data collection in plugin","Send Later extension, anonymous data collection, sneaking","Send Later extension, data collection, sneaking, avoid dark pattern",DPs prevention in software,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/jiacai2050/hot-posts/issues/222,2023-03-14 Hot Posts,https://github.com/jiacai2050/hot-posts/issues/222,"# Hacker News


#### [Launch HN: Electric Air (YC W23) – Heat pump sold directly to homeowners]()

616 points by [cmui](https://news.ycombinator.com/user?id=cmui) at 00:45:07 | [577 comments](https://news.ycombinator.com/item?id=35138319)


#### [Changes at YC](https://www.ycombinator.com/blog/changes-at-yc/)

375 points by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) at 04:42:55 | [349 comments](https://news.ycombinator.com/item?id=35142245)


#### [Experian is a pile of dark pattern garbage](https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage)

343 points by [stanleydrew](https://news.ycombinator.com/user?id=stanleydrew) at 05:14:53 | [68 comments](https://news.ycombinator.com/item?id=35142787)


#### [Ring LLC home security company ransomed by ALPHV ransomware](https://web.archive.org/web/20230314015249/https://twitter.com/vxunderground/status/1635427567271329792)

214 points by [DyslexicAtheist](https://news.ycombinator.com/user?id=DyslexicAtheist) at 15:01:26 | [82 comments](https://news.ycombinator.com/item?id=35148221)


#### [SVB collapse: Peter Thiel’s role scrutinized as spark of bank run](https://www.washingtonexaminer.com/news/business/svb-collapse-peter-thiel-silicon-valley-)

193 points by [MilnerRoute](https://news.ycombinator.com/user?id=MilnerRoute) at 04:10:17 | [234 comments](https://news.ycombinator.com/item?id=35141775)


#### [Microsoft lays off one of its responsible AI teams](https://www.platformer.news/p/microsoft-just-laid-off-one-of-its)

184 points by [Amorymeltzer](https://news.ycombinator.com/user?id=Amorymeltzer) at 08:03:41 | [275 comments](https://news.ycombinator.com/item?id=35145189)


#### [California cancels salmon fishing season](https://www.cbsnews.com/sanfrancisco/news/california-cancels-salmon-fishing-season/)

174 points by [makerofspoons](https://news.ycombinator.com/user?id=makerofspoons) at 04:57:22 | [118 comments](https://news.ycombinator.com/item?id=35142469)


#### [Russian Assets Reportedly Seized at Baikonur Cosmodrome by Kazakh Authorities](https://tlpnetwork.com/news/2023/03/russian-assets-seized-at-the-baikonur-cosmodrome)

135 points by [taubek](https://news.ycombinator.com/user?id=taubek) at 14:43:59 | [63 comments](https://news.ycombinator.com/item?id=35148131)


#### [Stanford Alpaca, and the acceleration of on-device LLM development](https://simonwillison.net/2023/Mar/13/alpaca/)

134 points by [Kye](https://news.ycombinator.com/user?id=Kye) at 03:54:37 | [35 comments](https://news.ycombinator.com/item?id=35141531)


#### [US court rules Uber and Lyft workers are contractors](https://www.bbc.com/news/business-64947695)

123 points by [gostsamo](https://news.ycombinator.com/user?id=gostsamo) at 12:15:35 | [86 comments](https://news.ycombinator.com/item?id=35147384)


#### [Using a Mac without a network connection](https://eclecticlight.co/2023/03/14/using-a-mac-without-a-network-connection/)

113 points by [frizlab](https://news.ycombinator.com/user?id=frizlab) at 15:59:17 | [80 comments](https://news.ycombinator.com/item?id=35148534)


#### [Switching from C++ to Rust](https://laplab.me/posts/switching-from-cpp-to-rust/)

112 points by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) at 06:01:07 | [86 comments](https://news.ycombinator.com/item?id=35143573)


#### [Generating aerial imagery with your iPhone&#39;s Lidar sensor](https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/)

96 points by [jakecopp](https://news.ycombinator.com/user?id=jakecopp) at 05:03:41 | [17 comments](https://news.ycombinator.com/item?id=35142588)


#### [LNER Peppercorn Class A1 60163 Tornado](https://en.wikipedia.org/wiki/LNER_Peppercorn_Class_A1_60163_Tornado)

67 points by [camtarn](https://news.ycombinator.com/user?id=camtarn) at 05:25:44 | [31 comments](https://news.ycombinator.com/item?id=35142991)


#### [Mediterranean diet may lower dementia risk by a quarter, study suggests](https://www.theguardian.com/society/2023/mar/14/mediterranean-diet-may-lower-dementia-risk-by-a-quarter-study-suggests)

46 points by [lentil_soup](https://news.ycombinator.com/user?id=lentil_soup) at 17:34:59 | [39 comments](https://news.ycombinator.com/item?id=35149105)


#### [Show HN: Counter – Simple and free web analytics](https://counter.dev/)

41 points by [ihucos](https://news.ycombinator.com/user?id=ihucos) at 05:29:21 | [25 comments](https://news.ycombinator.com/item?id=35143052)


#### [Analysis of distances between London&#39;s bus stops](https://www.michalpaszkiewicz.co.uk/blog/busdistributions/index.html)

41 points by [transportguy](https://news.ycombinator.com/user?id=transportguy) at 16:51:46 | [39 comments](https://news.ycombinator.com/item?id=35148834)


#### [An experiment in elastically scaling a thread pool using a PID controller](https://github.com/stevana/elastically-scalable-thread-pools)

38 points by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) at 14:31:17 | [21 comments](https://news.ycombinator.com/item?id=35148068)


#### [Nearly Every Person in Iraq Is an Illegal Streaming Pirate, Sources Say](https://torrentfreak.com/nearly-every-person-in-iraq-is-a-pirate-sources-say-230313/)

24 points by [CoBE10](https://news.ycombinator.com/user?id=CoBE10) at 08:24:16 | [23 comments](https://news.ycombinator.com/item?id=35145402)


#### [Usury](https://en.wikipedia.org/wiki/Usury)

22 points by [yamrzou](https://news.ycombinator.com/user?id=yamrzou) at 07:45:44 | [6 comments](https://news.ycombinator.com/item?id=35144989)


#### [Boundary Conditions, Rain, and Startup Fragility](https://www.analogmantra.com/blog/2023-02-27-fragility-and-boundary-conditions/)

17 points by [MagnusHambleton](https://news.ycombinator.com/user?id=MagnusHambleton) at 16:51:10 | [7 comments](https://news.ycombinator.com/item?id=35148829)


#### [Trees Across the U.S. Are Sprouting Leaves Earlier Than Usual This Year](https://www.wsj.com/articles/cherry-blossom-trees-record-early-spring-7484812c)

10 points by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) at 20:17:41 | [3 comments](https://news.ycombinator.com/item?id=35150270)


#### [Building a Second Income Stream by Writing a Book](https://fatsoftwareengineer.substack.com/p/building-a-second-income-stream-by)

7 points by [fat-se-uk](https://news.ycombinator.com/user?id=fat-se-uk) at 09:10:33 | [0 comments](https://news.ycombinator.com/item?id=35145920)


#### [Paul Krugman: “Silicon Valley Bank Isn’t Lehman”](https://www.nytimes.com/2023/03/13/opinion/silicon-valley-bank-lehman-bailout.html)

6 points by [MilnerRoute](https://news.ycombinator.com/user?id=MilnerRoute) at 06:29:06 | [0 comments](https://news.ycombinator.com/item?id=35143962)


#### [Microsoft’s bet on Azure unlocked an AI revolution](https://news.microsoft.com/source/features/ai/how-microsofts-bet-on-azure-unlocked-an-ai-revolution/)

6 points by [EMM_386](https://news.ycombinator.com/user?id=EMM_386) at 06:08:22 | [1 comments](https://news.ycombinator.com/item?id=35143676)


#### [Bitbucket Is Down](https://bitbucket.status.atlassian.com/incidents/0s3fntjgx88g)

5 points by [arthurgibson](https://news.ycombinator.com/user?id=arthurgibson) at 02:30:23 | [0 comments](https://news.ycombinator.com/item?id=35140241)


#### [What can I read to convince me I should care about online privacy more?]()

4 points by [steponlego](https://news.ycombinator.com/user?id=steponlego) at 05:46:19 | [4 comments](https://news.ycombinator.com/item?id=35143311)


#### [Open Circuits: The Inner Beauty of Electronic Components]()

4 points by [daly](https://news.ycombinator.com/user?id=daly) at 04:57:58 | [0 comments](https://news.ycombinator.com/item?id=35142483)


#### [Relationship Hero (YC S17) Is Hiring Sales Associates (Remote)](https://relationshiphero.com/careers?role=salesAssociate)

1 points by [Liron](https://news.ycombinator.com/user?id=Liron) at 09:00:19 | [ comments](https://news.ycombinator.com/item?id=35145810)


#### [Hotglue (YC S21) Is Hiring](https://www.ycombinator.com/companies/hotglue/jobs/aSSnalB-senior-integrations-engineer)

1 points by [dmolot](https://news.ycombinator.com/user?id=dmolot) at 20:00:15 | [ comments](https://news.ycombinator.com/item?id=35150117)



# V2EX


  <details>
    <summary>
      <strong>我是懂如何 V2 推广的，手握 100 个内购码，送完即止！</strong>
    </summary>
    App Store 搜索：iChatbot ，或点击链接：<br><a target=""_blank"" href=""https://apps.apple.com/cn/app/ichatbot/id1671394393"" rel=""nofollow noopener"">https://apps.apple.com/cn/app/ichatbot/id1671394393</a><br>视频教程： <a target=""_blank"" href=""https://www.bilibili.com/video/BV1ns4y1G7Rc/"" rel=""nofollow noopener"">https://www.bilibili.com/video/BV1ns4y1G7Rc/</a><br>TG 群： <a target=""_blank"" href=""https://t.me/iChatbots"" rel=""nofollow noopener"">https://t.me/iChatbots</a><br>欢迎关注通知频道： <a target=""_blank"" href=""https://t.me/iTelecast"" rel=""nofollow noopener"">https://t.me/iTelecast</a><br>—————————————————————————————————<br> [ iChatbot Pro ] ：评论留下邮箱，邮箱可 Base64 再回复。
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923752"">206 comments</a> by <a href=""https://www.v2ex.com/u/strengthen"">strengthen</a>
    at 08:02:27
    in <a href=""https://www.v2ex.com/go/promotions"">推广</a>
    </p>


  <details>
    <summary>
      <strong>一个月入 4k 的人很迷茫</strong>
    </summary>
    看各位大佬动不动就是月入几十 k 很是羡慕，本人目前在搞弱电工程的主要搞电脑维修接插座等那些偶尔组建下局域网路由器交换机那些，最近想学编程转行入 it 技术，看着工资高，大家觉得往哪个方向好？
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923756"">142 comments</a> by <a href=""https://www.v2ex.com/u/yewenji52"">yewenji52</a>
    at 08:17:43
    in <a href=""https://www.v2ex.com/go/career"">职场话题</a>
    </p>


  <details>
    <summary>
      <strong>Brave 是当下我认为最好的浏览器</strong>
    </summary>
    <p>因为我是个多平台的使用者（ Windows 、Linux 、Android 、iOS ），所以浏览器对我而言首先需要多平台数据同步，其次才是浏览器在各平台的特色功能，因此先排除了 Safari 、Kiwi 这些只能在单个平台上运行的浏览器。Firefox 因为内核的问题，性能确实和 Chromium 内核的浏览器有差距，在网站兼容性上也有些许问题，因此也被我排除在外。</p>
<p>先说 Brave 的缺点：</p>
<p>浏览器内置很多虚拟货币和 web3 相关的内容，例如 Brave 钱包、Brave 奖励等等内容，这对于不使用虚拟货币、不对 web3 感兴趣的人是一种“骚扰”。不过这些功能都可以在设置里禁用，在主界面也可以隐藏这些图标</p>
<p>再说 Brave 的特色功能：</p>
<p>1.全平台集成 AdBlock ，这个 AdBlock 是 Brave 自己实现的： <a href=""https://github.com/brave/adblock-rust"" rel=""nofollow"">https://github.com/brave/adblock-rust</a> ，不受到 Manifest V3 升级带来的影响，内置常用的规则列表，在除 iOS 端以外都可以自行添加规则列表
<img alt=""01"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.imgur.com/s7bhCsR.png""></p>
<p><img alt=""02"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.imgur.com/XRoVr6Z.png""></p>
<p>2.Speedreader 模式：这个功能默认开启，可以极大地缩短网页加载的时间，适配大部分的资讯类网站，这个功能和其他浏览器的 “阅读模式” 不太一样，其他浏览器的阅读模式需要自己每次手动点一下开启，而且排版不怎么好看，Brave 的这个模式会在网页加载前就获取网页的内容并重新排版，不仅速度快，而且省流量，效果看图（用到的网页链接 <a href=""https://9to5google.com/2023/03/13/microsoft-bing-users"" rel=""nofollow"">https://9to5google.com/2023/03/13/microsoft-bing-users</a> ）：
<img alt=""03"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.imgur.com/uMVKpx0.png""></p>
<p>开启后：</p>
<p><img alt=""04"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.imgur.com/QJwBZ52.png""></p>
<p>3.Brave 会一直支持 Manifest V2 的扩展： <a href=""https://twitter.com/brave/status/1574822799700541446"" rel=""nofollow"">https://twitter.com/brave/status/1574822799700541446</a> ，uBlock Origin 和我常用的 Bypass Paywalls Chrome Clean 都可以在未来继续使用</p>
<p>4.安卓和 iOS 可以开启 黑暗模式 和 音频后台播放，前者类似于 dark reader 插件，可以让网页强制变为深色，后者可以在锁屏或者切换到其他应用后保持音频的播放，例如在听 YouTube 节目时可以锁屏收听</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923789"">126 comments</a> by <a href=""https://www.v2ex.com/u/charlieethan"">charlieethan</a>
    at 09:52:50
    in <a href=""https://www.v2ex.com/go/browsers"">浏览器</a>
    </p>


  <details>
    <summary>
      <strong>为什么买房的人都不在乎楼层厚度？没有商家拿厚度来做卖点？</strong>
    </summary>
    现在商品房一个最烦人的原因之一就是上下楼的噪音 但是一般是楼板太薄导致的 甚至无数人为此卖房 为什么买房的人基本上都不怎么关心楼板厚度呢？为什么房地产商在卖楼的时候不拿这个作为卖点来吸引人呢？
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923760"">110 comments</a> by <a href=""https://www.v2ex.com/u/520discuz"">520discuz</a>
    at 08:47:17
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>Zenlayer 这家公司好让人失望</strong>
    </summary>
    <p>这两年时不时也会关注这家公司，主要觉得公司官网做的比较简洁活泼，因此一直很期待他们家的云服务。</p>
<p>前几天试用 Ucloud 香港机器，网速非常快，IP 显示 Zenlayer 机房，于是毫不犹豫去 Zenlayer 官网下单购买了香港区的 VM ，1 核 2G ，带宽按量付费，一个月大概 20 美金，虽然很心疼，但还是很期待。开机后 ping 值延迟超高，北京 300ms 左右（全国最慢四川成都[电信] 433ms 平均 276.7ms ）。于是关机取消订阅，然后联系客服申请退款。</p>
<p>今天得到客服回复说预付费模式不支持退款，赶忙打电话过去解释了充分的退款理由，客服就只会说不退款，反正明确告诉你就是退不了（客服原话）。第一次碰到不能退款的云服务，对个人用户谁家不是预付费的？基本都是随用随退。早期的腾讯阿里退款机制不完善时联系客服也能退款，Zenlayer 没有免费试用不说，初次购买又那么贵居然收了钱就别想要回来。真是失望透顶，格局连小 VPS 厂商都比不过。</p>
<p>今天的真实经历，发出来希望大家不要踩坑！</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923728"">109 comments</a> by <a href=""https://www.v2ex.com/u/Calen"">Calen</a>
    at 00:07:22
    in <a href=""https://www.v2ex.com/go/cloud"">云计算</a>
    </p>


  <details>
    <summary>
      <strong>api 调试工具又死了一个</strong>
    </summary>
    <p>之前用 postman, 有次改版, 搞不清楚怎么用了
换到 insomnia, 然后前几天手欠,升级, 要登陆, 然后我之前的 query 都不见了, 也不知道咋用了. </p>
<p>多了一堆我不想要的功能</p>
<p>这次用 vscode 插件了, 再不行就用 curl 了.</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923819"">103 comments</a> by <a href=""https://www.v2ex.com/u/echoless"">echoless</a>
    at 10:45:20
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>我宣布这是我目前用的最快的 chatgpt 第三方！</strong>
    </summary>
    <p>我这也属于王婆卖瓜自卖自夸了。
非市面上 3.5api 的接口
采用了 chatgpt 网页接口加 chatgpt plus 账号，反应速度毫秒级，可媲美官方！
不过需要登录。。。</p>
<p>欢迎来体验，如果你有更快的第三方且不用翻墙的那种，请务必留言让我也用一下！</p>
<p>地址： <a href=""https://www.mulaen.com"" rel=""nofollow"">https://www.mulaen.com</a></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923757"">85 comments</a> by <a href=""https://www.v2ex.com/u/xyy003"">xyy003</a>
    at 08:31:04
    in <a href=""https://www.v2ex.com/go/promotions"">推广</a>
    </p>


  <details>
    <summary>
      <strong>.idea 上传到 git 么？</strong>
    </summary>
    <p>想问下大家用 intellij 的会把这个.idea 在上传到 git repo 时候忽略掉么？</p>
<p>还是为了保证大家有一样的配置，会直接上传呢？</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923749"">83 comments</a> by <a href=""https://www.v2ex.com/u/Nnq"">Nnq</a>
    at 06:36:38
    in <a href=""https://www.v2ex.com/go/git"">git</a>
    </p>


  <details>
    <summary>
      <strong>[VVEX] 使用 Flutter 开发的第二好看的 V2 客户端 🤪</strong>
    </summary>
    <p>最近在学习 Flutter ，顺便做一个 V 站客户端 <strong><a href=""https://github.com/guozhigq/flutter_v2ex"" rel=""nofollow"">VVEX</a></strong> 练练手，（人均一个 V2 客户端🤪）</p>
<p>主要特点是使用了 Flutter &amp;&amp; Material You 取色 （按壁纸自适应 app 主题色）
<br></p>
<h3>功能</h3>
<p>挑几个主要的说下吧</p>
<ul>
<li><input disabled type=""checkbox""> 自动签到</li>
<li><input disabled type=""checkbox""> base64 加 /解密</li>
<li><input disabled type=""checkbox""> 自动 /手动夜间模式</li>
<li><input disabled type=""checkbox""> 动态主题、Material You 3 取色</li>
<li><input disabled type=""checkbox""> 高级搜索 - soV2ex</li>
<li><input disabled type=""checkbox""> @回复多人</li>
<li><input disabled type=""checkbox""> 快速回顶</li>
<li><input disabled type=""checkbox""> 2FA 登录、google 登录</li>
</ul>
<h3>TDDO</h3>
<ul>
<li><input disabled type=""checkbox""> markdown 发帖、图片上传</li>
<li><input disabled type=""checkbox""> 消息跳转对应楼层</li>
<li><input disabled type=""checkbox""> 数据缓存</li>
<li><input disabled type=""checkbox""> 等等...</li>
</ul>
<h3>预览图</h3>
<p><img alt=""2FA"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://files.catbox.moe/w3pnbd.png"">
<img alt=""抽屉"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://files.catbox.moe/kpuks8.png"">
<img alt=""详情页"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://files.catbox.moe/dkf8qt.png"">
<img alt=""设置"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://files.catbox.moe/xij4ov.png""></p>
<h3>下载</h3>
<p>Android 版本 : <a href=""https://github.com/guozhigq/flutter_v2ex/releases"" rel=""nofollow"">VVEX</a></p>
<h3>项目地址</h3>
<p><a href=""https://github.com/guozhigq/flutter_v2ex"" rel=""nofollow"">https://github.com/guozhigq/flutter_v2ex</a></p>
<h3>其他</h3>
<ul>
<li>建议跟意见大家都可以提，不定时查看。</li>
<li>更换了 package name ，已安装的朋友可能需要卸载重装了</li>
<li>🙏感谢 <a href=""https://github.com/w4mxl/V2LF"" rel=""nofollow"">V2LF</a></li>
</ul>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923791"">78 comments</a> by <a href=""https://www.v2ex.com/u/guozhigq"">guozhigq</a>
    at 09:56:24
    in <a href=""https://www.v2ex.com/go/create"">分享创造</a>
    </p>


  <details>
    <summary>
      <strong>开店了，开店卖啥好过干码农。</strong>
    </summary>
    鉴于大城市太内卷，什么 996 等。<br>打算跑路回老家步行街开个实体店。<br>不求大富大贵，只求温饱自如顾家。<br>问题来了：<br>卖啥呢？<br>大家一起来出出主意吧，三人行必有我师。
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923759"">66 comments</a> by <a href=""https://www.v2ex.com/u/JasonFW"">JasonFW</a>
    at 08:41:06
    in <a href=""https://www.v2ex.com/go/life"">生活</a>
    </p>


  <details>
    <summary>
      <strong>Edge 浏览器右上角出现了一个膈应的 b</strong>
    </summary>
    <p><img alt=""膈应的 B"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.v2ex.co/JieLThXq.png""></p>
<p>右侧的 B 没有选项可以关闭，鼠标悬浮上去就有菜单弹出来，好难受。考虑不用 edge 了</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923788"">65 comments</a> by <a href=""https://www.v2ex.com/u/bigtan"">bigtan</a>
    at 09:52:09
    in <a href=""https://www.v2ex.com/go/edge"">Edge</a>
    </p>


  <details>
    <summary>
      <strong>家里老人用的 windows 台式机，每年回家都要重新安装系统或清理垃圾软件，否则慢的要死。有什么办法能禁止垃圾软件安装呢？</strong>
    </summary>
    比如通过另外建立一个给老人用的低权限用户，平时只能浏览网页，上 QQ ，用 office ，禁止安装软件的权限。管理员账户我拿着，密码不告诉老人，如果确实有需要再让老人登陆管理员账户。这个低权限用户怎么设置呢？能否实现远离垃圾软件？多谢～
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/923780"">65 comments</a> by <a href=""https://www.v2ex.com/u/dongpeng121"">dongpeng121</a>
    at 09:39:02
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>



",2023-03-15T00:48:59Z,2023-03-15T00:48:59Z,open,0,"Hacker News Daily, resources of dark pattern, blog post","Experian CreditLock, examples","Experian CreditLock, blog, post, documentation",Papers/Docs/Sources,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/AdguardTeam/AdGuardSDNSFilter/issues/1412,"ezodn.com IS tracking cancer, but also required to get past a common GDPR dark pattern",https://github.com/AdguardTeam/AdGuardSDNSFilter/issues/1412,"### Prerequisites

- [X] This site DOES NOT contains sexually explicit material;
- [X] The problem occurs only when using AdGuard DNS or DNS filtering with AdGuard DNS filter, it is not caused by other ad blockers;
- [X] You're using an up-to-date version of AdGuard DNS filter;
- [X] Browser version is up-to-date;
- [X] If a website or an app is broken, disabling AdGuard DNS filter resolves the issue.

### What DNS server do you use?

Other

### Version

_No response_

### What DNS upstream(s) do you use in AdGuard apps or AdGuard Home?

my own, and it doesn't matter

### What DNS filters do you have enabled?

https://adguardteam.github.io/AdGuardSDNSFilter/Filters/filter.txt

### What browser or app do you use?

Firefox, Chrome, Safari, Microsoft Edge, Opera, Yandex Browser, Other app

### Which device type do you use?

Desktop

### What type of problem have you encountered?

Website or app doesn't work properly

### Where did you encounter the problem?

_No response_

### Add your comment and screenshots

A particularly annoying GDPR dark pattern does not work when ezodn.com is blacklisted.

For privacy reasons I obviously can't show where I encountered it last, but it's a generic problem. Some of you probably saw this before. Maybe, if you find it again on some generic mainstream site, you can post.

Without your blacklist, it looks like:
![image](https://github.com/AdguardTeam/AdGuardSDNSFilter/assets/56206745/c049117c-6f60-46e0-af29-e72f994c66a1)

Where you are expected to go through a gigantic list one by one to achieve basic dignity. (or use an add-on to do it for you)

With it blacklisted, you cannot get past it:
![image](https://github.com/AdguardTeam/AdGuardSDNSFilter/assets/56206745/a86f2903-9258-4392-8163-01527627d9a5)

It doesn't react to clicks at all.

Not sure how this should be handled. Yes, this domain, and their entire company are obviously cancer, but that hits a philosophical question: Do you submit to the death-grip of capitalism, or die? If you are forced to use such a site, you are forced to whitelist it anyway. It's common, and might be on a supermarket's site, which you are forced to use, or some other store you need to survive physically.

It's surprising that a majority of capitalists are still dumb enough to not simply use such a model on everything. It's extremely simple to defeat AGH and similar blacklists: Just put the crap behind a host that must be whitelisted.

This thing has a CSS id of 'ez-cookie-dialog-wrapper'.

For the techy people, here's a minimal userscript you can share:
https://greasyfork.org/en/scripts/462127-ez-cookie-remover/code

Now I can be stubborn enough to find this, make or find a script, but that's niche-in-a-niche territory.

For regular people, having a basic standard list break a basic cookie abuse prompt is a problem. Especially, if you set up a minimal AGH installation for them, and they have no clue why stuff suddenly breaks.

Another fun fact about how retarded the EU is: None of these even work. No matter, if you accept or not, or remove the thing altogether, cookies have already been set. The whole 'consent' shenanigans don't do anything.

Suggestions?

I think I might even want to keep it blacklisted to point out the idiocy wherever possible. Maybe this thread can serve that. However, that means fewer people will be willing to put up with AGH/etc at all. An emerging problem!

### Privacy

- [X] I agree to follow this condition",2023-07-01T11:19:46Z,2023-07-06T09:04:33Z,closed,8,"ezodn.com, usage of (GDPR-related) dark pattern, confusing consent form, default opt-in setting, hard to decline consent","GDPR, ezodn.com is blacklisted, functionality issue","ezodn.com, GDPR, consent, opt-in/out, obstruction, default",DPs used in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/go-gitea/gitea/issues/25283,"When deleting a repo, it is forbidden to use the mouse to select the repo name",https://github.com/go-gitea/gitea/issues/25283,"### Feature Description

like github：
![image](https://github.com/go-gitea/gitea/assets/89133723/306f55e0-231b-436d-bf0e-e3444106c96c)

this is gitea：
![image](https://github.com/go-gitea/gitea/assets/89133723/cc91e66a-4168-4586-a5ca-262db86c7f06)


### Screenshots

_No response_",2023-06-15T08:19:02Z,2023-08-01T00:01:14Z,closed,3,"GitHub, usage of dark pattern in software, repository deletion, forced action, typing required to delete a repo","forcing user to write the name of repo when deleting, obstruction","GitHub, repository deletion, forced action",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/qnblackcat/uYouPlus/issues/1138,Tapping “Play next in queue” shows YouTube Premium page,https://github.com/qnblackcat/uYouPlus/issues/1138,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Have you read the FAQ?

- [X] Yes, I did read the FAQ

### Device info

- iOS/iPadOS version: 16.5
- Device model: iPhone 14 Pro
- Sideload tool (AltStore, Sideloadly, TrollStore,...): AltStore
- The specific version of uYouPlus (**latest or newest is NOT a version number!**): 18.14.1-3.0


### Describe the bug

When I tap “Play next in queue” it opens up the YouTube Premium page. Is it possible to unlock this for non-Premium members?

https://github.com/qnblackcat/uYouPlus/assets/34712694/4fc7896d-9888-47a9-8351-a8e784607fdb



### Steps to reproduce the issue

1. Find any video
2. Open the context menu (three dots)
3. Tap “Play next in queue”


### Crash log (if the app crashes)

_No response_

### Are you using the newest version of uYouPlus? If not, why?

✅ Yes, I'm using the latest version of uYouPlus right now

### Does the issue happen with the official YouTube from AppStore?

❌ No, I can't reproduce this issue in the official YouTube from AppStore

### Additional context

_No response_",2023-05-24T19:24:34Z,2023-09-03T16:45:48Z,closed,9,"Youtube, usage of dark pattern in software, premium users, ""play next in queue"" prompts to premium page","YouTube, Play next in Queue for premium, button placement, UI manipulation","YouTube, trick users to buy paid products",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Shelf-nu/shelf.nu/issues/307,[Feature request]: Custom fields,https://github.com/Shelf-nu/shelf.nu/issues/307,"### Contact Details

jurre@whale-agency.com

### Is your feature request related to a problem? Please describe?

Based on multiple user requests wishing for the option to add custom fields in order to realise a customised workflow suited to their needs.

### Describe the solution you'd like

Functionality for managing custom fields.

WIP designs: https://www.figma.com/file/2XkiKJ4II7Mux6JJL9hYTm/Shelf-App-%7C-Production-Ready?type=design&node-id=6683-336967&mode=design

- Under settings, add a tab called 'Custom fields'
- Create 'Custom fields' index
- Option to create new 'Custom field' with field type 'Single line text' (more field types will follow)
- Option to delete 'Custom field' when no asset was ever created with that specific custom field active. @DonKoko  Would be good to discuss this in detail. Want to avoid data being lost.
- Option to archive 'Custom field'
- Option to either show or hide the data filled for the custom field on asset page
- Created 'Custom fields' that are active should show in the 'Create/Edit asset' view

### Describe alternatives you've considered

_No response_

### Additional context

_No response_",2023-08-21T11:38:24Z,2023-09-19T10:34:23Z,closed,6,"Shelf (Open Source Asset Management Infrastructure), usage of dark pattern in software, custom fields limitation due to unpaid and paid versions","cannot delete custom field even in paid version, forced action","Shelf, forced action, custom field",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/ossc-db/pg_hint_plan/issues/132,Plugging in a lex/yyac layer into pg_hint_plan,https://github.com/ossc-db/pg_hint_plan/issues/132,"Hi all,

I was looking at the proposed patch to allow the parsing of hints in multiple locations: https://github.com/ossc-db/pg_hint_plan/pull/101. FWIW, my opinion about it is that it is not acceptable as it stands.

First, I am pretty sure that there are some dark patterns where that would break depending on the query parsed. Second, this is a duplication of a logic that already exists in Postgres core: src/backend/parser/, mostly around scan.l that has the flex rules. And the core code has been studied and maintained for many years. An issue with the core code is that it is not possible to rely on its rules because anything related to comments is ignored. See this part in scan.l:

```
<xc>{
{xcstart}       {
                    (yyextra->xcdepth)++;
                    /* Put back any characters past slash-star; see above */
                    yyless(2);
                }

{xcstop}        {
                    if (yyextra->xcdepth <= 0)
                        BEGIN(INITIAL);
                    else
                        (yyextra->xcdepth)--;
                }

{xcinside}      {
                    /* ignore */
                }
```

So the contents of the comments are simply skipped, and something like core_yylex(), that would retrieve the tokens from the grammar, does not give the possibility to get access to that, either. There are two things that I think can be done here:

1. Submit a patch to upstream and make the core parser more pluggable for comment contents, which could be done by saving the contents from the comments in a dedicated area, for example. That would be grotty, and I suspect rejection until we have an actual proposal for query hints that could target upstream. If this were to happen, this would be only part of 17.
2. Introduce a copy of upstream's scan.l for the sake of parsing the hints, including all the rules for escapes, quotes, and such on the way. That's obviously heavy, though scan.l could be made lighter so as we ignore all the contents we don't want, *except* the hints. Then we'd need to plus in a yacc layer that generates tokens for the hints, based on the contents retrieved from the comments. 

I'd like to think that 2. would be the best way to move forward if we were to allow hints in various places. Note that having a proper lex/yacc parser would also simplify a lot pg_hint_plan.c for:

1. The generation of the hint nodes, switching a list handling, without the need of having all the current code parsing the hint strings.
2.  The code retrieving the hints from the query strings.

At this point, I think that I'd like to hear opinions from @MasahikoSawada @rjuju and @horiguti. Perhaps you have better ideas, I don't know. ",2023-04-24T07:44:49Z,2023-10-20T06:01:20Z,closed,11,,"lex/yyac layer, query parse",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/chanzuckerberg/napari-hub/issues/1217,Links to plugin docs and source code should be made much more prominent,https://github.com/chanzuckerberg/napari-hub/issues/1217,"#### Description
Links to the plugin webpage and plugin source code should be included prominently in the abstract text section of each plugin page, not only behind buttons hidden away in the top right corner of the screen. It seems almost like a dark pattern designed to keep users only interacting with plugins via the hub page.

![Screenshot 2023-08-14 at 11 40 20 am copy 2](https://github.com/chanzuckerberg/napari-hub/assets/30920819/e2563b19-abcd-499d-a86f-af27168dba2f)


The problems with the current icon-only situation are:
* It's difficult to find this information. It's even more difficult if you are new, and it's possible to miss entirely.
* When you do find it, you have to spend several clicks to open the page you need (a few to see the dropdowns for each icon, and then to click through to the actual plugin webpage)
* The icons are not intuitive. At best, `</>` for ""code"" is the only one that sort of seems like it's related, but honestly I never see this used elsewhere so I don't remember it here either.
    ![Screenshot 2023-08-14 at 11 46 36 am](https://github.com/chanzuckerberg/napari-hub/assets/30920819/0b6aef33-e601-47b6-b8dc-2ccc715f5134)
* The location of the icons is also not ideal. Looking at the UI, the most important pieces of information go into the biggest, central column. Secondary information has been put into the left hand side bar. I do not expect to find really critical pieces of information (the plugin project page and source code links) tucked away on the right hand side (because this is the third tier of information, I don't recognize the icons, and the right hand side looks mostly blank or has internal links to different subheadings on the same page)

I think it's really important that new users are (1) directed to the full documentation websites for plugins, (2) see the actual source code, and (3) know where to report issues directly to the plugin authors. That's why I'd like to see the hub page improved.

#### Expected Results
I'd expect to see lines like this in the abstract after the one line description and before the plugin author names.

> Plugin website: www.plugin-amazing-docs.com
> Plugin source code: www.github.com/super-awesome/napari-plugin-foo

![Screenshot 2023-08-14 at 11 52 05 am](https://github.com/chanzuckerberg/napari-hub/assets/30920819/f0ffbd3b-1dd6-447b-9a2c-4d39063ebd37)

*Note: I'm not suggesting getting rid of the icons in the corner if you don't want to. This issue is about making sure that critical pieces of information are displayed in a clear and obvious manner (i.e. adding the info to the abstract in the centre of the screen).
",2023-08-14T02:32:18Z,2023-09-19T22:02:17Z,closed,1,"prevention of dark pattern, links to plugins and code source, consistent, no obstructions","buttons hidden, only in hub page, design hierarchy","avoid dark pattern, plug-in",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/admob-plus/admob-plus/issues/601,How to deal with the (soon) required UMP (consent) requirements by Google Admob?,https://github.com/admob-plus/admob-plus/issues/601,"Like everyone using Admob (on Android) I get mails and messages (from Google) like this;

> Later this year, Google will require all publishers serving ads to EEA and UK users to use a Google-certified Consent Management Platform (CMP). You can use any [Google-certified CMP ](https://support.google.com/admob/answer/13554116) for this purpose, including Google's own consent management solution. If you are interested in using Google's consent management solution, start by setting up your GDPR message and implementing the [UMP SDK](https://support.google.com/admob/answer/10113005).

![image](https://github.com/admob-plus/admob-plus/assets/15701574/d73de7a5-44f2-48b5-addf-5f94a9d07853)

At the moment I am **not** using any consent solution, since I am targeting some lower numbered Android-API's, but before the end of this year I have to implement this solution or ad serving will stop (I guess).

---

###  How to solve this situation?

Google does offer a walk-through for creating a message and like, but at the end you have to implement their UMP (User Messeging Platform) SDK to get the consent for ad-serving to the end-user.

![image](https://github.com/admob-plus/admob-plus/assets/15701574/e900d592-31a0-454e-9e3b-793126240469)

---

### How did you solve / manage this?

Is it enough to complete the form in the second screenshot and implement Ratsons ""consent plug-in"";

https://admob-plus.github.io/docs/cordova/consent

Or did you use a more native (?) plug-in like this;

https://github.com/jellomaster/cordova-plugin-google-ump

---

**We all have to implement the UMP SDK before the end of this year, so I think it's important to have the solution clear for everyone.**",2023-07-24T11:35:19Z,2023-12-15T11:45:19Z,open,38,"Google, UMP (User Messaging Platform)/consent for CMP (Consent Management Platform) required, gdpr, usage of dark pattern, ""manage options"" and ""comfirm""","UMP/CMP, consent issue, design hierarchy","Google, UMP/CMP, GDPR","DPs used in software, DPs examples/definitions",,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/hinoshiba/news/issues/394,[BleepingComputer] FTC: Amazon trapped millions into hard-to-cancel Prime memberships,https://github.com/hinoshiba/news/issues/394,"

The Federal Trade Commission (FTC) says Amazon allegedly used dark patterns to trick millions of users into enrolling in its Prime program and trapping them by making it as difficult as possible to cancel the automatically-renewing subscriptions. \[...\]



<https://www.bleepingcomputer.com/news/security/ftc-amazon-trapped-millions-into-hard-to-cancel-prime-memberships/>

",2023-06-21T15:47:35Z,2023-06-23T16:24:13Z,closed,2,"(Federal Trade Commission) FTC lawsuit points, Amazon, usage of dark pattern in e-commerce, hard-to-cancel, prime memebership","Amazon, trick to Prime, Roach Motel","Amazon, FTC(Federal Trade Commission), e-commerce, roach motel, hard to cancel","DPs used in software, DPs related regulation ",,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/hinoshiba/news/issues/397,"[RegisterSoftware] Amazon Prime too easy to join, too hard to quit, says FTC lawsuit",https://github.com/hinoshiba/news/issues/397,"

#### Dark patterns at Amazon worthy of a Homeric epic? Surely not!

The Federal Trade Commission today filed a lawsuit against Amazon for what it describes as a ""years-long effort to enroll consumers into its Prime program without their consent while knowingly making it difficult for consumers to cancel their subscriptions.""…



<https://go.theregister.com/feed/www.theregister.com/2023/06/21/amazon_prime_ftc_lawsuit/>

",2023-06-21T16:39:38Z,2023-06-23T17:16:11Z,closed,2,"law regulation, FTC, Amazon, usage of dark pattern in software, hard-to-cancel, prime program","Amazon, trick to Prime, Roach Motel",(Federal Trade Commission),,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/SecOpsNews/news/issues/15633,[BleepingComputer] FTC: Amazon trapped millions into hard-to-cancel Prime memberships,https://github.com/SecOpsNews/news/issues/15633,"

The Federal Trade Commission (FTC) says Amazon allegedly used dark patterns to trick millions of users into enrolling in its Prime program and trapping them by making it as difficult as possible to cancel the automatically-renewing subscriptions. \[...\]



<https://www.bleepingcomputer.com/news/security/ftc-amazon-trapped-millions-into-hard-to-cancel-prime-memberships/>

",2023-06-21T15:46:16Z,2023-06-22T16:06:11Z,closed,2,"law regulation, FTC, Amazon, usage of dark pattern in software, hard-to-cancel, prime program","Amazon, trick to Prime, Roach Motel",,,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/kee-org/browser-addon/issues/316,[Enhancement] Don't spam the connect tab and notification if user dismisses it more than once,https://github.com/kee-org/browser-addon/issues/316,"Sometimes Kee will ask to connect to Keepass database again by requesting connection password (it happened to me just now in Brave even though I was using it for a long time with no issues).

If I close the tab with the password prompt it will reopen itself in a few seconds, and it will do that incessantly again and again until I relent and do what it wants. Not only that, but it will also spam some toast notifications every time the tab is auto-opened again, even though I have disabled notifications both in the browser for all websites and in Windows for all applications.

I can't even begin to describe how annoying and disrespectful that behavior is -- it borders on a dark pattern and reminds me of malware.

TL;DR -- you can't just hijack the whole browser and nag until whatever you want users to do with your extension is complete, because the users might have more pressing things to do in that browser at the moment.

I have uninstalled Kee until it stops behaving like my computer is yours.",2022-06-16T18:24:21Z,2023-08-18T22:38:46Z,closed,1,"usage of dark pattern in software, nagging, connection popup, notification spam","reopening tab after closing it, obstrcution, interface intereference","nagging, pop-up, obstruction",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/SecOpsNews/news/issues/15640,"[RegisterSoftware] Amazon Prime too easy to join, too hard to quit, says FTC lawsuit",https://github.com/SecOpsNews/news/issues/15640,"

#### Dark patterns at Amazon worthy of a Homeric epic? Surely not!

The Federal Trade Commission today filed a lawsuit against Amazon for what it describes as a ""years-long effort to enroll consumers into its Prime program without their consent while knowingly making it difficult for consumers to cancel their subscriptions.""…



<https://go.theregister.com/feed/www.theregister.com/2023/06/21/amazon_prime_ftc_lawsuit/>

",2023-06-21T16:46:18Z,2023-06-22T17:05:38Z,closed,2,"law regulation, FTC, Amazon, usage of dark pattern in software, hard-to-cancel, prime program","Amazon Prime, Roach Motel",,,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/tModLoader/tModLoader/issues/3607,Get rid of countdown on migration warning.,https://github.com/tModLoader/tModLoader/issues/3607,"### Do you intend to personally contribute/program this feature?

No

### I would like to see this change made to improve my experience with

Gameplay as a Player

### Description

When being warned about the 1.4.4 migration there is a countdown before you can proceed. This is an anti-feature and dark pattern that has no place in open-source software. Also, it is way too long for such a short message.

### What does this proposal attempt to solve or improve?

Removing the countdown makes the software less intrusive.

### Which (other) solutions should be considered?

You could have the message show up somewhere else without being intrusive if you don't want it to be closed to early.",2023-07-08T03:57:40Z,2023-07-08T05:43:07Z,closed,4,"tModLoader (open-source project), prevention of dark pattern, migration warning, countdown, fake urgency","countdown for migration, rushing user, urgency","tModLoader, fake urgency, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/108,[component] dark patterns statistycs,https://github.com/BraindeadHermit/arkan/pull/108,,2023-03-31T08:35:30Z,2023-03-31T08:57:12Z,closed,2,miscellaneous,,,,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/teambtcmap/btcmap-android/issues/40,Can't install on pixel7 from fdroid,https://github.com/teambtcmap/btcmap-android/issues/40,There is a warning that system has blocked installation of a dangerous app,2023-07-09T06:55:47Z,2023-07-11T11:26:17Z,closed,4,"usage of dark pattern in software, fdroid, play store version, unsafe app blocked","Google, F-Droid, difficulty downoad, tracking","Googl, F-Droid, download, privacy issue, tracking",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/amazonlinux/amazon-linux-2023/issues/245,[Feature Request] - Enable swap space by default,https://github.com/amazonlinux/amazon-linux-2023/issues/245,"**Is your feature request related to a problem? Please describe.**
Swap memory is an integral part of the Linux Kernel. It helps the memory allocation in the Kernel a lot, when there is some swap space available. Even if it's only a fraction of the available system memory, having a bit of headroom in case of emergencies is always welcome.

Red Hat on the matter
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_storage_devices/getting-started-with-swap_managing-storage-devices

Other enterprise solutions like RHEL and Suse come with swap pre-configured, because it's so important.

More so, there are multiple AWS Products that support swap, but not by default:
- https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-store-swap-volumes.html
- https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-swap.html

This actually creates some rather annoying scenarios: When you want to use swap, you'll have to configure it at different locations, every time things like the auto-scaling logic change and refresh instances.

**Describe the solution you'd like**
The solution would be fairly straight-forward: Have the base system image come with a limited swap-file pre-configured. I would aim at no more then 1 GB. This will mean that smaller EC2 instances will have more swap by comparison, but it also means that for larger servers with more memory, it really only exits as a fallback.

- [ ] Create 1GB swap-file on instance creation
- [ ] Enable swap space usage 

**Describe alternatives you've considered**
A user could manually configure it, but that would take a lot of effort when using advanced features like auto-scaling. You could add this as a configurable setting to the related components, but knowing how hard it is to get such things well integrated in a UI, I would  not recommend that.

**Summary**
Adding a small base swap-file can help with all kinds of expected memory-shuffles, and unexpected troubles.",2022-12-07T09:04:55Z,2023-09-26T09:36:58Z,closed,8,"miscellaneous (ASW, lower RAM, promote upgraded users)","ASW, RAM, pushing to higher computer tier, forced action, manipulation, obstruction",miscellaneous,miscellaneous ,"ASW, lower RAM, promote upgraded users",,DPs used in software,dps used in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/107,[component] User Dark Pattern Actions Statisctics,https://github.com/BraindeadHermit/arkan/issues/107,,2023-03-30T18:47:16Z,2023-04-02T21:34:28Z,closed,0,miscellaneous,,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/kunjgit/GameZone/issues/892,[New game]: I WANT TO GOOGLE THE GAME 👾,https://github.com/kunjgit/GameZone/issues/892,"### 🎮 Game Request

Game logic and basic description
- In a world where the game cannot be found, you point your browser to the venerable search engine.
- Overcome the obstacles of the uncharted Internet, such as paywalls, dark patterns, and web standards.
- You have to walk this path alone.
- You want to google the game.


### Point down the features

Game points
- Just completing the puzzles one by one, the game points are not provided in this game

<!--

https://github.com/kunjgit/GameZone/assets/92252895/da951802-6d2d-40bd-a866-b11aae1dffeb



-->

### Select program in which you are contributing

GSSoC23

### Code of Conduct

- [X] I follow [CONTRIBUTING GUIDELINE](https://github.com/kunjgit/GameZone/blob/main/.github/CONTRIBUTING_GUIDELINE.md) of this project.",2023-06-07T07:16:52Z,2023-06-10T04:32:38Z,closed,3,"prevention of dark pattern, gaming","game, ways to avoid dp","gaming, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/GameSphere-MultiPlayer/GameSphere/issues/237,[New game]: I WANT TO GOOGLE THE GAME 👾,https://github.com/GameSphere-MultiPlayer/GameSphere/issues/237,"### 🎮 Game Request

Game logic and basic description
- In a world where the game cannot be found, you point your browser to the venerable search engine.
- Overcome the obstacles of the uncharted Internet, such as paywalls, dark patterns, and web standards.
- You have to walk this path alone.
- You want to google the game.


### Point down the features

Game points
- Just completing the puzzles one by one, the game points are not provided in this game

<!--

https://github.com/GameSphere-MultiPlayer/GameSphere/assets/92252895/acf7fcb8-9224-45eb-a312-7cfc8207c650

-->

### Select The Game Type
- Single Player

### Additional Context
- I'm a GSSOC Contributor

### Code of Conduct

- [X] I follow [CONTRIBUTING GUIDELINE](https://github.com/Aman1-coder/GameSphere/blob/main/CODE_OF_CONDUCT.md) of this project.",2023-06-07T13:24:29Z,2023-06-12T16:11:54Z,closed,0,"prevention of dark pattern, gaming",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/86,[page] dark pattern description layout,https://github.com/BraindeadHermit/arkan/pull/86,,2023-03-16T15:30:39Z,2023-03-16T15:32:01Z,closed,0,miscellaneous,,,,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/47,[component] dark pattern dropdown,https://github.com/BraindeadHermit/arkan/pull/47,,2023-03-08T10:12:38Z,2023-03-08T10:14:21Z,closed,0,miscellaneous,,,,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/41,[component] dark pattern card,https://github.com/BraindeadHermit/arkan/pull/41,,2023-03-06T16:22:30Z,2023-03-06T16:23:19Z,closed,0,miscellaneous,,,,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/woocommerce/woocommerce/issues/39668,WooPayments shows in the admin menu without being installed,https://github.com/woocommerce/woocommerce/issues/39668,"### Prerequisites

- [X] I have carried out troubleshooting steps and I believe I have found a bug.
- [X] I have searched for similar bugs in both open and closed issues and cannot find a duplicate.

### Describe the bug

Since the last WooCommerce update, I have noticed WooPayments (FKA WooCommerce Payments) now mysteriously appears in the admin menu as if I have the plugin installed when I do not.
![image](https://github.com/woocommerce/woocommerce/assets/123473359/bcd510b0-4830-458d-8dc1-8633ea0a7428)

This seems a very a covert way of advertising the plugin on sites which use different payment gateways. You can see I don't have WooPayments installed, yet a menu item with a notification bubble to draw attention to it conveniently appears.
![image](https://github.com/woocommerce/woocommerce/assets/123473359/5ca02a28-429b-485a-b118-7af023db7817)


### Expected behavior

Not to see an admin menu item for a plugin that is not installed.

### Actual behavior

I see the WooPayments menu item as if I have the plugin installed. 

### Steps to reproduce

1. Go to your WordPress admin dashboard
2. Navigate around a bit
3. BAM! WooPayments mysteriously appears
4. It will then disappear randomly and appear again depending on where you are on the dashboard.

I am able to recreate this on 3 stores

Here is the link to the page, all you need is WooCommerce installed:
/wp-admin/admin.php?page=wc-admin&path=%2Fwc-pay-welcome-page



### WordPress Environment

`
### WordPress Environment ###

WordPress address (URL): https://brightonbackyardultra.co.uk
Site address (URL): https://brightonbackyardultra.co.uk
WC Version: 8.0.1
REST API Version: ✔ 8.0.1
WC Blocks Version: ✔ 10.6.5
Action Scheduler Version: ✔ 3.6.1
Log Directory Writable: ✔
WP Version: 6.3
WP Multisite: –
WP Memory Limit: 256 MB
WP Debug Mode: –
WP Cron: ✔
Language: en_GB
External object cache: –

### Server Environment ###

Server Info: Apache
PHP Version: 7.4.33
PHP Post Max Size: 128 MB
PHP Time Limit: 300
PHP Max Input Vars: 2500
cURL Version: 8.1.2
OpenSSL/1.1.1t-fips

SUHOSIN Installed: –
MySQL Version: 5.5.5-10.4.30-MariaDB-log
Max Upload Size: 128 MB
Default Timezone is UTC: ✔
fsockopen/cURL: ✔
SoapClient: ✔
DOMDocument: ✔
GZip: ✔
Multibyte String: ✔
Remote Post: ✔
Remote Get: ✔

### Database ###

WC Database Version: 8.0.1
WC Database Prefix: 4c_
Total Database Size: 14.99MB
Database Data Size: 11.94MB
Database Index Size: 3.05MB
4c_woocommerce_sessions: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_woocommerce_api_keys: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_woocommerce_attribute_taxonomies: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_woocommerce_downloadable_product_permissions: Data: 0.02MB + Index: 0.06MB + Engine InnoDB
4c_woocommerce_order_items: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_woocommerce_order_itemmeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_woocommerce_tax_rates: Data: 0.02MB + Index: 0.06MB + Engine InnoDB
4c_woocommerce_tax_rate_locations: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_woocommerce_shipping_zones: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_woocommerce_shipping_zone_locations: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_woocommerce_shipping_zone_methods: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_woocommerce_payment_tokens: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_woocommerce_payment_tokenmeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_woocommerce_log: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_actionscheduler_actions: Data: 0.06MB + Index: 0.11MB + Engine InnoDB
4c_actionscheduler_claims: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_actionscheduler_groups: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_actionscheduler_logs: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_affiliatemeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_affiliates: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_campaigns: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_connections: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_affiliate_wp_coupons: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_creatives: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_customermeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_customers: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_custom_links: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_groups: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_affiliate_wp_notifications: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_payouts: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_referralmeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_affiliate_wp_referrals: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_rest_consumers: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_sales: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_affiliate_wp_visits: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_cartflows_ca_cart_abandonment: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_cartflows_ca_email_history: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_cartflows_ca_email_templates: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_cartflows_ca_email_templates_meta: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_commentmeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_comments: Data: 0.02MB + Index: 0.09MB + Engine InnoDB
4c_e_events: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_e_notes: Data: 0.02MB + Index: 0.17MB + Engine InnoDB
4c_e_notes_users_relations: Data: 0.02MB + Index: 0.05MB + Engine InnoDB
4c_e_submissions: Data: 0.08MB + Index: 0.27MB + Engine InnoDB
4c_e_submissions_actions_log: Data: 0.02MB + Index: 0.11MB + Engine InnoDB
4c_e_submissions_values: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_links: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_options: Data: 5.03MB + Index: 0.06MB + Engine InnoDB
4c_postmeta: Data: 3.08MB + Index: 0.19MB + Engine InnoDB
4c_posts: Data: 2.06MB + Index: 0.06MB + Engine InnoDB
4c_rank_math_404_logs: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_rank_math_internal_links: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_rank_math_internal_meta: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_rank_math_redirections: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_rank_math_redirections_cache: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_snippets: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_termmeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_terms: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_term_relationships: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_term_taxonomy: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_usermeta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_users: Data: 0.02MB + Index: 0.05MB + Engine InnoDB
4c_wc_admin_notes: Data: 0.06MB + Index: 0.00MB + Engine InnoDB
4c_wc_admin_note_actions: Data: 0.05MB + Index: 0.02MB + Engine InnoDB
4c_wc_category_lookup: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_wc_customer_lookup: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_download_log: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_orders: Data: 0.02MB + Index: 0.11MB + Engine InnoDB
4c_wc_orders_meta: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_order_addresses: Data: 0.02MB + Index: 0.06MB + Engine InnoDB
4c_wc_order_coupon_lookup: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_order_operational_data: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_order_product_lookup: Data: 0.02MB + Index: 0.06MB + Engine InnoDB
4c_wc_order_stats: Data: 0.02MB + Index: 0.05MB + Engine InnoDB
4c_wc_order_tax_lookup: Data: 0.02MB + Index: 0.03MB + Engine InnoDB
4c_wc_product_attributes_lookup: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_wc_product_download_directories: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_wc_product_meta_lookup: Data: 0.02MB + Index: 0.09MB + Engine InnoDB
4c_wc_rate_limits: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_wc_reserved_stock: Data: 0.02MB + Index: 0.00MB + Engine InnoDB
4c_wc_tax_rate_classes: Data: 0.02MB + Index: 0.02MB + Engine InnoDB
4c_wc_webhooks: Data: 0.02MB + Index: 0.02MB + Engine InnoDB

### Post Type Counts ###

attachment: 77
custom_css: 1
customize_changeset: 3
elementor_library: 17
nav_menu_item: 21
page: 21
post: 17
product: 2
revision: 107
shop_order: 1

### Security ###

Secure connection (HTTPS): ✔
Hide errors from visitors: ✔

### Active Plugins (12) ###

AffiliateWP: by AffiliateWP – 2.15.2
AffiliateWP - Affiliate Area Shortcodes: by AffiliateWP – 1.3.1
AffiliateWP - Allowed Products: by Sandhills Development
LLC – 1.3

AffiliateWP - Custom Affiliate Slugs: by Sandhills Development
LLC – 1.2

Code Snippets: by Code Snippets Pro – 3.4.2
Elementor Pro: by Elementor.com – 3.15.1
Elementor: by Elementor.com – 3.15.2
Perfmatters: by forgemedia – 2.1.4
Rank Math SEO: by Rank Math – 1.0.121
String Locator: by InstaWP – 2.6.1
WooCommerce Cart Abandonment Recovery: by CartFlows Inc – 1.2.25
WooCommerce: by Automattic – 8.0.1

### Inactive Plugins (0) ###


### Must Use Plugins (1) ###

StackCache: by Stack CP –

### Settings ###

API Enabled: –
Force SSL: –
Currency: GBP (£)
Currency Position: left
Thousand Separator: ,
Decimal Separator: .
Number of Decimals: 2
Taxonomies: Product Types: external (external)
grouped (grouped)
simple (simple)
variable (variable)

Taxonomies: Product Visibility: exclude-from-catalog (exclude-from-catalog)
exclude-from-search (exclude-from-search)
featured (featured)
outofstock (outofstock)
rated-1 (rated-1)
rated-2 (rated-2)
rated-3 (rated-3)
rated-4 (rated-4)
rated-5 (rated-5)

Connected to WooCommerce.com: –
Enforce Approved Product Download Directories: ✔
HPOS feature screen enabled: –
HPOS feature enabled: –
Order datastore: WC_Order_Data_Store_CPT
HPOS data sync enabled: –

### WC Pages ###

Shop base: #782 - /shop
Basket: ❌ Page does not contain the [woocommerce_cart] shortcode or the woocommerce/cart block.
Checkout: #23 - /checkout
My account: #24 - /my-account
Terms and conditions: #74 - /policies/terms-conditions

### Theme ###

Name: Hello Elementor
Version: 2.8.1
Author URL: https://elementor.com/?utm_source=wp-themes&utm_campaign=author-uri&utm_medium=wp-dash
Child Theme: ❌ – If you are modifying WooCommerce on a parent theme that you did not build
personally we recommend using a child theme. See: How to create a child theme

WooCommerce Support: ✔

### Templates ###

Overrides: –

### Admin ###

Enabled Features: activity-panels
analytics
product-block-editor
coupons
core-profiler
customer-effort-score-tracks
import-products-task
experimental-fashion-sample-products
shipping-smart-defaults
shipping-setting-tour
homescreen
marketing
mobile-app-banner
navigation
onboarding
onboarding-tasks
remote-inbox-notifications
remote-free-extensions
payment-gateway-suggestions
shipping-label-banner
subscriptions
store-alerts
transient-notices
woo-mobile-welcome
wc-pay-promotion
wc-pay-welcome-page

Disabled Features: minified-js
new-product-management-experience
product-variation-management
settings
async-product-editor-category-field

Daily Cron: ✔ Next scheduled: 2023-08-10 09:24:54 +01:00
Options: ✔
Notes: 82
Onboarding: completed

### Action Scheduler ###

Complete: 76
Oldest: 2023-07-10 10:35:52 +0100
Newest: 2023-08-10 10:02:58 +0100

Failed: 3
Oldest: 2023-07-08 10:34:11 +0100
Newest: 2023-07-28 09:31:56 +0100

Pending: 4
Oldest: 2023-08-10 19:06:47 +0100
Newest: 2023-08-27 09:47:28 +0100


### Status report information ###

Generated at: 2023-08-10 10:04:41 +01:00
`

### Isolating the problem

- [X] I have deactivated other plugins and confirmed this bug occurs when only WooCommerce plugin is active.
- [X] This bug happens with a default WordPress theme active, or [Storefront](https://woocommerce.com/storefront/).
- [X] I can reproduce this bug consistently using the steps above.",2023-08-10T09:06:15Z,2023-09-12T13:39:06Z,closed,21,"WooPayments, usage of dark pattern, disguised ads (placing an ad that looks like a management panel)","WooPayments, ad disguised, design manipulation, interface interference","WooPayments, disguised ads",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/GeopJr/DNOME/issues/7,libadwaita version,https://github.com/GeopJr/DNOME/pull/7,"Most of the changelog is at #6 

The gist is:

- no more recoloring - do actual component styling to kind of match libadwaita (but not *too* much as to not completely destroy discord's branding)
- less nitro dark patterns (like shiny buttons or gift button on the message input)
- repo organization - it should now be a lot easier to maintain
- run dist through csso to minify and optimize the built css
- wrote a small guide on theming discord
- removed unused styles and css variables
- added some config options
- added a attribution and dnome version string at the bottom of settings sidebar

closes: #6 ",2022-11-05T16:25:02Z,2023-05-31T01:14:50Z,closed,0,"prevention of dark pattern,  nitro dark patterns (shiny button)","Discord, libadwaita version, removing dp","Discord, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/50,[server] retrive dark pattern info,https://github.com/BraindeadHermit/arkan/pull/50,,2023-03-08T18:33:29Z,2023-03-08T18:35:04Z,closed,2,miscellaneous,,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/lukaskupczyk/react-hook-consent/issues/19,Make Settings Toggle Available to Developers,https://github.com/lukaskupczyk/react-hook-consent/pull/19,"First of all I like your way of thinking in creating this Package, thanks for creating it!
Fell into a rabbit hole when looking for GDPR banners without having to use an external service
and settled on yours : ).

This PR will move toggling the Details / Settings Modal to `useConsentState` in order to make it available
as `isDetailsVisible` & `toggleDetails()` to a Developer.
And while you seem to have made all Services being auto enabled by default in one of your last commits,
to my knowledge that's against the GDPR and a dark pattern. So I changed it to only make the mandatory
ones auto enabled.

Hope the changes are to your liking and this PR will get merged.
Up till then I'm using the following patch with [patch-package](https://www.npmjs.com/package/patch-package)
(has to be renamed to `.patch` & put into a `patches` folder - for whatever reason GitHub doesn't support patch files % ):
 
[react-hook-consent+3.2.0.txt](https://github.com/lukaskupczyk/react-hook-consent/files/11497952/react-hook-consent%2B3.2.0.txt)

Best,

Tim.",2023-05-17T12:25:04Z,2023-05-30T16:50:01Z,closed,2,"regulation required, gdpr banner, against dark pattern, prevention of dark pattern","Settings, all services auto enabled, preselection","auto enabled, preselection, GDPR, regulation, avoid dark pattern","DPs prevention in software, DPs related regulation ",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/53,[page] dark pattern information posts layout,https://github.com/BraindeadHermit/arkan/issues/53,,2023-03-11T08:56:45Z,2023-03-16T15:33:04Z,closed,0,miscellaneous,,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/49,[server] retrive dark pattern data,https://github.com/BraindeadHermit/arkan/issues/49,,2023-03-08T18:16:21Z,2023-03-08T18:44:26Z,closed,0,miscellaneous,,,,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/department-of-veterans-affairs/va.gov-cms/issues/14002,Design: Improve Editorial UI for News promo block,https://github.com/department-of-veterans-affairs/va.gov-cms/issues/14002,"## Description

### User story

**AS A** Homepage Manager role
**I WANT** the UX of altering the News promo block to be clearer and have revision logs
**SO THAT** I am more likely to successfully keep that area of the homepage fresh.

### Design

[News promo Figma file](https://www.figma.com/file/sOMpovTM82TgC08ugF0FxF/News-Promo-Block?type=design&node-id=0%3A1&mode=design&t=fqOkdRBl50BIRhv6-1)

### Engineering notes / background

Dave C edited the News promo block just before hard launch of the new homepage and made the following observations:

- We need to do some QA on the help text associated with any of these fields.
- There's no way to ""cancel"" my edits when I've started editing.
- Revision logs are not required
- It's not clear why the Link Text CTA is a dropdown if the only option is ""Read the full article"". (Reason: #11172 will add further options.)


**Where to find in CMS:**
Filter block type on [Staging blocks list](https://staging.cms.va.gov/admin/structure/block/block-content)

[Overview of Homepage Editor UX](https://github.com/department-of-veterans-affairs/va.gov-cms/issues/11802) of steps and UI (possibly slightly outdated)


### Analytics considerations


### Quality / testing notes


## Acceptance criteria
- [x] Documented the following updates in a Figma design
  - [x] Help text is accurate and complete
       - [x] Link Text help text ONLY on News Promo
       - [x] Block Description help text on both Benefit and News promos
       - [x] Promo Headline help text on both Benefit and News promos
  - [x] Added a way to ""cancel"" my edits when I've started editing.
  - [x] Revision logs are required
  - [x] Decided whether we can should leave the Link Text CTA as a dropdown if the only option is ""Read the full article"". (Reason: #11172 will add further options.) - We're keeping this a dropdown
- [x] Added Figma link to implementation ticket #13863.
- [ ] Design reviewed by @wesrowe and @davidconlon ",2023-06-06T00:18:11Z,2023-07-20T16:00:51Z,closed,10,miscellaneous (avoid dark pattern design),"asks for authorization even tho ""anyone can view"", forced action, obstruction","forced action, authorization, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/woocommerce/woocommerce/issues/39383,Add/user menu component,https://github.com/woocommerce/woocommerce/pull/39383,"### Submission Review Guidelines:

-   I have followed the [WooCommerce Contributing Guidelines](https://github.com/woocommerce/woocommerce/blob/trunk/.github/CONTRIBUTING.md) and the [WordPress Coding Standards](https://make.wordpress.org/core/handbook/best-practices/coding-standards/).
-   I have checked to ensure there aren't other open [Pull Requests](https://github.com/woocommerce/woocommerce/pulls) for the same update/change.
-   I have reviewed my code for [security best practices](https://developer.wordpress.org/apis/security/).
-   Following the above guidelines will result in quick merges and clear and detailed feedback when appropriate.

<!-- You can erase any parts of this template not applicable to your Pull Request. -->

### Changes proposed in this Pull Request:

<!-- If necessary, indicate if this PR is part of a bigger feature. Add a label with the format `focus: name of the feature [team:name of the team]`. -->

<!-- Describe the changes made to this Pull Request and the reason for such changes. -->

Closes https://github.com/Automattic/woocommerce.com/issues/17509

<!-- Begin testing instructions -->

### How to test the changes in this Pull Request:

<!-- Include detailed instructions on how these changes can be tested. Review and follow the guide for how to write high-quality testing instructions. -->

Using the [WooCommerce Testing Instructions Guide](https://github.com/woocommerce/woocommerce/wiki/Writing-high-quality-testing-instructions), include your detailed testing instructions:

1. Before checking out the branch, checkout `trunk` and set up a connection to WooCommerce.com with a test account. (you can do this by clicking ""Connect"" at `/wp-admin/admin.php?page=wc-addons&section=helper`).
2. Checkout this branch
    a. from the `plugins/woocommerce` folder, you may need to run `composer dump-autoload`
    b. from the `plugins/woocommerce-admin` folder, you may need to run `pnpm install` if you get dependency issues
3. Build the project by going to `plugins/woocommerce` and running `pnpm run --filter=woocommerce build`
4. Visit the Extensions page (WP Env URL is http://localhost:8888/wp-admin/admin.php?page=wc-admin&path=%2Fextensions)
5. The component should appear as a small icon above the Discover and Extensions tabs.
6. Check against the MVP design in Figma - you should see the **connected** version, and the **local** user avatar.
7. Test the logged out version by editing [this line](https://github.com/woocommerce/woocommerce/blob/6557db1a5abc3f20d9d539146c0706362e14dfb3/plugins/woocommerce/includes/admin/helper/class-wc-helper-admin.php#L24) to `'isConnected' => false,`
    - **note no rebuild is required for this test**

<!-- End testing instructions -->

### Screenshots
**Logged out:**
<img width=""451"" alt=""Screenshot 2023-07-26 at 16 56 00"" src=""https://github.com/woocommerce/woocommerce/assets/22053773/f830324b-aff9-4659-8011-9f635e1d396b"">

**Logged in:**
<img width=""399"" alt=""Screenshot 2023-07-26 at 16 56 17"" src=""https://github.com/woocommerce/woocommerce/assets/22053773/d6866e20-aff0-4448-b102-cd91c11ec304"">

### Changelog entry

<!-- You can optionally choose to enter a changelog entry by checking the box and supplying data. -->

-   [ ] Automatically create a changelog entry from the details below.

<details>

#### Significance

<!-- Choose only one -->

-   [ ] Patch
-   [ ] Minor
-   [ ] Major

#### Type

<!-- Choose only one -->

-   [ ] Fix - Fixes an existing bug
-   [ ] Add - Adds functionality
-   [ ] Update - Update existing functionality
-   [ ] Dev - Development related task
-   [ ] Tweak - A minor adjustment to the codebase
-   [ ] Performance - Address performance issues
-   [ ] Enhancement - Improvement to existing functionality

#### Message <!-- Add a changelog message here -->

#### Comment <!-- If the changes in this pull request don't warrant a changelog entry, you can alternatively supply a comment here. Note that comments are only accepted with a significance of ""Patch"" -->

</details>",2023-07-24T14:45:46Z,2023-09-12T17:01:10Z,closed,12,miscellaneous (avoid deceptive design practice),"open in new tab, back, unnecessary steps, distraction",miscellaneous,miscellaneous ,"avoid deceptive design practice, distraction",,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/iCHAIT/awesome-macOS/issues/626,Add DevUtils app,https://github.com/iCHAIT/awesome-macOS/pull/626,"<!-- Thanks for contributing to awesome-macOS  -->

<!-- Please fill out the following: -->

0. [x] I have read the [Contribution Guidelines](https://github.com/iCHAIT/awesome-macOS/blob/master/.github/contributing.md)
1. [x] Project URL: https://devutils.com
2. [x] Why should this project be added: I think it's an awesome native macOS app and useful for many developers. It's being used by 10,000+ developers and teams around the world. It would be great if we can include it in this repo, thanks! (Disclosure: I'm the author of the app).
3. [x] End all descriptions with a full stop/period
4. [x] Entry is ordered alphabetically
5. [x] Appropriate icon(s) added if applicable (OSS, freeware)

<!--

Again, please read https://github.com/iCHAIT/awesome-macOS/blob/master/.github/contributing.md if you didn't yet.

-->
",2023-01-02T03:18:12Z,2023-05-14T06:58:12Z,closed,2,"DevUtils (all-in-one toolbox), usage of dark pattern, trick users to download","hidden costs with download button, sneaking, hidden costs","DevUtils, hidden costs, sneaking, decceptive design practices",DPs used in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/debug-js/debug/issues/924,Erroneous CVE causing havoc with package vulnerability scanners (2.6.9),https://github.com/debug-js/debug/issues/924,"Technically an issue but not with code. More of an FYI for the package owner and others experiencing issues with failing security audits.

Summary is a new CVE [CVE-2017-20165](https://www.cve.org/CVERecord?id=CVE-2017-20165) that appears to be a duplicate of [CVE-2017-16137](https://www.cve.org/CVERecord?id=CVE-2017-16137) erroneously identifies 2.6.9 as being vulnerable.

@dougwilson from the express project took the time to do the top level investigation, thread is [available here](https://github.com/expressjs/express/issues/5088#issuecomment-1378028914)",2023-01-10T23:45:17Z,2023-08-04T16:11:32Z,closed,5,"miscellaneous (avoid dark pattern design, NPM, GitHub)","failing security audit, show personal info to know project info, manipulation",,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3c/permissions-ws-2022/issues/32,Add slides for dark patterns talk,https://github.com/w3c/permissions-ws-2022/pull/32,,2023-02-08T09:25:38Z,2023-02-08T09:32:22Z,closed,0,miscellaneous,,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/monopoint/dark-patterns/issues/2,"Adds scoreboard functionality, stored in browser local memory",https://github.com/monopoint/dark-patterns/pull/2,"Adds a very simple scoreboard feature. The scoreboard is the first page in the flow, greeting the player.
When completing the flow, the player will be asked to input contact info, which is stored in local storage in the browser.
This is used to populate the scoreboard, and can be used to contact the winner.
  
![image](https://user-images.githubusercontent.com/44222176/233339912-a10c3617-ad38-4076-86df-9d10798cbba7.png)
![image (1)](https://user-images.githubusercontent.com/44222176/233339925-5480c062-0c5a-431d-a1d1-5956e8345c1d.png)
(typos have been fixed since picture was taken)",2023-04-20T10:30:14Z,2023-04-20T13:56:51Z,closed,1,dark-pattern-related project,,miscellaneous,miscellaneous,UI/UX design,,DPs or not,dps or not,,,
https://api.github.com/repos/monopoint/dark-patterns/issues/1,Text fixes,https://github.com/monopoint/dark-patterns/pull/1,,2023-04-20T10:06:26Z,2023-04-20T10:07:11Z,closed,1,dark-pattern-related project,,miscellaneous,miscellaneous,UI/UX design,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/padloc/padloc/issues/698,"[Feature Request] Allow adding premium fields without premium subscription, but don't render them outside editor.",https://github.com/padloc/padloc/issues/698,"I want to evaluate whether Padloc fits my needs. I intend to transfer from Bitwarden. Although Bitwarden necessitates payment to generate TOTP codes, it allows the user to add the TOTP key. I want to ascertain whether Padloc can support everything that I have stored in my Bitwarden vault, such as
* Markdown text (despite `bw` not supporting that). I obviously see the option to add it, but want to see things like whether a character limit exists to ensure that no truncation occurs; and
* multiple TOTP codes. I realize that this might be in the documentation somewhere, but being able to actually see that I am able to add multiple TOTP keys to a single vault entry (which `bw` doesn't support) would incentivize me to try the subscription.",2023-04-10T13:38:16Z,2023-04-18T21:16:32Z,closed,4,"usage of dark pattern in software, premium version, trial version","premium features for free trial, manipulation, forced action",trick users to buy paid products,DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/git-ecosystem/git-credential-manager/issues/1355,Microsoft Account user model on Windows.,https://github.com/git-ecosystem/git-credential-manager/issues/1355,"Hi @vtbassmatt , @wolf99 , @mjcheetham , I would like to learn more about what's the reason you mentioned this notes in the [windows-broker.md](https://github.com/git-ecosystem/git-credential-manager/blob/main/docs/windows-broker.md#for-microsoft-accounts):
 

> Two very important things to note:
>   
>   If you haven't connected any Microsoft accounts to Windows before, the first account you connect will cause the local Windows user account to be converted to a connected account.
>   In addition, you can't change the usage preference for the first Microsoft account connected to Windows: all Microsoft apps will be able to sign you in with that account.
>   As far as we can tell, there are no workarounds for either of these behaviors (other than to not use the WAM broker).

I believe there are some misunderstandings about how MSA works in WAM as well as SSO.
By adding the MSA via application such as GCM, the MSA can be added as associated (SSO) or secondary (CSO, one click sign on) and it's controlled by user.
In addition, it should not convert your local account into MSA. 

Please let me know what's your experience and the reason behind those notes that you have added.
Thanks.",2023-07-26T20:04:41Z,2023-08-02T19:10:32Z,closed,5,"prevention of dark pattern in software, Microsoft sign-in in Windows, crediential access","Microsoft, WAM, modal, design hierarchy","Microsoft, modal, avoid dark pattern",DPs prevention in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/ansible/awx/issues/12250,Experimental direct role execution,https://github.com/ansible/awx/pull/12250,"<!--- changelog-entry
# Fill in 'msg' below to have an entry automatically added to the next release changelog.
# Leaving 'msg' blank will not generate a changelog entry for this PR.
# Please ensure this is a simple (and readable) one-line string.
---
msg: ""Adds support for direct role execution defined by properties on the job template""
-->

##### SUMMARY
<!--- Describe the change, including rationale and design decisions -->
See this old issue: https://github.com/ansible/awx/issues/3780

This is work towards adding Direct Role execution capabilities into AWX. Since we're moving towards Execution Environments as the mode of execution and Collections as one of the primary delivery pipelines adding support for this gives another vector for delivering automation directly to Controller itself.

Having direct role execution also enables more targeted use of Role Arg Spec as a capability within Ansible core itself, potentially being able to inform Survey semantics. This also leads towards being able to select playbooks from Collections as a source of automation.

The functionality provided here may also lead to directly publishing content from GalaxyNG and Dev Tools where those systems have a deep understanding of the source and provenance of the automation content but don't have the capability to create and publish a source control repo. Imagine a scenario where a developer is testing a role or a playbook and has the ability to push it directly into AWX organization specifically confined for automation testing.

This change also encourages users and organizations to standardize on automation content publishing without needing to expose source control semantics to the automation system itself.

The way this PR is implemented is that it removes the hard requirement that a project and playbook be defined and instead allows either a Project/Playbook to be used OR the FQCN+Role be specified. This will trigger different behavior in Ansible Runner.

This PR is missing some things that would make it generally more useful for an integration:

- [x] Tests
- [ ] Documentation
- [ ] Collection and Role indexing from the Execution Environment itself. This is currently done in a partial way from the Job runtime and should be changed so that the information is also stored adjacent to the EE.
- [ ] UI/UX -- The UI is deeply confused and concerned that there's no project or playbook assigned 
- [ ] We can probably take care of https://github.com/ansible/awx/issues/10409 at the same time, as right now there's just a placeholder value for the SCM revision.
- [ ] Direct Playbook Execution from a Collection
(More that I'm sure will come up as part of discussion)

There are some adjacent things I'm using as part of the validation while working on this, namely:

- https://github.com/ansible/ansible-tower-samples/pull/26 is a PR on the demo git repo that allows generating a collection from its content
- The EE definition that makes use of that change to produce an EE containing that collections: https://gist.github.com/matburt/94c5410a4ba7da20c9cf09ce07091c73
- The EE (quay.io/matburt/ansible-sample-ee:latest) that I've published to my quay account that is the manifestation of both of those things: https://quay.io/repository/matburt/ansible-sample-ee?tab=tags



<!---
If you are fixing an existing issue, please include ""related #nnn"" in your
commit message and your description; but you should still explain what
the change does.
-->

##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->
 - Feature Pull Request

##### COMPONENT NAME
<!--- Name of the module/plugin/module/task -->
 - API
 - UI
 - Collection

##### AWX VERSION
<!--- Paste verbatim output from `make VERSION` between quotes below -->
```
HEAD
```


##### ADDITIONAL INFORMATION
<!---
Include additional information to help people understand the change here.
For bugs that don't have a linked bug report, a step-by-step reproduction
of the problem is helpful.
  -->
![directro8](https://user-images.githubusercontent.com/89544/169078279-c2580910-d068-429c-a5f2-2cd7e9a33cb7.gif)

<!--- Paste verbatim command output below, e.g. before and after your change -->
```

```
",2022-05-18T15:00:57Z,2023-06-14T15:01:20Z,closed,4,"prevention of dark pattern, ad hoc command","ad hoc commands, inventory interface","ad hoc commands, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/24,[component] site image input,https://github.com/BraindeadHermit/arkan/issues/24,A specific component for inserting a screenshot of the Dark Pattern that has been detected,2022-12-15T16:19:58Z,2023-03-16T10:55:26Z,closed,0,"dark pattern detect, screenshots of detected dp ",,detection,DPs detection Tools,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/WordPress/openverse/issues/543,Discourage users from right-click and saving images from single result views,https://github.com/WordPress/openverse/issues/543,"## Problem
<!-- Describe a problem solved by this feature; or delete the section entirely. -->

Inspired by [@sarayourfriend's comment](https://github.com/WordPress/openverse-frontend/pull/1493#pullrequestreview-999446176) on a related PR, I was reminded that it's fairly common for Openverse users to right click and save the images from the single results as a method of downloading Openverse images. This isn't ideal for a few reasons:

- The user might not get the highest-quality possible image, or other desirable formats, especially if we switch to using our image proxy on single image results in the future
- The image might be taken down at the source due to a copyright infringement or other issue, and without checking the user might put themselves at legal risk.

## Description
<!-- Describe the feature and how it solves the problem. -->

Here are two ideas for fixing this, the first the friendliest I can think of and the second a potential dark-pattern:

1. Show a flash message on screen when the user attempts to click, or right click the image, that shows them a version of the text in this issue description. We could also include a direct link to the source in this message. We could make this message appear once only, and allow saving the image on subsequent interactions. This would be meant to discourage but not prevent the default behavior.
2. We could silently block any interacting with the image via CSS, forcing users to inspect the page in devtools to download the images. You can see this modeled in the desktop/web version of Instagram. 

## Alternatives
<!-- Describe any alternative solutions or features you have considered. How is this feature better? -->

## Additional context
<!-- Add any other context about the feature here; or delete the section entirely. -->

## Implementation
<!-- Replace the [ ] with [x] to check the box. -->
- [ ] 🙋 I would be interested in implementing this feature.
",2022-06-08T23:01:49Z,2023-06-09T21:53:41Z,closed,5,"usage of dark pattern in design, encourage/force users to save image","downloading image, block interaction of user witgh imagem forced action - inspect the image","download, forced action",DPs in design coding,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/open-sauced/app/issues/799,Dark Pattern: The entire PR list item should be clickable,https://github.com/open-sauced/app/issues/799,"### Type of feature

🍕 Feature

### Current behavior

<img width=""1414"" alt=""Screen Shot 2023-01-26 at 5 38 06 AM"" src=""https://user-images.githubusercontent.com/5713670/214849464-577700ef-05d1-4579-811b-6307d62076f1.png"">


### Suggested solution

<img width=""908"" alt=""Screen Shot 2023-01-26 at 5 37 04 AM"" src=""https://user-images.githubusercontent.com/5713670/214849487-2eecb920-3beb-48bd-9803-a193d6fd90f5.png"">

Make the entire line (red box) linked to the PR.

### Additional context

_No response_

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct

### Contributing Docs

- [ ] I agree to follow this project's Contribution Docs",2023-01-26T13:38:52Z,2023-02-14T18:57:04Z,closed,2,"dark pattern design, dp:the entire PR list item should be clickable","PR list not clickable, example",UI/UX design,DPs in design coding,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/26,Card for DP Detected Through Analysis,https://github.com/BraindeadHermit/arkan/issues/26,A special card to show information about dark patterns detected through analysis,2022-12-15T16:31:57Z,2023-03-06T16:25:50Z,closed,0,"dark pattern detection, card for DP detected through analysis",,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/25,User detected DP Card,https://github.com/BraindeadHermit/arkan/issues/25,A special card to show information about dark patterns detected by the user,2022-12-15T16:28:08Z,2023-03-06T16:26:01Z,closed,0,"dark pattern detection, card for DP detected by users",,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/open-sauced/app/issues/798,Dark pattern: User cannot not navigate to their profile.,https://github.com/open-sauced/app/issues/798,"### Type of feature

🍕 Feature

### Current behavior

<img width=""306"" alt=""Screen Shot 2023-01-26 at 5 33 31 AM"" src=""https://user-images.githubusercontent.com/5713670/214848637-77272b2c-ffbd-4f7e-b185-ea2a63d2b076.png"">


### Suggested solution

<img width=""306"" alt=""Screen Shot 2023-01-26 at 5 33 31 AM"" src=""https://user-images.githubusercontent.com/5713670/214848847-c0892767-b54d-4e5a-9180-c2f5ac22e766.png"">

This is a quick fix. A design is not needed. We need the link with the user name there. 

cc @OgDev-01 @getaheaddev 

### Additional context

_No response_

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct

### Contributing Docs

- [ ] I agree to follow this project's Contribution Docs",2023-01-26T13:36:37Z,2023-02-02T18:35:17Z,closed,5,"dark pattern design, user cannot not navigate to their profile, forced action","navigate button absent, fixed",miscellaneous,miscellaneous,"navigated button missing, forced action, UI/UX design",,DPs used in software,dps used in software,,,
https://api.github.com/repos/leo-lox/camelus/issues/16,"Push to refresh my feed, do not show new notes. Only show new notes on my feed if first I go to global feed.",https://github.com/leo-lox/camelus/issues/16,"Hi,

Push to refresh my feed, do not show new notes. Only show new notes on my feed if first I go to global feed. See the video:


https://user-images.githubusercontent.com/1178856/226183841-658274c5-af0f-4d90-b7e7-cf11a24d64c4.mp4

",2023-03-19T14:48:58Z,2023-03-19T19:53:21Z,closed,4,"Nostr, prevention dark pattern design in software","pull to refresh, addicting, emotional manipulation","Nostr, refresh page, addictive, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/mastodon/mastodon/issues/23075,The ability to split an account into channels!,https://github.com/mastodon/mastodon/issues/23075,"### Pitch

An user can setup channels. An user can post to channels (or every channel). Following an user automatically subscribes to all channels (especially since the followed user might make more channels at any time and you wouldn't find out about it), and channels can be individually blocked/unsubscribed.

### Motivation

We don't know why ppl follow us but we'd like to not flood their feed with our struggles with ADLs or programming stuff or whatnot. This would give ppl the choice to opt-out of some of these, for better or worse.

There's stuff we wouldn't give our followers the choice to opt-out of, like uh, being queer. Yeah that one is non-negotiable. But like, we don't think most ppl wanna know about us cleaning our room in detail. So they should be able to skip those. And ""channels"" would be a lot more convenient for this than CWs, since channels are about the writer's direct interpersonal relationships rather than about the post's contents.

(Also this is explicitly NOT circles; circles are curated by the user, whereas this is self-curated by the followers.)",2023-01-13T00:09:18Z,2023-05-20T20:29:23Z,closed,5,"Mastodon (open-source social network service), ","split accounts, subscription emails","Mastodon, subscription emails",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/OhMyGuus/I-Still-Dont-Care-About-Cookies/issues/2352,[REQ] www.saxxunderwear.ca,https://github.com/OhMyGuus/I-Still-Dont-Care-About-Cookies/issues/2352,"Someone reported anonymously: 
  ### Website URL

https://www.saxxunderwear.ca

### What browser are u using?

Firefox 109

### Version

1.1.0

### Notes

I get a cookie banner at the bottom to accept cookies or to accept necessary cookies with a dark pattern",2023-02-16T16:58:04Z,2023-02-24T00:27:28Z,closed,1,"dark pattern design mechanism, manage subscribtion options/preferences","accept cookies, forced action","cookie consent, forced action, deceptive design practices",DPs examples/definitions,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/ProtonMail/proton-bridge/issues/379,Indicator applet UI is surprising on Gnome,https://github.com/ProtonMail/proton-bridge/issues/379,"Issue tracker is ONLY used for reporting bugs with technical details. ""It doesn't work"" or new features should be discussed with our customer support. Please use bug report function in Bridge or contact bridge@protonmail.ch.
<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
<!--- Tell us what should happen -->

A single click on applets in the indicator applet bar on Gnome should open a theme-consistent menu.

## Current Behavior
<!--- Tell us what happens instead of the expected behavior -->

A single click does nothing. A double click brings a theme inconsistent pane which is not really a menu, but which has an almost dark patterned menu button at the bottom right. ~This menu does not close when the outer pane is dismissed, remaining present when the applet indicator icon is double clicked again to open it.~

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->

## Steps to Reproduce
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant -->

1. File issue #255
    First issue:
    1. Single click on the applet indicator icon in Gnome.
    2. :cricket: 

    ~Second issue:~
    1. ~Double click on the icon.~
    2. ~Click on the three dots at the bottom right of the pane.~
    3. ~Click away.~
    4. ~Double click on the applet indicator icon.~
2. Wait one year.
3. Have original issue closed without investigation on the basis that the OS version is no longer supported and despite that the issue is a design issue and the code that does the work that is at issue has not been changed.
4. Install the latest version on a 22.04 VM and mess around for half an hour getting indicator applets to work with the full expectation that the issue will still be present, because you know, that's how not changing code impacts on changing behaviour.
5. See, surprising no-one, that indeed the design issue is still present. The second issue of not correctly updating pane state is resolved, presumably due to fixes in Qt or Gnome.

## Version Information
<!--- Which version of the app(s) were you using when you experienced this issue? -->

v3.0.21

## Context (Environment)
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

Ubuntu 22.04

## Detailed Description
<!--- Provide a detailed description of the change or addition you are proposing -->

## Possible Implementation
<!--- Not obligatory, but suggest an idea for implementing addition or change -->
",2023-04-15T01:47:00Z,2023-05-31T08:02:09Z,closed,4,"applet UI in Gnome, usage of dark pattern, dark patterned menu button design","Gnome, single click does not do desired behavior","Gnome, UI/UX design",DPs used in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/transcend-io/consent-manager-ui/issues/115,Adds new banner types,https://github.com/transcend-io/consent-manager-ui/pull/115,"## Related Issues

- links https://transcend.height.app/T-21959
- links https://transcend.height.app/T-22793

### `AcceptAllOrMoreChoices`

**WARNING: This UI is a dark pattern and risks non-compliance. Use at own discretion.**

![ViewState = AcceptAllOrMoreChoices](https://user-images.githubusercontent.com/10264973/221736031-2526a3a0-153b-484d-9067-c1072017d974.png)

#### Button Mapping

| Button Title           | Callback Description                                                                                                                                                                                                                                                                                             |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Accept All             | Opts the user into all allowed purposes in current consent experience.                                                                                                                                                                                                                                           |
| More choices           | Redirects to the `CompleteOptions` view state. No purposes change.                                                                                                                                                                                                                                               |
| See our Privacy Policy | Redirects to the privacy policy link specified in [Consent Display Settings](https://app.transcend.io/consent-manager/display-settings) or the [`data-privacy-policy`](https://docs.transcend.io/docs/consent/faq#how-can-i-customize-the-privacy-policy-link-when-hosting-on-multiple-domains?) data attribute. |

### `AcceptOrRejectAllOrMoreChoices`

Similar to `AcceptOrRejectAll`, but the ""More Choices"" button is a primary button.

![ViewState = AcceptOrRejectAllOrMoreChoices](https://user-images.githubusercontent.com/10264973/221736879-13ebbca0-34d6-4424-b358-7c6a56a97737.png)

#### Button Mapping

| Button Title           | Callback Description                                                                                                                                                                                                                                                                                             |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Accept All             | Opts the user into all allowed purposes in current consent experience.                                                                                                                                                                                                                                           |
| Reject All             | Opts the user out of all allowed purposes in current consent experience. Essential is never opted out.                                                                                                                                                                                                           |
| More choices           | Redirects to the `CompleteOptions` view state. No purposes change.                                                                                                                                                                                                                                               |
| See our Privacy Policy | Redirects to the privacy policy link specified in [Consent Display Settings](https://app.transcend.io/consent-manager/display-settings) or the [`data-privacy-policy`](https://docs.transcend.io/docs/consent/faq#how-can-i-customize-the-privacy-policy-link-when-hosting-on-multiple-domains?) data attribute. |
",2023-02-28T02:17:39Z,2023-02-28T16:45:22Z,closed,2,"prevention of dark pattern design in software, compliance regulation, consent management UI, accept all, more choices, reject all","cookies, UI, modal, forced action","modal, cookie consent, forced action, regulation, avoid dark pattern","DPs prevention in software, DPs related regulation ",,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/element-hq/element-web/issues/23306,Cancelling the Element Home dialog yields two cancel buttons,https://github.com/element-hq/element-web/issues/23306,"### Steps to reproduce

1. In the home page, I click on my avatar
2. I click on ""Upgrade to Element Home""
3. I click on the arrow at the top right
4. I have a modal with two cancel buttons

<img width=""786"" alt=""Screenshot 2022-09-19 at 15 06 10"" src=""https://user-images.githubusercontent.com/2621378/191024075-3a1cb47c-38a4-46dc-a4cd-cedf19df029c.png"">


### Outcome

#### What did you expect?

I expect to have on cancel button

#### What happened instead?

I have two  cancel buttons


### Operating system

macOS

### Browser information

Chrome 105.0.5195.125 (Official Build) (arm64)

### URL for webapp

https://app.element.io/

### Application version

Version de Element : 1.11.5 Version de Olm : 3.2.12

### Homeserver

_No response_

### Will you send logs?

Yes",2022-09-19T13:09:26Z,2023-03-02T17:36:19Z,closed,3,"dark pattern design, avoid/prevention of dp in cancel buttons design","two cancel buttons, forced action, obstruction","UI/UX design, cancel button, obstruction, avoid dark pattern",DPs prevention in design,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/ker0olos/fable/issues/46,hourly pulls,https://github.com/ker0olos/fable/issues/46,"Changed in #62 

~~a fixed hourly quota of pulls, each player gets let's say *5* pulls an hour, and players get to keep all of the characters they pull. 
This a straight ripoff from mudae, though I highly doubt it was their own original idea, it's a very good spin on the typical energy bars you see in different ftp games, just tailored to fit gacha games and very effective at building a habit. 
Once a player finds a character, said character cannot be pulled by any other player on the server. Players cannot pull duplicated characters. 
It was decided during design that the timer won't be on a set interval but the timer only starts if and only if the player has 0 pulls, it's more of a dark pattern than mudae in which players are more pressured to come back exactly one hour each time or be behind other guild members since every second you have pulls in your account is a second you are not getting back.~~
",2023-01-27T16:57:57Z,2023-03-15T19:12:08Z,closed,0,"usage of dark pattern in game mechanics, fake urgency, zero pulls users have to return frequently ",,"gaming, fake urgency, deceptive design practice",DPs used in software,,,dark pattern or not,dark pattern or not,,,
https://api.github.com/repos/ProtonMail/proton-bridge/issues/255,Indicator applet UI is surprising on Gnome,https://github.com/ProtonMail/proton-bridge/issues/255,"Issue tracker is ONLY used for reporting bugs with technical details. ""It doesn't work"" or new features should be discussed with our customer support. Please use bug report function in Bridge or contact bridge@protonmail.ch.
<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
<!--- Tell us what should happen -->

A single click on applets in the indicator applet bar on Gnome should open a theme-consistent menu.

## Current Behavior
<!--- Tell us what happens instead of the expected behavior -->

A single click does nothing. A double click brings a theme inconsistent pane which is not really a menu, but which has an almost dark patterned menu button at the bottom right. This menu does not close when the outer pane is dismissed, remaining present when the applet indicator icon is double clicked again to open it.

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->

## Steps to Reproduce
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant -->

First issue:
1. Single click on the applet indicator icon in Gnome.
2. :cricket: 

Second issue:
1. Double click on the icon.
2. Click on the three dots at the bottom right of the pane.
3. Click away.
4. Double click on the applet indicator icon.

## Version Information
<!--- Which version of the app(s) were you using when you experienced this issue? -->

v2.1.0

## Context (Environment)
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

Ubuntu 18.0.4

## Detailed Description
<!--- Provide a detailed description of the change or addition you are proposing -->

## Possible Implementation
<!--- Not obligatory, but suggest an idea for implementing addition or change -->
",2022-02-04T01:45:01Z,2023-04-14T12:31:34Z,closed,5,"applet UI in Gnome, usage of dark pattern, dark patterned menu button design","Gnome, single click does not do desired behavior",,,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/tabler/tabler/issues/1468,new page: Cookie banner,https://github.com/tabler/tabler/pull/1468,"![Screenshot 2023-02-12 at 21 15 08](https://user-images.githubusercontent.com/1282324/218334824-b1f98c0a-abab-4571-84f6-3da26964648c.png)
",2023-02-12T20:15:37Z,2023-02-21T14:13:07Z,closed,6,"prevention of dark pattern in design, cookie consent buttons design","cookie consent, color design hierarchy, manipulation","cookie consent, design hierarchy, UI/UX design",DPs prevention in design,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/easylist/easylist/issues/12285,tweakers.net - cookiebar blocking prevents users from enabling 3rd-party embeds,https://github.com/easylist/easylist/issues/12285,"### List the website(s) you're having issues:
`https://tweakers.net/nieuws/197852/portal-achtige-puzzelgame-the-entropy-centre-komt-in-2022-uit.html`

### What happens?
When I click on 'Open cookievoorkeuren' nothing happens:
![image](https://user-images.githubusercontent.com/32640525/173234335-24a9c519-6875-4028-8fd3-0d14800459d3.png)

What **should** happen is that this should open the cookie-consent bar which will enable the user to give consent for embedding e.g. YouTube:
![image](https://user-images.githubusercontent.com/32640525/173234410-a3aea249-47bb-4ba0-946e-6e1f8e8b78ff.png)

### List Subscriptions you're using:
EasyList
Easylist Cookie List

### Your settings
- OS/version: Windows 7/10/11
- Browser/version: Firefox 101, Chrome 102
- Adblock Extension/version: AdblockPlus 3.14

### Other details:
The culprit is the recent addition of the following rule to the Easylist Cookie List in https://github.com/easylist/easylist/issues/12281:
`tweakers.net##.koekie_bar`

Now obviously I am a representative of the webite in question. I am mainly reporting this issue to raise awareness to the negative consequences that blocking cookie-consent bars have for users. We understand that these cookie-bars (and walls) can be an annoyance to users, but not only are they mandatory for websites because of EU-regulations (GDPR), they also give users the possibility to decide for themselves what they deem acceptable in terms of the trade-off between functionality (e.g. watching YouTube embeds) and privacy.

We are very proud to be able to say that our website is by default completely free of any third-party tracking, and our cookie-consent bar is - in our view - a prime example of an unbiased selection tool. We do hope that you understand that in this case you are taking away this choice from users without giving them any alternative option. This also often results in false bugreports adressed to us.",2022-06-12T13:16:58Z,2023-06-27T14:04:12Z,closed,9,"Tweakers, prevention of dark pattern in software, Easylist cookie, consent buttons design, no preselection","cookiebar, ""allow"" default, preselection","Tweakers, default, preselection, avoid dark pattern, cookie consent",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/alveusgg/alveusgg/issues/16,"Website: Cookie Consent, Privacy Policy, Terms etc.",https://github.com/alveusgg/alveusgg/issues/16,"# TODO

- Consent Manager => For GDPR
  - ~~use service? e.g. cookiebot~~ => costs $10+
  - implement ourselves:
    - [ ] ask for consent (UI), maybe use klaro?
       - List Purpose, Data processor (Name, Country, Privacy Policy)
       - Default to only necessary (opt-in)
       - No nudging/dark patterns
    - [ ] allow to revoke consent/edit choices (linked in footer and/or privacy policy page)
    - [ ] save consent ids
    - [ ] delay embeds (iframe/script)
    - [ ] allow per-use consent at the place of embedding if global consent was not given
- [ ] ~~Terms of Service ~~ =>  Probably do not need this with current scope.
- [x] Privacy Policy => Required for CCPA and GDPR
- [x] ~~Contact/Imprint => For US it seems to be optional, required for EU? ~~
- [ ] #176

# Requieres Consent

- [ ] Twitch embed
- [ ] Youtube embed
- [ ] Streamable embed
- [ ] The Giving Block embed

# ""Problematic"" areas

- Twitch embed -> Ask for consent, link Twitch Privacy Policy
- Session/Login (OAuth) -> Ask for consent, define storage (time, place, who has access) of user data etc., provide data rights (deletion, disclosure etc.), link Privacy Policies of auth providers
- Push Service-Worker registration (makes users identifyable)
- If used: OneSignal Push Provider -> has access to browser identification + unique user id (if provided)
- Analytics? (not implemented yet) -> Ask for consent, link Privacy Policy of provider
- YT embed (not implemented yet) -> Ask for consent, link YT Privacy Policy
- Hosting (Vercel - log files?) and, if used, the CDN
- unclear: What about the Push Services by the Browsers (FCM, Mozilla, Apple etc.)
- not problematic by design: Fonts self-hosted

# Laws

## Should comply with

- GDPR (Europe)

## Probably not required

- COPPA
- CCPA/CPRA (California), VCDPA (Virigina), CPA (Colorado), UCPA (Utah), CTDPA (Connecticut)  => Probably fine to ignore, as this is neither a for-profit business nor controlled by one, https://pro.bloomberglaw.com/brief/data-privacy-laws-in-the-u-s/ https://www.mmmlaw.com/media/connecticut-becomes-the-fifth-state-to-pass-data-privacy-act/
- New York SHIELD Act ""any person or business that owns or licenses private information of a New York resident""

- https://www.osano.com/articles/data-privacy-laws



",2022-12-14T01:48:19Z,2023-04-08T11:38:30Z,closed,6,"CCPA and GDPR required, regulation, prevention of dark pattern in design, cookie consent, privacy policy, terms, no nudging/dp","cookie consent, avoid nagging","cookie consent, CCPA, GDPR, regulation, privacy issue, avoid dark pattern",DPs prevention in design,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/SecOpsNews/news/issues/7249,"[BleepingComputer] Epic Games to pay $520 million for privacy violations, dark patterns",https://github.com/SecOpsNews/news/issues/7249,"

The Federal Trade Commission (FTC) says Epic Games, the maker of Fortnite, will pay $520 million to settle allegations of violating children's privacy laws and using dark patterns to trick millions of gamers into making unintentional in-game purchases. \[...\]



<https://www.bleepingcomputer.com/news/gaming/epic-games-to-pay-520-million-for-privacy-violations-dark-patterns/>

",2022-12-19T15:34:47Z,2022-12-20T16:04:13Z,closed,2,"law regulation, FTC (Federal Trade Commission), Fortnite, Epic game, usage of dark pattern in gaming, privacy violation, trick gamers to make unintentional in-game purchases","Epic Games, Fortnite, children making unintentional game purchase, manipulation, forced action","Epic Games, Fortnite, trick users to buy paid products, privacy issue, regulation, FTC","DPs used in software, DPs related regulation ",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tinymce/tinymce/issues/8582,Self-Hosted Non-Premium v6 integration RTC error,https://github.com/tinymce/tinymce/issues/8582,"`Uncaught (in promise) Error: Failed to get RTC instance not yet initialized.`

Seems in the process of attempting to vendor-lock with the CDN based implementations you've broken the library itself.

...

```
import tinymce from 'tinymce';

import 'tinymce/icons/default';

import 'tinymce/themes/silver';
import 'tinymce/models/dom';

import 'tinymce/skins/ui/oxide/skin.css';

import 'tinymce/plugins/advlist';
import 'tinymce/plugins/code'; // FIXME: Not picking up changes made in editor view? NOTE: Works again in v5
import 'tinymce/plugins/emoticons';
import 'tinymce/plugins/emoticons/js/emojis';
import 'tinymce/plugins/link';
import 'tinymce/plugins/lists';
import 'tinymce/plugins/table';

import contentUiSkinCss from 'tinymce/skins/ui/oxide/content.css';
import contentCss from 'tinymce/skins/content/default/content.css';
```


```
tinymce.init({
	selector: `#mg-wysiwyg-${this._uid}`,
	height: parseInt(this.height),
	readonly: this.disabled,
	//min_height: this.height,
	placeholder: this.placeholder,

	resize: 'both',

	menubar: false,
	plugins: ['advlist', 'code', 'emoticons', 'link', 'lists', 'table'],
	toolbar: 'undo redo | bold italic forecolor backcolor | bullist numlist checklist table | link emoticons | code',
	model: 'dom', // FIXME: Forcing ""dom"" because non-existant RTC ""Premium plugin"" getting in the way

	// Configuration required for local self-install
	skin: false,
	content_css: false,
	content_style: contentUiSkinCss.toString() + '\n' + contentCss.toString(),

	//promotion: false, // Oh yeah we really want adverts!

	// Bound to ""change keyup"" events as per https://github.com/tinymce/tinymce-vue/blob/b41c2a47eb8d9629eb01a41d6c6c633651f2d078/src/main/ts/Utils.ts#L115-L119
	init_instance_callback: editor => {
		editor.on('change keyup', e => {
			this.data = editor.getContent({ format: this.syntax })
		})
	},
});
```
",2023-03-23T01:33:31Z,2023-03-23T23:54:44Z,closed,6,"usage of dark pattern in software, lock users into vendor's Content Delivery Network (CDN), paid subscription ","vendor-lock, CDN, subscription, forced action","vendor-lock, CDN, paid subscription, forced action",DPs used in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/sugarlabs/www/issues/395,[Feature Request] Dark Mode Feature.,https://github.com/sugarlabs/www/issues/395,I think adding a dark mode in this web application is very important and necessary. I can work on this issue if anyone approves.,2023-02-23T11:08:47Z,2023-02-24T08:52:49Z,closed,4,miscellaneous (dark pattern ads),,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/cockroachdb/cockroach/issues/76437,clisqlshell: handle interactive query cancellation,https://github.com/cockroachdb/cockroach/pull/76437,"Fixes #76433. 

As of this PR, there's a bug in lib/pq which forces the session to
terminate when any query gets cancelled. We find this unacceptable
and we plan to fix it later.

Release note (cli change): The interactive SQL shell (`cockroach sql`,
`cockroach demo`) now supports interrupting a currently running
query with Ctrl+C, without losing access to the shell.",2022-02-11T16:14:55Z,2023-05-17T18:23:10Z,closed,14,not sure,"clisqlshell, hiding connection lost, sneaking","clisqlshell, hiding connection lost, sneaking",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/Automattic/jetpack/issues/29643,Add yoast promo in seo settings banner,https://github.com/Automattic/jetpack/pull/29643,"## Proposed changes:
<!--- Explain what functional changes your PR includes -->
* Modify the Banner component to support icons without circle design
* Add Yoast promo banner to SEO settings

### Other information:

- [ ] Have you written new tests for your changes, if applicable?
- [ ] Have you checked the E2E test CI results, and verified that your changes do not break them?
- [ ] Have you tested your changes on WordPress.com, if applicable (if so, you'll see a generated comment below with a script to run)?

## Jetpack product discussion
<!-- If you're an Automattician, include a shortlink to the p2 discussion with Jetpack Product here. -->
<!-- Make sure any changes to existing products have been discussed and agreed upon -->

## Does this pull request change what data or activity we track or use?
<!--- If so, please add the ""[Status] Needs Privacy Updates"" label and explain what changes there are. -->
<!--- Check existing Jetpack support documents for a preview of the information we need. -->

## Testing instructions:
<!-- If you were reviewing this PR, how would you like the instructions to be presented? -->
<!-- Please include detailed testing steps, explaining how to test your change. -->
<!-- Bear in mind that context you working on is not obvious for everyone.  -->
<!-- Adding ""simple"" configuration steps will help reviewers to get to your PR as quickly as possible. -->
<!-- ""Before / After"" screenshots can also be very helpful when the change is visual. -->

* Checkout this branch `add/yoast-promo-traffic-block`
* Run your docker env
* Go to `/wp-admin/admin.php?page=jetpack#/traffic`
* See that ""Search engine optimization"" block promotes Yoast Free:
<img width=""1071"" alt=""CleanShot 2023-03-22 at 18 57 16@2x"" src=""https://user-images.githubusercontent.com/8419292/227071749-17b6ddf3-4210-46ab-8de4-32a432d4e8ef.png"">

* Ensure CTA link is `https://yoa.st/yoast-jetpack-boost?domain=<your_site>`
* Go to ""/wp-admin/plugins.php"" and install (and activate) Yoast plugin
* Go to `/wp-admin/admin.php?page=jetpack#/traffic`
* See that ""Search engine optimization"" block promotes Yoast Premium:
<img width=""1057"" alt=""CleanShot 2023-03-22 at 18 58 21@2x"" src=""https://user-images.githubusercontent.com/8419292/227071831-cea5c18a-9bc9-4c56-96b8-17b66bb2b5df.png"">

* Ensure CTA link is `https://yoa.st/yoast-upgrade-jetpack-boost?domain=<your_site>`
* A12s - reach out to me to install Yoast Premium plugin
* Go to `/wp-admin/admin.php?page=jetpack#/traffic`
* The ad should not be displayed anymore

<img width=""1057"" alt=""CleanShot 2023-03-22 at 18 59 54@2x"" src=""https://user-images.githubusercontent.com/8419292/227072015-1570d0f1-8eba-4adc-92ae-cfc81a527f71.png"">

",2023-03-23T00:54:08Z,2023-03-27T17:46:48Z,closed,7,"Jetpack plugin, usage of dark pattern in open-source project, coerce users to spending money on paid version","promoting trialware, Jetpack","Jetpack, trick users to buy paid products",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/LiamANeeson/MSc-Game-Engine-Project-Website/issues/15,"Adding website, game engine and dark pattern game prototypes to remote repo",https://github.com/LiamANeeson/MSc-Game-Engine-Project-Website/pull/15,"I have added the following for discussion:

- Wireframes: website & HGE.
- Low-fidelity prototypes: website & HGE.
- Med-fidelity prototypes: website & HGE.

-Med-fidelity prototypes for UI explainer & API architecture.

I think the majority looks good except maybe some tweaks with UI explainer & API architecture.",2022-10-10T20:34:17Z,2022-11-28T11:44:08Z,closed,7,"usage of dark pattern in gaming (prototype), sneaking-into-basket, obstructions",game,"gaming, sneaking into basket, obstructions",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ethyca/fides/issues/2694,Auto-Generate config documentation,https://github.com/ethyca/fides/pull/2694,"Closes #2627 

### Code Changes

* [x] autogenerate the config file as valid `toml` that includes helpful metadata
* [x] add an assertion that there are no ""TODO"" descriptions
* [x] add a page for it in the docs
* [x] added a new `generate_docs` Nox session, included as part of the backend checks
* [x] make this the default file that gets output as part of `fides init`
* [x] copy relevant docs from the new site back here in preparation for removing config docs from the new site (will end up cross-linking)
* [x] overhaul how analytics consent requests work
  * [x] refactor the `check_and_update_analytics_config` function so that it doesn't check for a `none` value (since the default is now `true`, this is pointless)
  * [x] do not call the function from the main code-path, only call it from `fides init` or `fides deploy up`
  * [x] combine the logic for consent/writing default config/updating config values into a reusable function for `init` and `deploy up`
* [x] add a link to the config docs page at the top of the config file

### Steps to Confirm

* [ ] spin up the docs with `nox -s docs_serve` and visit the `configuration` page. Confirm the toml snippet is rendering properly
* [ ] Verbiage/accuracy check on the docstring updates
* [ ] go into an empty dir and run `fides init`, verify that the new config file is produced
* [ ] verify that the new config file can be used to configure a fides instance (make updates to it and run `fides view config` to verify the updates)
* [ ] verify the new `generat_docs` nox session and CI check

### Pre-Merge Checklist

* [ ] All CI Pipelines Succeeded
* Documentation:
  * [x] documentation complete, [PR opened in fidesdocs](https://github.com/ethyca/fidesdocs/pulls) - https://github.com/ethyca/fidesdocs/pull/66
  * [ ] documentation [issue created in fidesdocs](https://github.com/ethyca/fidesdocs/issues/new/choose)
* [x] Issue Requirements are Met
* [x] Relevant Follow-Up Issues Created
* [x] Update `CHANGELOG.md`

### Description Of Changes

This PR fundamentally changes how our ""default"" config file is produced and therefore also fundamentally changes `fides init`.

The new config file is built from the source code directly and includes with it all of the useful metadata we have as part of Pydantic and Pydantic `Field` objects. An important piece is that the generated config file is still valid `toml` and will be what the user interacts with directly when configuring their instance! *CI Checks will fail if a config value doesn't have a description, the description is blank, or it is ""TODO""*

Additionally, the new configuration file reference is built and hosted on the docs site, as a reference to users on older versions or who have been upgrading and used a past version of `fides init`. The new configuration docs will be cross-linked from the new docs site.

Note that as part of this change, how/when we collect user consent has changed. It is less intrusive now. It defaults to opt-out (no dark patterns here) but gives the option to opt-in upon `fides init` and will update the config file directly.

__Note__: **Given the lack of a `None` type in `toml`, `Optional` or empty values are no longer valid in the configuration file! If needed, you can set a default value and do a truthiness check. i.e. `"""" == False`, as does `[] == False`, so we need to leverage that type of check instead.**


#### Preview of new autogenerated config

```toml
# Fides Configuration File
# Additional Documentation at : https://ethyca.github.io/fides/stable/config/

#--------------#
#-- ADMIN_UI --#
#--------------------------------------------------------------------#
[admin_ui] # Configuration settings for the Admin UI.

# Toggle whether the Admin UI is served.
enabled = true # boolean

#---------#
#-- CLI --#
#--------------------------------------------------------------------#
[cli] # Configuration settings for the command-line appliation.

# A fully anonymized unique identifier that is automatically generated
# by the application. Used for anonymous analytics when opted-in.
analytics_id = ""951ddced878629858409539c4296ad8c"" # string

# When set to True, disables functionality that requires making calls
# to a Fides webserver.
local_mode = false # boolean

# The protocol used by the Fides webserver.
server_protocol = ""http"" # string

# The hostname of the Fides webserver.
server_host = ""localhost"" # string

# The port of the Fides webserver
server_port = ""8080"" # string

#--------------#
#-- DATABASE --#
#--------------------------------------------------------------------#
[database] # Configuration settings for the application database.

# Number of concurrent database connections Fides will use for API
# requests. Note that the pool begins with no connections, but as they
# are requested the connections are maintained and reused up to this
# limit.
api_engine_pool_size = 50 # integer
...
```
",2023-02-24T06:01:21Z,2023-03-01T14:50:48Z,closed,8,"prevention of dark pattern, user consent, default opt-out, opt-in option",default opt-out for consent,"consent, opt-in/out, default, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/yuezeng723/WatermelonDetector/issues/1,Add files via upload,https://github.com/yuezeng723/WatermelonDetector/pull/1,The algorithm that detects dark patterns on watermelon V1.0,2022-11-29T19:00:39Z,2022-11-29T19:07:32Z,closed,0,"watermelon V1.0, algorithm to detect DPs",detection tool,"watermelon V1.0, algorithm, detection",DPs detection Tools,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/124,Dka dark patterns,https://github.com/w3ctag/privacy-principles/pull/124,"I suggest removing the language about and definitions of dark patterns – not because this isn't good material but because we've actually moved away from this term in the EWP and because it's not mentioned anywhere else in the doc.


<!--
    This comment and the below content is programmatically generated.
    You may add a comma-separated list of anchors you'd like a
    direct link to below (e.g. #idl-serializers, #idl-sequence):

    Don't remove this comment or modify anything below this line.
    If you don't want a preview generated for this pull request,
    just replace the whole of this comment's content by ""no preview""
    and remove what's below.
-->
***
<a href=""https://pr-preview.s3.amazonaws.com/w3ctag/privacy-principles/pull/124.html"" title=""Last updated on Feb 9, 2022, 1:47 PM UTC (646cb16)"">Preview</a> | <a href=""https://pr-preview.s3.amazonaws.com/w3ctag/privacy-principles/124/ef51159...646cb16.html"" title=""Last updated on Feb 9, 2022, 1:47 PM UTC (646cb16)"">Diff</a>",2022-02-09T13:47:12Z,2022-09-06T15:47:45Z,closed,1,miscellaneous (remove DP-related definition in document),,,,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/hometown-fork/hometown/issues/1168,"Remove ""I don't like this"" from new report UI",https://github.com/hometown-fork/hometown/issues/1168,"### Pitch

The ""I don't like this"" selection doesn't do anything and is a dark pattern.

### Motivation

Mastodon/its forks are loved because moderation is human. Let's not take that out of it. Everyone benefits from removing this option, except for extra large instances like the flagship ones.",2022-05-09T06:04:18Z,2022-12-01T16:38:48Z,closed,3,"prevention of dark pattern in design, ""I don't like this"" selection in UI","""I don't like this"" button, emotional manipulation, nagging","avoid dark pattern, ""I don't like this"" button, UI/UX design",DPs prevention in design,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/BraindeadHermit/arkan/issues/18,Porting from Vite.js to Next.js?,https://github.com/BraindeadHermit/arkan/issues/18,would it be better to port the project to next.js to use serverless functions or take a host for the backend?,2022-12-06T07:37:50Z,2022-12-13T19:56:26Z,closed,1,"dark pattern detection in coding, detection algorithms, Vite.js, Next.js",,"coding, detection, algorithms, Vite.js, Next.js",DPs detection Tools,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/web-and-wine/orga/issues/28,Ask Hendrik if he wants to present his dark patterns talk @tresmo,https://github.com/web-and-wine/orga/issues/28,,2022-10-13T17:07:33Z,2022-10-19T12:43:07Z,closed,1,miscellaneous,,,,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/feinheit/feincms3-cookiecontrol/issues/25,no dark patterns,https://github.com/feinheit/feincms3-cookiecontrol/issues/25,"I fear we use ""dark patterns"" - stupid term - to nudge users to consent to the usage of tracking cookies. This might be a problem for GDPR compliance.

We need a third button ""accept only essential cookies"" or ""deny all"" with the same styling and level of ""accept all"".",2022-05-05T06:09:23Z,2022-08-19T18:25:13Z,closed,3,"gdpr compliance required, prevention of dark pattern in user consent of cookies tracking, buttons ""accept only essential cookies"" or ""deny all""","consent, nudge, example","GDPR, cookie consent, tracking, avoid dark pattern",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/yuwen-lu/dark-pita/issues/1,Merge facebook dark patterns,https://github.com/yuwen-lu/dark-pita/pull/1,"Added following dark patterns:
- people you may know
- sponsored content
- ""Suggested for you"" content
- Reels and short videos",2022-08-15T23:46:04Z,2022-08-15T23:48:50Z,closed,0,"usage of dark pattern (merge from Facebook), people you may know, sponsored content, ""Suggested for you"" content, Reels and short videos","Facebook, examples","Facebook, examples",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/njelich/LinkOff/issues/42,"Un-check by default ""Follow this employer"" when applying to job",https://github.com/njelich/LinkOff/issues/42,"**Is your feature request related to a problem? Please describe.**
Annoying that when you apply to a job and on the last page before clicking Submit there's ""Follow this employer"".   
As a result you ""catch"" all those follows and then later wonder why you have all these companies in your feed. Yes, LinkOff may remove them but still you become involuntary follower of a lot of companies this way.

**Describe the solution you'd like**
Have the box unchecked by default.

**Additional context**
![image](https://user-images.githubusercontent.com/329079/188001226-c7f30fc6-2414-41a0-a73f-4011f1ba379a.png)",2022-09-01T20:00:29Z,2022-12-02T14:37:27Z,closed,4,"LinkOff, usage of dark pattern in software, preselection, auto-check checkbox, checkbox to follow other users","autofollow default,uncheck needed, preselection","LinkOff, preselection, auto-check boxes",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/simtape/dark_pattern_research/issues/4,feat: api calls to dark pattern backend and created heuristics file,https://github.com/simtape/dark_pattern_research/pull/4,,2022-09-07T13:40:34Z,2022-09-07T14:34:43Z,closed,0,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/tijlleenders/ZinZen/issues/783,Change donation link,https://github.com/tijlleenders/ZinZen/issues/783,"Right now the donation link page goes to a GoFundMe.com page that relies on 'dark pattern' default of including a 15% tip by default (yes that's a lot). The idea is that you can choose to lower it - but if people want to support the platform I believe it should be a concious and explicit choice - not a default that a certain percentage of people will 'overlook'.

New URL should be: 
https://donate.stripe.com/6oE4jK1iPcPT1m89AA

I'v considered all other kinds of donation/payment providers but they are all either more expensive or have some barrier:
- GitHub Sponsors requires a GitHub account
- Buckaroo is cheaper so it would be a better choice but it is  unclear to me at the moment how to set up a simple payment link => will investigate
- Indiegogo
            5% of total
            2.9% + payment processor + 0.30€
- Kickstarter
            5% of total
            Per transaction:
                3% + Payment processing fees + $0.20 per pledge
                Pledges under $10: 5% + $0.05 per pledge
- App stores : 15-30%",2022-11-20T13:29:03Z,2022-11-20T19:26:06Z,closed,2,"ZinZen (a platform for planning your purpose), usage & prevention of dark pattern in software, preselection, donation link of 15% tip by default","default tip, GoFundMe, preselection","ZinZen, avoid dark pattern, preselection, default",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/skeletonlabs/skeleton/issues/385,Make it so dialog cannot be closed,https://github.com/skeletonlabs/skeleton/issues/385,"### Describe what feature you'd like. Pseudo-code, mockups, or screenshots of similar solutions are encouraged!

I have a use case whereby a user must fill out a prompt before they can continue or close the dialog box. At the moment the dialog box can be closed and there appears to be no option to only allow closing programmatically.

### What type of pull request would this be?

_No response_

### Any links to similar examples or other references we should review?

_No response_",2022-10-16T10:10:27Z,2023-01-05T08:32:33Z,closed,9,"Skeleton (open source UI toolkit), prevention of dark pattern in design","Modal, dialog cannot be closed, forced action, obstruction","Skeleton, modal, avoid dark pettern, forced action, obstruction",DPs prevention in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/cloudscape-design/components/issues/385,"ensure that openEnd and if and only 1 page, don't show ellipse",https://github.com/cloudscape-design/components/pull/385,"### Description

Dynamically loading in content, in combination with `openEnd` produces odd display of one page and ellipses `< 1 ... >`

This can happen when
* Page count whos base is great than the number of items loaded in.
  * ex: page count base is 15 (15 items per page) and only 14 items exist...  ...therefore, only 1 page
  * i have the `openEnd` flag and produces `<1 ... >`

One line change
`{rightDots && pagesCount > 1 && <li className={styles.dots}>...</li>}`

No change needed for `leftDots` case as you can't get to page 2 if page 1 doesn't exist

### Documentation changes

[*Do the changes include any API documentation changes?*]
- [ ] _Yes, this change contains documentation changes._
- [x] _No._

### Related Links

[*Attach any related links/pull request for this change*]


<details>
   <summary>Review checklist</summary>

_The following items are to be evaluated by the author(s) and the reviewer(s)._

#### Correctness

- [x] _Changes are backward-compatible if not indicated, see [`CONTRIBUTING.md`](CONTRIBUTING.md#public-apis)._
- [x] _Changes do not include unsupported browser features, see [`CONTRIBUTING.md`](CONTRIBUTING.md#browsers-support)._
- [x] _Changes were manually tested for accessibility, see [accessibility guidelines](https://cloudscape.design/foundation/core-principles/accessibility/)._

#### Security

- [x] _If the code handles URLs: all URLs are validated through [the `checkSafeUrl` function](https://github.com/cloudscape-design/components/blob/main/src/internal/utils/check-safe-url.ts)._

#### Testing

- [ ] _Changes are covered with new/existing unit tests?_
- [ ] _Changes are covered with new/existing integration tests?_
</details>

By submitting this pull request, I confirm that you can use, modify, copy, and redistribute this contribution, under the terms of your choice.
",2022-10-18T00:59:47Z,2022-10-19T20:51:55Z,closed,4,miscellaneous (avoid/prevention of dark pattern),,miscellaneous,miscellaneous,avoid/prevention of dark pattern,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/196,Create pull request for vulnerability content,https://github.com/w3ctag/privacy-principles/issues/196,"Here is the content for the pull request:

**Vulnerability**

An individual may not realise when they disclose personal data that they are vulnerable or could become vulnerable. Some individuals may be more vulnerable to privacy risks or harm as a result of collection, misuse, loss or theft of personal data because of their attributes, interests, opinions or behaviour. Others may be vulnerable because of the situation or setting (e.g., where there is information asymmetry or other power imbalances), or they lack the capacity to fully assess the risks, or because choices are not presented in an easy-to-understand meaningful way (e.g., dark patterns). Yet others may be vulnerable because they have not been consulted about their privacy needs and expectations, or considered in the decisions about the design of the product of service.

Sometimes communities of individuals are classed as “vulnerable”, typically children and the elderly, but anyone could be privacy vulnerable in a given context. Additional privacy protections may be needed for personal data of vulnerable individuals or sensitive information which could cause someone to become vulnerable if their personal data is collected, used or shared.

Even in populations of individuals classed as “vulnerable” (such as children), each individual is unique with their own desires and expectations for privacy. While sometimes others can help vulnerable individuals assess privacy risks and make decisions about privacy (such as parents, guardians and peers), everyone has their own right to privacy.

**Principle:** User agents and sites should allow for gracefully degraded user experience where some features or functionality may not be available because users have chosen stronger privacy protections (e.g., blocking tracking elements, sensor data or information about installed software or connected devices).",2022-11-18T18:34:47Z,2022-11-30T17:35:26Z,closed,0,"vulnerability contents, education, users' data privacy, lack of ability to assess the risks such as dark patterns, ","pull req, vulnerability, confusing way of portraying","vulnerability contents, privacy issue, dark pattern education",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/GeopJr/DNOME/issues/6,libadwaita version,https://github.com/GeopJr/DNOME/issues/6,"Hi, I don't really use Discord anymore but had some free time today so I started working on the libadwaita version.

I tried to make it look closer to Fractal which included not-just-recoloring (aka changed some paddings, heights, borders, margins, border-radius etc.)

(Additionally I removed more Nitro dark patterns (gift button next to text input, sparkles, shiny animation on buttons))

TODO:

- consistency between colors, padding, border-radius
- settings pages (switches, drop-downs, checkboxes)
- other components I didn't have the chance to test (new bot uis, voice chat, video chat, group chat...)
- clean DNOME - most css is no longer needed and it not really that easy to maintain

You can use it from the `dev` branch - I updated all the links to point to that.

I'm not really sure if I can continue maintaining DNOME after this. I don't use Discord much and the way theming works is too annoying to maintain - for those unaware, you have to use css wildcard selectors to target the elements you need while also being specific enough so it doesn't target others sharing the same class:

```less
div[class*=""chat-""] {
    main>form {
    }
    div[class*=""callContainer-""] {
    }
    >div[class*=""content-""] {
        div[class*=""divider-""] {
            &[class*=""isUnread-""] {
            }
        }
        >div[class*=""container-""] {
            >aside[class*=""membersWrap-""] {
                div[class*=""member-""] {
                    >div[class*=""layout-""] {
```

You have to use wildcard selectors because classes get a random suffix when they build their frontend (e.g. `layout-2yBXZl`).

Nested CSS makes maintaining it slightly easier but that's about it.

### Screenshots

![Screenshot of discord client with the DNOME theme applied - not really useful as alt text](https://user-images.githubusercontent.com/18014039/199425908-b9c866f1-4dc3-47af-b37f-ec7c59615c52.png)
![Screenshot of discord client with the DNOME theme applied - not really useful as alt text](https://user-images.githubusercontent.com/18014039/199425921-2412a945-2572-4ad0-a95e-ed6ba2171e49.png)

![Screenshot of discord client with the DNOME theme applied - not really useful as alt text](https://user-images.githubusercontent.com/18014039/199426898-42205ac4-cfd3-4254-9e2e-3ed043712304.png)
![Screenshot of discord client with the DNOME theme applied - not really useful as alt text](https://user-images.githubusercontent.com/18014039/199426904-1d215777-d4e2-4485-a9e2-d0c775802e5c.png)
",2022-11-02T07:52:34Z,2022-11-06T09:40:43Z,closed,2,prevention of Nitro dark patterns in software ,"Discord, libadwaita version, removing dp","Discord, libadwaita version, avoid dark pattern",DPs prevention in software,,,miscellaneous,miscellaneous,,,
https://api.github.com/repos/skeletonlabs/skeleton/issues/857,Polish Pass: Components & Actions,https://github.com/skeletonlabs/skeleton/issues/857,"Base on: https://github.com/skeletonlabs/skeleton/issues/782

The goal of this pass will be to improve, refine, and finalized all Svelte components and actions in Skeleton as we move closer to our release candidate status for the library.

- [x] Fix and address known issues and bugs
- [x] Improve the current styles, minimize code, better handling of edge cases
- [x] Expand with new features as relevant
- [x] Ensure form components play well with `use:enhance` forms
- [x] Move `SvgIcons` component from `/lib` to `/docs` to remove from the public library
- [x] Ensure Vitest test cases are passing
- [x] Implement type of `CssClasses` (or similar) to identify Tailwind style props for IntelliSense auto-suggestions.
- [x] Update the CLI template(s) per the new component updates

## Actions

### Clipboard

- [x] Minor documentation improvements.

### Filters

- [x] Minor code refactor for filter action
- [x] BREAKING: the filter action now requires `#` (ex: `""#Apollo""`)
- [x] Documentation improvements
- [x] ""How it Works"" section added
- [x] Interactive examples - can switch images

### Focus Trap

- [x] Code snippets improved on the doc page
- [x] Documentation added explaining how it works
- [x] Documentation expanded to cover Modal/Drawers

## Components

### Accordions

- [x] Rename `AccordionGroup` component to `Accordion` for library consistency
- [x] Refactored to drop Disclosure elements in favor of accessible markup
- [x] Enable slide open/close animations for accordion contents
- [x] Allow the Item open state behavior to be controlled with the `autocollapse` property
- [x] Improve documentation and examples

### App Bar

- [x] BREAKING: renamed prop `space` to `spacing` for library consistency
- [x] Refactor slots and props to allow for more configurations
- [x] Introduce a new and optional ""headline"" row
- [x] The design has been updated to be less opinionated by default
- [x] Main/top row is now grid-based, rather than using flexbox
- [x] Update documentation to show a variety of preset configurations

> NOTE: want the old shadow effect? Use `shadow=""shadow-lg""`

### App Rail

- [x] Added a new `border` prop on the AppRail
- [x] Improved documentation in regards to anchor tiles
- [x] Documented the process of setting the active state

### App Shell

- [x] The `#page` region now reports the vertical scroll position via the `on:scroll` event.
- [x] Provided better visualization of the scrollable portion of the App Shell
- [x] Added a new `regionPage` prop for adding classes to the scrollable `#page` region 
- [x] Document how to setup a sticky `pageHeader` slot
- [x] Linked to responsive sidebar/drawer tutorial

### Avatars

- [x] Documented techniques to add interactive borders
- [x] Provided support for `style` attribute, this allows Skeleton filters via CSS

> NOTE: investigated the bug for off center initials ([reference](https://user-images.githubusercontent.com/85238383/213514129-02b607a1-ea43-453e-aba0-79c16ba6fe70.png)). Unfortunately I cannot pin down a fix. Per the settings provided this the SVG text SHOULD be centered. Could be a browser issue?

### Conic Gradients

- [x] Stops are now reactive and will update as the values change
- [x] Greatly improved the documentation, added new usage techniques
- [x] Added props for `regionCaption|Cone|Legend` to apply arbitrary region classes

### File Buttons

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] The design has been updated to be less opinionated by default
- [x] Documentation has been expanded

### File Dropzone

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] Improved the code, added more config options, easier to style
- [x] Redesigned the UI to be more visually appealling
- [x] The `disabled` attribute now has a visual affect on the input
- [x] Documentation has been expanded

### Input Chips

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] Embeds a native `<select>` input to provide better support for native forms
- [x] UI redesign from the ground up, including animations
- [x] Supports disabled state, per ([#824](https://github.com/skeletonlabs/skeleton/issues/824))
- [x] Provide a `max` prop to limit the maximum chips allowed
- [x] Provide `minlength` and `maxlength` props to control input character length

### Listboxes

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] By default uses `radio` inputs for single selection
- [x] Apply the `multiple` prop to convert this to a `checkbox` input
- [x] Update the custom modal example using a Listbox

> NOTE: tested replacing with native select[size/multiple], but Safari support just isn't there yet.

### Paginators

- [x] Minor improvements to documentation and the example
- [x] Updated `$: page` -> `let page` in docs to prevent server-side pagination rubber banding bug

> NOTE: we may revisit this component when we return to data tables

### Progress Bars

- [x] BREAKING: Replace `label` with `labelledby`, we recommend a wrapping `<label>` as needed
- [x] Minor refactor to the component logic and template
- [x] The design has been updated to be less opinionated by default

> NOTE: Documented native alternative, added native progress bar styles to `forms.css`

### Progress Radials

- [x] BREAKING: Replace `label` with `labelledby`, we recommend a wrapping `<label>` as needed
- [x] The design has been updated to be less opinionated by default
- [x] Improved documentation and examples

### Radio Groups

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] BREAKING: `borderSize/borderWidth` combined into singular `border` prop for library consistency. 
- [x] This component is now a wrapper around a native radio checkbox input.
- [x] Renamed `accent` prop to `active` for library consistency
- [x] The design has been updated to be less opinionated by default
- [x] Supports disabled state, per ([#824](https://github.com/skeletonlabs/skeleton/issues/824))

### Range Sliders

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] Minor refactor and code adjustments
- [x] Improved documentation and examples
- [x] Documented current browser support (Safari not fully supported)

### Slide Toggles

- [x] BREAKING: The `name` property is now required to support Svelte's native form submission.
- [x] BREAKING: the `accent` property renamed to `active` for library consistency 
- [x] BREAKING: `borderSize/borderWidth` combined into singular `border` prop for library consistency. 
- [x] The design has been updated to be less opinionated by default
- [x] The `class` attribute is now correctly implemented on the parent element
- [x] Improved documentation and examples

> Note: we investigated switching to styled native input[checkbox] elements ([ala Daisy](https://daisyui.com/components/toggle/)), but found the a11y story lacking.

### Steppers

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] Features a new horizontal layout by (EXTREMELY) popular demand!
- [x] Most properties have been updated or modified.
- [x] Allows for all English wording to be overwritten (ex: button labels, ""Step"", etc)

> NOTE: No plans to support a vertical version at this time.

### Tabs

> **Warning** BREAKING: This component has been completely rebuilt from the ground up.

- [x] Now includes an optional ""panel"" slot to improve a11y, per ([#516](https://github.com/skeletonlabs/skeleton/issues/516))
- [x] Minor redesign with updated props, events, and settings
- [x] Icon position is now above the text label
- [x] Improved documentation and examples

> NOTE: can be used in place of a bottom navigation bar when customized. See the doc example.

### Tables

- [x] Reviewed a means to fix overlays (ex: tooltips) being clipped - NOTE: won't fix, see below
- [x] Minor documentation improvements

> NOTE: per the clipping issue, this is due to the wrapping `.table-container` using `overflow-x-auto` and `.table` using `.overflow-hidden`. These are required styles, so unfortunately I'm going to have to advise against using overlays within tables for now. This is generally bad UX, so please avoid it.

### Table of Contents

- [x] Added `spacing` prop to set vertical spacing between rows
- [x] Added a note pointing to the example on the docs for desktop users.",2023-01-19T22:16:49Z,2023-02-06T21:53:54Z,closed,10,"Skeleton (open source UI toolkit), prevention of dark pattern in design","Polish Pass, modal difficult to close, obstruction","Skeleton, Polish Pass, modal, obstruction, avod dark pattern",DPs prevention in design,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/BetterDiscord/BetterDiscord/issues/1392,Malicious plugin author action support request.,https://github.com/BetterDiscord/BetterDiscord/issues/1392,"Earlier today one of the plugins installed in my Better Discord forcibly and permanently disabled all its functionality and replaced itself with a message containing a dark pattern seemingly designed to manipulate users into deleting the file.

There was no prior indication or confirmation of these actions and as of now I am unable to restore the plugin to its previous state as all the code has been replaced.

The plugin in question is Show Hidden Channels by DevilBro.

The plugin was installed via the official Better Discord website. However, I understand that recently the plugin has had support dropped due to updated guidelines. Nonetheless it is clearly unacceptable to delete files from users computers without their consent and attempt to manipulate them with dark patterns.

As such I am inquiring how to raise this issue further so that action can be taken regarding these clearly malicious actions as per the code of conduct mentioned in the [CONTRIBUTING](https://github.com/BetterDiscord/BetterDiscord/blob/main/CONTRIBUTING.md) readme as well as the new updated guidelines themselves. Which I feel this plugin author has clearly went against both of.

I apologize if this is the wrong place to raise such an issue. I initially inquired on the Better Discord server and was eventually directed  here after being rudely dismissed and having to explain why such a thing was even a concern.

I also now understand after some reading that there has been some degree of friction in the Better Discord community on either side of this issue regarding the plugins removal. Despite that it is my hope that these concerns can still be addressed with civility here as opposed to the responses to the support request on the Better Discord server.",2022-09-06T05:27:05Z,2022-10-12T19:45:21Z,closed,23,"BetterDiscord (an extension of Discord), violate security issues, usage of dark pattern in software, Show Hidden Channel plugin (coerce users into deleting it without their consent)","Better Discord, delete files without consent, manipulation","BetterDiscord, privacy issue, forced action",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/bottlesdevs/website/issues/30,Remove dark pattern,https://github.com/bottlesdevs/website/pull/30,"Closes https://github.com/bottlesdevs/website/issues/22.

![image](https://user-images.githubusercontent.com/50847364/175441270-39644b1e-e060-4db4-b73b-bffbf3c7db11.png)

/cc @Doomsdayrs",2022-06-24T01:25:16Z,2022-06-24T09:51:54Z,closed,0,"Mastodon, prevention of dark patterns in software, cookie consent ","cookies for better experience of the website, emotional manipulation","Mastodon, avoid dark pattern, cookie consent ",DPs prevention in software,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/certbot/certbot/issues/9462,Remove misleading prompt that shares alerting email with the EFF.,https://github.com/certbot/certbot/issues/9462,"## My operating system is (include version):

Ubuntu 20.04

## I installed Certbot with (snap, OS package manager, pip, certbot-auto, etc):

snap

## I ran this command and it produced this output:

```
sudo certbot --nginx
```

Output in relevant part:

```
Enter email address (used for urgent renewal and security notices)
(Enter ""c' to cancel) : [my email]
```

```
Would you be willing, once your first certificate is successfully issued, to
share your email address with the Electronic Frontier Foundation, a founding
partner of the Let's Encrypt project and the non-profit organization that
develops Certbot? We'd like to send you email about our work encrypting the web
EFF news, campaigns, and ways to support digital freedom.
```

## Certbot's behavior differed from what I expected because:

**Observed Behavior**
The email I provided for ""urgent renewal and security notices"" *pages my team when emailed* is not ""my"" email. The alerting email was subscribed to an EFF mailing list. This woke me up the first time it went off. 

**Expected Behavior**
I expected the script to ask for my email address since that's what I'd consented to. I did not expect or intend to give ISRG permission to share my paging email with the EFF.

**Comments**
Frankly, I didn't want to sign up for the mailing list. I was answering ""yes"" in the middle of an incident triggered by an expired cert, was basically doing the human equivalent of `yes Y |`. I imagine this isn't that uncommon a situation among certbot users. 

I trust the ISRG and the EFF wouldn't intentionally build a consent-grabbing dark pattern.",2022-11-12T08:22:21Z,2022-11-17T22:31:27Z,closed,5,"Certbot, dark pattern or not, misleading prompt to trick users to share elart email with EFF, yes | Y",possible dp for consent taking,"Certbot, misleading, dark pattern or not, prompt",DPs or not,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/eliben/go-sudoku/issues/1,Use semantic markup for the checkbox label,https://github.com/eliben/go-sudoku/pull/1,"Checkbox labels that don't interact with the checkbox are a pet peeve, so I just had to fix it. It's also a popular dark pattern when the presenter doesn't want you to toggle the checkbox (e.g. turning off telemetry in Edge, etc.).",2022-09-05T14:48:44Z,2022-09-05T16:07:53Z,closed,0,"go-sudoku (toolkit to help solve sudoku puzzle), prevention of dark pattern, checkbox label","semantic markup, checkbox","go-sudoku, checkbox, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/bottlesdevs/website/issues/22,Remove dark pattern,https://github.com/bottlesdevs/website/issues/22,"@Doomsdayrs reported on Mastodon that there is some dark pattern in the website for accepting cookies:
![image](https://user-images.githubusercontent.com/50847364/172732804-37cd79ce-f449-45a8-a6f0-429ae112baed.png)

I suggest to remove that dark pattern.",2022-06-08T23:15:47Z,2022-06-24T08:55:59Z,closed,0,"Mastodon, prevention of dark patterns in software, cookie consent ","cookies for better experience of the website, emotional manipulation","Mastodon, avoid dark pattern, cookie consent ",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/plone/plone.org/issues/13,Cookie banner improvements and fixes,https://github.com/plone/plone.org/issues/13,"The cookie banner in the https://beta.plone.org site could use some work. 

<img width=""1792"" alt=""Screenshot 2022-11-11 at 19 12 12"" src=""https://user-images.githubusercontent.com/5127672/201393636-a09354da-693c-43f9-bac8-0ebe807258f1.png"">


- Bug: the X close button the right corner always mimimizes user choises to only functional cookies
- Improvement: It is not generally goo to emphasize Accept all -button. Better to emphasize ""only necessary"" or ""save my preferences""
- Feature: need to add/change Google Analytics to Matomo - since we use that to analytics. However, if/when we use YouTube embeds (for Plone 6 screencasts or other), we need to allow Google advertisement cookies. 
- Improvement: Make the cookie button less obtrusive on the mobile view? Put it to footer maybe? This is just nice to have. 
- Bug: Fix cookie banner contrast issues (image below, tested with Wave toolbar): 

![Uploading Screenshot 2022-11-11 at 19.12.00.png…]()

 

",2022-11-11T17:13:39Z,2022-12-12T13:07:30Z,closed,2,"plone.org, prevention of dark pattern in software, cookie consent UI design, color psychology on the ""accept all"" button to trick user ","cookie banner acceptance, design hierarchy, manipulation","plone.org, cookie concent, avoid dark pattern, design hierarchy, UI/UX design",DPs prevention in design,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/microsoft/terminal/issues/13955,Windows Terminal crashing on exit when settings.json is corrupted,https://github.com/microsoft/terminal/issues/13955,"### Windows Terminal version

1.14.2281.0

### Windows build number

10.0.19044.1949

### Other Software

_No response_

### Steps to reproduce

If there is an error in `settings.json` Windows Terminal will report it on startup:

![image](https://user-images.githubusercontent.com/16415478/189353671-ea5c28df-c1e7-48ae-aeab-3d38c25c0786.png)

Dismissing the error dialog by clicking the OK button, and then closing the application by any means (clicking `[X]` in the top right corner or pressing `Alt-F4`) leads to Just-In-Time debugger being launched (or a crash if you don't have Visual Studio or another debugger installed).

**Exception details:**
```
Unhandled exception at 0x00007FFBE890EE0E (Windows.UI.Xaml.dll) in WindowsTerminal.exe: 0xC0000005: Access violation reading location 0x0000000000000130.
```
**Call stack:**
```
 	[Inline Frame] Windows.UI.Xaml.dll!DirectUI::DXamlCore::GetWindow() Line 278	C++
 	Windows.UI.Xaml.dll!DirectUI::ContentDialog::DetachEventHandlersForOpenDialog() Line 2507	C++
 	Windows.UI.Xaml.dll!DirectUI::ContentDialog::~ContentDialog() Line 74	C++
 	Windows.UI.Xaml.dll!ctl::ComObject<DirectUI::ContentDialog>::`scalar deleting destructor'(unsigned int)	C++
 	Windows.UI.Xaml.dll!ctl::ComBase::ReleaseImpl() Line 307	C++
 	[Inline Frame] TerminalApp.dll!winrt::Windows::Foundation::IUnknown::release_ref() Line 2140	C++
 	[Inline Frame] TerminalApp.dll!winrt::Windows::Foundation::IUnknown::{dtor}() Line 2045	C++
>	TerminalApp.dll!winrt::TerminalApp::implementation::AppLogic::~AppLogic() Line 57	C++
 	TerminalApp.dll!winrt::TerminalApp::implementation::AppLogic::`scalar deleting destructor'(unsigned int)	C++
 	TerminalApp.dll!winrt::implements<winrt::TerminalApp::implementation::AppLogic,winrt::TerminalApp::AppLogic,winrt::TerminalApp::IDirectKeyListener,winrt::TerminalApp::IDialogPresenter,IInitializeWithWindow>::Release() Line 7859	C++
 	ucrtbase.dll!<lambda>(void)()	Unknown
 	ucrtbase.dll!__crt_seh_guarded_call<int>::operator()<<lambda_7777bce6b2f8c936911f934f8298dc43>,<lambda>(void) &,<lambda_3883c3dff614d5e0c5f61bb1ac94921c>>()	Unknown
 	ucrtbase.dll!_execute_onexit_table()	Unknown
 	TerminalApp.dll!dllmain_crt_process_detach(const bool is_terminating) Line 182	C++
 	TerminalApp.dll!dllmain_dispatch(HINSTANCE__ * const instance, const unsigned long reason, void * const reserved) Line 293	C++
 	ntdll.dll!LdrpCallInitRoutine()	Unknown
 	ntdll.dll!LdrShutdownProcess()	Unknown
 	ntdll.dll!RtlExitUserProcess()	Unknown
 	kernel32.dll!ExitProcessImplementation()	Unknown
 	ucrtbase.dll!exit_or_terminate_process()	Unknown
 	ucrtbase.dll!common_exit()	Unknown
 	WindowsTerminal.exe!__scrt_common_main_seh() Line 295	C++
 	kernel32.dll!BaseThreadInitThunk()	Unknown
 	ntdll.dll!RtlUserThreadStart()	Unknown
```
Offending `settings.json` is attached.

I also have a minidump taken with:
```
procdump.exe -ma -e -x C:\winterm Microsoft.WindowsTerminal_1.14.2281.0_x64__8wekyb3d8bbwe
```
If there is any way to share it without being publicly visible please let me know, I have it ready for upload.

[settings.zip](https://github.com/microsoft/terminal/files/9535731/settings.zip)


### Expected Behavior

Application should not crash on exit when `settings.json` is corrupted.

### Actual Behavior

Application crashes on exit when `settings.json` is corrupted.",2022-09-09T13:34:11Z,2023-01-10T18:20:55Z,closed,17,"miscellaneous (Windows 10, Microsoft Edge, deceptive UI designs to drive user behavior towards monetization and unwanted advertising, paying Window liscense)","Win10, Microsoft Edge, ads, monetizing features, examples","Windows 10, Microsoft Edge, ads, trick users to buy paid products, examples",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/motis-project/ridesharing-flutter/issues/40,Profile page,https://github.com/motis-project/ridesharing-flutter/pull/40,"co-authored by @Eddie-42 
description written by @Eddie-42 

Hey guys :) We have some little changes (like 1700) for you :))

First and foremost, the **profile page**! This page shows all information we have about profiles, and if you visit your own page, you can edit everything except your email. 

* We are especially proud of how you can edit your profile features, which is a neat solution to the ordering problem in cards. Note how you can't select two mutually exclusive features, such as _smoking_ and _no smoking_.
* You can upload profile pictures from your gallery. In order to do this, we have a new library: ImagePicker. Therefore, for iOS, this PR includes some files that are needed for permission handling.
* If you click on the avatar, it shows it bigger on a separate screen, as you would expect.
* If you are viewing a profile other than yourself, you can report it while giving a reason. This is stored in the database (please also review the supabase table and RLS policies. Users should only be permitted to insert and read their own reports!), and you cannot review the same person again for 3 days.

Also, a few refactorings, nothing big. I sincerely urge you to completely disregard how we noticed only now that the title of the ride detail page was translated completely incorrectly. You didn't see that right?

A11y and l10n are coming, but please review the PR already. You can trust us that we aren't going to mess up translations, right?

",2023-01-05T23:10:16Z,2023-01-11T08:02:30Z,closed,25,"miscellaneous (profile page UI design, usage of dark pattern in software, same as ""try-to-delete-an-account-on-Amazon-dark-pattern"")","log-in/log-out, sneaking","log-in/logout, UI/UX design, sneaking",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/SecOpsNews/news/issues/8975,[DataBreaches] FTC Enforcement Action to Bar GoodRx from Sharing Consumers’ Sensitive Health Info for Advertising,https://github.com/SecOpsNews/news/issues/8975,"

The Federal Trade Commission has taken enforcement action for the first time under its Health Breach Notification Rule against the telehealth and prescription drug discount provider GoodRx Holdings Inc., for failing to notify consumers and others of its unauthorized disclosures of consumers’ personal health information to Facebook, Google, and other companies. In a first-of-its-kind proposed order, filed by the Department of Justice on behalf of the FTC, GoodRx will be prohibited from sharing user health data with applicable third parties for advertising purposes, and has agreed to pay a $1.5 million civil penalty for violating the rule. The proposed order must be approved by the federal court to go into effect. “Digital health companies and mobile apps should not cash in on consumers’ extremely sensitive and personally identifiable health information,” said Samuel Levine, Director of the FTC’s Bureau of Consumer Protection. “The FTC is serving notice that it will use all of its legal authority to protect American consumers’ sensitive data from misuse and illegal exploitation.” California-based GoodRx operates a digital health platform that offers prescription drug discounts, telehealth visits, and other health services. The company collects personal and health information about its users, including information from users themselves and from pharmacy benefit managers confirming when a consumer purchases a medication using a GoodRx coupon. Since January 2017, more than 55 million consumers have visited or used GoodRx’s website or mobile apps. According to the FTC’s complaint, GoodRx violated the FTC Act by sharing sensitive personal health information for years with advertising companies and platforms—contrary to its privacy promises—and failed to report these unauthorized disclosures as required by the Health Breach Notification Rule. Specifically, the FTC said GoodRx: Shared Personal Health Information with Facebook, Google, Criteo, and Others: Since at least 2017, GoodRx deceptively promised its users that it would never share personal health information with advertisers or other third parties. GoodRx repeatedly violated this promise by sharing sensitive personal health information—including its users’ prescription medications and personal health conditions—with third party advertising companies and advertising platforms like Facebook, Google, and Criteo, and other third parties like Branch and Twilio. Used Personal Health Information to Target its Users with Ads: GoodRx monetized its users’ personal health information, and used data it shared with Facebook to target GoodRx’s own users with personalized health- and medication-specific advertisements on Facebook and Instagram. For example, in August 2019, GoodRx compiled lists of its users who had purchased particular medications such as those used to treat heart disease and blood pressure, and uploaded their email addresses, phone numbers, and mobile advertising IDs to Facebook so it could identify their profiles. GoodRx then used that information to target these users with health-related advertisements. Failed to Limit Third-Party Use of Personal Health Information: GoodRx allowed third parties it shared data with to use that information for their own internal purposes, including for research and development or to improve advertising. It also falsely claimed that it complied with the Digital Advertising Alliance principles, which require companies to get consent before using health information for advertising. Misrepresented its HIPAA Compliance: GoodRx displayed a seal at the bottom of its telehealth services homepage falsely suggesting to consumers that it complied with the Health Insurance Portability and Accountability Act of 1996 (HIPAA), a law that sets forth privacy and information security protections for health data. Failed to Implement Policies to Protect Personal Health Information: GoodRx failed to maintain sufficient policies or procedures to protect its users’ personal health information. Until a consumer watchdog publicly revealed GoodRx’s actions in February 2020, GoodRx had no sufficient formal, written, or standard privacy or data sharing policies or compliance programs in place. Health Breach Notification Rule Violation According to the FTC complaint, as a vendor of personal health records, GoodRx is subject to the Health Breach Notification Rule. GoodRx lets users keep track of their personal health information, including to save, track, and receive alerts about their prescriptions, refills, pricing, and medication purchase history. GoodRx violated the Health Breach Notification Rule by failing to notify consumers, the FTC, and the media about the company’s unauthorized disclosure of individually identifiable health information to Facebook, Google, Criteo, Branch, and Twilio. The FTC issued a policy statement in September 2021 warning health apps and others that collect or use consumers’ health information that they must comply with the Health Breach Notification Rule. More information on compliance and reporting breaches under the Health Breach Notification Rule are available at the FTC’s Health Privacy page. Proposed Order In addition to the $1.5 million penalty for violating the rule, the proposed federal court order also prohibits GoodRx from engaging in the deceptive practices outlined in the complaint and requires the company to comply with the Health Breach Notification Rule. To remedy the FTC’s numerous allegations, other provisions of the proposed order against GoodRx also: Prohibit the sharing of health data for ads: GoodRx will be permanently prohibited from disclosing user health information with applicable third parties for advertising purposes. Require user consent for any other sharing: The company must obtain users’ affirmative express consent before disclosing user health information with applicable third parties for other purposes. The order requires the company to clearly and conspicuously detail the categories of health information that it will disclose to third parties and prohibits the company from using manipulative designs, known as dark patterns, to obtain users’ consent to share the information. Require company to seek deletion of data: The company must direct third parties to delete the consumer health data that was shared with them and inform consumers about the breaches and the FTC’s enforcement action against the company. Limit Retention of Data: GoodRx will be required to limit how long it can retain personal and health information according to a data retention schedule. It also must publicly post a retention schedule, and detail the information it collects and why such data collection is necessary. Implement Mandated Privacy Program: It must put in place a comprehensive privacy program that includes strong safeguards to protect consumer data. The Commission voted 4-0 to refer the complaint and stipulated final order to the Department of Justice for filing. Commissioner Christine S. Wilson issued a concurring statement. \[…\]



<https://www.databreaches.net/ftc-enforcement-action-to-bar-goodrx-from-sharing-consumers-sensitive-health-info-for-advertising/>

",2023-02-01T18:48:35Z,2023-02-02T19:03:35Z,closed,2,"Federal Trade Commission (FTC) regulation, ban GoodRx for sharing consumers’ sensitive health data for advertising, data breaches","FTC Enforcement Action, avoiding dp","FTC, data collection, privacy issue, avoid dark pattern",DPs prevention in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Mailu/Mailu/issues/2770,Disable HaveIBeenPwned,https://github.com/Mailu/Mailu/issues/2770,"Hi all

**congrats for the new release!** Haven't tried yet, but I need to mention this. (You knew this would be coming.)

I absolutely do not want our Mailu to make ANY network requests that are not explicitly user/admin-generated. rspamd is already questionable, but let's ignore that for now.

- Passwords should absolutely **never be sent anywhere**, not hashed, not partly, not at all.
- It generates **metadata** about server usage. That's no one's business.
- It generates metadata about passwords even if hashed.
- Passwords are solely the **user's responsibility**.
- **Nobody should ever force the user.** Sometimes you want a test account, sometimes it simply doesn't matter, sometimes you bring out a 128 char pass and go hard. User choice.
- It uses a **centralized service** which is exactly what Mailu has been made for avoiding.
- It uses it for no reason, unlike rspamd list updates, there's **no benefit** here. The user who would pick a super weak password will just use the next shitty 'cloud' password manager, use 'save password' browser features, or **hurt himself in a million other ways**. If you ever had the misfortune of working in corporate, you know people come up with just about anything to avoid forced pass changes or similar. The imagined 'benefit' quickly turns into a negative. I knew billion dollar institutions where almost everyone routinely incremented or added a known date or something else that turns it into a sham.
- Adding it just because some silly RFC etc. suggests so is pointless.
- The **ratelimiter is a lot more valuable** than any password list. Even, if a user picks some top 1000 pass, with ratelimiting it doesn't really matter all that much. Don't know how the code works now, but e.g. something exponentially escalating defeats virtually every attempt. It doesn't even have to be exponential. Going from 0 to 5 seconds to 10, 15 up to 5mins max is already more than enough to stop any attacker from ever having a realistic chance. Brute force bots are not going to waste resources like that. (An emergency override is always needed, in case of CGNAT/auto-retry/user error.)
- Notifying a user about a password breach is the **user's choice**. _If he wants that, he can go to that website, sign up, and leak his own metadata._ That's **not the task of an insular mail stack**.
- We're not google and **we don't trade privacy for an imaginary security benefit** that is even weak in an ideal scenario. Dedicating the resources to get past the ratelimiter + working an enormous list = extremely unlikely. It's far easier to just lie to the user or have him click 'yes' on TOS.
- **Instead of assuming our users are idiots, we teach them.** If you took the time to set up mailu, you can spend a minute to teach a complete newbie some basics and suggest password strategies.

I can't see any config option for this.

Thank you for reading!",2023-04-12T19:09:29Z,2023-04-21T19:28:39Z,closed,9,not sure,"opt-in/opt-out, avoiding dp suggestions, examples","opt-in/out, avoid dark patterns, examples",DPs prevention in design,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/sourcegraph/sourcegraph/issues/34688,Fix CTA banner late rendering and sliding down other content,https://github.com/sourcegraph/sourcegraph/issues/34688,https://sourcegraph.slack.com/archives/C03B4EMBXL4/p1651153966869059,2022-04-29T08:53:49Z,2022-09-19T05:14:02Z,closed,4,not sure,"CTA banner sliding issue, obstruction","CTA banner sliding issue, obstruction, UI/UX design",DPs examples/definitions,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/freeCodeCamp/freeCodeCamp/issues/48385,feat(client): add a confirmation modal on signout,https://github.com/freeCodeCamp/freeCodeCamp/pull/48385,"Adds a confimation modal when a user signs out from the web client.

Ref #46623

",2022-11-03T21:23:02Z,2022-11-04T09:31:54Z,closed,7,"freeCodeCamp, prevention of dark pattern in software, no double-comfirmation of sign-out","confirmation for logging out, modal, confirm shaming","freeCodeCamp, sign-out, double confirmation, avoid dark pattern",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/flutter/website/issues/7364,[PAGE ISSUE]: Flutter authored 'Creating flavors for Flutter',https://github.com/flutter/website/issues/7364,"### Page URL

https://docs.flutter.dev/deployment/flavors/

### Page source

https://github.com/flutter/website/tree/main/src/deployment/flavors.md

### Describe the problem

Important documentation should be accessible on the [flutter.dev](flutter.dev) website, not on third party sites that might change or break without notice. Especially not on a dark pattern ridden piece of ...Hell that is medium.com.

### Expected fix

Host all relevant documentation on flutter.dev

### Additional context

medium.com started of as a free publishing platform and has since pulled a bait-and-switch and it's now paywalled.",2022-07-14T10:55:13Z,2022-08-12T12:11:45Z,closed,1,"Medium.com, usage of dark pattern in software, pop-ups, subscription prompts, content blockers, visual interference","documentation on third party websites, obstruction, interface interference","Medium.com, interface interference, pop-up, prompt",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/nelsonic/nelsonic.github.io/issues/862,Best Value-for-money Mobile Network [Data Plan] in PT 🇵🇹,https://github.com/nelsonic/nelsonic.github.io/issues/862,"## Context

Due to BREXIT I'm unable to use my UK mobile number in PT longer term. 🤦‍♂️ 

## Lack of Competition --> High Prices


Been using the NOWO network for the past couple of years: https://github.com/nelsonic/nelsonic.github.io/issues/781 it's _garbage_. 
I wanted the lowest possible monthly cost because I seldom use data away from the house. 
Thinking **`500mb`** would be enough I signed up to the **`€7.50/month`** plan.
On several occasions in the last 2 years I have been _trying_ to work or trying to send someone a Signal message.
Since Signal (or any other messaging service) uses the Mobile Data, if you run out of data - NOWO cut you off **completely** - and you are stuck. But it's not just messaging, since the NOWO App uses mobile data to check your status or update your account settings, you can't even add more data if you run out. It's like being stuck in a foreign land without your passport. But when border control sees you don't have a passport they confiscate your wallet too!!

## Woo? 

<img width=""1464"" alt=""image"" src=""https://user-images.githubusercontent.com/194400/173373879-021332f8-07bb-4c69-9463-44eaa4bd021b.png"">

Woo has the policy that they _never_ cut you off even if you run out of data on your plan:
<img width=""1464"" alt=""image"" src=""https://user-images.githubusercontent.com/194400/173374006-dc759276-a3c0-48b5-bb17-ca6fda638e0a.png"">

<img width=""1464"" alt=""image"" src=""https://user-images.githubusercontent.com/194400/173374942-bd4af311-bd0f-43a1-bd03-7e29d29ac24a.png"">
",2022-06-13T15:00:28Z,2022-09-14T06:57:26Z,closed,4,"Yorn (bandwidth,network company), usage of dark pattern in software, comparison prevention",,"Yorn, comparison prevention",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ArisOvayolu/DPE/issues/4,Website almost completed awaiting additions to dark pattern techniques page.,https://github.com/ArisOvayolu/DPE/pull/4,,2022-05-20T18:18:56Z,2022-05-20T18:19:08Z,closed,0,miscellaneous,,,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/BetonQuest/BetonQuest/issues/1872,Less user hostile cookie consent,https://github.com/BetonQuest/BetonQuest/pull/1872,"# Description
The cookie banner of mkdocs follows many common practices of other websites.
But by doing that it also implements some deceptive, user-hostile designs (commonly referred to as Dark Patterns).

For more information on what Dark Patterns are and why they should be avoided I suggest reading this article:
https://usercentrics.com/knowledge-hub/dark-patterns-and-how-they-affect-consent/

To sum it up deceptive designs are noticed and disliked by users while being potentially illegal.

As a first step to fix this google analytics should be opt-in instead of opt-out. 
Additionally I opened an issue at mkdocs to alter the consent dialogue [1].  

## Related Issues
1. squidfunk/mkdocs-material#3970

## Checklist
Run maven Verify in your IDE and ensure it SUCCEEDS!

### Reviewer's checklist
<!-- DON'T DO ANYTHING HERE -->
<!-- This is a checklist for the reviewers, and will be checked by them! -->
Did the contributor...
- [ ]  ... test their changes?
~~- [ ]  ... update the changelog?~~
~~- [ ]  ... update the documentation?~~
~~- [ ]  ... adjust the ConfigUpdater?~~
~~- [ ]  ... solve all TODOs?~~
~~- [ ]  ... remove any commented out code?~~
~~- [ ]  ... add debug messages?~~
~~- [ ]  ... clean the commit history?~~

Check if the build pipeline succeeded for this PR!
",2022-05-30T10:01:59Z,2022-06-12T10:56:24Z,closed,2,"Material for MkDocs, prevention of dark pattern, less user hostile cookies consent, add ""deny"" button","consent cookie, opt-in instead of opt-out, examples","MkDocs, avoid dark pattern, examples, cookie consent, opt-in/out",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/tuskyapp/Tusky/issues/2423,With 17.0 beta 1 it's no longer possible to refresh under the timeline,https://github.com/tuskyapp/Tusky/issues/2423,"With the previous versions I was able to refresh the timeline ""above"" my currently last read toot. So I would scroll the ""load more"" button to the top of my timeline so it's barely visible and then refresh, new toots would load but I'd stay at my current place in the timeline. With the 17.0 beta 1 version I'm no longer able to do that. My ""view"" is always ""above"" the newly loaded toots, while before I was able to keep it below. The downside is that if I want to continue to read my TL chronological from where I stopped to now I have to scroll, refresh, scroll refresh. That is a bit annoying. If #89 would be introduced that would probably fix this as well.

One the plus side: I never encountered the missing messages bug from tusky 16 again, thanks for that <3

* * * *
- Tusky Version: 17.0 beta 1 (Google)
- Android Version: 11
- Android Device: OnePlus Nord CE 5g
- Mastodon instance (if applicable): chaos.social (but doesn't matter)

- [x] I searched or browsed the repo’s other issues to ensure this is not a duplicate.
",2022-04-07T21:53:15Z,2022-11-08T19:24:08Z,closed,13,"miscellaneous (dark pattern in design, visual interference)","Tusky, cannot refresh, hiding title","Tusky, interface interference, UI/UX design",DPs in design coding ,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/PostHog/posthog/issues/11093,feat:  LemonButton refactor,https://github.com/PostHog/posthog/pull/11093,"## Problem

Rework of buttons to match new Design System as closely as possible, drastically reducing the freedom people have with the LemonButton and therefore their ability to deviate from the design.

## Changes

Notable changes:
* Many options for LemonButton have been removed to simplify things
* ""stealth"" is now a status rather than a type as it is more todo with colors than anything else

<img width=""1072"" alt=""Screenshot 2022-08-04 at 13 02 19"" src=""https://user-images.githubusercontent.com/2536520/182831831-42009d1d-318e-4a5d-8c92-caa9de0cc16c.png"">
<img width=""1082"" alt=""Screenshot 2022-08-04 at 13 02 32"" src=""https://user-images.githubusercontent.com/2536520/182831843-77cb1699-c0c5-43be-a4ea-5ca62b87f280.png"">


* To get an idea of how messy things were before:
Before buttons where styled in a range of different ways, many combinations not really working at all...
![2022-08-02 15 34 37](https://user-images.githubusercontent.com/2536520/182387981-96a3a567-74e6-4467-afb5-b7ba0aff58d7.gif)

👉 *Stay up-to-date with [PostHog coding conventions](https://posthog.com/docs/contribute/coding-conventions) for a smoother review.*

### Side effect changes:
> These are things I had to fix but am not trying to fully match a perfect state
* Had to update Paths buttons and styles as they were super screwed up already
|Before|After|
|----|----|
|<img width=""223"" alt=""Screenshot 2022-08-04 at 11 03 35"" src=""https://user-images.githubusercontent.com/2536520/182808408-331b35dc-bd83-4d7f-9048-1434280dc272.png"">|<img width=""221"" alt=""Screenshot 2022-08-04 at 12 31 51"" src=""https://user-images.githubusercontent.com/2536520/182826391-18ade067-2620-4eee-bffb-12f7cf2fe97a.png"">|

* Slightly different button styles for playback of recordings

![2022-08-04 13 47 08](https://user-images.githubusercontent.com/2536520/182839620-529363b2-016e-4853-8b8c-298a2bea3b3c.gif)

* Invite modal changes
![2022-08-05 10 11 25](https://user-images.githubusercontent.com/2536520/183033205-161d080a-f86e-42e7-acbd-c9584cb9bcbe.gif)

* LemonSwitch changes (to fit design system)
@clarkus the padding feels weird to me but if you're happy then we can go with it (it exactly matches whats in Figma)

|Before|After|
|----|----|
|<img width=""338"" alt=""Screenshot 2022-08-05 at 12 16 34"" src=""https://user-images.githubusercontent.com/2536520/183057175-d14773fa-2e7e-4edc-8623-1e5999fb9bff.png"">|<img width=""352"" alt=""Screenshot 2022-08-05 at 12 17 45"" src=""https://user-images.githubusercontent.com/2536520/183057181-1d4ce968-82dd-4520-8d68-d682a6370986.png"">|



## How did you test this code?

<!-- Briefly describe the steps you took. -->
<!-- Include automated tests if possible, otherwise describe the manual testing routine. -->

## TODO

- [x] Fix buttons that are ""stealth"" but with a border (e.g. data range filter)
- [x] Fix buttons that are ""stealth"" but with status ""danger"" expecting to be red
- [x] Generally what to do about ""stealth"". It is essentially a color change (to default dark) and a font change. Maybe it should be a separate property?
- [x] Fix LemonSwitch
- [x] Fix Sidebar coffee icon
- [ ] Fix Sidebar hover icon background
- [x] Fix AuthorizedUrl edit view
- [ ]",2022-08-02T13:36:27Z,2022-08-08T06:27:02Z,closed,15,"PostHog (all-in-one, open source platform for building better products), prevention of dark pattern in design, LemonButton design","LemonButton, confusing deadend feature","PostHod, LemonButton, avoid dark pattern",DPs prevention in design,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/mwittrien/BetterDiscordAddons/issues/1627,[IMPROVEMENT] - ImageUtilities - Autoblur NSFW Images off by default,https://github.com/mwittrien/BetterDiscordAddons/issues/1627,"It was insanely confusing on startup, I thought discord had added a dark pattern to discourage users from participating in nsfw channels, but no, it was image utilities. Secondly, it really is a needless dark pattern. I can totally understand if someone wants to enable this, but it doesn't really make sense as default. If someone clicks on an nsfw channel, typically, they want to see nsfw images unobstructed. As well, it's not so much an image utility as changing the behavior of how spoilering works, which isn't the primarily advertised feature. Lastly, those who previously had the extension installed you could kind of treat as users who have always had it off, and in a way you're kind of changing their settings by having it be automatically on.
I dont mind the feature being there. In fact, I think it may have it's uses; say if you have guests, are in public, are streaming, want to have that stuff always cw'd, etc. Just make it something you have to toggle on instead of the other way around <3

Thank you so much for your time. I know this may seem nitpicky but it genuinely did really confuse me for a second, and i think it would be an improvement to have it be a non-default feature. I had actually gotten mad at the discord for a moment there because i thought it was vanilla, lol.",2022-06-23T02:22:00Z,2022-06-23T08:14:00Z,closed,1,"miscellaneous (dark pattern design practices, Discord, autoblur NSFW images)","ImageUtilities, Autoblur NSFW, forced action",,,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/FreeTubeApp/FreeTube/issues/2251,[Bug]: YouTube is doing some A/B tests that will likely break FreeTube in the near future,https://github.com/FreeTubeApp/FreeTube/issues/2251,"### Guidelines

- [X] I have encountered this bug in the [latest release of FreeTube](https://github.com/FreeTubeApp/FreeTube/releases).
- [X] I have searched the [issue tracker](https://github.com/FreeTubeApp/FreeTube/issues) for a bug report that matches the one I want to file, without success.

### Describe the bug

YouTube is currently doing some very unpopuler A/B tests, due to those changes FreeTube will likely break once they are fully implemented. As we have learnt in the past the less popular a change is, the higher the chance is that YouTube will make it permanent. At this point I'm starting to question the sanity of the people working at YouTube.

Here are the ones that will likely affect FreeTube:
1. video lengths are being removed from thumbnails (this is probably a dark pattern with the goal to increase overall watchtime on the platform) [reddit post on r/youtube](https://old.reddit.com/r/youtube/comments/us3gct/video_lengths_have_just_been_removed_from_the/)
2. removing sorting by oldest on channels [reddit post on r/youtube](https://old.reddit.com/r/youtube/comments/uqyevv/youtube_made_it_so_you_cant_sort_by_oldest_anymore/)
3. Watch page redesign [reddit post on r/youtube](https://old.reddit.com/r/youtube/comments/uof13c/what_the_hell_is_this_layout_my_eyes_are_burning/)
4. Removing the likes from under the video, presumably a continuation of their fever dream where they thought that removing the dislikes was a good idea [reddit post on r/youtube](https://www.reddit.com/r/youtube/comments/udmn8v/are_they_removing_likes_now/)

Personally I haven't seen FreeTube breaking because of those changes just yet, but it's just a matter of time so I thought I would create this issue to let everyone know early.

### Expected Behavior

n/a

### Issue Labels

race condition

### FreeTube Version

all of them

### Operating System Version

all of them

### Installation Method (If applicable)

_No response_

### Last Known Working FreeTube Version (If Any)

_No response_

### Primary API used

_No response_

### Additional Information

_No response_

### Nightly Build

- [ ] I have encountered this bug in the latest [nightly build](https://docs.freetubeapp.io/development/nightly-builds).",2022-05-18T06:28:50Z,2022-07-28T12:17:09Z,closed,11,"FreeTube (open source desktop YouTube player), dark pattern removal, video lengths are removed from thumbnails ","YouTube, removing video length, sneaking","FreeTube, YouTube, avoid dark pattern, sneaking",DPs prevention in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/squidfunk/mkdocs-material/issues/3970,"Add ""deny"" button to cookie consent",https://github.com/squidfunk/mkdocs-material/issues/3970,"### Contribution guidelines

- [X] I've read the [contribution guidelines](https://github.com/squidfunk/mkdocs-material/blob/master/CONTRIBUTING.md) and wholeheartedly agree

### I want to suggest an idea and checked that ...

- [X] ... to my best knowledge, my idea wouldn't break something for other users
- [X] ... the documentation does not mention anything about my idea
- [X] ... there are no open or closed issues that are related to my idea

### Description

The cookie banner which was implemented to close #1914 followed many common practices of other websites. 
But by doing that it also implemented some deceptive, user-hostile designs (commonly referred to as _Dark Patterns_).

For more information on what Dark Patterns are and why they should be avoided I suggest reading this article:
https://usercentrics.com/knowledge-hub/dark-patterns-and-how-they-affect-consent/

To sum it up deceptive designs are noticed and disliked by users while being potentially illegal.

Also I think a documentation site should be as easy to use as possible and it's really bad practice to annoy new users with unintuitive ui. 

### Fixes
- [ ] Add `Deny` or similar option to the consent banner right next to the Accept button, in the same colour and style.
- [ ] Modify the [initial state](https://squidfunk.github.io/mkdocs-material/setup/ensuring-data-privacy/#native-cookie-consent) to be unchecked by default.

### Additional Features
- [ ] Have an `X` in the top right corner of the consent banner that just closes it, denying all cookies / choices.  
       I know not everyone will like that but as an user is very intuitive and saves a lot of annoyance
- [ ] Add a `Change cookie settings` link to the sites footer, right next to the copyright information so it is always present.


### Use Cases

All new users first discovering a mkdocs site with a cookie banner would benefit from making consent easier.  

Users that are curios about the use of their personal data would get a better first impression of the site.  

Administrators of sites would have a reduced risk of being held accountable for non compliance.

### Screenshots / Mockups

![grafik](https://user-images.githubusercontent.com/17405009/170966420-ae9e8fb2-f6af-4541-9156-97e4b8304436.png)
",2022-05-30T09:50:30Z,2022-06-05T11:34:08Z,closed,5,"Material for MkDocs, prevention of dark pattern, less user hostile cookies consent, add ""deny"" button","no 'deny' button for cookie consent, examples and definitions","MkDocs, avoid dark pattern, examples, cookie consent",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/forem/forem/issues/18128,Add the ability to react to a post directly on feed,https://github.com/forem/forem/issues/18128,"We want to allow users browsing the feed to be able to like a post without visiting the post page. To do this we will change the current ""X reactions"" link into a button with heart icon and text ""<number> Likes"" (or ""like"" singular if applicable).

If you don't ""like"" the post already, then hovering over it should result in the icon having a dark fill colour [as per the prototype](https://www.figma.com/proto/Rl50gxO5BHioRC3nUoRQ7M/Reactions-%E2%9D%A4%EF%B8%8F?page-id=602%3A17&node-id=731%3A2330&viewport=4302%2C-1062%2C0.43&scaling=min-zoom&starting-point-node-id=731%3A2330).

If you do already ""like"" the post, the icon should have the ""active"" colour, and so should the text - this is the same colour as we already use in the post page.


## Implementation notes

- The button should be a toggle button. This means it should have a static label (e.g. ""Like post: <title of post>, 22 likes""), and an `aria-pressed` attribute set to either `true` or `false` depending if it is currently active (""liked"")
- We can re-use code from `app/assets/javascripts/initializers/initializeArticleReactions.js` to handle updating the reaction in the backend / updating the UI with the new reaction count

We will need to bear in mind that feed story cards are created in multiple places, and will need to each be updated:

- `app/views/articles/_single_story.html.erb`
- `app/assets/javascripts/utilities/buildArticleHTML.js`
- `app/javascript/articles/Article.jsx`

Also to note when testing, feed story cards appear on the following pages:

- Home feed
- User's profile page
- Index page for a given tag
- Search results

Functionality should work in all locations.",2022-07-15T07:25:12Z,2022-08-09T08:46:00Z,closed,13,"Forem (open source software for building communities), dark pattern or not, like button for posts from index page instead of post page, prevention of dark pattern in design",,"Forem, UI/UX design, dark pattern or not, avoid dark pattern","dark pattern or not, DPs prevention in design",,,DPs used in software,dps used in software,,,
https://api.github.com/repos/ipfs/ipfs-gui/issues/125,Define basic metrics and patterns for consent & collection.,https://github.com/ipfs/ipfs-gui/issues/125,"At a bare minimum, we should be able to get the following metrics for our projects for users that haven't opted-in to collecting the full set of metrics supported by Countly

1. Weekly/daily/monthly active users
   * see https://github.com/ipfs/ipfs-gui/issues/128
2. ~~web-vitals (where appropriate) - https://www.npmjs.com/package/web-vitals~~
3. download counts (where appropriate)
4. pageviews
5. session time

## Disclaimer

Note that until this, https://github.com/ipfs/ipfs-gui/issues/130, and https://discuss.ipfs.tech/t/ipfs-gui-metrics-changes-in-progress/15695 have been available to the community for feedback for enough time( see https://github.com/ipfs-shipyard/ignite-metrics/issues/2), we will continue with the implementation we currently have in public-gateway-checker: 
* metrics implementation was already merged (https://github.com/ipfs/public-gateway-checker/pull/309), but it's not opt-out yet. I.e. until you accept/decline, no metrics are sent. see https://github.com/ipfs-shipyard/ignite-metrics/issues/2

---

### Current problems with metrics

See https://pl-strflt.notion.site/Telemetry-b005d4f217f44db3986902c67d922cf4

### Current planned solution

https://www.notion.so/pl-strflt/Telemetry-b005d4f217f44db3986902c67d922cf4#0833d8c86b4f4ffc99337305159d27b0

### Metrics distinctions

`minimal` metrics will be 'sessions' and 'views' as [categorized by countly](https://support.count.ly/hc/en-us/articles/360037441932-Web-analytics-JavaScript-#features-for-consent) (i.e. `const minimalFeatures = ['sessions', 'views']`). See https://github.com/ipfs/ipfs-gui/issues/130 for more information

#### Minimal Metrics (opt-out)

We will allow the disabling of `minimal` features once we switch to opt-out metrics. See https://github.com/ipfs-shipyard/ignite-metrics/issues/2

* sessions - tracks when, how often, and how long users use your website
* views - allows for the views/pages accessed by a user to be tracked
    * Note that these view metrics are ""App views"" and not page URL (i.e. public/private gateway access views that include CID)

#### All Metrics (opt-in)

Note that while these are `opt-in`, when presented with our cookie banner/modal for the first time (see https://github.com/ipfs/public-gateway-checker/issues/340#issuecomment-1352395130), the checkbox will be enabled for ""all"" metrics. Closing the banner without other actions will update your consent from ""minimal"" to ""all"".

* events - allows your events to be sent to the server
* scrolls - allows a user’s scrolls to be tracked on the heatmap
* clicks - allows a user’s clicks and link clicks to be tracked on the heatmap
* forms - allows a user’s form submissions to be tracked
* crashes - allows JavaScript errors to be tracked
* attribution - allows the campaign from which a user came to be tracked
* users - allows user information, including custom properties, to be collected/provided
* star-rating - allows user rating and feedback tracking through rating widgets
* feedback - allows survey, nps rating and feedback tracking through feedback widgets
* apm - allows performance tracking of application by recording traces
* location - allows a user’s location (country, city area) to be recorded

### Current planned solution


### Describe alternatives you've considered

#### General
1. Not collecting metrics
    * Not viable due to the need to prioritize efforts to satisfy customer needs.
1. Opt-in only metrics (i.e. only send metrics when users consent)
    * Having opt-in-only metrics is not giving us the full picture. See `Current problems with metrics` above.

#### IPFS-companion

1. Using only firefox & chrome store metrics
    * This is no longer viable, as we have no way to normalize these metrics with our other projects' metrics.


### Child tasks

- [x] [Create post on discuss.ipfs.tech to let the community know and give a chance for community feedback](https://discuss.ipfs.tech/t/ipfs-gui-metrics-changes-in-progress/15695)
- [x] #130
- [x] #131


---

I'm proposing the following settings for countly metrics for our projects:

```
  /**
   * @see https://support.count.ly/hc/en-us/articles/360037441932-Web-analytics-JavaScript-#features-for-consent
   */
  const minimalFeatures = ['sessions', 'views']
  const marketingFeatures = ['attribution', 'users', 'location']
  const performanceFeatures = ['events', 'crashes', 'apm']
  const trackingFeatures = ['scrolls', 'clicks', 'forms', 'star-rating', 'feedback']

  Countly.group_features({
    all: [...minimalFeatures, ...marketingFeatures, ...performanceFeatures, ...trackingFeatures],
    minimal: minimalFeatures,
    marketing: marketingFeatures,
    tracking: trackingFeatures,
    performance: performanceFeatures
  })
```

---

Note that from the above list, 2(web-vitals) is not provided by default from countly, and without `events` in the `performanceFeatures` group from the above code snippet, we cannot submit custom events/metrics/analytics. However, if we enable `events` for ""minimal"" metrics, it's possible that at some point in the future, a custom metric could be sent that does not adhere to our groupings and opt-in ethics. Therefore, 2(web-vitals) above will be considered an opt-in metric only to keep our `minimal` metrics light.

However, we can use countly's `trackView` event in order to track page views without exposing the full blown ""events"" functionality to limit user risk.",2022-11-28T20:29:34Z,2023-01-18T18:57:44Z,closed,15,"miscellaneous (forced accepting telemetry (data collection), no option to opt-out)","consent, collection, forced telemetry, no opt-out, forced action","consent, data collection, telemetry, opt-in/out, forced action",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/hashicorp/go-tfe/issues/401,🔧 Bump the circleci resource class when we run,https://github.com/hashicorp/go-tfe/pull/401,"## Description

Bump the resource class to something reasonable.
",2022-05-16T21:44:40Z,2022-06-20T21:23:40Z,closed,5,"CircleCI, deceptive design practices, juicy sales","code, dp for sales","CircleCI, coding, deceptive design practices, promote sales",DPs used in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/aegis-icons/aegis-icons/issues/598,Icon request: popads,https://github.com/aegis-icons/aegis-icons/issues/598,"### URL for the brand / site / app

https://www.popads.net/

### Logo resources for the icon

https://static.popads.net/img/logo.png

### Anything else?

_No response_",2022-05-17T09:52:25Z,2022-05-23T12:15:01Z,closed,1,"PopAds, popunders ads",icon for popunder ad,"PopAds, ads",DPs examples/definitions,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/PaperMC/Velocity/issues/662,Replace opt-out dark pattern with opt-in.,https://github.com/PaperMC/Velocity/pull/662,"This PR removes the ""opt-out"" dark pattern and replaces it with privacy first ""opt-in"" to ensure that users consent to having telemetry sent.",2022-03-12T06:27:13Z,2022-03-14T03:57:40Z,closed,2,"Velocity, usage of dark pattern in softare, opt-in/out, consent ",using opt-in instead of opt-out,"Velocity, opt-in/out, consent ",DPs used in software,,,DPs detection Tools,dps detection tools,,,
https://api.github.com/repos/tijlleenders/ZinZen/issues/329,Design ZinZen first use FAQ page(s),https://github.com/tijlleenders/ZinZen/issues/329,"After someone chooses a language and theme for the first time, a screen with two choices should appear:
- I have questions about ZinZen
- I already know ZinZen

If the first option is chosen, the next page is a page with frequently asked questions:
\==============================
**What is ZinZen?**
ZinZen helps you and your partner :
 - balance your lives with your priorities
 - plan your time realistically
 - remember important stuff on time

**Is ZinZen private?**
ZinZen respects your privacy.  
ZinZen does not know your name, email, address or phone number.  
All your data will be kept on this device only, so ZinZen can't see it.

**Is ZinZen expensive?**
ZinZen is free, open source and financed by voluntary contributions.  
No ads or dark patterns - ever.

**Too good to be true?**
Don't believe us, just try!

**I have a different question**
\==============================
The last option will lead to the Feedback / Question page.",2022-05-15T03:14:00Z,2022-05-27T09:13:08Z,closed,7,"ZinZen, no dark patterns in software, good UI & UX",,"ZinZen, avoid dark pattern, UI/UX design",DPs prevention in design,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/nayafia/microgrants/issues/66,added Atila,https://github.com/nayafia/microgrants/pull/66,,2022-06-14T12:44:23Z,2022-06-28T13:23:25Z,closed,6,"Atila, usage of dark pattern in software, nagging popups","Atila, pop-up screens, nagging","Atila, pop-up, nagging",DPs used in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/glitch-soc/mastodon/issues/1758,Remove “I don't like it” option from report modal,https://github.com/glitch-soc/mastodon/pull/1758,"When a user clicks the “report” button, they usually want to actually make a report, which the “I don't like it” option does not do, and instead only reminds them of the “mute”, “block” (and “unfollow”) options. But those options are always alongside the “report” one, so I feel this report option is not useful, and instead just makes the flow a bit confusing and discouraging.",2022-04-29T09:00:41Z,2022-05-01T19:58:20Z,closed,3,"Mastodon, prevention of dark pattern","suggesting other options instead of ""report"", obstruction, misdirection","Mastodon, avoid dark pattern, obstruction",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/rockstor/rockon-registry/issues/331,"Move scrutiny to official image, altering options accordingly #329",https://github.com/rockstor/rockon-registry/pull/331,"Move from linuxserver.io to official master-omnibus image and remove redundant settings.

Fixes #329
@FroggyFlox & @Hooverdan96 Ready for review. Tests carried out to date to follow in comments.

## Includes:
- Rewording and simplifying instructions.
- Capitalisation fixes.
- Removal of SCRUTINY_API_ENDPOINT option (to simplify).
- Adding COLLECTOR_CRON_SCHEDULE set option. It is often desired to control of when a collection is enacted. This also surfaces that this is only done once per day.
- Update Rock-on json file version number.
- Correct prior mix of tab and spaces.

### Caveats:
The ""--privileged"" option was found to be required but was not
referenced in the upstream documentation! We already have the two
referenced ""--cap-add"".

### Checklist
- [x] Passes [JSONlint](https://jsonlint.com) validation
- [x] Entry added to `root.json` in _alphabetical_ order (for new rock-on only)
- [x] `""description""` object lists and links to the docker image used
- [x] `""description""` object provides information on the image's particularities (advantage over another existing rock-on for the same project, for instance)
- [x] `""website""` object links to project's main website
",2022-06-12T17:31:44Z,2022-06-17T14:03:47Z,closed,7,"Scrutiny, rockon, usage of dark pattern in software, cookies consent dialog","Scrutiny, consent cookie","Scrutiny, cookie consent",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/supabase/supabase/issues/5139,Delete project modal doesn't submit on enter in Studio,https://github.com/supabase/supabase/issues/5139,"# Bug report

## Describe the bug

When I press enter to submit the delete project form, it does not work.

## To Reproduce

<img width=""550"" alt=""CleanShot 2022-01-24 at 11 11 04@2x"" src=""https://user-images.githubusercontent.com/9113740/150831010-637acfd4-70b4-4188-adc7-2be5c18e510e.png"">

## Expected behavior

The form to submit on enter 😄 ",2022-01-24T17:12:22Z,2022-06-16T17:42:15Z,closed,8,"Studio, usage of dp in software, obstructions, hard-to cancel/delete ","extra step to delete project, confirmshaming, obstruction","Studio, obstruction, hard to cancel",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/internetarchive/wayback-machine-webextension/issues/864,"Disable requirement to log to archive.org account prior to enabling ""Save Page Now""",https://github.com/internetarchive/wayback-machine-webextension/issues/864,"It appears that with the 3.0 version of the Wayback Machine extension that you must now log in to your archive.org account before the ""Save Page Now"" button will be enabled. This wasn't the case in prior versions. I don't know the full reasoning behind this change other than I note there are at least a couple of new options (off by default) that would probably require a person to be logged in. One of these is ""Save to my Web Archive"" and the other I can see is ""Email Outlinks"". There might be others I'm missing.

I don't ever want to save anything I've archived to my account, and I'm not interested in any of the other personalization features. I'm also one of those people that frequently clears browser data and ends up logged out of everything, so I will be logging in repeatedly to use the ""Save Page Now"" button, which eliminates the efficiency it would otherwise provide. 

Additionally, I use this browser extension in contexts where I do not wish to log in to my account (e.g. at work). In those contexts, the ""Save Page Now"" feature is now unusable.

**Describe the solution you'd like**
It would be nice if the ""Save Page Now"" button was enabled even when logged out if none of the personalization features were enabled. 

Even if this is possible, I admit that this appears to be a UX challenge. Right now the UX is the same for everyone, but if my change could be implemented, the experience for people who have enabled personalization functions will be different from those that haven't. I don't necessarily have a good suggestion to overcome that other than to provide additional context as to why the user must log in. 

**Describe alternatives you've considered**
If this can't be made to work, my work around would be to stop using the extension for saving pages and go back to using the web interface.
",2022-02-19T14:16:37Z,2022-05-02T09:07:04Z,closed,7,"archive.org, Wayback Machine extension, usage of dp in software, forced action, sign-in required","Wayback Machine, login to archive,org required to save page, forced action","archive.org, Wayback Machine, forced action, signup/log-in required ",DPs used in software,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/HedvigInsurance/web-onboarding/issues/870,Default to selecting least expensive bundle,https://github.com/HedvigInsurance/web-onboarding/pull/870,"<!-- 
To link the branch/PR to a Jira issue either
1. (preferred) add the issue key to the name of your branch (e.g. GRW-123/fix/some-annoying-bug)
2. prefix your PR title with it

Also, if applicable, include whether this is a Fix, Feature or Chore.

Example PR title: GRW-123 / Feature / Awesome new thing
-->

## What?

If no bundle is explicitly selected, default to the one with the fewest quotes.

## Why?

Seems like a dark pattern to select the most expensive bundle by default.


**Ticket(s): []**
<!-- If there is a Jira issue, add the key (e.g. GRW-123) between the brackets, and a link to that issue will automatically be created. -->


<!-- If it makes sense, add screenshots and/or screen recordings below, with headlines and/or descriptions if needed. -->
<!--
## Screenshots / recordings 
-->

<!-- Finally, you can create a review app on Heroku to make it easier to review and/or get input from the design team before merging. -->
<!--
### [Review app]()
-->

",2022-03-15T08:03:17Z,2022-03-16T10:12:01Z,closed,1,"Hedvig Web Onboarding, good ""preselection"" dark pattern, least expensive option selected by default","default selecting most expensive bundle, preselection","Hedvig Web Onboarding, preselection, default",DPs examples/definitions,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/arkenfox/user.js/issues/1382,Why is DoH not enabled or DoH rollout not explicity off? [solved: this is not up to arkenfox as there is no right answer],https://github.com/arkenfox/user.js/issues/1382,"I don't understand why Arkenfox does not enable DNS over HTTPS by default. Is there something wrong with the current implementation of it in Firefox? I thought that DoH is always a good thing, unless you need to inspect network traffic. Is this not the case?",2022-02-24T23:50:19Z,2022-04-29T08:50:57Z,closed,3,"Mozilla, Firefox, DNS over HTTPS, prevention of dp in software","Arkenfox, enable DNS or HTTPS","Mozilla, Firefox, DNS over HTTPS, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/privacyguides/privacyguides.org/issues/565,Reconsidering StartPage,https://github.com/privacyguides/privacyguides.org/issues/565,"## Remove startpage or at least warn the users

The website says: 
`""Startpage is a search engine that provides Google search results. It is a very convenient way to get Google search results without experiencing dark patterns such as difficult captchas or being refused access because you used a VPN or Tor.""`

Which is clearly not the case as I have received this: 
![994c12ae-d4d1-431b-8ac1-45ca7808b63a](https://user-images.githubusercontent.com/93835541/149901393-1c7b9de5-fd02-4029-8c56-6d7c5116a64f.png)
Often this appears more than once a day. Tried using different VPN providers too and confirmed from others, they experienced similar problems. 
***
**A service that doesn't respect its users enough to let them use VPN/TOR might not be worth recommendation in my opinion.**
***
Nevertheless if value be found in its recommendation then the users should be made aware that they need to use it only when off VPN/Tor networks.  

**URL of affected page:** https://privacyguides.org/search-engines/
",2022-01-18T08:52:30Z,2022-03-22T17:14:30Z,closed,3,"StartPage, search engine without DPs, prevention of dp in software","Startpage, search without captcha/dp","StartPage, avoid dark pattern",DPs prevention in software,,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/PostHog/posthog/issues/8789,Incorrect pattern used for required fields on experimentation,https://github.com/PostHog/posthog/issues/8789,"## Bug description

This is a dark pattern for indicating required fields. It conflicts with the patterns used elsewhere in the product. It's also injected with generated content, which feels problematic to me. 

<img width=""1175"" alt=""Screen Shot 2022-03-01 at 8 31 09 AM"" src=""https://user-images.githubusercontent.com/254612/156208950-4fc55f95-8168-4e17-a1a8-03e267d39165.png"">

## Expected behavior

All fields are required in the product unless indicated otherwise. We communicate things that are optional, as most often they won't make up the bulk of a form. 

<img width=""737"" alt=""Screen Shot 2022-03-01 at 8 33 06 AM"" src=""https://user-images.githubusercontent.com/254612/156209252-3a90baa5-60ee-4060-8390-5ab1a4887f7a.png"">


## How to reproduce

1. Create a new experiment
## Environment

- [x] PostHog Cloud
- [ ] self-hosted PostHog (ClickHouse-based), version/commit: _please provide_
- [ ] self-hosted PostHog (Postgres-based, legacy), version/commit: _please provide_

## Additional context

- [Slack thread](https://posthog.slack.com/archives/C02283301EK/p1646149337959139)
- [Figma](https://www.figma.com/file/gQBj9YnNgD8YW4nBwCVLZf/PostHog-App?node-id=7348%3A35498)

#### *Thank you* for your bug report – we love squashing them!
",2022-03-01T16:34:42Z,2022-03-16T17:37:23Z,closed,1,"PostHog (all-in-one, open source platform for building better products), usage of dp in software, forced action, required fields","required fields not specified properly, design confusing, sneaking","PostHog, forced action, UI/UX design",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/withfig/fig/issues/969,Be more user friendly by making email optional and making telemetry an opt in feature rather than an opt out,https://github.com/withfig/fig/issues/969,"### Sanity checks

- [X] I have searched [github.com/withfig/fig/issues](https://github.com/withfig/fig/issues?q=) and there are no duplicates of my feature

### Feature Details

### Description:

Fig is an awesome tool which works great and is open source. Yet it follows that same dark patterns as many more money focused and evil products by forcing users to enter their email for a product that is supposed to be completely local and then collecting telemetry without notifying the user.

The feature should be making the email optional and making the telemetry an opt in rather than an opt out.

",2022-02-21T14:15:27Z,2022-02-22T23:50:09Z,closed,1,"Fig (comment line shell), usage of dark patterns in software, forced action, required email, collecting telemertry with users' consent  ","telemetry opt-out, forced action, requires email when free and local","Fig, telemetry, consent, forced action, email required",DPs used in software,,,DPs related regulation,dps related regulation,,,
https://api.github.com/repos/mui/mui-toolpad/issues/795,[RFC] Remove releases from the community plan,https://github.com/mui/mui-toolpad/issues/795,"### Duplicates

- [X] I have searched the existing issues

### Latest version

- [X] I have tested the latest version

### Summary 💡

Release management is an advanced feature that should not be there in the community version.

When the user clicks Deploy we should:
1.  Directly show the deployed URL
2. Not show the release workflow
3. Remove the Releases tab

### Context

https://www.notion.so/Toolpad-Pricing-50df8f336b3d4120b8df8a8cef0b7fa9?d=0af1ff513e5b4bdf9bfe3f748d10035d#de48ce63c7c34c149c2aa68a57299e9d",2022-08-15T18:09:21Z,2022-09-02T13:08:53Z,closed,18,miscellaneous,"allowed to make changes but can't save, obstruction, unethical",deceptive design practices,DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/openfoodfacts/smooth-app/issues/1222,Implement an analytics consent UI as a checkbox in the onboarding (or just after ?),https://github.com/openfoodfacts/smooth-app/issues/1222,"### What

- [ ] Implement an analytics consent UI as a checkbox in the onboarding (or just after ?)

### V1 inspiration
<img width=""269"" alt=""image"" src=""https://user-images.githubusercontent.com/920265/89418188-0590d000-d730-11ea-8715-12d13909528b.jpg"">
<img width=""269"" alt=""image"" src=""https://user-images.githubusercontent.com/1689815/155174560-2f095e96-ece7-455b-97c6-44924971def2.png"">
<img width=""269"" alt=""image"" src=""https://user-images.githubusercontent.com/1689815/124359876-1c34f500-dc27-11eb-9fe8-53e6b674a61b.png"">",2022-03-16T16:12:29Z,2022-03-29T13:04:20Z,closed,10,"Smooth App (open food facts app), analytics consent UI, usage of dp in software   ","consent for analytics, UI dp design","Smooth App, consent, analytics, UI/UX design",DPs used in software,,,DPs prevention in design,dps prevention in design,,,
https://api.github.com/repos/deltachat/deltachat-core-rust/issues/2951,Remove default signature advertsing Delta Chat,https://github.com/deltachat/deltachat-core-rust/pull/2951,,2022-01-06T01:47:44Z,2022-01-25T20:44:34Z,closed,7,"Delta Chat, usage of dp in software, default signature advertsing, preselection",Delta Chat ads,"Delta Chat, default, preselection",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/duckduckgo/Android/issues/1660,Not an issue with the apk but with the download site,https://github.com/duckduckgo/Android/issues/1660,"I have just downloaded and installed the (Android version of the) DDG browser from its ""official"" website. Initially, I was disappointed that the only two OBVIOUS download options were via the Apple and the Google stores. It took me scrolling down screen after screen to the very end of the download page to find that there are indeed two other options (though presented only in ""small print"", almost like a dark pattern): directly from the DDG website and via f-droid (which I prefer).

Why not show these two options (for Android users) at the top and more prominently to boot? I do realise there are reasons why some people prefer the stores but many do not and those people (me included) should have a choice without scrolling down screen after screen. IMO of course.

Given DDG's vigorous attempts to make web privacy available to all (which I applaud), I find this sad and actually somewhat disconcerting. Either you take this privacy thing seriously or you don't. Again, strictly IMO.",2022-01-10T10:52:11Z,2022-01-12T13:19:51Z,closed,1,"Apple, Google stores, apps download, visual interference, obstructions","DDG browser download, design hierarchy, small buttons at bottom of page","Apple, Google stores, interface interference, obstruction, design hierarchy",DPs examples/definitions,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/caprover/one-click-apps/issues/612,App issue: focalboard embeds spyware,https://github.com/caprover/one-click-apps/issues/612,"Focalboard, like Mattermost, embeds silent, nonconsensual, phone-home spyware by default.  (It's made by the same people as Mattermost.)

The mattermost OCA template patches this out automatically, but the Focalboard one does not.

This is a tracking issue - I intend to send a PR to fix this (as I did when I created the Mattermost OCA template) soon.",2022-01-21T10:03:33Z,2022-01-25T00:25:44Z,closed,6,"Spyware, deceptive design practices","spyware, tracking issue, unethical","Spyware, tracking, deceptive design practices",DPs examples/definitions,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/101,Fix some of sandandsnow's comments from #94.,https://github.com/w3ctag/privacy-principles/pull/101,"> Re: section 1: “The goal of this document is to define principles that may prove useful in developing technology and policy that relate to privacy and personal data”, it would be helpful if we could elevate the goal to “define privacy principles for Web technologies” (or similar)

Done.

> Re: section 2.2: Perhaps we could leave out the point about data paternalism as the explanation of user agent duties make it clear that is not what is envisaged.

Done, and I removed the reference from the autonomy section.

> Also, is “duty of discretion” the right term?

This comes from [Taking Trust Seriously in Privacy Law](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2655719), which is cited above the list of duties. I've tried to adjust the text to match that definition of discretion better, but @darobin please check that I haven't subverted your intent.

> You might also want to note at the end that “fiduciary” also has legal meaning.

Added. Please check that I said the right thing about the legal meaning.

> Re: section 3: One aspect to keep in mind is that typically in online contexts other parties may be present that are unobservable to the person. At an in-person cocktail party, a person can see who is present and may be monitoring their attributes and actions. Of course, today a cocktail party attendee may not know that the host has a so-called “smart assistant” in listening/observing mode.

Delegated to #97.

> Re: section 4: Would we say burying privacy implications in pages of legalese is a dark pattern or another form of bad behaviour?

We think it is in some cases, but there wasn't any text to add about this.

> Re: section 4.1: We might want to include a statement to the effect that some controls are in practice illusory because the person or user effectively has no choice, accept the terms or don’t use the service.

Delegated to #35.

> Re: section 4.2: I would argue that privacy labour has been increased by a consent-based model for allowing data processing, i.e. where only consent is needed.

Added.


<!--
    This comment and the below content is programmatically generated.
    You may add a comma-separated list of anchors you'd like a
    direct link to below (e.g. #idl-serializers, #idl-sequence):

    Don't remove this comment or modify anything below this line.
    If you don't want a preview generated for this pull request,
    just replace the whole of this comment's content by ""no preview""
    and remove what's below.
-->
***
<a href=""https://pr-preview.s3.amazonaws.com/jyasskin/privacy-principles/pull/101.html"" title=""Last updated on Jan 19, 2022, 5:20 PM UTC (7568fe7)"">Preview</a> | <a href=""https://pr-preview.s3.amazonaws.com/w3ctag/privacy-principles/101/36e9b27...jyasskin:7568fe7.html"" title=""Last updated on Jan 19, 2022, 5:20 PM UTC (7568fe7)"">Diff</a>",2022-01-12T23:58:29Z,2022-01-19T17:21:40Z,closed,0,miscellaneous (burying privacy implications in pages),,miscellaneous,miscellaneous,burying privacy implications in pages,,DPs used in software,dps used in software,,,
https://api.github.com/repos/w3ctag/privacy-principles/issues/94,Reorganize the document to flow better,https://github.com/w3ctag/privacy-principles/pull/94,"I tried to incorporate Robin's goal for a coherent narrative instead of just a specification, and my goal of including non-data privacy. I left lots of issues where there's still more work to do to clean up the text, but hopefully the direction is clear and matches y'all's intentions.

Fixes #89.


<!--
    This comment and the below content is programmatically generated.
    You may add a comma-separated list of anchors you'd like a
    direct link to below (e.g. #idl-serializers, #idl-sequence):

    Don't remove this comment or modify anything below this line.
    If you don't want a preview generated for this pull request,
    just replace the whole of this comment's content by ""no preview""
    and remove what's below.
-->
***
<a href=""https://pr-preview.s3.amazonaws.com/w3ctag/privacy-principles/pull/94.html"" title=""Last updated on Jan 12, 2022, 7:17 PM UTC (9479374)"">Preview</a> | <a href=""https://pr-preview.s3.amazonaws.com/w3ctag/privacy-principles/94/9fd56a9...9479374.html"" title=""Last updated on Jan 12, 2022, 7:17 PM UTC (9479374)"">Diff</a>",2022-01-07T07:01:11Z,2022-01-12T19:19:18Z,closed,5,miscellaneous (burying privacy implications in pages),,miscellaneous,miscellaneous,burying privacy implications in pages,,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/easylist/easylist/issues/11762,Reclassification request: transcend.io,https://github.com/easylist/easylist/issues/11762,"`transcend.io` was recently added to your cookie consent warning / notice list. This is causing some privacy tools to block our domain, which actually increases first-party tracking as our tools are used for privacy compliance and are designed in a privacy-respecting manner. This also causes Privacy Centers for our customers to not load due to an inability to interface with our backend endpoints.

We do host a tracking consent banner notice / prompt in the form of an optional (inactive by default) consent UI for our customers. Due to our modular architecture, this UI alone could easily be blocked on the network level by easylist instead of all of `transcend.io`. We would prefer if you replaced the current entry in easylist_cookie with the following rule:

```
||cdn.transcend.io/*/ui.js$third-party
```

Non-essential tracking disclosure:
- We have an optional telemetry domain (`telemetry.transcend.io`) that [collects non-PII operational data](https://www.notion.so/transcend/Compliance-4551414bf7434c309e532b817f625017) that you may want to add to easylist_cookie.
- We support optional private local cross-domain consent & quarantine sync that doesn't expose sync data over network requests. These endpoints are hosted at `sync.transcend.io` by default although they can be easily self-hosted by customers with a static HTML snippet at a predetermined location.

### List the website(s) you're having issues:

This is only causing issues with Ghostery users at the moment, but a couple examples are:
- `indiegogo.com` - Consent manager can't regulate network traffic
- `privacy.patreon.com` - Site doesn't load due to blocked Transcend backend endpoints

### What happens?

Everything from transcend.io in a third-party context is blocked by some content blockers, for reasoning that is not in line with the intended purpose of easylist_cookie.

### List Subscriptions you're using:

- easylist_cookie",2022-04-22T08:13:19Z,2022-05-10T13:59:56Z,closed,10,"transcend.io, unified privacy and data governance app, annoying consent prompts, nagging",cookie consent manager to avoid dp,"transcend.io, prompt, nagging, cookie consent, avoid dark pattern",DPs prevention in software,,,DPs prevention in software,dps prevention in software,,,
https://api.github.com/repos/apache/airflow/issues/23335,Unify approach for user questions asked in Breeze,https://github.com/apache/airflow/pull/23335,"This change documents and unifies the approach we've taken for
the user inut handling when it comes to confirmation questions.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

---
**^ Add meaningful description above**

Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.
In case of fundamental code change, Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvements+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragement file, named `{pr_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",2022-04-28T19:02:46Z,2022-05-19T20:26:53Z,closed,20,"usage of dark pattern, nagging for upgrade/up-to-date","Breeze, nagging to keep up to date","Breeze, nagging, update notification",,,,DPs in design coding,dps in design coding,,,
https://api.github.com/repos/reduxjs/redux/issues/4325,Mark `createStore` as deprecated,https://github.com/reduxjs/redux/issues/4325,"We don't want anyone using the core `createStore` method directly in their apps today. We want them using `configureStore` from RTK instead.

We should tag `createStore` as `@deprecated` on both the 4.x and 5.x branches, and do another 4.x release.

**edit**

After a bunch of discussion, it's become clear that a lot of people aren't familiar with what RTK actually _is_, or what the technical differences are between the core `createStore` API and RTK's `configureStore`.  Let me provide some background resources.

First, I had a chance to do a livestream with Jason Lengstorf where we explained what people disliked about Redux historically, and how RTK was created to solve those issues.  We then built a small example app with RTK+TS:

- https://www.youtube.com/watch?v=9zySeP5vH9c

Next, the ""Modern Redux with RTK"" tutorial page shows the differences in usage between ""vanilla"" Redux and RTK for things like store setup and writing reducers:

- https://redux.js.org/tutorials/fundamentals/part-8-modern-redux

And for a lot of additional background on why RTK was created and how it evolved, see [my ""Redux Toolkit 1.0"" announcement post](https://blog.isquaredsoftware.com/2019/10/redux-toolkit-1.0/).

For the actual technical differences, [Lenz had a very good explanation on Twitter today]():

> In short: `configureStore` calls `applyMiddleware` and `combineReducers` for you and sets up the devtools, all while having a more ""sane"" api than `createStore`. For that reason alone, it should be a technical successor of `createStore`.
> In dev, it also adds two additional middlewares per default (middleware added by `configureStore` is freely configurable): One checks for accidental store mutations, both between renders as well as inside the reducer.
> That means it eliminates a whole class of bugs that only surface in ""UI sometimes not rerendering"" or things ""being out of order some time later"" - hard and frustrating to find. The other warns if you put non-(de)serializable values like classes into the store.
> Not only do these make a lot of problems with the devtools or libraries like redux-persist, even something as simple as a Date instance can mutate itself out of the normal Redux data flow.
> So, even if you were not to use the *rest* of RTK (which still makes you life a lot easier beyond that, removing the need for action types and manual immutable logic), it would still be a good idea to install RTK and use only `configureStore` out of it, instead of `createStore`.

There's some comparisons of the before and after setup here:

- https://redux.js.org/usage/configuring-your-store
- https://redux.js.org/tutorials/fundamentals/part-8-modern-redux#store-setup",2022-04-09T19:24:08Z,2022-04-19T13:05:36Z,closed,61,miscellaneous (Redux Toolkit),"forced action, Redux-toolkit ",miscellaneous,miscellaneous,"Redux Toolkit, forced action",,Papers/Docs/Sources,papers/docs/sources,,,
https://api.github.com/repos/ConsumerDataStandardsAustralia/future-plan/issues/159,DSB Item - Independent Health Check: Dark Patterns,https://github.com/ConsumerDataStandardsAustralia/future-plan/issues/159,"The DSB has engaged University of South Australia on the topic of dark patterns.

The purpose of this work is to understand identify Dark Patterns that are relevant and likely to be used in the CDR, and consider how resistant the CDR is to these Dark Patterns. 

The focus of this work are articulated in the [Data Standards](https://consumerdatastandardsaustralia.github.io/standards/), [Rules](https://www.legislation.gov.au/Details/F2023C00735), and various proposed changes particularly:

- the [Consumer Experience (CX)](https://consumerdatastandardsaustralia.github.io/standards/#consumer-experience) data standards;
- the [Security Profile’s Authentication Flow](https://consumerdatastandardsaustralia.github.io/standards/#authentication-flows) standards;
- [Rules](https://www.legislation.gov.au/Details/F2023C00735) relating to consumer dashboards, consent, authorisation, amendments, notifications, and withdrawal; and
- proposed Dark Patterns requirements consulted on in a [joint DSB/TSY consultation](https://treasury.gov.au/consultation/c2023-434434-consent).

The outputs of this work will help inform the substance and direction of the consent review proposals relating to dark patterns.",2024-02-13T04:16:30Z,2024-02-13T04:17:16Z,open,0,"DSB (Data Standards Australia), dp education, DPs in CDR (comsumer data right)","CDR resistance to dp, ways to avoid it","DSB (Data Standards Australia), dark pattern education, avoid dark pattern","DPs prevention in software, DPs examples/definitions",,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/nikshepmp/GithubNikshep/issues/1,Dark Pattern Detection - OGC,https://github.com/nikshepmp/GithubNikshep/issues/1,"Designing and prototyping an innovative app or software to detect dark patterns on e-commerce platforms involves several key components. Here's a conceptual overview:

### App Name: OGC 

#### Key Features:

1. **User-friendly Interface:**
   - A clean and intuitive interface for easy navigation.
   - Dashboard displaying an overview of detected dark patterns.

2. **Dark Pattern Detection:**
   - Utilizes machine learning algorithms to analyze website interfaces.
   - Recognizes common dark patterns, such as misleading information, urgency tactics, and hidden costs.

3. **Type and Scale Identification:**
   - Categorizes detected dark patterns into types (e.g., urgency, misdirection, forced continuity).
   - Provides a severity scale indicating the potential impact on user experience.

4. **Real-time Monitoring:**
   - Constantly monitors user interactions during online shopping.
   - Alerts users in real-time if a potential dark pattern is identified.

5. **Transparent Explanations:**
   - Provides clear explanations of detected dark patterns and their implications.
   - Offers educational content on recognizing and avoiding such patterns.

6. **Customization Options:**
   - Allows users to customize detection preferences based on personal tolerance levels.
   - Enables users to report new or unidentified dark patterns for future updates.

7. **Browser Extension Integration:**
   - Offers a browser extension for seamless integration with popular web browsers.
   - Allows users to enable/disable monitoring based on their preferences.

8. **Data Privacy and Security:**
   - Prioritizes user privacy by anonymizing and securing collected data.
   - Clearly communicates the app's data usage policies and adheres to privacy regulations.

9. **User Feedback Mechanism:**
   - Includes a feedback system for users to report false positives/negatives.
   - Regularly updates the algorithm based on user feedback and emerging dark pattern trends.

10. **Educational Resources:**
    - Integrates tutorials and resources on recognizing ethical e-commerce practices.
    - Collaborates with consumer rights organizations to provide up-to-date information.

#### Prototype Overview:

1. **Homepage:**
   - Overview of recent detections and user-specific alerts.
   - Quick access to settings, reports, and educational resources.

2. **Detection Dashboard:**
   - Visual representation of detected dark patterns.
   - Drill-down options for detailed analysis.

3. **Real-time Alerts:**
   - Pop-up notifications and in-app alerts for real-time detection.
   - User-friendly explanations for each alert.

4. **Settings:**
   - Customization options for detection sensitivity.
   - Preferences for receiving alerts (e.g., notifications, emails).

5. **Reports and History:**
   - Historical data on detected dark patterns and user interactions.
   - Trends and insights for users to track improvements in e-commerce ethics.

6. **Educational Section:**
   - Tutorials, articles, and videos on understanding and avoiding dark patterns.
   - Integration with ethical shopping guides.

#### Next Steps:

1. **Usability Testing:**
   - Conduct usability testing to refine the user interface and overall user experience.

2. **Integration Partnerships:**
   - Establish partnerships with e-commerce platforms for seamless integration.

3. **Security Audits:**
   - Conduct thorough security audits to ensure user data privacy and app security.

4. **Continuous Improvement:**
   - Regularly update the app's database and algorithms based on emerging dark pattern trends and user feedback.

By incorporating these features and considerations, EthicalShopGuard aims to empower users to make informed and ethical choices while promoting transparency in the e-commerce landscape.",2023-12-30T13:07:16Z,2023-12-30T13:07:16Z,open,0,"DP detection tool, e-commerce platforms",spec for tool to detect dp,"detection, e-commerce",DPs detection Tools,,,DPs examples/definitions,dps examples/definitions,,,
https://api.github.com/repos/Anukool99/Oliver-The-dark-pattern-detection-extension/issues/4,#4 ML Models for Detecting Dark Patterns,https://github.com/Anukool99/Oliver-The-dark-pattern-detection-extension/issues/4,"- [x] Identify faults in current
- [x] #11
- [ ] #14
- [x] Integrate scrapped data with current data to create balanced dataset/Use OpenSource Dataset
- [ ] #12
- [ ] Define and validate metrics to check the dataset
- [ ] Implement with LLMs and check differences in speed and performance
- [ ] Integration with backend",2024-02-01T04:48:39Z,2024-02-05T17:19:16Z,open,1,"detection tool, machine learning models, ",tool to detect dp,"detection, machine learning models",DPs detection Tools,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/OpenWebAdvocacy/OpenWebCompetitionPlatform/issues/12,Dark patterns installing 3rd party browsers in Edge,https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/issues/12,"### Description

When a user installs a 3rd party browser in Microsoft Edge there are various banners and pop-ups in the UI designed to scare users away from downloading and installing another browser.

- Prominent search ad when searching for many other browsers using Bing
- Tool tip pop-up when on the download page of Chrome
- Banner inserted into website after downloading Chrome
- Survey opened in sidebar after downloading Chrome

In order:

The same happens when searching for many 3rd party browsers by name, including ""Chrome"", ""Vivaldi"", ""UC Browser"", ""Tor Browser"", ""Maxthon"", ""Safari"" and ""Chromium"". This also happens irrespecive of whether you are using Bing in Edge or in other browsers.
![Microsoft Edge Search - Browser](https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/36278229/cd000800-28a2-424e-b142-9cda4b8d7e20)
![Microsoft Edge - Chrome Download Page 1](https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/36278229/b803ed09-33ee-4ffe-812c-6d675e353b24)
![Microsoft Edge - Chrome Download Page 2](https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/36278229/a2fc4a90-e5c3-4dc1-97fb-ee9cde408949)
As well as reducing the space that can be used by the 3rd party browser's website, this survey encourages users to use the Microsoft recommended settings, which sets Edge to the default. It also links to other settings pages inside of Edge, keeping users inside the browser and away from the website containing instructions for setting up a 3rd party browser.
![Microsoft Edge - Chrome Download Page 2 Variant](https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/36278229/88bffaf5-083f-400c-959a-5b182dd1f7d2)

Compounding factors

- Most users who want to install a 3rd party browser on a new Windows 10/11 installation use Edge to do so
- Edge uses Bing as its default search engine
- Chrome is the most popular browser on Windows with well over a majority marketshare

The combination of these factors mean that most users who install a 3rd party browser on Windows will be exposed to at least the first of these dark patterns, if not all of them.

### Outcome

- Microsoft Edge and Bing remove all banners, pop-ups and other promotional material that aim to disuade users from downloading a 3rd party browser.
- Ensure that future advertising/promotion of Edge can only be done in the same areas that other browser vendors have the opportunity to advertise in, such as standard search engine ads, and is in no way prioritised over that of competitors.",2024-02-05T00:39:05Z,2024-02-05T13:19:50Z,open,0,"Microsoft Edge, usage of dp in software, banners and pop-ups when installing 3rd party browser, nagging ","Edge, downloading 3rd party browsers, obstruction ","Microsoft Edge, pop-ups, nagging, obstruction",DPs used in software,,,DPs used in software,dps used in software,,,
https://api.github.com/repos/OpenWebAdvocacy/OpenWebCompetitionPlatform/issues/5,Dark Pattern in Default Browser Choice Selector on iOS,https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/issues/5,"### Description

iOS employs a clear dark pattern in order to:

1. Ensure it is difficult for users to change the default browser if it is set to Safari
2. Ensure it is easier for users to change the default browser back to Safari if another browser is the default

#### Details
The following image compares the settings page of Safari when it is the default browser and when it is not. When Safari is the default browser the **default browser choice is hidden**, but when Safari is not the default browser the choice appears.

<img width=""540"" alt=""image"" src=""https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/11502425/992f1532-aeed-49f6-9e1f-347377ae7cb1"">

For all other browsers the default browser choice selection is always shown:
<img width=""523"" alt=""image"" src=""https://github.com/OpenWebAdvocacy/OpenWebCompetitionPlatform/assets/11502425/6fb1d8fb-d5ea-4746-b21b-5b774b31c7fb"">

#### Compounding Issues

The issue is compounded by:
1. Third-party browsers cannot prompt users to change the default.
2. Third-party browsers cannot detect whether they are the default.
3. Safari's settings are prominently positioned on the iOS settings page compared to third party browsers.
4. Searching for ""default"" or ""default browser"" in settings yields no results.
5. There is no centralized location for changing default apps (including browsers) on iOS.

Combined, these factors significantly restrict users' free choice in selecting and switching between their choice of browser.

### Outcome

This issue is to document and then track the removal of this dark pattern.

The exact outcomes we would expect are listed in other issues including:
1. A centralised location with a browser-vendor-neutral UI in settings to remove the default browser.
2. The ability of browsers to ask the user to set their browser as the default.
3. The ability of browsers to detect if they are the default browser.
4. Ensuring that Safari settings are placed alongside with all the other apps and do not receive a privileged position in the settings list.
5. Ensuring that searching for ""default"" or ""default browser"" in settings displays the appropriate settings.",2024-01-25T03:49:28Z,2024-01-25T03:50:42Z,open,0,"iOS, usage of dp in software, Default Browser Choice Selector, obstruction","default browser in iOS, obstruction, sneaking","iOS, default, obstruction",DPs used in software,,,,,,,
https://api.github.com/repos/microsoft/vscode-dotnettools/issues/985,[SUGGESTION] Disable telemetry,https://github.com/microsoft/vscode-dotnettools/issues/985,"### Describe the feature you'd like

I would like to opt out of telemetry.

### Alternatives considered

Preferably make the telemetry OPT-IN instead of OPT-OUT.  
Do not use dark patterns, be ethical.

### Environment Information

multiple weird `values.xml` files. That keeps reappearing even when deleted.",2024-03-13T07:39:27Z,2024-03-19T01:11:31Z,open,1,"vscode, prevention of dark pattern, telemetry disabled, opt-in/out","telemetry, preselection","VSCode, telemetry, preselection, opt-in/out, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/SecOpsNews/news/issues/24260,[RegisterSoftware] Mozilla slams Microsoft for using dark patterns to drive Windows users toward Edge,https://github.com/SecOpsNews/news/issues/24260,"

#### Asks why only one Bing ad – the one you see when searching for other browsers – looks like a Windows popup

Mozilla on Thursday accused Microsoft of forcing its Edge browser down the throats of Windows users through ""dark patterns"" – design elements geared to push people towards certain decisions.…



<https://go.theregister.com/feed/www.theregister.com/2024/02/02/mozilla_slams_microsoft_dark_patterns/>

",2024-02-02T07:48:53Z,2024-02-02T07:48:54Z,open,0,"Mozilla accused/slamed Microsoft of using dp to drive Windows users toward Edge, usage of dp in software",examples of how Microsoft forces to use Edge,"Microsoft, Edge, forced action",DPs used in software,,,,,,,
https://api.github.com/repos/coder/coder/issues/10373,"Dark pattern: notifying security issues disabled, when telemetry is disabled ",https://github.com/coder/coder/issues/10373,"Original implementation:
https://github.com/coder/coder/pull/10354/files#diff-97adc2e016c98e027e50edbef66f4579501cc0e631d631cbabb3c752be0dd5ecR38

Just because telemetry is disabled doesn’t mean it should be impossible to subscribe to security notifications.",2023-10-21T12:23:12Z,2023-10-23T10:54:13Z,open,1,"prevention of dp in software, security notifications","telemetry, security concerns, concern of dp","telemetry, privacy issues, notifications, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/Tanuron/repo/issues/4,Create aboutpage,https://github.com/Tanuron/repo/pull/4,"includes
about, types of dark pattern,hall of shame",2024-01-16T16:37:23Z,2024-01-16T16:37:23Z,open,0,"dark pattern education, about page, types of DP, hall of shame",,"dark pattern education, hall of shame",DPs examples/definitions,,,,,,,
https://api.github.com/repos/SecOpsNews/news/issues/18538,[RegisterSoftware] India warns ecommerce 'basket sneaks' and 'confirm shamers' their days are numbered,https://github.com/SecOpsNews/news/issues/18538,"

#### Floats draft guidelines prohibiting 'dark patterns' developed with help from Amazon, Google, and Meta

The Indian government has commenced a consultation on how to regulate – and possibly prohibit – tricky tactics called ""dark patterns"" designed to fool consumers as they transact online.…



<https://go.theregister.com/feed/www.theregister.com/2023/09/08/india_dark_pattern_prohibition_draft/>

",2023-09-08T02:36:09Z,2023-09-08T02:36:09Z,open,0,"India, government regulation on dp usage in e-commerce, sneaking basket, comfirmshamers, Amazon, Google, Meta",examples of confirm shaming in shopping,"regulation, India, e-commerce, confirmshaming, sneaking into basket, Amazon, Meta","DPs used in software, DPs related regulation ",,,,,,,
https://api.github.com/repos/Flocloud9/GCC-3v-Cellphone-Rumble/issues/3,Please add STEP Files!!!,https://github.com/Flocloud9/GCC-3v-Cellphone-Rumble/issues/3,"I can not believe that a bracket designed for an open source board posted to be supposedly open source only has a proprietary file format used for source file...

Shapr3D is an absolute garbage pile. I had to go through a 5min tutorial that is impossible to skip, teaching me shit I already know from every other damn CAD. Then you have to sign up for an account and even then I can't export the model as a step file without a Subscription! You can't even export a quality 3mf or stl which is just insane. I'm not signing up for a free trial either and giving them a credit card just for them to charge when I forget!! These are hard core dark patterns I don't even want this software on my computer.

![image](https://github.com/Flocloud9/GCC-3v-Cellphone-Rumble/assets/26284634/2ddf002b-159d-4cee-bc06-767f48f45127)


It is clear based on the quality of the stl's you personally must own a license to Shapr3D so could I beg you to please export the project as step files so that others can import it into ANY CAD software?

The stl isn't enough I really don't want to deal with all these tri's.
![image](https://github.com/Flocloud9/GCC-3v-Cellphone-Rumble/assets/26284634/657aea0f-0604-4586-8abb-a1394c1d3ee4)
",2024-03-18T04:49:25Z,2024-03-18T05:00:04Z,open,1,"Shapr3D, usage of dp in software, forced action, sign-up required, ","forced continuity, unnecessary steps, obstruction, misdiretion","Shapr3D, forced action, signup/log-in required, obstruction",DPs used in software,,,,,,,
https://api.github.com/repos/teekamsuthar/Mutify/issues/11,Mutify is everything software should be.,https://github.com/teekamsuthar/Mutify/issues/11,"I've lived through a lot, I've written a lot of code which has impacted a lot of lives. I've left a google review, however I need to communicate this and I've been drinking so here we go.

This software is the greatest thing the human race has produced in decades when measured in terms of net benefit.

Sure writing Spotify is an effort, however software is about enriching lives and advancing the human condition. Not dark patterns and monopolies. Writing Napster was an effort too, a place I discovered much rare and now impossible to find music.

Nothing I have seen in multiple decades of software engineering meets this goal of human enrichment like Mutify.

This may be noise when considered as an ""issue"" but I wished to use the platform of github to communicate to you just how much I think you've met the goal. A goal every one of us strive for when utilising our magical powers of software creation

This is the pinnacle of software development and you should be extraordinarily proud.

Great work!",2024-02-21T15:01:21Z,2024-03-09T10:38:32Z,open,1,"Mutify, against DPs application","example of dp free software, Mutify","Mutify, avoid dark pattern, examples",DPs prevention in software,,,,,,,
https://api.github.com/repos/RocketChat/Rocket.Chat/issues/31601,User limitation (25 user),https://github.com/RocketChat/Rocket.Chat/issues/31601,"I deployed the project on my localhost and am planning to deploy it on my own server. As far as I know, this is an open-source project, so it shouldn't be subject to any kind of limitation. However, for some reason, the app is restricted to only 25 users, even though I am not using Rocket.chat services. I am a little bit confused. is it paid service even if am using the open-source code?





PS: I was following this guide to deploy using Docker:
https://docs.rocket.chat/deploy/deploy-rocket.chat/deploy-with-docker-and-docker-compose",2024-02-01T13:39:20Z,2024-03-12T07:39:12Z,open,4,"rocket.chat, open-source project app, usage of dp in software, usage limitation","limitation of users, paid after a limit, obstruction, hidden costs","rocket.chat, trick users to buy paid prodcuts, hidden costs",DPs used in software,,,,,,,
https://api.github.com/repos/yhj-zone/hackernews-daily/issues/124,Hacker News Daily Point Above 100 @2024-02-24,https://github.com/yhj-zone/hackernews-daily/issues/124,"1. **[Meta's new LLM-based test generator is a sneak peek to the future of development](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator)** | [comments](https://news.ycombinator.com/item?id=39486717)

2. **[Tell HN: Equifax free credit report dark patterns](https://news.ycombinator.com/item?id=39485259)** | [comments](https://news.ycombinator.com/item?id=39485259)

3. **[Scuttlebutt social network: a decentralised platform](https://scuttlebutt.nz/)** | [comments](https://news.ycombinator.com/item?id=39484907)

4. **[AMD ROCm Software Blogs](https://rocm.blogs.amd.com/)** | [comments](https://news.ycombinator.com/item?id=39484321)

5. **[Show HN: OK-Robot: open, modular home robot framework for pick-and-drop anywhere](https://ok-robot.github.io/)** | [comments](https://news.ycombinator.com/item?id=39483482)

6. **[Why Writing by Hand Is Better for Memory and Learning](https://www.scientificamerican.com/article/why-writing-by-hand-is-better-for-memory-and-learning/)** | [comments](https://news.ycombinator.com/item?id=39482641)

7. **[Mamba: The Easy Way](https://jackcook.com/2024/02/23/mamba.html)** | [comments](https://news.ycombinator.com/item?id=39482428)

8. **[Leaked Files Show the Secret World of China's Hackers for Hire](https://www.nytimes.com/2024/02/22/business/china-leaked-files.html)** | [comments](https://news.ycombinator.com/item?id=39482246)

9. **[Certain dogs are capable of learning the names for more than 100 different toys](https://www.scientificamerican.com/article/dog-language-geniuses-are-rare-but-apparently-real/)** | [comments](https://news.ycombinator.com/item?id=39481805)

10. **[I Spent a Week with Gemini Pro 1.5–It's Fantastic](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic)** | [comments](https://news.ycombinator.com/item?id=39481670)

11. **[Gemma.cpp: lightweight, standalone C++ inference engine for Gemma models](https://github.com/google/gemma.cpp)** | [comments](https://news.ycombinator.com/item?id=39481554)

12. **[German Bundestag Passes Cannabis Legalization](https://www.bundestag.de/dokumente/textarchiv/2024/kw08-de-cannabis-990684)** | [comments](https://news.ycombinator.com/item?id=39481188)

13. **[Nvidia hits $2T valuation as AI frenzy grips Wall Street](https://www.reuters.com/technology/global-markets-marketcap-pix-2024-02-23/)** | [comments](https://news.ycombinator.com/item?id=39481131)

14. **[I don't think the cheapest APC Back-UPS units can be monitored except in Windows](https://strugglers.net/~andy/blog/2024/02/23/i-dont-think-the-cheapest-apc-back-ups-units-can-be-monitored-except-in-windows/)** | [comments](https://news.ycombinator.com/item?id=39480751)

15. **[After 14 years in the industry, I still find programming difficult](https://www.piglei.com/articles/en-programming-is-still-hard-after-14-years/)** | [comments](https://news.ycombinator.com/item?id=39480605)

16. **[High Interest Savings Leaderboard](https://www.highinterest.io/)** | [comments](https://news.ycombinator.com/item?id=39480513)

17. **[Satoshi – Sirius emails 2009-2011](https://mmalmi.github.io/satoshi/)** | [comments](https://news.ycombinator.com/item?id=39480407)

18. **[Jim Keller criticizes Nvidia's CUDA, x86](https://www.tomshardware.com/tech-industry/artificial-intelligence/jim-keller-criticizes-nvidias-cuda-and-x86-cudas-a-swamp-not-a-moat-x86-was-a-swamp-too)** | [comments](https://news.ycombinator.com/item?id=39480341)

19. **[Beyond A*: Better Planning with Transformers](https://arxiv.org/abs/2402.14083)** | [comments](https://news.ycombinator.com/item?id=39479478)

20. **[Thanks FedEx, this is why we keep getting phished](https://www.troyhunt.com/thanks-fedex-this-is-why-we-keep-getting-phished/)** | [comments](https://news.ycombinator.com/item?id=39479001)

",2024-02-24T00:30:14Z,2024-02-24T00:30:15Z,open,0,"Hacker News Daily, resources of dark pattern, docs",examples in free credit reports,"documentation, examples","Papers/Docs/Sources, DPs examples/definitions",,,,,,,
https://api.github.com/repos/mozilla/platform-tilt/issues/31,Azure AD authentication only works with Edge user agents on mobile,https://github.com/mozilla/platform-tilt/issues/31,"Steps to reproduce:

1. Try to sign in to a Azure AD/Entra protected service/app with a non-MS Edge browser (e.g. Fennec 119.1.0 on Android or Firefox 115.6.0esr on openSUSE) on a mobile device
2. Error appears ""You can't get there from here""
3. Set user agent to Edge - in Firefox about:config option general.useragent.override (for example: ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0."")
4. Re-try to login
5. It works!

I suppose this is caused by a setting that IT departments are tricked into/suggested to set for ""more security"" when configuring Azure AD/Entra - aka dark patterns. As it obviously only relies on the user agent it doesn't provide any improved security and clearly was introduced to rule out other browsers and to increase the use of MS Edge.

",2024-01-23T21:28:12Z,2024-01-23T21:28:12Z,open,0,"Azure AD/Entra, usage of dp in software, forced action, restricted authentication","Azure AD authentication, only works with Edge, redirection, obstruction","Azure AD/Entra, Edge, obstruction, forced action",DPs used in software,,,,,,,
https://api.github.com/repos/upbeatDiamond/project-daybreak-gd4/issues/2,Which network overlay should this project use for multiplayer?,https://github.com/upbeatDiamond/project-daybreak-gd4/issues/2,"Consider the following, or any similar apps to the following:
- I2P
- InterPlanetary File System (IPFS)
- GNUnet
- Seedbox
- Freenet / Hyphanet
- Retroshare

I was thinking about writing up something quick, but seeing as I'm currently busying myself with language parsing, pathfinding, and the mere concept of multiplayer, I don't have time or skill enough to create and then distribute a solution.

The ideal multiplayer interface would enable LAN, F2F, and after passing through some dark patterns, WAN P2P.

The solution should be fast enough to carry all packets regarding player movements, battle requests, etc, but solid enough that I can play with anyone and not be able to tell where they live more precisely than what hemisphere they're *likely* playing in.

It needs to carry both remote procedure calls (Godot functions send via interweb), and allow for chat and map sharing, which is allowed to be a lot slower.",2023-12-17T04:29:03Z,2023-12-17T04:40:36Z,open,1,"usage of dark pattern, WAN P2P (wide area network peer to peer) connectivity in a multiplayer interface","game, multiplayers, easy selection","WAN P2P, gaming",DPs used in software,,,,,,,
https://api.github.com/repos/SecOpsNews/news/issues/18924,[HackerNews] Retool Falls Victim to SMS-Based Phishing Attack Affecting 27 Cloud Clients,https://github.com/SecOpsNews/news/issues/18924,"

Software development company Retool has disclosed that the accounts of 27 of its cloud customers were compromised following a targeted and SMS-based social engineering attack.
The San Francisco-based firm blamed a Google Account cloud synchronization feature recently introduced in April 2023 for making the breach worse, calling it a ""dark pattern.""
""The fact that Google Authenticator syncs to



<https://thehackernews.com/2023/09/retool-falls-victim-to-sms-based.html>

",2023-09-18T07:10:16Z,2023-09-18T07:10:17Z,open,0,,"SMS phishing, Google account",,,,,,,,,
https://api.github.com/repos/mozilla/pontoon/issues/3110,Add specs for Email consent opt-in and Unsubscribe page,https://github.com/mozilla/pontoon/pull/3110,Fixes #3109,2024-02-21T22:55:22Z,2024-03-18T21:02:45Z,open,7,"Pontoon (translation management system developed by the Mozilla localization community), prevetion of df in software, nagging of opt-in","consent opt-in, nagging","Pontoon, consent, nagging, opt-in/out, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/getcursor/cursor/issues/1052,Don't automatically update the default program for file extensions,https://github.com/getcursor/cursor/issues/1052,"I thought I'd try out `Cursor` for a couple of minutes.
I then noticed that all coding related file-extensions now have cursor as their default program.
Don't do that without asking.",2023-11-07T12:11:48Z,2023-12-04T15:50:59Z,open,5,"Cursor (AI code editor), preselection, override default applications choice","don't update default settings for extensions, override, preselection","Cursor, preselection, default",DPs examples/definitions,,,,,,,
https://api.github.com/repos/lgarron/folderify/issues/84,Get SourceForge to take down their unsanctioned mirror,https://github.com/lgarron/folderify/issues/84,"`https://sourceforge.net/projects/folderify.mirror/` seems to have a bunch of dark patterns in service of getting you to visit and see ads/use their services. There's a disclaimer rendered in tiny text, but it's significantly outweighed by a lot of other bright UI elements and the only link to the project page is a buried link to the ""folderify Web Site"" under a section called ""Follow folderify"".

The page is jumbled, with:

- a project icon that is a blurry picture of the word ""folderify"",
- a description consisting of sentences from different sections of `README.md` mashed together arbitrarily,
- unrelated bullet points grouped as ""features"",
- screenshots listed as ""project samples"",
- ""Additional Project Details"" that list the programming language as Python even though there isn't a single line of Python left in the project source, and
- no install instructions, but
- numerous downloads of the source code that are useless to the kind of people who wouldn't already know how to find the project on GitHub,
- where the download seems to be throttled by a 5-second speed bump to show you more ads.

<details>
<img src=""https://github.com/lgarron/folderify/assets/248078/c5a2805d-6f78-4f21-879e-fc4a6ae19177"">
</details>

I have no problem denouncing this as garbage, but a small mercy seems to be that no one is downloading or leaving ""reviews"" there. It also looks like the downloads include any ""value added"" beyond the project source, or any sketchy installers.

I'd still like to get it taken down, because this is a clear SEO grab that doesn't actually help users. If someone knows the most effective to take it down way I'd love to hear, else I'll have to figure out how to poke them some time.",2024-01-15T07:59:06Z,2024-01-15T08:02:21Z,open,0,"SourceForge, usage of dp in software, ads everywhere","ads, force hierarchy by design in webiste","SourceForge, ads, design hierarchy, deceptive design practices",DPs used in software,,,,,,,
https://api.github.com/repos/meixger/hackernews-daily/issues/525,Hacker News Daily Top 30 @2024-02-24,https://github.com/meixger/hackernews-daily/issues/525,"1. [**Thanks FedEx, this is why we keep getting phished** <code>www.troyhunt.com</code>](https://www.troyhunt.com/thanks-fedex-this-is-why-we-keep-getting-phished/) - [510 comments 1546 points](https://news.ycombinator.com/item?id=39479001)
2. [**Show HN: OK-Robot: open, modular home robot framework for pick-and-drop anywhere** <code>ok-robot.github.io</code>](https://ok-robot.github.io/) - [92 comments 438 points](https://news.ycombinator.com/item?id=39483482)
3. [**Gemma.cpp: lightweight, standalone C++ inference engine for Gemma models** <code>github.com</code>](https://togithub.com/google/gemma.cpp) - [123 comments 359 points](https://news.ycombinator.com/item?id=39481554)
4. [**Satoshi – Sirius emails 2009-2011** <code>mmalmi.github.io</code>](https://mmalmi.github.io/satoshi/) - [351 comments 354 points](https://news.ycombinator.com/item?id=39480407)
5. [**Intel Processor Instability Causing Oodle Decompression Failures** <code>www.radgametools.com</code>](https://www.radgametools.com/oodleintel.htm) - [218 comments 346 points](https://news.ycombinator.com/item?id=39478551)
6. [**Beyond A*: Better Planning with Transformers** <code>arxiv.org</code>](https://arxiv.org/abs/2402.14083) - [116 comments 291 points](https://news.ycombinator.com/item?id=39479478)
7. [**German Bundestag Passes Cannabis Legalization** <code>www.bundestag.de</code>](https://www.bundestag.de/dokumente/textarchiv/2024/kw08-de-cannabis-990684) - [212 comments 248 points](https://news.ycombinator.com/item?id=39481188)
8. [**Meta's new LLM-based test generator is a sneak peek to the future of development** <code>read.engineerscodex.com</code>](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator) - [122 comments 241 points](https://news.ycombinator.com/item?id=39486717)
9. [**Mamba: The Easy Way** <code>jackcook.com</code>](https://jackcook.com/2024/02/23/mamba.html) - [55 comments 236 points](https://news.ycombinator.com/item?id=39482428)
10. [**I Spent a Week with Gemini Pro 1.5–It's Fantastic** <code>every.to</code>](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic) - [193 comments 227 points](https://news.ycombinator.com/item?id=39481670)
11. [**GPT in 500 Lines of SQL** <code>explainextended.com</code>](https://explainextended.com/2023/12/31/happy-new-year-15/) - [15 comments 222 points](https://news.ycombinator.com/item?id=39488668)
12. [**A former Gizmodo writer changed name to 'Slackbot', stayed undetected for months** <code>www.theverge.com</code>](https://www.theverge.com/2024/2/23/24081249/slack-slackbot-gizmodo-tom-mckay) - [64 comments 213 points](https://news.ycombinator.com/item?id=39487341)
13. [**Certain dogs are capable of learning the names for more than 100 different toys** <code>www.scientificamerican.com</code>](https://www.scientificamerican.com/article/dog-language-geniuses-are-rare-but-apparently-real/) - [180 comments 211 points](https://news.ycombinator.com/item?id=39481805)
14. [**High Interest Savings Leaderboard** <code>www.highinterest.io</code>](https://www.highinterest.io/) - [209 comments 207 points](https://news.ycombinator.com/item?id=39480513)
15. [**Generative Models: What do they know? Do they know things? Let's find out** <code>intrinsic-lora.github.io</code>](https://intrinsic-lora.github.io/) - [52 comments 195 points](https://news.ycombinator.com/item?id=39487124)
16. [**After 14 years in the industry, I still find programming difficult** <code>www.piglei.com</code>](https://www.piglei.com/articles/en-programming-is-still-hard-after-14-years/) - [183 comments 191 points](https://news.ycombinator.com/item?id=39480605)
17. [**Jim Keller criticizes Nvidia's CUDA, x86** <code>www.tomshardware.com</code>](https://www.tomshardware.com/tech-industry/artificial-intelligence/jim-keller-criticizes-nvidias-cuda-and-x86-cudas-a-swamp-not-a-moat-x86-was-a-swamp-too) - [117 comments 190 points](https://news.ycombinator.com/item?id=39480341)
18. [**Tell HN: Equifax free credit report dark patterns** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=39485259) - [80 comments 179 points](https://news.ycombinator.com/item?id=39485259)
19. [**I don't think the cheapest APC Back-UPS units can be monitored except in Windows** <code>strugglers.net</code>](https://strugglers.net/~andy/blog/2024/02/23/i-dont-think-the-cheapest-apc-back-ups-units-can-be-monitored-except-in-windows/) - [226 comments 174 points](https://news.ycombinator.com/item?id=39480751)
20. [**Why Writing by Hand Is Better for Memory and Learning** <code>www.scientificamerican.com</code>](https://www.scientificamerican.com/article/why-writing-by-hand-is-better-for-memory-and-learning/) - [115 comments 170 points](https://news.ycombinator.com/item?id=39482641)
21. [**Scuttlebutt social network: a decentralised platform** <code>scuttlebutt.nz</code>](https://scuttlebutt.nz/) - [100 comments 170 points](https://news.ycombinator.com/item?id=39484907)
22. [**A 'scam manual' written to help immigrants not become victims** <code>www.atlasobscura.com</code>](https://www.atlasobscura.com/articles/columns-scam-guide-books-con-artists) - [85 comments 144 points](https://news.ycombinator.com/item?id=39481948)
23. [**Nvidia hits $2T valuation as AI frenzy grips Wall Street** <code>www.reuters.com</code>](https://www.reuters.com/technology/global-markets-marketcap-pix-2024-02-23/) - [257 comments 129 points](https://news.ycombinator.com/item?id=39481131)
24. [**Brave's AI assistant now integrates with PDFs and Google Drive** <code>brave.com</code>](https://brave.com/leo-docsupport/) - [114 comments 123 points](https://news.ycombinator.com/item?id=39478677)
25. [**Tauri 2.0 tries to make mobile apps crossplatform** <code>beta.tauri.app</code>](https://beta.tauri.app/guides/) - [35 comments 116 points](https://news.ycombinator.com/item?id=39485098)
26. [**Leaked Files Show the Secret World of China's Hackers for Hire** <code>www.nytimes.com</code>](https://www.nytimes.com/2024/02/22/business/china-leaked-files.html) - [29 comments 110 points](https://news.ycombinator.com/item?id=39482246)
27. [**AMD ROCm Software Blogs** <code>rocm.blogs.amd.com</code>](https://rocm.blogs.amd.com/) - [45 comments 108 points](https://news.ycombinator.com/item?id=39484321)
28. [**Please Make Your Table Headings Sticky** <code>btxx.org</code>](https://btxx.org/posts/Please_Make_Your_Table_Headings_Sticky/) - [21 comments 91 points](https://news.ycombinator.com/item?id=39488836)
29. [**PGlite – Postgres in WASM** <code>github.com</code>](https://togithub.com/electric-sql/pglite) - [16 comments 90 points](https://news.ycombinator.com/item?id=39477457)
30. [**Show HN: GPU Prices on eBay** <code>gpupricecompare.com</code>](https://gpupricecompare.com) - [74 comments 89 points](https://news.ycombinator.com/item?id=39477848)",2024-02-24T06:10:42Z,2024-02-24T06:10:42Z,open,0,"Hacker News Daily, resources of dark pattern, docs",examples in free credit reports,documentation,Papers/Docs/Sources,,,,,,,
https://api.github.com/repos/microsoft/lisa/issues/3086,Print only missing requirements or features in 'No available VM size' error spew,https://github.com/microsoft/lisa/issues/3086,"LISA can throw an error and skip deployment if the environment requirements are not met based on the runbook or test requirements. The current error message is super verbose and not helpful for debugging what happened. An example:

```
deployment skipped: [""no available vm size found on 'westus3'.""], runbook: Environment(name='generated_2', topology='subnet', nodes_raw=None, nodes_requirement=[type:requirement,name:,default:False,count:1,core:[1,],mem:[512,],disk:has_resource_disk: None,os_disk_type: allowed:True,items:[DiskType.PremiumSSDLRS,DiskType.StandardHDDLRS,DiskType.StandardSSDLRS,DiskType.Ephemeral],data_disk_type: allowed:True,items:[DiskType.PremiumSSDLRS,DiskType.StandardHDDLRS,DiskType.StandardSSDLRS,DiskType.UltraSSDLRS],count: [0,],caching: None,iops: [0,],throughput: [0,],size: [0,],max_data_disk_count: None,disk_controller_type: allowed:True,items:[DiskControllerType.SCSI,DiskControllerType.NVME],network interface: data_path:allowed:False,items:[NetworkDataPath.Sriov,NetworkDataPath.Synthetic], nic_count:[1,], max_nic_count:[1,], gpu:[0,],f:allowed:True,items:[gen:1,SecurityProfileSettings(extended_schemas={}, type='Security_Profile', security_profile=allowed:False,items:[SecurityProfileType.CVM,SecurityProfileType.Standard,SecurityProfileType.SecureBoot], encrypt_disk=False, disk_encryption_set_id=''),disk_count:[0,],arch:x64],ef:None,NodeSpace(type='requirement')], _original_nodes_requirement=[type:requirement,name:,default:False,count:1,core:[1,],mem:[512,],disk:has_resource_disk: None,os_disk_type: allowed:True,items:[DiskType.PremiumSSDLRS,DiskType.StandardHDDLRS,DiskType.StandardSSDLRS,DiskType.Ephemeral],data_disk_type: allowed:True,items:[DiskType.PremiumSSDLRS,DiskType.StandardHDDLRS,DiskType.StandardSSDLRS,DiskType.UltraSSDLRS],count: [0,],caching: None,iops: [0,],throughput: [0,],size: [0,],max_data_disk_count: None,disk_controller_type: allowed:True,items:[DiskControllerType.SCSI,DiskControllerType.NVME],network interface: data_path:allowed:False,items:[NetworkDataPath.Sriov,NetworkDataPath.Synthetic], nic_count:[1,], max_nic_count:[1,], gpu:[0,],f:allowed:True,items:[gen:1,SecurityProfileSettings(extended_schemas={}, type='Security_Profile', security_profile=allowed:False,items:[SecurityProfileType.CVM,SecurityPro...
```
If there is a missing feature or a requirement which the environment isn't able to meet, LISA should only print the missing features/requirements instead of dumping the entire environment.

The current error message leads to dark patterns like just specifying 'maximize_capability' everywhere which can cause other problems like your test pass running test suites which the environment doesn't support.",2023-12-01T18:40:52Z,2023-12-01T18:40:52Z,open,0,"Linux Integration Services Automation (LISA), Linux quality validation system, verbose error message",code confusion,,,,,,,,,
https://api.github.com/repos/Mintplex-Labs/anything-llm/issues/753,[BUG]: Windows desktop app Get Started flow: Providing an email address isn't optional despite claim that it is,https://github.com/Mintplex-Labs/anything-llm/issues/753,"### How are you running AnythingLLM?

AnythingLLM desktop app

### What happened?

At the end of the Get Started flow, I'm presented with this screen:

![Screenshot 2024-02-18 163832](https://github.com/Mintplex-Labs/anything-llm/assets/429567/ac698901-e9ac-4280-9f59-26371a22ea41)

Despite the fact that the heading says ""Optional"", I cannot proceed with setup leaving the email field blank. Unless I fill in the email field, the arrow button to the right keeps popping up the admonition shown in the screenshot.

### Are there known steps to reproduce?

1. Download and run the desktop app installer for Windows.
2. Complete the setup process, choosing LLM, embeddings and vector store providers.
3. End up at the abovementioned screen.",2024-02-19T00:49:34Z,2024-02-19T18:00:21Z,closed,2,"AnythingLLM, usage of dp in software, forced action, forced email, dp in open source apps","opt-out without email confusing, sneaking","AnythingLLM, forced action, email required",DPs used in software,,,,,,,
https://api.github.com/repos/Opticos/GWSL-Source/issues/182,Is This Paid Now?,https://github.com/Opticos/GWSL-Source/issues/182,"Reviews around, the official website list this as a free program, but there's only a link to a gimpy overpriced Windows Store app.

I'd rather eat glass than sign in to use the Windows store.

So is this dead as a free project now?

Like, is the idea a bait and switch where you say it's 'free', but then it's a huge pain that requires a degree in computer science to build, and thus dark-pattern forces users into a purchase?",2024-02-06T03:53:10Z,2024-02-09T13:26:39Z,closed,0,"GWSL, usage of dp, bait-and-switch, promote to paid version","concern of bait and switch, paid app","GWSL, bait to switch, paid version",DPs used in software,,,,,,,
https://api.github.com/repos/meixger/hackernews-daily/issues/442,Hacker News Daily Top 30 @2023-12-03,https://github.com/meixger/hackernews-daily/issues/442,"1. [**Tiny volumetric display** <code>mitxela.com</code>](https://mitxela.com/projects/candle) - [136 comments 1128 points](https://news.ycombinator.com/item?id=38498109)
2. [**You don't need JavaScript for that** <code>www.htmhell.dev</code>](https://www.htmhell.dev/adventcalendar/2023/2/) - [312 comments 793 points](https://news.ycombinator.com/item?id=38497445)
3. [**No new boss at NSA until it answers questions on buying location, browsing data** <code>www.theregister.com</code>](https://www.theregister.com/2023/12/02/nsa_held_hostage/) - [179 comments 320 points](https://news.ycombinator.com/item?id=38498090)
4. [**Ancient redwoods recover from fire by sprouting 1000-year-old buds** <code>www.science.org</code>](https://www.science.org/content/article/ancient-redwoods-recover-fire-sprouting-1000-year-old-buds) - [99 comments 271 points](https://news.ycombinator.com/item?id=38497624)
5. [**Not a real engineer (2019)** <code>twitchard.github.io</code>](https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html) - [23 comments 218 points](https://news.ycombinator.com/item?id=38503486)
6. [**Ask HN: What are some unpopular technologies you wish people knew more about?** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=38499134) - [279 comments 213 points](https://news.ycombinator.com/item?id=38499134)
7. [**Infants understand language via rhythm and tone rather than individual sounds** <code>www.theguardian.com</code>](https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists) - [68 comments 185 points](https://news.ycombinator.com/item?id=38500906)
8. [**GQL – Git Query Language** <code>github.com</code>](https://togithub.com/AmrDeveloper/GQL) - [51 comments 177 points](https://news.ycombinator.com/item?id=38498688)
9. [**Easy to use OpenID Connect client and server library written for Go** <code>github.com</code>](https://togithub.com/zitadel/oidc) - [43 comments 154 points](https://news.ycombinator.com/item?id=38496264)
10. [**Is Ada safer than Rust?** <code>old.reddit.com</code>](https://old.reddit.com/r/rust/comments/17miqiu/is_ada_safer_than_rust/) - [96 comments 153 points](https://news.ycombinator.com/item?id=38498775)
11. [**Can't sign in with FIDO2 key on office.com** <code>bugzilla.mozilla.org</code>](https://bugzilla.mozilla.org/show_bug.cgi?id=1824831) - [68 comments 147 points](https://news.ycombinator.com/item?id=38502340)
12. [**Review: A Dive into Mikrotik's Weird SmartNIC (2022)** <code>alyx.sh</code>](https://alyx.sh/posts/mikrotiks-weird-smartnic/) - [36 comments 137 points](https://news.ycombinator.com/item?id=38496669)
13. [**Dark patterns in UX design and how to avoid them** <code>dodonut.com</code>](https://dodonut.com/blog/10-dark-patterns-in-ux-design/) - [54 comments 120 points](https://news.ycombinator.com/item?id=38499824)
14. [**Cicadas are so loud, fiber optic cables can ‘hear’ them** <code>www.wired.com</code>](https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/) - [50 comments 120 points](https://news.ycombinator.com/item?id=38500065)
15. [**Open-source drawing tool – Excalidraw** <code>github.com</code>](https://togithub.com/excalidraw/excalidraw) - [28 comments 115 points](https://news.ycombinator.com/item?id=38499375)
16. [**Why are we being DDoSed by Cloudflare?** <code>news.ycombinator.com</code>](https://news.ycombinator.com/item?id=38496357) - [48 comments 113 points](https://news.ycombinator.com/item?id=38496357)
17. [**EmacsConf Live Now** <code>emacsconf.org</code>](https://emacsconf.org) - [57 comments 108 points](https://news.ycombinator.com/item?id=38499197)
18. [**Generative AI is killing our sense of awe** <code>www.fastcompany.com</code>](https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe) - [128 comments 107 points](https://news.ycombinator.com/item?id=38499843)
19. [**Galactic algorithm** <code>en.wikipedia.org</code>](https://en.wikipedia.org/wiki/Galactic_algorithm) - [15 comments 103 points](https://news.ycombinator.com/item?id=38500782)
20. [**Submarine Cable Map 2023** <code>submarine-cable-map-2023.telegeography.com</code>](https://submarine-cable-map-2023.telegeography.com/) - [49 comments 101 points](https://news.ycombinator.com/item?id=38496816)
21. [**Mundane emotions: Losing yourself in boredom, time and technology (2022)** <code>journals.sagepub.com</code>](https://journals.sagepub.com/doi/10.1177/14705931221138617) - [16 comments 100 points](https://news.ycombinator.com/item?id=38500681)
22. [**UniFi Express** <code>ui.com</code>](https://ui.com/cloud-gateways/express) - [124 comments 99 points](https://news.ycombinator.com/item?id=38504027)
23. [**Scalable extraction of training data from (production) language models** <code>arxiv.org</code>](https://arxiv.org/abs/2311.17035) - [14 comments 98 points](https://news.ycombinator.com/item?id=38496715)
24. [**LibreChat – Enhanced ChatGPT Clone** <code>github.com</code>](https://togithub.com/danny-avila/LibreChat) - [16 comments 95 points](https://news.ycombinator.com/item?id=38502805)
25. [**How Meta patches Linux at hyperscale** <code>thenewstack.io</code>](https://thenewstack.io/how-meta-patches-linux-at-hyperscale/) - [70 comments 93 points](https://news.ycombinator.com/item?id=38501779)
26. [**Understanding Objective-C by transpiling it to C++** <code>www.jviotti.com</code>](https://www.jviotti.com/2023/12/01/understanding-objective-c-by-transpiling-it-to-cpp.html) - [58 comments 91 points](https://news.ycombinator.com/item?id=38498934)
27. [**Retinal cells that help stabilize our world view** <code>optometry.berkeley.edu</code>](https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/) - [20 comments 84 points](https://news.ycombinator.com/item?id=38501878)
28. [**Google Maps now looks more like Apple Maps** <code>www.techradar.com</code>](https://www.techradar.com/computing/software/google-maps-now-looks-more-like-apple-maps-and-a-lot-of-people-arent-happy) - [91 comments 83 points](https://news.ycombinator.com/item?id=38496867)
29. [**Factory construction boom in the US** <code>wolfstreet.com</code>](https://wolfstreet.com/2023/12/02/the-eyepopping-factory-construction-boom-in-the-us/) - [77 comments 75 points](https://news.ycombinator.com/item?id=38503462)
30. [**Designing a distributed SQL engine: Challenges and decisions** <code>en.oceanbase.com</code>](https://en.oceanbase.com/blog/2596985600) - [4 comments 75 points](https://news.ycombinator.com/item?id=38496702)",2023-12-03T06:11:05Z,2023-12-03T06:11:05Z,open,0,"Hacker News Daily, resources of dark pattern, docs",examples and how to avoid dp,documentation,Papers/Docs/Sources,,,,,,,
https://api.github.com/repos/LeeKyungwook/get-arxiv-noti/issues/926,"New submissions for Wed, 10 Jan 24",https://github.com/LeeKyungwook/get-arxiv-noti/issues/926,"## Keyword: detection
### Why is the User Interface a Dark Pattern? : Explainable Auto-Detection  and its Analysis
 - **Authors:** Authors: Yuki Yada, Tsuneo Matsumoto, Fuyuko Kido, Hayato Yamana
 - **Subjects:** Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2401.04119
 - **Pdf link:** https://arxiv.org/pdf/2401.04119
 - **Abstract**
 Dark patterns are deceptive user interface designs for online services that make users behave in unintended ways. Dark patterns, such as privacy invasion, financial loss, and emotional distress, can harm users. These issues have been the subject of considerable debate in recent years. In this paper, we study interpretable dark pattern auto-detection, that is, why a particular user interface is detected as having dark patterns. First, we trained a model using transformer-based pre-trained language models, BERT, on a text-based dataset for the automatic detection of dark patterns in e-commerce. Then, we applied post-hoc explanation techniques, including local interpretable model agnostic explanation (LIME) and Shapley additive explanations (SHAP), to the trained model, which revealed which terms influence each prediction as a dark pattern. In addition, we extracted and analyzed terms that affected the dark patterns. Our findings may prevent users from being manipulated by dark patterns, and aid in the construction of more equitable internet services. Our code is available at https://github.com/yamanalab/why-darkpattern.
### FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild
 - **Authors:** Authors: Zhi-Song Liu, Robin Courant, Vicky Kalogeiton
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2401.04210
 - **Pdf link:** https://arxiv.org/pdf/2401.04210
 - **Abstract**
 Automatically understanding funny moments (i.e., the moments that make people laugh) when watching comedy is challenging, as they relate to various features, such as body language, dialogues and culture. In this paper, we propose FunnyNet-W, a model that relies on cross- and self-attention for visual, audio and text data to predict funny moments in videos. Unlike most methods that rely on ground truth data in the form of subtitles, in this work we exploit modalities that come naturally with videos: (a) video frames as they contain visual information indispensable for scene understanding, (b) audio as it contains higher-level cues associated with funny moments, such as intonation, pitch and pauses and (c) text automatically extracted with a speech-to-text model as it can provide rich information when processed by a Large Language Model. To acquire labels for training, we propose an unsupervised approach that spots and labels funny audio moments. We provide experiments on five datasets: the sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive experiments and analysis show that FunnyNet-W successfully exploits visual, auditory and textual cues to identify funny moments, while our findings reveal FunnyNet-W's ability to predict funny moments in the wild. FunnyNet-W sets the new state of the art for funny moment detection with multimodal cues on all datasets with and without using ground truth information.
### RaceFixer -- An Automated Data Race Fixer
 - **Authors:** Authors: Sanjay Malakar, Tameem Bin Haider, Rifat Shahriar
 - **Subjects:** Software Engineering (cs.SE); Programming Languages (cs.PL)
 - **Arxiv link:** https://arxiv.org/abs/2401.04221
 - **Pdf link:** https://arxiv.org/pdf/2401.04221
 - **Abstract**
 Fixing software bugs has always been an essential and time-consuming process in software development. Fixing concurrency bugs has become especially critical in the multicore era. However, fixing concurrency bugs is challenging due to non-deterministic failures and tricky parallel reasoning. Beyond correctly fixing the original problem in the software, a good patch should also avoid introducing new bugs, degrading performance unnecessarily, or damaging software readability. Existing tools cannot automate the whole fixing process and provide good-quality patches. We present RaceFixer, a tool that automates the process of fixing one common type of concurrency bug: single-variable atomicity violations. RaceFixer starts from the bug reports of an existing bug-detection tool ThreadSanitizer. It augments these with static analysis to construct a suitable patch for each bug report. It tries to combine the patches of multiple bugs for better performance and code readability. Finally, we test RaceFixer on benchmarks from TheadSanitizer.
### SOAP: Cross-sensor Domain Adaptation for 3D Object Detection Using  Stationary Object Aggregation Pseudo-labelling
 - **Authors:** Authors: Chengjie Huang, Vahdat Abdelzad, Sean Sedwards, Krzysztof Czarnecki
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04230
 - **Pdf link:** https://arxiv.org/pdf/2401.04230
 - **Abstract**
 We consider the problem of cross-sensor domain adaptation in the context of LiDAR-based 3D object detection and propose Stationary Object Aggregation Pseudo-labelling (SOAP) to generate high quality pseudo-labels for stationary objects. In contrast to the current state-of-the-art in-domain practice of aggregating just a few input scans, SOAP aggregates entire sequences of point clouds at the input level to reduce the sensor domain gap. Then, by means of what we call quasi-stationary training and spatial consistency post-processing, the SOAP model generates accurate pseudo-labels for stationary objects, closing a minimum of 30.3% domain gap compared to few-frame detectors. Our results also show that state-of-the-art domain adaptation approaches can achieve even greater performance in combination with SOAP, in both the unsupervised and semi-supervised settings.
### Data-Agnostic Face Image Synthesis Detection Using Bayesian CNNs
 - **Authors:** Authors: Roberto Leyva, Victor Sanchez, Gregory Epiphaniou, Carsten Maple
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04241
 - **Pdf link:** https://arxiv.org/pdf/2401.04241
 - **Abstract**
 Face image synthesis detection is considerably gaining attention because of the potential negative impact on society that this type of synthetic data brings. In this paper, we propose a data-agnostic solution to detect the face image synthesis process. Specifically, our solution is based on an anomaly detection framework that requires only real data to learn the inference process. It is therefore data-agnostic in the sense that it requires no synthetic face images. The solution uses the posterior probability with respect to the reference data to determine if new samples are synthetic or not. Our evaluation results using different synthesizers show that our solution is very competitive against the state-of-the-art, which requires synthetic data for training.
### Robust Image Watermarking using Stable Diffusion
 - **Authors:** Authors: Lijun Zhang, Xiao Liu, Antoni Viros Martin, Cindy Xiong Bearfield, Yuriy Brun, Hui Guan
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04247
 - **Pdf link:** https://arxiv.org/pdf/2401.04247
 - **Abstract**
 Watermarking images is critical for tracking image provenance and claiming ownership. With the advent of generative models, such as stable diffusion, able to create fake but realistic images, watermarking has become particularly important, e.g., to make generated images reliably identifiable. Unfortunately, the very same stable diffusion technology can remove watermarks injected using existing methods. To address this problem, we present a ZoDiac, which uses a pre-trained stable diffusion model to inject a watermark into the trainable latent space, resulting in watermarks that can be reliably detected in the latent vector, even when attacked. We evaluate ZoDiac on three benchmarks, MS-COCO, DiffusionDB, and WikiArt, and find that ZoDiac is robust against state-of-the-art watermark attacks, with a watermark detection rate over 98% and a false positive rate below 6.4%, outperforming state-of-the-art watermarking methods. Our research demonstrates that stable diffusion is a promising approach to robust watermarking, able to withstand even stable-diffusion-based attacks.
### BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method  guided by multi-scale feature information aggregation
 - **Authors:** Authors: Yonghui Tan, Xiaolong Li, Yishu Chen, Jinquan Ai
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04330
 - **Pdf link:** https://arxiv.org/pdf/2401.04330
 - **Abstract**
 The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment metrics and evaluation effects of the model described in this paper on the publicly available datasets DSIFN-CD and S2Looking are the best when compared to other models.
### A Change Point Detection Integrated Remaining Useful Life Estimation  Model under Variable Operating Conditions
 - **Authors:** Authors: Anushiya Arunan, Yan Qin, Xiaoli Li, Chau Yuen
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)
 - **Arxiv link:** https://arxiv.org/abs/2401.04351
 - **Pdf link:** https://arxiv.org/pdf/2401.04351
 - **Abstract**
 By informing the onset of the degradation process, health status evaluation serves as a significant preliminary step for reliable remaining useful life (RUL) estimation of complex equipment. This paper proposes a novel temporal dynamics learning-based model for detecting change points of individual devices, even under variable operating conditions, and utilises the learnt change points to improve the RUL estimation accuracy. During offline model development, the multivariate sensor data are decomposed to learn fused temporal correlation features that are generalisable and representative of normal operation dynamics across multiple operating conditions. Monitoring statistics and control limit thresholds for normal behaviour are dynamically constructed from these learnt temporal features for the unsupervised detection of device-level change points. The detected change points then inform the degradation data labelling for training a long short-term memory (LSTM)-based RUL estimation model. During online monitoring, the temporal correlation dynamics of a query device is monitored for breach of the control limit derived in offline training. If a change point is detected, the device's RUL is estimated with the well-trained offline model for early preventive action. Using C-MAPSS turbofan engines as the case study, the proposed method improved the accuracy by 5.6\% and 7.5\% for two scenarios with six operating conditions, when compared to existing LSTM-based RUL estimation models that do not consider heterogeneous change points.
### Message-Passing Receiver for OCDM over Multi-Lag Multi-Doppler Channels
 - **Authors:** Authors: Yun Liu (1), Fei Ji (2), Miaowen Wen (2), Hua Qing (3) ((1) Guangdong University of Finance, Guangzhou, China, (2) South China University of Technology, Guangzhou, China, (3) Zhengzhou University of Light Industry, Zhengzhou, China)
 - **Subjects:** Information Theory (cs.IT); Signal Processing (eess.SP)
 - **Arxiv link:** https://arxiv.org/abs/2401.04358
 - **Pdf link:** https://arxiv.org/pdf/2401.04358
 - **Abstract**
 As a new candidate waveform for the next generation wireless communications, orthogonal chirp division multiplexing (OCDM) has attracted growing attention for its ability to achieve full diversity in uncoded transmission, and its robustness to narrow-band interference or impulsive noise. Under high mobility channels with multiple lags and multiple Doppler-shifts (MLMD), the signal suffers doubly selective (DS) fadings in time and frequency domain, and data symbols modulated on orthogonal chirps are interfered by each other. To address the problem of symbol detection of OCDM over MLMD channel, under the assumption that path attenuation factors, delays, and Doppler shifts of the channel are available, we first derive the closed-form channel matrix in Fresnel domain, and then propose a low-complexity method to approximate it as a sparse matrix. Based on the approximated Fresnel-domain channel, we propose a message passing (MP) based detector to estimate the transmit symbols iteratively. Finally, under two MLMD channels (an underspread channel for terrestrial vehicular communication, and an overspread channel for narrow-band underwater acoustic communications), Monte Carlo simulation results and analysis are provided to validate its advantages as a promising detector for OCDM.
### SoK: Facial Deepfake Detectors
 - **Authors:** Authors: Binh M. Le, Jiwon Kim, Shahroz Tariq, Kristen Moore, Alsharif Abuadbba, Simon S. Woo
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2401.04364
 - **Pdf link:** https://arxiv.org/pdf/2401.04364
 - **Abstract**
 Deepfakes have rapidly emerged as a profound and serious threat to society, primarily due to their ease of creation and dissemination. This situation has triggered an accelerated development of deepfake detection technologies. However, many existing detectors rely heavily on lab-generated datasets for validation, which may not effectively prepare them for novel, emerging, and real-world deepfake techniques. In this paper, we conduct an extensive and comprehensive review and analysis of the latest state-of-the-art deepfake detectors, evaluating them against several critical criteria. These criteria facilitate the categorization of these detectors into 4 high-level groups and 13 fine-grained sub-groups, all aligned with a unified standard conceptual framework. This classification and framework offer deep and practical insights into the factors that affect detector efficacy. We assess the generalizability of 16 leading detectors across various standard attack scenarios, including black-box, white-box, and gray-box settings. Our systematized analysis and experimentation lay the groundwork for a deeper understanding of deepfake detectors and their generalizability, paving the way for future research focused on creating detectors adept at countering various attack scenarios. Additionally, this work offers insights for developing more proactive defenses against deepfakes.
### Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using  Dimension Reduction Methods
 - **Authors:** Authors: Dongeon Kim, YeongHyeon Park
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04437
 - **Pdf link:** https://arxiv.org/pdf/2401.04437
 - **Abstract**
 Recent studies try to use hyperspectral imaging (HSI) to detect foreign matters in products because it enables to visualize the invisible wavelengths including ultraviolet and infrared. Considering the enormous image channels of the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be considered to reduce but those cannot ease the fundamental limitations, as follows: (1) latency of HSI capturing. (2) less explanation ability of the important channels. In this paper, to circumvent the aforementioned methods, one of the ways to channel reduction, on anomaly detection proposed HSI. Different from feature extraction methods (i.e., PCA or UMAP), feature selection can sort the feature by impact and show better explainability so we might redesign the task-optimized and cost-effective spectroscopic camera. Via the extensive experiment results with synthesized MVTec AD dataset, we confirm that the feature selection method shows 6.90x faster at the inference phase compared with feature extraction-based approaches while preserving anomaly detection performance. Ultimately, we conclude the advantage of feature selection which is effective yet fast.
### D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly  Detection
 - **Authors:** Authors: Justin Tebbe, Jawad Tayyub
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04463
 - **Pdf link:** https://arxiv.org/pdf/2401.04463
 - **Abstract**
 Diffusion models have found valuable applications in anomaly detection by capturing the nominal data distribution and identifying anomalies via reconstruction. Despite their merits, they struggle to localize anomalies of varying scales, especially larger anomalies like entire missing components. Addressing this, we present a novel framework that enhances the capability of diffusion models, by extending the previous introduced implicit conditioning approach Meng et al. (2022) in three significant ways. First, we incorporate a dynamic step size computation that allows for variable noising steps in the forward process guided by an initial anomaly prediction. Second, we demonstrate that denoising an only scaled input, without any added noise, outperforms conventional denoising process. Third, we project images in a latent space to abstract away from fine details that interfere with reconstruction of large missing components. Additionally, we propose a fine-tuning mechanism that facilitates the model to effectively grasp the nuances of the target domain. Our method undergoes rigorous evaluation on two prominent anomaly detection datasets VISA and BTAD, yielding state-of-the-art performance. Importantly, our framework effectively localizes anomalies regardless of their scale, marking a pivotal advancement in diffusion-based anomaly detection.
### Fighting Fire with Fire: Adversarial Prompting to Generate a  Misinformation Detection Dataset
 - **Authors:** Authors: Shrey Satapara, Parth Mehta, Debasis Ganguly, Sandip Modha
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04481
 - **Pdf link:** https://arxiv.org/pdf/2401.04481
 - **Abstract**
 The recent success in language generation capabilities of large language models (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset does not scale well because of the extensive manual effort required to annotate the data. In this paper, we propose an LLM-based approach of creating silver-standard ground-truth datasets for identifying misinformation. Specifically speaking, given a trusted news article, our proposed approach involves prompting LLMs to automatically generate a summarised version of the original article. The prompts in our proposed approach act as a controlling mechanism to generate specific types of factual incorrectness in the generated summaries, e.g., incorrect quantities, false attributions etc. To investigate the usefulness of this dataset, we conduct a set of experiments where we train a range of supervised models for the task of misinformation detection.
### A Novel Framework of K-repetition Grant-free Access via Diversity  Slotted Aloha (DSA)
 - **Authors:** Authors: Haoran Mei, Limei Peng, Pin-Han Ho
 - **Subjects:** Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04539
 - **Pdf link:** https://arxiv.org/pdf/2401.04539
 - **Abstract**
 This article introduces a novel framework of multi-user detection (MUD) for K-repetition grant-free non-orthogonal multiple access (K-GF-NOMA), called $\alpha$ iterative interference cancellation diversity slotted aloha ($\alpha$-IIC-DSA). The proposed framework targets at a simple yet effective decoding process where the AP can intelligently exploit the correlation among signals received at different resource blocks (RBs) so as to generate required multi-access interference (MAI) for realizing the signal-interference cancellation (SIC) based MUD. By keeping all operation and hardware complexity at the access point (AP), the proposed framework is applicable to the scenarios with random and uncoordinated access by numerous miniature mMTC devices (MTCDs). Numerical experiments are conducted to gain deep understanding on the performance of launching the proposed framework for K-GF-NOMA.
### Generic Knowledge Boosted Pre-training For Remote Sensing Images
 - **Authors:** Authors: Ziyue Huang, Mingming Zhang, Yuan Gong, Qingjie Liu, Yunhong Wang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04614
 - **Pdf link:** https://arxiv.org/pdf/2401.04614
 - **Abstract**
 Deep learning models are essential for scene classification, change detection, land cover segmentation, and other remote sensing image understanding tasks. Most backbones of existing remote sensing deep learning models are typically initialized by pre-trained weights obtained from ImageNet pre-training (IMP). However, domain gaps exist between remote sensing images and natural images (e.g., ImageNet), making deep learning models initialized by pre-trained weights of IMP perform poorly for remote sensing image understanding. Although some pre-training methods are studied in the remote sensing community, current remote sensing pre-training methods face the problem of vague generalization by only using remote sensing images. In this paper, we propose a novel remote sensing pre-training framework, Generic Knowledge Boosted Remote Sensing Pre-training (GeRSP), to learn robust representations from remote sensing and natural images for remote sensing understanding tasks. GeRSP contains two pre-training branches: (1) A self-supervised pre-training branch is adopted to learn domain-related representations from unlabeled remote sensing images. (2) A supervised pre-training branch is integrated into GeRSP for general knowledge learning from labeled natural images. Moreover, GeRSP combines two pre-training branches using a teacher-student architecture to simultaneously learn representations with general and special knowledge, which generates a powerful pre-trained model for deep learning model initialization. Finally, we evaluate GeRSP and other remote sensing pre-training methods on three downstream tasks, i.e., object detection, semantic segmentation, and scene classification. The extensive experimental results consistently demonstrate that GeRSP can effectively learn robust representations in a unified manner, improving the performance of remote sensing downstream tasks.
### On the Target Detection Performance of a Molecular Communication Network  with Multiple Mobile Nanomachines
 - **Authors:** Authors: Nithin V. Sabu, Abhishek K. Gupta
 - **Subjects:** Information Theory (cs.IT); Signal Processing (eess.SP)
 - **Arxiv link:** https://arxiv.org/abs/2401.04636
 - **Pdf link:** https://arxiv.org/pdf/2401.04636
 - **Abstract**
 A network of nanomachines (NMs) can be used to build a target detection system for a variety of promising applications. They have the potential to detect toxic chemicals, infectious bacteria, and biomarkers of dangerous diseases such as cancer within the human body. Many diseases and health disorders can be detected early and efficiently treated in the future by utilizing these systems. To fully grasp the potential of these systems, mathematical analysis is required. This paper describes an analytical framework for modeling and analyzing the performance of target detection systems composed of multiple mobile nanomachines of varying sizes with passive/absorbing boundaries. We consider both direct contact detection, in which NMs must physically contact the target to detect it, and indirect sensing, in which NMs must detect the marker molecules emitted by the target. The detection performance of such systems is calculated for degradable and non-degradable targets, as well as mobile and stationary targets. The derived expressions provide various insights, such as the effect of NM density and target degradation on detection probability.
### Mixture of multilayer stochastic block models for multiview clustering
 - **Authors:** Authors: Kylliann De Santiago, Marie Szafranski, Christophe Ambroise
 - **Subjects:** Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)
 - **Arxiv link:** https://arxiv.org/abs/2401.04682
 - **Pdf link:** https://arxiv.org/pdf/2401.04682
 - **Abstract**
 In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of multilayer Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The identifiability of the model parameters is established and a variational Bayesian EM algorithm is proposed for the estimation of these parameters. The Bayesian framework allows for selecting an optimal number of clusters and components. The proposed approach is compared using synthetic data with consensus clustering and tensor-based algorithms for community detection in large-scale complex networks. Finally, the method is utilized to analyze global food trading networks, leading to structures of interest.
### HiRace: Accurate and Fast Source-Level Race Checking of GPU Programs
 - **Authors:** Authors: John Jacobson, Martin Burtscher, Ganesh Gopalakrishnan
 - **Subjects:** Distributed, Parallel, and Cluster Computing (cs.DC)
 - **Arxiv link:** https://arxiv.org/abs/2401.04701
 - **Pdf link:** https://arxiv.org/pdf/2401.04701
 - **Abstract**
 Data races are egregious parallel programming bugs on CPUs. They are even worse on GPUs due to the hierarchical thread and memory structure, which makes it possible to write code that is correctly synchronized within a thread group while not being correct across groups. Thus far, all major data-race checkers for GPUs suffer from at least one of the following problems: they do not check races in global memory, do not work on recent GPUs, scale poorly, have not been extensively tested, miss simple data races, or are not dependable without detailed knowledge of the compiler. Our new data-race detection tool, HiRace, overcomes these limitations. Its key novelty is an innovative parallel finite-state machine that condenses an arbitrarily long access history into a constant-length state, thus allowing it to handle large and long-running programs. HiRace is a dynamic tool that checks for thread-group shared memory and global device memory races. It utilizes source-code instrumentation, thus avoiding driver, compiler, and hardware dependencies. We evaluate it on a modern calibrated data-race benchmark suite. On the 580 tested CUDA kernels, 346 of which contain data races, HiRace finds races missed by other tools without false alarms and is more than 10 times faster on average than the current state of the art, while incurring only half the memory overhead.
## Keyword: face recognition
There is no result 
## Keyword: augmentation
### Robust Calibration For Improved Weather Prediction Under Distributional  Shift
 - **Authors:** Authors: Sankalp Gilda, Neel Bhandari, Wendy Mak, Andrea Panizza
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2401.04144
 - **Pdf link:** https://arxiv.org/pdf/2401.04144
 - **Abstract**
 In this paper, we present results on improving out-of-domain weather prediction and uncertainty estimation as part of the \texttt{Shifts Challenge on Robustness and Uncertainty under Real-World Distributional Shift} challenge. We find that by leveraging a mixture of experts in conjunction with an advanced data augmentation technique borrowed from the computer vision domain, in conjunction with robust \textit{post-hoc} calibration of predictive uncertainties, we can potentially achieve more accurate and better-calibrated results with deep neural networks than with boosted tree models for tabular data. We quantify our predictions using several metrics and propose several future lines of inquiry and experimentation to boost performance.
### Deep Efficient Private Neighbor Generation for Subgraph Federated  Learning
 - **Authors:** Authors: Ke Zhang, Lichao Sun, Bolin Ding, Siu Ming Yiu, Carl Yang
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
 - **Arxiv link:** https://arxiv.org/abs/2401.04336
 - **Pdf link:** https://arxiv.org/pdf/2401.04336
 - **Abstract**
 Behemoth graphs are often fragmented and separately stored by multiple data owners as distributed subgraphs in many realistic applications. Without harming data privacy, it is natural to consider the subgraph federated learning (subgraph FL) scenario, where each local client holds a subgraph of the entire global graph, to obtain globally generalized graph mining models. To overcome the unique challenge of incomplete information propagation on local subgraphs due to missing cross-subgraph neighbors, previous works resort to the augmentation of local neighborhoods through the joint FL of missing neighbor generators and GNNs. Yet their technical designs have profound limitations regarding the utility, efficiency, and privacy goals of FL. In this work, we propose FedDEP to comprehensively tackle these challenges in subgraph FL. FedDEP consists of a series of novel technical designs: (1) Deep neighbor generation through leveraging the GNN embeddings of potential missing neighbors; (2) Efficient pseudo-FL for neighbor generation through embedding prototyping; and (3) Privacy protection through noise-less edge-local-differential-privacy. We analyze the correctness and efficiency of FedDEP, and provide theoretical guarantees on its privacy. Empirical results on four real-world datasets justify the clear benefits of proposed techniques.
### LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using  Adversarial Training
 - **Authors:** Authors: Khoi M.Le, Trinh Pham, Tho Quan, Anh Tuan Luu
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2401.04348
 - **Pdf link:** https://arxiv.org/pdf/2401.04348
 - **Abstract**
 Paraphrases are texts that convey the same meaning while using different words or sentence structures. It can be used as an automatic data augmentation tool for many Natural Language Processing tasks, especially when dealing with low-resource languages, where data shortage is a significant problem. To generate a paraphrase in multilingual settings, previous studies have leveraged the knowledge from the machine translation field, i.e., forming a paraphrase through zero-shot machine translation in the same language. Despite good performance on human evaluation, those methods still require parallel translation datasets, thus making them inapplicable to languages that do not have parallel corpora. To mitigate that problem, we proposed the first unsupervised multilingual paraphrasing model, LAMPAT ($\textbf{L}$ow-rank $\textbf{A}$daptation for $\textbf{M}$ultilingual $\textbf{P}$araphrasing using $\textbf{A}$dversarial $\textbf{T}$raining), by which monolingual dataset is sufficient enough to generate a human-like and diverse sentence. Throughout the experiments, we found out that our method not only works well for English but can generalize on unseen languages as well. Data and code are available at https://github.com/phkhanhtrinh23/LAMPAT.
### Towards Real-World Aerial Vision Guidance with Categorical 6D Pose  Tracker
 - **Authors:** Authors: Jingtao Sun, Yaonan Wang, Danwei Wang
 - **Subjects:** Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04377
 - **Pdf link:** https://arxiv.org/pdf/2401.04377
 - **Abstract**
 Tracking the object 6-DoF pose is crucial for various downstream robot tasks and real-world applications. In this paper, we investigate the real-world robot task of aerial vision guidance for aerial robotics manipulation, utilizing category-level 6-DoF pose tracking. Aerial conditions inevitably introduce special challenges, such as rapid viewpoint changes in pitch and roll. To support this task and challenge, we firstly introduce a robust category-level 6-DoF pose tracker (Robust6DoF). This tracker leverages shape and temporal prior knowledge to explore optimal inter-frame keypoint pairs, generated under a priori structural adaptive supervision in a coarse-to-fine manner. Notably, our Robust6DoF employs a Spatial-Temporal Augmentation module to deal with the problems of the inter-frame differences and intra-class shape variations through both temporal dynamic filtering and shape-similarity filtering. We further present a Pose-Aware Discrete Servo strategy (PAD-Servo), serving as a decoupling approach to implement the final aerial vision guidance task. It contains two servo action policies to better accommodate the structural properties of aerial robotics manipulation. Exhaustive experiments on four well-known public benchmarks demonstrate the superiority of our Robust6DoF. Real-world tests directly verify that our Robust6DoF along with PAD-Servo can be readily used in real-world aerial robotic applications.
### Phase-shifted remote photoplethysmography for estimating heart rate and  blood pressure from facial video
 - **Authors:** Authors: Gyutae Hwang, Sang Jun Lee
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04560
 - **Pdf link:** https://arxiv.org/pdf/2401.04560
 - **Abstract**
 Human health can be critically affected by cardiovascular diseases, such as hypertension, arrhythmias, and stroke. Heart rate and blood pressure are important biometric information for the monitoring of cardiovascular system and early diagnosis of cardiovascular diseases. Existing methods for estimating the heart rate are based on electrocardiography and photoplethyomography, which require contacting the sensor to the skin surface. Moreover, catheter and cuff-based methods for measuring blood pressure cause inconvenience and have limited applicability. Therefore, in this thesis, we propose a vision-based method for estimating the heart rate and blood pressure. This thesis proposes a 2-stage deep learning framework consisting of a dual remote photoplethysmography network (DRP-Net) and bounded blood pressure network (BBP-Net). In the first stage, DRP-Net infers remote photoplethysmography (rPPG) signals for the acral and facial regions, and these phase-shifted rPPG signals are utilized to estimate the heart rate. In the second stage, BBP-Net integrates temporal features and analyzes phase discrepancy between the acral and facial rPPG signals to estimate SBP and DBP values. To improve the accuracy of estimating the heart rate, we employed a data augmentation method based on a frame interpolation model. Moreover, we designed BBP-Net to infer blood pressure within a predefined range by incorporating a scaled sigmoid function. Our method resulted in estimating the heart rate with the mean absolute error (MAE) of 1.78 BPM, reducing the MAE by 34.31 % compared to the recent method, on the MMSE-HR dataset. The MAE for estimating the systolic blood pressure (SBP) and diastolic blood pressure (DBP) were 10.19 mmHg and 7.09 mmHg. On the V4V dataset, the MAE for the heart rate, SBP, and DBP were 3.83 BPM, 13.64 mmHg, and 9.4 mmHg, respectively.
### Low-Resource Vision Challenges for Foundation Models
 - **Authors:** Authors: Yunhua Zhang, Hazel Doughty, Cees G.M. Snoek
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04716
 - **Pdf link:** https://arxiv.org/pdf/2401.04716
 - **Abstract**
 Low-resource settings are well-established in natural language processing, where many languages lack sufficient data for machine learning at scale. However, low-resource problems are under-explored in computer vision. In this paper, we strive to address this gap and explore the challenges of low-resource image tasks with vision foundation models. Thus, we first collect a benchmark of genuinely low-resource image data, covering historic maps, circuit diagrams, and mechanical drawings. These low-resource settings all share the three challenges of data scarcity, fine-grained differences, and the distribution shift from natural images to the specialized domain of interest. While existing foundation models have shown impressive generalizability, we find they cannot transfer well to our low-resource tasks. To begin to tackle the challenges of low-resource vision, we introduce one simple baseline per challenge. Specifically, we propose to i) enlarge the data space by generative models, ii) adopt the best sub-kernels to encode local regions for fine-grained difference discovery and iii) learn attention for specialized domains. Experiments on the three low-resource data sources in our benchmark demonstrate our proposals already provide a better baseline than common transfer learning, data augmentation, and fine-grained methods. This highlights the unique characteristics and challenges of low-resource vision for foundation models that warrant further investigation. Project website: https://xiaobai1217.github.io/Low-Resource-Vision/.
### A Simple Baseline for Spoken Language to Sign Language Translation with  3D Avatars
 - **Authors:** Authors: Ronglai Zuo, Fangyun Wei, Zenggui Chen, Brian Mak, Jiaolong Yang, Xin Tong
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2401.04730
 - **Pdf link:** https://arxiv.org/pdf/2401.04730
 - **Abstract**
 The objective of this paper is to develop a functional system for translating spoken languages into sign languages, referred to as Spoken2Sign translation. The Spoken2Sign task is orthogonal and complementary to traditional sign language to spoken language (Sign2Spoken) translation. To enable Spoken2Sign translation, we present a simple baseline consisting of three steps: 1) creating a gloss-video dictionary using existing Sign2Spoken benchmarks; 2) estimating a 3D sign for each sign video in the dictionary; 3) training a Spoken2Sign model, which is composed of a Text2Gloss translator, a sign connector, and a rendering module, with the aid of the yielded gloss-3D sign dictionary. The translation results are then displayed through a sign avatar. As far as we know, we are the first to present the Spoken2Sign task in an output format of 3D signs. In addition to its capability of Spoken2Sign translation, we also demonstrate that two by-products of our approach-3D keypoint augmentation and multi-view understanding-can assist in keypoint-based sign language understanding. Code and models will be available at https://github.com/FangyunWei/SLRT
",2024-01-10T17:00:06Z,2024-01-10T17:00:06Z,open,0,"paper submisson, explainable auto-detection of dp in UI, transformer-based model, BERT, paper title: Why is the User Interface a Dark Pattern? : Explainable Auto-Detection and its Analysis",definitions and examples,"BERT, detection, dark pattern education","Papers/Docs/Sources, DPs detection Tools",,,,,,,
https://api.github.com/repos/consumer-reports-innovation-lab/data-rights-protocol/issues/73,Adding new CCPA rights as 'Issues',https://github.com/consumer-reports-innovation-lab/data-rights-protocol/issues/73,"These are the CCPA rights which are encoded in v0.9 of the protocol:

Regime 	Right 	            Details

ccpa 	  sale:opt_out 	      RIGHT TO OPT-OUT OF SALE
ccpa 	  sale:opt_in 	      RECONSENT OR OPT-IN TO DATA SALE
ccpa 	  deletion 	          RIGHT TO DELETE
ccpa 	  access 	            RIGHT TO KNOW
ccpa 	  access:categories 	RIGHT TO KNOW[☆]
ccpa 	  access:specific 	  RIGHT TO KNOW[☆]

These are the CCPA rights recommended for future use, based on the actual complaint form used by the CPPA at https://cppa.ca.gov/webapplications/complaint:

Regime 	Right

ccpa    Right to Delete
ccpa    Right to Correct
ccpa    Right to Know
ccpa    Right to Opt-out of Sale/Sharing
ccpa    Right to Limit the Use of My Sensitive Personal Information

In addition to what we generally agree on are CCPA rights, there is a provision in the CCPA I call, 'Questions Or Concerns in CCPA Rights Explanation':

Privacy Policy.	
""(e) The privacy policy shall include the following information:
(3) An explanation of how consumers can exercise their CCPA rights and what consumers can expect from that process, which includes the following: 
(J) A contact for questions or concerns about the business’s privacy policies and Information Practices using a method reflecting the manner in which the business primarily interacts with the consumer. ""	""(e) The privacy policy shall include the following information: 
(2) An explanation of the rights that the CCPA confers on consumers regarding their personal information, which includes the following:  (J) A contact for questions or concerns about the business’s privacy policies and Information Practices using a method reflecting the manner in which the business primarily interacts with the consumer.""

I propose adding a ""General Questions Or Concerns"" category, based on the following information collected in the CPPA Complaint Form:

Regime 	Issue
ccpa    A business’s collection, use, storing or sharing of my personal information
ccpa    A business is trying to get my consent unlawfully (such as using confusing or tricky language or dark patterns)
ccpa    It’s unclear how to submit a privacy request to a business
ccpa    Children's privacy
ccpa    Financial incentive or loyalty programs
ccpa    Don’t know/not sure
ccpa    Other

These are issues, not rights. California consumers have the right to private action, which is unlisted due to this being the wrong venue, but another unlisted right is the RIGHT TO FILE A CONSUMER COMPLAINT, which could be an acceptable alternative.

When I file complaints about an organization's use of AI for Automated Decisionmaking, I could file it as a RIGHT TO LIMIT (which no one at this time could understand and process correctly), which is why I use the Questions & Concerns Contact method. I have no expectation that the organization is legally obliged to respond, but I do expect that my request is included in the organization's record-keeping of all privacy rights requests, which must include why my request was denied. ",2023-10-27T16:27:55Z,2023-10-27T16:27:55Z,open,0,"CCPA (California Consumer Privacy Act), usage of dp on consent permission","CCPA rights, taking consent trickily ","CCPA, consent, trick users",DPs used in software,,,,,,,
https://api.github.com/repos/mozilla/fxa/issues/16053,"The Sync sign-in success page just says ""Sign in to this Firefox to complete set-up"" without any other context (if you're not signed in)",https://github.com/mozilla/fxa/issues/16053,"## Description

tl;dr: If you're not signed in to Sync or Accounts, https://accounts.firefox.com/connect_another_device is a little too mysterious -- it just says ""Sign in to this Firefox to complete set-up"", without providing any other info about what it's doing or what it's for.

This matters because a user might have a tab or window open at this URL, from a previous trial-run of Sync which they decided against using. (The sync sign-in process terminates at this URL.)  If a user stumbles back across this page with its lack-of-information about why it's there or what's going to happen, users might perceive this mysterious ""Sign in to complete set-up"" page as a dark pattern, trying to trick them into giving Sync another try when they already chose not to use it.

### Steps to reproduce
(1) User signs into Firefox Sync (maybe clicking through some Firefox UI to create/sign-in to an account for the first time).
(2) At the end of the Sync sign-in/setup process, the user lands at a final URL of something like https://accounts.firefox.com/connect_another_device?context=fx_desktop_v3&entrypoint=preferences&action=email&service=sync
(3) Let's say the user leaves that Firefox window alone and forgets about it, and then decides they don't want to use Sync after all. So, they sign out of their browser (e.g. from the Sync toolbar icon or from preferences), and they sign out of https://accounts.firefox.com.
(4) Later on, the user quits Firefox and restores their previously-opened windows.

### Actual result
The user ends up with a restored Firefox window viewing a page that they've never seen before, which just says the following:
```
Sign in to this Firefox to complete set-up
[Sign in]
```
...with no other context.

They've got this page because it's the URL that was left behind from the Sync sign-in process (step 2) and this happens to be how that URL renders if you're not signed in. The user then potentially gets frustrated with Firefox because (from their perspective) it looks like we're annoying them to sign back into Sync when they already decided against it.

### Expected result
The Sync setup process final-page should probably be designed to be something with a more ""inert"" rendering if you happen to still have it around after having logged out of Sync (as in the STR).   Or, if we really want it to have a sign-in button, we should provide clearer context about what set-up we're asking the user to complete by clicking through there.


For context, I'm spinning this off of a bug report from https://bugzilla.mozilla.org/show_bug.cgi?id=1833050 , where a user got very frustrated thinking Sync was repeatedly trying to nudge them to sign in. I'm not sure my STR exactly match what the user did on that bug, but this is the closest I could come to reconstructing what might have happened.

### Environment
Firefox Nightly 121.0a1 on Ubuntu 22.04

┆Issue is synchronized with this [Jira Task](https://mozilla-hub.atlassian.net/browse/FXA-8649)
",2023-11-08T05:24:20Z,2023-11-10T08:10:31Z,open,3,"Firefox, avoid dp in software, ""sign in to Sync"" button","Firefix sign in, not enough info","Firefox, avoid dark pattern, signup/log-in required",DPs prevention in software,,,,,,,
https://api.github.com/repos/mozilla/standards-positions/issues/908,Page Embedded Permission Control,https://github.com/mozilla/standards-positions/issues/908,"## Request for Mozilla Position on an Emerging Web Specification

* Specification title: Page Embedded Permission Control
* Specification or proposal URL (if available): (in progress)
* Explainer URL (if available): https://github.com/WICG/PEPC
* Proposal author(s) (`@`-mention GitHub accounts): @andypaicu @tomayac  @b1tr0t   
* Caniuse.com URL (optional): tbd
* Bugzilla URL (optional): tbd
* Mozillians who can provide input (optional): 

### Other information
Discussion at TPAC Breakout: https://github.com/w3c/tpac2023-breakouts/issues/35
Discussion at TPAC Web App Sec WG: https://github.com/w3c/webappsec/blob/main/meetings/2023/2023-09-15-TPAC-minutes.md
Discussion at w3c Permissions Workshop: https://www.w3.org/Privacy/permissions-ws-2022/report#novel-building-blocks-for-capability-control
",2023-10-17T00:28:55Z,2024-03-07T09:09:27Z,open,6,"prevention of dp, inline permission prompts, trick users to grant unwanted permissions","permission control, ways to avoid using dp","avoid dark pattern, trick users, prompts",DPs prevention in software,,,,,,,
https://api.github.com/repos/getcursor/cursor/issues/1308,Interpreter Mode Not Working at all.,https://github.com/getcursor/cursor/issues/1308,"MacOS Somona latest, M2 Max 14"" model.

It says my ""API key is not supported"" Uh excuse me? I pay OpenAI 20$ a month because you dont allow us to use open source models for whatever reason, (if you did i would pay YOU instead of openAI but you guys went the lame route. i get it (not really)). But OpenAIs docs specifically say to use interpreter mode wiht GPT-4, and I have been using GPT-4 in cursor since i downloaded it months ago. But now it says it wont work? but i can still chat with gpt-4 though (i think? because it would ONLY tell me that it was gpt-3 and that as far as it knew there was no get 4 or interpreter mode. and it would not believe me until i showed it a screenshot of itself. Are you guys tricking us and using GPT-3 instead of letting us use our API keys THAT WE PAY FOR in the way that we WISH TO USE THEM, and all the functionality that you SAY you offer? cus that would be pretty shitty... )
![Screenshot 2024-03-08 at 4 59 14 PM](https://github.com/getcursor/cursor/assets/131201760/ef3d0358-2882-4eed-9ae4-4916df8641d2)
![Screenshot 2024-03-08 at 4 59 25 PM](https://github.com/getcursor/cursor/assets/131201760/8d419931-7f7d-4488-8233-69931d0f5480)
![Screenshot 2024-03-08 at 5 06 35 PM](https://github.com/getcursor/cursor/assets/131201760/7456fa49-1a20-49de-8464-671228f4748d)


Im not trying to sound rude, but I am really really frustrated right now as nothing seems to be working for me today at all in the slightest and im about to throw my computer at the wall.",2024-03-08T23:07:39Z,2024-03-12T01:14:13Z,open,7,"ChatGPT, usage of dark pattern in LLMs contexts, API keys limitation, paid/pro version",,"ChatGPT, API, limitations, paid version",DPs used in software,,,,,,,
https://api.github.com/repos/karpathy/minbpe/issues/19,Minbpe as a potential course,https://github.com/karpathy/minbpe/issues/19,"I thoroughly enjoy Karpathy's YouTube content; it's consistently top-notch. I've been wondering whether this could potentially evolve into a concise course on platforms like Coursera or edX. The content he provides, usually around two hours long, is substantial, and I've noticed the inclusion of coding exercises for Minibpe. If complemented with quizzes, it could transform into a robust course. At the same time, I understand that organizing and setting up a course requires additional effort. 

We could explore a dedicated platform, akin to deeplearning.ai, which could be worth considering. I felt compelled to share this thought.

Moreover, a considerable number of people might be willing to contribute their time and efforts to help build such a platform(open-source), considering the extensive reach and impact of his video content.

I'm curious to hear the thoughts of others on this matter.  ",2024-02-19T23:56:00Z,2024-03-01T01:26:27Z,closed,4,"Minbpe, usge of dark pattern in software","Minbpe, potential open-source platform, enroll","Minbpe, examples",DPs used in software,,,,,,,
https://api.github.com/repos/tournesol-app/tournesol/issues/1904,"[ext][back] bug: ""Watch on Tounesol"" button doesn't work when the video is not in the database AND the user is disconnected",https://github.com/tournesol-app/tournesol/issues/1904,"<img width=""773"" alt=""image"" src=""https://github.com/tournesol-app/tournesol/assets/52411229/abe7112e-c8c6-4896-9158-b84874fab056"">


The new ""Watch on Tournesol"" button displayed under YouTube videos works fine for videos that are already in the Tournesol database. It also works for users who are disconnected from Tournesol. But when the user is disconnected AND the video is not in the Tournesol database, a ""Not found"" error is displayed.
<img width=""916"" alt=""image"" src=""https://github.com/tournesol-app/tournesol/assets/52411229/05d845dd-1264-48dd-9d07-04751df3d97e"">

You can use this random YouTube video for testing, as it's likely not in the Tournesol database: https://perchance.org/youtube-video",2024-01-29T20:29:59Z,2024-02-19T13:41:00Z,closed,3,"Youtube, deceptive design practice, ""Watch on Tournesol"" button","Tournesol button, YouTube API","Youtube, API, deceptive design practice",DPs examples/definitions,,,,,,,
https://api.github.com/repos/minimaxir/hacker-news-undocumented/issues/72,HN News,https://github.com/minimaxir/hacker-news-undocumented/issues/72,"My own Observations (2022). Full disclosure, I no longer use HN News, they have demonstrated that they don't value rational discourse or community.  Many of the problematic behaviors I saw while commenting on HN were very similar in structural elements to those used for Thought Reform, and described by renowned psychiatrist Robert Lifton regarding Maoist struggle sessions from the 1950s.

A few things:
Vote manipulation has been a longstanding issue. Sybil attacks were at the time common and growing in frequency.
A -4 hides any unsanctioned post from view, negative karma closes people's account and while they claim there are protections against downvote-bombing, I've seen these downvote brigades happen many times.

Posts with certain keywords are automatically down-voted, but may snap back before the 1hr mark, this can be used to ""struggle"" people (Psychology of Totalism) that respond in disagreement. These downvotes take away karma as well as squelch people. 

HN claims to not have a record of these vote manipulations (in the short term), it was clearly happening regularly so someone was being dishonest or they lack any kind of non-repudiation for their vote systems. (A fundamental of any Information Assurance/IT Security) 

HN rules are designed to be applied arbitrarily and are fundamentally not-defined in a way that can be applied consistently. As a result they are inconsistent and contradictory.

This appears intentional. Dang was notified of the inconsistencies, and no changes were made. HN prefers to make you guess at what the rules actually mean, and the meaning/contexts they apply those rules to disciplinarily after the fact, change regularly based on the feeling of the mod that day.  They do not follow rational guidelines, and appear hegelian in nature.

After a time, a failure to correct means its sanctioned and by design. Terms such as swipe are not properly defined, as are the flame bait rules. Discipline of these rules is applied broadly to any critical discussion; with warnings given to all parties involved, though individuals who post quality over quantity are punished more heavily.  

Marxist-based comments, soft propaganda and malign influence are a big problem on the site. Worse, anyone correcting misleading or false statements gets disciplined for breaking the rules (as flame bait). Propaganda and malign influence regularly seem to get free reign.

Useful information is hidden. A post about which manufacturers of TVs still made non-SMART TVs, had all Sceptre models (one of the few mfg's who provided these TVs at the time) downvoted/hidden from view. Several people mentioned it, every such post was removed or hidden in a enveloped post that isn't visible/doesn't load. No explanation given.

HN Rules are also used to punish people for correcting incorrect information, and for disagreeing. Its very collectivist in structure. 
To demonstrate just how crazy this got, there was a person who promoted consuming lead as a nutritional supplement (WeNeedLead); claiming spuriously that it was not harmful. This was allowed to remain, as the flag option was not available (to an account with over the 31 karma claimed to be needed to flag, I had several hundred at the time).

Even following the clarification provided by Dang directly about how HN must allow the community to correct false and misleading information (as not a moderator responsibility), and applying that later verbatim, this still resulted in Dang disciplining all parties for infractions of the rules, for following what he himself said (which I still have in writing). 

Also, occasionally the top border bar and site themes changes to red, the entire color scheme changes; not sure what this is about. All Red colors tend to promote criticality as a dark pattern, whereas orange is neutral. Its a subtle dark pattern with a documented effect.

Chat-GPT use goes unpunished.

Irrational and fallacy based argumentation goes unpunished for voluminous accounts.

Correcting false information (rational discourse), and disagreeing respectfully results in mod discipline or downvotes for supposedly breaking the rules, rules which can be applied completely arbitrarily to just about any intelligent conversation. Collectivist.

In my opinion, the site is run by deceitful people with a malevolent agenda. Its not a place anyone should be spending time.",2023-12-27T05:46:27Z,2024-01-02T05:18:22Z,closed,0,"HN (Hacker News) news, usage of dp in software, color psychology to  affect user behaviors",,"examples, psychology",DPs examples/definitions,,,,,,,
https://api.github.com/repos/ldeluigi/2ppy/issues/26,Next steps,https://github.com/ldeluigi/2ppy/issues/26,"- [x] Avoid using dark patterns in python (fluent builder/factory)
- [x] Improving the API thanks to generators
- [x] Coverage reports, coverage driven tests
- [x] `Theory.getClauses()` does not implement java.lang.Iterable",2023-10-16T19:40:31Z,2023-10-19T13:03:04Z,closed,3,Avoid using dark patterns in python,requirement to not use dp in python,"Python, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/jiacai2050/hot-posts/issues/569,"[2024-02-24] GPT in 500 Lines of SQL — Show HN: OK-Robot: open, modular home robot framework for pick-and-drop anywhere",https://github.com/jiacai2050/hot-posts/issues/569,"# Hacker News


#### [GPT in 500 Lines of SQL](https://explainextended.com/2023/12/31/happy-new-year-15/)

587 points by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) at 10:45:31 | [34 comments](https://news.ycombinator.com/item?id=39488668)


#### [Show HN: OK-Robot: open, modular home robot framework for pick-and-drop anywhere](https://ok-robot.github.io/)

379 points by [MahiShafiullah](https://news.ycombinator.com/user?id=MahiShafiullah) at 01:23:23 | [84 comments](https://news.ycombinator.com/item?id=39483482)


#### [A former Gizmodo writer changed name to &#39;Slackbot&#39;, stayed undetected for months](https://www.theverge.com/2024/2/23/24081249/slack-slackbot-gizmodo-tom-mckay)

291 points by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) at 07:10:11 | [99 comments](https://news.ycombinator.com/item?id=39487341)


#### [Generative Models: What do they know? Do they know things? Let&#39;s find out](https://intrinsic-lora.github.io/)

286 points by [corysama](https://news.ycombinator.com/user?id=corysama) at 06:46:46 | [82 comments](https://news.ycombinator.com/item?id=39487124)


#### [Mamba: The Easy Way](https://jackcook.com/2024/02/23/mamba.html)

211 points by [jackcook](https://news.ycombinator.com/user?id=jackcook) at 00:11:58 | [51 comments](https://news.ycombinator.com/item?id=39482428)


#### [Losing two jobs in one year](https://jbennetcodes.medium.com/how-to-lose-two-jobs-in-one-year-e8e428702b91)

189 points by [softwaredoug](https://news.ycombinator.com/user?id=softwaredoug) at 11:16:05 | [125 comments](https://news.ycombinator.com/item?id=39488833)


#### [Please make your table headings sticky](https://btxx.org/posts/Please_Make_Your_Table_Headings_Sticky/)

184 points by [aragilar](https://news.ycombinator.com/user?id=aragilar) at 11:16:51 | [46 comments](https://news.ycombinator.com/item?id=39488836)


#### [Show HN: Refractify – Optical software against myopia](https://refractify.io/)

133 points by [macilacilove](https://news.ycombinator.com/user?id=macilacilove) at 02:47:23 | [41 comments](https://news.ycombinator.com/item?id=39484590)


#### [Tell HN: Equifax free credit report dark patterns]()

132 points by [PopAlongKid](https://news.ycombinator.com/user?id=PopAlongKid) at 03:49:03 | [52 comments](https://news.ycombinator.com/item?id=39485259)


#### [Scuttlebutt social network: a decentralised platform](https://scuttlebutt.nz/)

130 points by [p4bl0](https://news.ycombinator.com/user?id=p4bl0) at 03:14:18 | [67 comments](https://news.ycombinator.com/item?id=39484907)


#### [Meta&#39;s new LLM-based test generator is a sneak peek to the future of development](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator)

120 points by [ben_s](https://news.ycombinator.com/user?id=ben_s) at 06:04:58 | [71 comments](https://news.ycombinator.com/item?id=39486717)


#### [Show HN: Consol3 – A 3D engine for the terminal that executes on the CPU](https://github.com/Victormeriqui/Consol3)

114 points by [victormeriqui](https://news.ycombinator.com/user?id=victormeriqui) at 10:17:42 | [18 comments](https://news.ycombinator.com/item?id=39488529)


#### [Power Metal: is it really about dragons? (2018)](https://notes.atomutek.org/power-metal-and-dragons.html)

113 points by [guardienaveugle](https://news.ycombinator.com/user?id=guardienaveugle) at 15:47:15 | [45 comments](https://news.ycombinator.com/item?id=39489920)


#### [Quality is a hard sell in big tech](https://www.pcloadletter.dev/blog/big-tech-quality/)

112 points by [ben_s](https://news.ycombinator.com/user?id=ben_s) at 14:09:46 | [90 comments](https://news.ycombinator.com/item?id=39489519)


#### [AMD ROCm Software Blogs](https://rocm.blogs.amd.com/)

102 points by [jrepinc](https://news.ycombinator.com/user?id=jrepinc) at 02:28:29 | [45 comments](https://news.ycombinator.com/item?id=39484321)



# V2EX


  <details>
    <summary>
      <strong>[进送年卡，评论抽 100 永久] 一键拷贝网站指定区域代码，粘贴可用，快速起 mvp，还允许您将代码克隆为 JSX 或 Tailwind CSS 的组件</strong>
    </summary>
    <p>CopyCss 来了，刚过完年送一波福利，助力开发者快速产品 mvp ！！！ 这个浏览器插件使您能够从任何网站提取 CSS ，还允许您将代码克隆为 JSX 或 Tailwind CSS 的组件。</p>
<p>手动修改这个元素的 CSS 是一件麻烦的事。使用 CopyCss ，您只需点击即可获得它。毫不费力地设计您的完美页面。</p>
<p>您可以在任何网站上获取任何元素的代码，并将其快速复制为 HTML/JSX ，CSS/Tailwind CSS 或您选择的任何其他格式。</p>
<p>评论区留绿色软件抽 100 个永久激活码</p>
<p>年卡激活码免费送 v 友：8BF88AB1-407B-40B7-A335-89DFD0CAF2EB</p>
<p>官网地址 <a href=""https://copycss.xyz"" rel=""nofollow"">https://copycss.xyz</a></p>
<p>插件地址： <a href=""https://chromewebstore.google.com/detail/copycss-copy-css-scan-fro/gomkcikdgjioepmicndedpjppeamobhh?utm_source=ext_app_menu"" rel=""nofollow"">https://chromewebstore.google.com/detail/copycss-copy-css-scan-fro/gomkcikdgjioepmicndedpjppeamobhh?utm_source=ext_app_menu</a></p>
<p>功能使用展示：
<img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://copycss.xyz/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fexport-codepen.48f59659.gif&amp;w=1920&amp;q=75""></p>
<p><img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://copycss.xyz/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fstyle-copy1.c1dcf6d8.gif&amp;w=1920&amp;q=75""></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018061"">87 comments</a> by <a href=""https://www.v2ex.com/u/mhhya"">mhhya</a>
    at 10:07:01
    in <a href=""https://www.v2ex.com/go/create"">分享创造</a>
    </p>


  <details>
    <summary>
      <strong>想请教一下回国的注意事项</strong>
    </summary>
    <p>今年黄金周准备回国内看一下家里老人家，今年 91 岁啦。<br>
由于时隔 13 年，特来请教一下各位大佬需要注意点什么。<br>
目前我想知道的有下面这几点：</p>
<ul>
<li>准备待两周，大概有 10 天闲着，有什么推荐的活动吗</li>
<li>需不需要翻墙工具？可能会用到的国外软件为 LINE ，X ，Apple Music ，Youtube ，不确定会不会敲代码</li>
<li>常年在国外是不是应该在国内办个网银？有什么推荐的银行吗？不过感觉需要国内手机号。。。</li>
<li>没有过二代身份证，补办用的照片可以直接自己照的么（我看支付宝里面有相关的）</li>
<li>买点特产送同事的话，推荐送什么（尽量福建地区的，虽然感觉也可以网购）</li>
</ul>
<p>目前就这些，如果有什么建议的话欢迎大佬们赐教～</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018103"">82 comments</a> by <a href=""https://www.v2ex.com/u/yechentide"">yechentide</a>
    at 13:56:22
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>由南京火灾重大伤亡事故引出的问题：高层住宅自备缓降逃生绳能否避免这种惨剧发生</strong>
    </summary>
    <p>网络示意图：
<a href=""https://www.zpic.org/i/0/2024/02/24/53c8f79f5fd47b9c.png"" rel=""nofollow""><img alt=""Screenshot from 2024-02-24 10-56-39.png"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://www.zpic.org/i/0/2024/02/24/53c8f79f5fd47b9c.png""></a></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018071"">81 comments</a> by <a href=""https://www.v2ex.com/u/sfdev"">sfdev</a>
    at 10:57:44
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>元宵佳节免费送 GPT-4，免费送 GPT PLUS</strong>
    </summary>
    <p>GPT Share 服务已经持续运营了一段时间，最近接入了微信生态，服务仍有许多地方需要提升改进。<br>
想试试上 V2EX 送周卡，可使用官方 ChatGPT PLUS 所有的功能，以此获取宝贵的建议。    </p>
<p>领取方式<br>
1 、前往<a href=""https://oai.xiamis.xyz"" rel=""nofollow"">https://oai.xiamis.xyz</a>使用微信扫码登录<br>
2 、将系统下发的令牌 发送给公众号并备注  如 ""abcd 来自 v2ex""<br>
3 、回复本帖 留下微信昵称 如 ""虾米 已留言"" 我将在后台为您赠送  </p>
<p>注意：令牌是登录系统的凭证 请勿泄露  </p>
<p><a href=""https://imgse.com/i/pFU6y38"" rel=""nofollow""><img alt=""pFU6y38.png"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://s11.ax1x.com/2024/02/24/pFU6y38.png""></a>
<a href=""https://imgse.com/i/pFU66gS"" rel=""nofollow""><img alt=""pFU66gS.png"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://s11.ax1x.com/2024/02/24/pFU66gS.png""></a>
<a href=""https://imgse.com/i/pFU6cjg"" rel=""nofollow""><img alt=""pFU6cjg.png"" class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://s11.ax1x.com/2024/02/24/pFU6cjg.png""></a></p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018080"">65 comments</a> by <a href=""https://www.v2ex.com/u/johnsonwong"">johnsonwong</a>
    at 11:55:59
    in <a href=""https://www.v2ex.com/go/promotions"">推广</a>
    </p>


  <details>
    <summary>
      <strong>一个人租住公寓，一日三餐怎么解决？</strong>
    </summary>
    <p>自己做饭又没有燃气，而且还特麻烦，点外卖又觉得又脏又不健康，吃预制菜又觉得是在吃添加剂也不健康</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018051"">60 comments</a> by <a href=""https://www.v2ex.com/u/kisshere"">kisshere</a>
    at 08:44:11
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>国外 esim + 干净的国外手机，可以做到反追踪吗？</strong>
    </summary>
    <p>我们知道，健康码是通过基站定位追踪位置的。</p>
<p>我们也知道，前年年底很多人是因为基站定位追踪位置被抓的。</p>
<p>我希望下次有人再到指定地点参加活动时，可以在不被追踪的前提下上网。</p>
<p>那么，拿一台干净的国外手机，这台手机没插过自己的卡，只用国外 esim 上网，再共享 wifi 出来（主力机连接 wifi 并且全局 vpn ），是不是就没人可以追踪到自己了呢？追查后台数据也只能查到有个国外卡在这地方上网，而不能通过实名信息关联到我本人。</p>
<p>但我顾虑的一点是，如果我把手机带回家联网一次，是不是就能追查到这张卡在我家附近上网，最终就能发现是我持有这张卡了。</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018068"">48 comments</a> by <a href=""https://www.v2ex.com/u/param"">param</a>
    at 10:41:50
    in <a href=""https://www.v2ex.com/go/qna"">问与答</a>
    </p>


  <details>
    <summary>
      <strong>入职远程工作两周,感觉不舒服要不要辞职?</strong>
    </summary>
    第一次远程工作,过年的时候入职,现在差不多两周<br><br>公司是新加坡,都是坐班模式,我面试的时候,特别提能不能远程<br><br>面完大概 2 个月通知可以远程上班<br><br>目前遇见的问题就是<br>1:公司坐班模式,然后群里基本不说话,只有我一个在汇报,甚至早会,运营技术对接会,都不让我参加<br>2:我入职就开始独立开发一个项目,是从考察,对比,规划,开发一个人全包<br>3:这让我有一种,本来可以外包价给你开发,但是你入职了可以更便宜,进度更快让你开发,因为要日报,周报,星期五下午还要写自己这周有什么升级点<br><br>第 3 个念头起来的时候,我就浑身不舒服,感觉就是这样<br><br>现在犹豫的点就是<br>A:是不是我太懒,上几天班受不了<br>B:现在上班是不是都这样,只是我不习惯?
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018062"">41 comments</a> by <a href=""https://www.v2ex.com/u/996bujiaban"">996bujiaban</a>
    at 10:08:43
    in <a href=""https://www.v2ex.com/go/career"">职场话题</a>
    </p>


  <details>
    <summary>
      <strong>分享神级去除 IOS 应用开屏广告的方法</strong>
    </summary>
    <p>之前在 v2 搜索去开屏广告, 大多都是通过小火箭或 surge 对广告域名或接口进行屏蔽, 但规则不能覆盖全部互联网 APP, 今天刷小红书发现可以通过快捷指令打开 url schema 跳转的方式来屏蔽广告.</p>
<p>这是模拟从其他地方跳转进 APP ，不少 APP 为了更好的体验，此时不会展示开屏广告, 使用步骤:</p>
<ol>
<li>新建快捷指令: 添加操作-&gt;搜索""打开 url""</li>
</ol>
<p><img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.v2ex.co/27Ju3J89.jpeg""></p>
<ol>
<li>输入应用的 url schema, 例如 bilibili://, 点击最下方的感叹号, 选择添加到主屏幕</li>
</ol>
<p><img alt class=""embedded_image"" loading=""lazy"" referrerpolicy=""no-referrer"" rel=""noreferrer"" src=""https://i.v2ex.co/9gBqNrEs.jpeg""></p>
<p>bilibili 设置后，不仅可以去开屏广告，还能加快启动速度，因为 bilibili 在启动时会故意延迟进入显示开屏画面😅，估计是在展示开屏画面的期间加载广告.</p>
<p>应用的 url schema 需要自己去找, 或者自己对安装包解包去获取, 我目前用的几个:</p>
<ul>
<li>小红书: xhsdiscover://home/</li>
<li>招商银行: cmbmobilebank://</li>
<li>京东读书: openapp.jdreader://</li>
<li>携程: CtripWireless://</li>
<li>一些合集: <a href=""https://gist.github.com/zhuziyi1989/3f96a73c45a87778b560e44cb551ebd2"" rel=""nofollow"">https://gist.github.com/zhuziyi1989/3f96a73c45a87778b560e44cb551ebd2</a></li>
</ul>
<p>添加到主屏幕可自己配置图标, 建议在<a href=""https://play.google.com/store/apps?hl=zh_CN&amp;gl=US"" rel=""nofollow"">Google Play</a>(无牛皮癣图标)上搜索对应的 app, 然后保存其图标</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018073"">40 comments</a> by <a href=""https://www.v2ex.com/u/weijancc"">weijancc</a>
    at 11:14:05
    in <a href=""https://www.v2ex.com/go/apple"">Apple</a>
    </p>


  <details>
    <summary>
      <strong>大佬们，自己开发的 App，每天 1-5 个下载，请问该怎么办啊</strong>
    </summary>
    自己开发的 App ，每天 1-5 个下载，请问该怎么办啊
  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018101"">31 comments</a> by <a href=""https://www.v2ex.com/u/helloword001"">helloword001</a>
    at 13:52:08
    in <a href=""https://www.v2ex.com/go/programmer"">程序员</a>
    </p>


  <details>
    <summary>
      <strong>关于 2 台电脑 3 块屏幕的快速切换问题</strong>
    </summary>
    <p>我有一台 macbook pro ，一台 windows 主机，然后一块 32 寸的主显示器，2 块 27 寸的副屏，一般开发的时候使用 mbp ，然后打游戏或者用到 windows 的某些功能的时候需要切换到 windows 。</p>
<p>现在是手动一台一台的去设置里切换信号源，然后键鼠 mbp 上用的蓝牙，windows 主机用的 2.4G 接收器切换。</p>
<p>想问问 v 友们有没有什么快速的方法同时切换三台显示器或者切换其中若干台显示器的信号源呢？手动切太费劲了😂</p>

  </details>
    <p>
    <a href=""https://www.v2ex.com/t/1018093"">30 comments</a> by <a href=""https://www.v2ex.com/u/Elaina"">Elaina</a>
    at 13:37:47
    in <a href=""https://www.v2ex.com/go/hardware"">硬件</a>
    </p>



",2024-02-25T00:42:45Z,2024-02-25T00:42:45Z,open,0,"Hacker News Daily, resources of dark pattern, docs","GPT, SQL, equifax free credit report","documentation, GPT, SQL",Papers/Docs/Sources,,,,,,,
https://api.github.com/repos/hinoshiba/news/issues/3208,[RegisterSoftware] India warns ecommerce 'basket sneaks' and 'confirm shamers' their days are numbered,https://github.com/hinoshiba/news/issues/3208,"

#### Floats draft guidelines prohibiting 'dark patterns' developed with help from Amazon, Google, and Meta

The Indian government has commenced a consultation on how to regulate – and possibly prohibit – tricky tactics called ""dark patterns"" designed to fool consumers as they transact online.…



<https://go.theregister.com/feed/www.theregister.com/2023/09/08/india_dark_pattern_prohibition_draft/>

",2023-09-08T02:36:33Z,2023-09-10T03:15:24Z,closed,2,"India, government regulation on dp usage in ecommerce, sneaking basket, comfirmshamers, Amazon, Google, Meta","Indian gov, ecommorce, prohibit ""basket sneaks"" ""confirm shamers""","regulation, India, e-commerce, confirmshaming, sneaking into basket, Amazon, Meta, Google","DPs used in software, DPs related regulation",,,,,,,
https://api.github.com/repos/privacycg/nav-tracking-mitigations/issues/64,Bounce tracking and technical stability for PETs,https://github.com/privacycg/nav-tracking-mitigations/issues/64,"Hello everyone, thanks for all the work you’ve been doing to limit harmful cross-site tracking and protect user privacy and security. It’s great to see how the browsers are putting an end to the systematic collection and sharing of personal data.
 
I want to bring back a question that has been mentioned in passing but was never properly considered. Once measures like Bounce Tracking Mitigation are in place, how will browsers ensure, from a technical perspective, that it is still possible for privacy-enhancing technologies (PETs) to operate? I’m hoping we can focus on the technical standardisation of the approach, on the understanding that innovation and competition are good for users and publishers so long as privacy, security and user experience are protected.
 
The BTM Explainer has a few short paragraphs on[ Block/Allow Lists](https://github.com/privacycg/nav-tracking-mitigations/blob/main/bounce-tracking-explainer.md#blockallow-lists) but it’s unclear how this will work in practice. Let’s take the scenario of a technology that uses bounce tracking or an alternative cross-site tracking technology in a privacy-preserving way - not some sort of ad tech whitewash but something that meets the most stringent legal requirements on privacy (perhaps even on a path towards achieving zero trust status). For example, a PET that by design and default only tracks cross-site data with opt-in user consent, makes data deletion and portability easy, aggregates and processes the data in the browser, minimises the data accessible by the tracking company and does not share personal data with any third party. It is both possible and desirable for the market to produce software that delivers the benefits of cross-site data without compromising privacy and security, but the rules must be clear.
 
How will browsers provide technical stability for PETs? Mozilla has done a great job explaining their red lines at[ disconnect.me](https://disconnect.me/trackerprotection), although manually curated allow-lists are probably better for privacy than blocklists. Either way, the ground rules for PETs must be tightly defined for transparency and consistency.
 
Keen to hear the group’s thoughts.",2023-10-03T13:30:43Z,2023-11-16T15:34:50Z,open,7,"PETs (privacy enhancing technologies), protect user privacy, no dp on collecting consent from users, easier to withdraw consent ","consent give/take back, tracking","PETs, tracking, privacy issue, cookie consent, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/websharkdev/folio-2023/issues/1,Responsible design [mobile],https://github.com/websharkdev/folio-2023/issues/1,"**Issue Title:** Implementing Responsible Design for Mobile Applications

**Description:**

**Overview:**
In recent years, there has been a growing emphasis on responsible design in the development of mobile applications. Responsible design encompasses various aspects, including accessibility, sustainability, and ethical considerations. This issue aims to track the implementation of responsible design practices specifically tailored for mobile applications.

**Objectives:**

1. **Accessibility:**
   - Ensure that the mobile application adheres to accessibility standards (e.g., WCAG) to make it usable for people with disabilities.
   - Implement features such as voice commands, screen reader compatibility, and adjustable text sizes to enhance accessibility.

2. **Sustainability:**
   - Evaluate the environmental impact of the mobile application, considering factors like energy consumption and resource usage.
   - Implement features to optimize energy efficiency, such as dark mode and background processing optimization.

3. **Ethical Considerations:**
   - Identify and address potential ethical concerns related to the use of the mobile application.
   - Implement privacy measures to protect user data and provide transparent data handling practices.
   - Avoid the use of dark patterns or manipulative design elements that may exploit users.

4. **User Education:**
   - Provide in-app guidance on responsible usage, educating users on features that contribute to accessibility, sustainability, and ethical use.
   - Create a knowledge base or FAQ section addressing common questions related to responsible design.

5. **Testing and Feedback:**
   - Conduct thorough testing of the mobile application to ensure that responsible design features work seamlessly.
   - Encourage user feedback on responsible design aspects and iterate based on user suggestions and concerns.

**Dependencies:**

- Integration with the design and development teams.
- Collaboration with user experience (UX) and accessibility experts.

**Additional Notes:**
This issue serves as a comprehensive guide for integrating responsible design practices into our mobile application development process. It focuses on creating a positive user experience while aligning with ethical and sustainability standards. Regular updates on progress and challenges should be shared within the development team.",2023-11-21T19:02:21Z,2023-11-27T17:10:28Z,closed,1,"resposible design in mobile apps, ethical considerations, dark pattern/manipulative design avoidance","mobile design, ethical approach","avoid dark pattern, mobile device, UI/UX design",DPs prevention in design,,,,,,,
https://api.github.com/repos/Olog/phoebus-olog-web-client/issues/114,Csstudio 2023 edit feature,https://github.com/Olog/phoebus-olog-web-client/pull/114,"## Summary of Changes

- Introduces the edit feature for logs
- Refactor:
  - create and reply features are route-based rather than state-based (from /logs/edit with url params to /logs/create for creating logs, and /logs/{id}/edit or /logs/{id}/reply for edit and reply)
  - Pulled description text field + attachments into their own component and tests. Attachment editing can be disabled for the log edit screen (since the edit feature in the backend doesn't support editing log attachments)
  - move logbook and tag fields into their own components to eliminate logbook/tag prop-drilling
  - searchParam state is represented as-is as objects (rather than names); search box now looks up logbooks and tags by name, and api calls interpret the state at point of call as needed
  - many other reorganizations, hooks, etc to reduce prop-drilling
  - project structure cleanup (mostly following bulletproof react conventions)
    - customization.js:
      - moved to config/customization.js
      - urlPrefix replaced with APP_BASE_URL (deduplicating)
    - utils broken apart and pulled into sections where actually used
    - service/api files moved to one api folder
    - providers moved to providers folder
    - re-exports/configs of moment & localization moved to lib/moment.js
- Fixes:
  - log result item title can overflow and push attachment and reply icons out of view; now uses ellipsis text with mouse-over description when overflowing

Edited elements have an ""edited"" link that appears if there are edits:
<img width=""576"" alt=""Screenshot 2023-11-14 at 10 11 12"" src=""https://github.com/Olog/phoebus-olog-web-client/assets/77395846/b0f0b99a-b115-4886-aad5-25b7c5a5e70e"">

Clicking the link takes you to a history page, and includes a button to download the history as JSON:
<img width=""754"" alt=""Screenshot 2023-11-14 at 10 11 57"" src=""https://github.com/Olog/phoebus-olog-web-client/assets/77395846/1391657d-1b5c-4f51-88b0-26cb9ff8fc06"">



## Visual Inspection
<!-- Before approving, view the app in your browser and verify it doesn't have any of the below problems. -->

- [ ] Conformance to Markdown styles: https://olog.esss.lu.se/Olog/help/CommonmarkCheatsheet
    - [ ] ...when viewing a log entry
    - [ ] ...when previewing HTML while writing a description
    - [ ] ...when viewing a log entry in the group view
- [ ] Scroll is possible (elements don't overflow their container, and they are scrollable)
    - [ ] ...search result list
    - [ ] ...log entry group view list
    - [ ] ...log entry single view
    - [ ] ...create new log entry page
- [ ] Overall layout fills full width and height of viewport
- [ ] Pagination element doesn't overflow into other elements
",2023-11-10T15:51:58Z,2023-11-16T15:37:07Z,closed,7,"dark pattern in software, small font size link, visual interference","log edits, possible dp?","interface interference, UI/UX design",DPs used in software,,,,,,,
https://api.github.com/repos/jasonthewhale/Capybara/issues/4,Functionality of jump to next and standard of label/highlight,https://github.com/jasonthewhale/Capybara/issues/4,"1. I have changed container of hiddenInfo (hiddenElements) from set to array, considering usability of index. Would you connect it into jump to next logic?

2. I have set templete of ""labelPattern"" and ""highlightPattern"" in the second-to-last and third-to-last functions in ""content.js"". Is possible to modify and call these functions in all kinds of dark patterns for consistency?

_(From my understanding, ""label"" is for all caught patterns and ""highlight"" is only for the single pattern that currently selected by user with jump to next.)_

@Alaurant @YokiiW ",2023-10-01T01:26:56Z,2023-10-04T05:22:12Z,closed,1,"usage of dark pattern in software, visual interference, small font size texts",,"interface interference, UI/UX design",DPs used in software,,,,,,,
https://api.github.com/repos/Automattic/newspack-plugin/issues/2695,Modal checkout: allow covering Stripe's fees,https://github.com/Automattic/newspack-plugin/pull/2695,"### All Submissions:

* [x] Have you followed the [Newspack Contributing guideline](https://github.com/Automattic/newspack-plugin/blob/master/.github/CONTRIBUTING.md)?
* [x] Does your code follow the [WordPress' coding standards](https://make.wordpress.org/core/handbook/best-practices/coding-standards/) and [VIP Go coding standards](https://vip.wordpress.com/documentation/vip-go/code-review-blockers-warnings-notices/)?
* [x] Have you checked to ensure there aren't other open [Pull Requests](../../pulls) for the same update/change?

<!-- Mark completed items with an [x] -->

<!-- You can erase any parts of this template not applicable to your Pull Request. -->

### Changes proposed in this Pull Request:

<!-- Describe the changes made to this Pull Request, and the reason for such changes. -->

Adds the option for the donor to cover Stripe's transaction fees:

<img width=""558"" alt=""image"" src=""https://github.com/Automattic/newspack-plugin/assets/7383192/1f7b49e4-4912-45b1-bf8e-0da3bce0ba9c"">


See 1200133283036252-as-1205668937699532

The feature is on by default. To opt-out, a change the ""Allow donors to cover transaction fees"" setting in Reader Revenue wizard, Stripe Gateway tab.

There's one non-covered edge case – use of coupons. The logic to handle covering fees with coupons applied would make this code overly complex, and since we're talking about donations here, usage of coupons seems like an extreme edge case. If coupons are applied to the order, the feature will disappear gracefully. 

### How to test the changes in this Pull Request:

1. Make sure you have ""Newspack"" set as the Reader Revenue platform and `Stripe (Credit Card)` enabled as a payment gateway
2. Visit a page with a donation prompt, and initiate the flow to trigger the modal checkout
3. Observe a ""Cover transaction fees?"" checkbox above the card details inputs in the ""Payment info"" section of the checkout
4. Complete transactions with and without opting to cover the fees, observe the WC orders in the latter case:
    - have the total order amount increased to offset the Stripe fee
    - have a `newspack_donor_covers_fees` meta field with value of `1`
    - have an order note attached commenting about the fact of covering fees
5. In WC settings, turn on coupons and create a coupon. Use the coupon in the checkout – observe that the feature is not active when the coupon is applied
6. Visit Newspack's Reader Revenue wizard, Stripe Gateway tab. Update the fee calculation inputs and observe these are reflected on the front-end.

### Other information:

* [x] Have you added an explanation of what your changes do and why you'd like us to include them?
* [ ] Have you written new tests for your changes, as applicable?
* [x] Have you successfully ran tests with your changes locally?

<!-- Mark completed items with an [x] -->",2023-10-12T14:49:42Z,2023-11-13T22:08:27Z,closed,7,"Stripe, prevention of dark pattern in design, avoid upsell","Stripe fee for donor, opt-out, preselection","Stripe, avoid dark pattern, preselection",DPs prevention in software,,,,,,,
https://api.github.com/repos/creachadair/cookies/issues/7,Add support for Firefox cookies,https://github.com/creachadair/cookies/pull/7,"Firefox uses a SQLite database similar to Chrome, but with somewhat less
pathological dark patterns to defend the ad business (e.g., encrypted cookies).

- firefox: add support for reading/editing Firefox cookies
- docs: update Chrome info from the public gist
- cmd/washcookies: add support for Firefox cookies
",2023-09-14T01:29:24Z,2023-09-14T01:30:57Z,closed,0,"Firefox, usage of dark pattern in software, encrypted cookies, ad bussiness ","Chrome, Firefox less pathological dp in comparison","Chrome, Firefox, ads, cookie consent",DPs used in software,,,,,,,
https://api.github.com/repos/hinoshiba/news/issues/3595,[HackerNews] Retool Falls Victim to SMS-Based Phishing Attack Affecting 27 Cloud Clients,https://github.com/hinoshiba/news/issues/3595,"

Software development company Retool has disclosed that the accounts of 27 of its cloud customers were compromised following a targeted and SMS-based social engineering attack.
The San Francisco-based firm blamed a Google Account cloud synchronization feature recently introduced in April 2023 for making the breach worse, calling it a ""dark pattern.""
""The fact that Google Authenticator syncs to



<https://thehackernews.com/2023/09/retool-falls-victim-to-sms-based.html>

",2023-09-18T07:14:07Z,2023-09-20T07:14:22Z,closed,2,,"Retool, SMS based phishing 27 accounts",,,,,,,,,
https://api.github.com/repos/Yukeaaa/arxiv-daily/issues/672,"【CS-part4】New submissions for Fri, 22 Sep 23",https://github.com/Yukeaaa/arxiv-daily/issues/672,"## Keyword: gpt
### Towards LLM-based Autograding for Short Textual Answers
 - **Authors:** Johannes Schneider, Bernd Schenk, Christina Niklaus, Michaelis Vlachos
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.11508
 - **Pdf link:** https://arxiv.org/pdf/2309.11508
 - **Abstract**
 Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while ""out-of-the-box"" LLMs provide a valuable tool to provide a complementary perspective, their readiness for independent automated grading remains a work in progress, necessitating human oversight.
### ""It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure  Risks and Benefits When Using LLM-Based Conversational Agents
 - **Authors:** Zhiping Zhang, Michelle Jia, Hao-Ping (Hank)Lee, Bingsheng Yao, Sauvik Das, Ada Lerner, Dakuo Wang, Tianshi Li
 - **Subjects:** Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
 - **Arxiv link:** https://arxiv.org/abs/2309.11653
 - **Pdf link:** https://arxiv.org/pdf/2309.11653
 - **Abstract**
 The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigmatic shifts to protect the privacy of LLM-based CA users.
### Generative AI in Mafia-like Game Simulation
 - **Authors:** Munyeong Kim, Sungsu Kim
 - **Subjects:** Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2309.11672
 - **Pdf link:** https://arxiv.org/pdf/2309.11672
 - **Abstract**
 In this research, we explore the efficacy and potential of Generative AI models, specifically focusing on their application in role-playing simulations exemplified through Spyfall, a renowned mafia-style game. By leveraging GPT-4's advanced capabilities, the study aimed to showcase the model's potential in understanding, decision-making, and interaction during game scenarios. Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo, demonstrated GPT-4's enhanced adaptability to the game environment, with significant improvements in posing relevant questions and forming human-like responses. However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged. Reflections on game development, financial constraints, and non-verbal limitations of the study were also discussed. The findings suggest that while GPT-4 exhibits promising advancements over earlier models, there remains potential for further development, especially in instilling more human-like attributes in AI.
### A Paradigm Shift in Machine Translation: Boosting Translation  Performance of Large Language Models
 - **Authors:** Haoran Xu, Young Jin Kim, Amr Sharaf, Hany Hassan Awadalla
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2309.11674
 - **Pdf link:** https://arxiv.org/pdf/2309.11674
 - **Abstract**
 Generative Large Language Models (LLMs) have achieved remarkable advancements in various NLP tasks. However, these advances have not been reflected in the translation task, especially those with moderate model sizes (i.e., 7B or 13B parameters), which still lag behind conventional supervised encoder-decoder translation models. Previous studies have attempted to improve the translation capabilities of these moderate LLMs, but their gains have been limited. In this study, we propose a novel fine-tuning approach for LLMs that is specifically designed for the translation task, eliminating the need for the abundant parallel data that traditional translation models usually depend on. Our approach consists of two fine-tuning stages: initial fine-tuning on monolingual data followed by subsequent fine-tuning on a small set of high-quality parallel data. We introduce the LLM developed through this strategy as Advanced Language Model-based trAnslator (ALMA). Based on LLaMA-2 as our underlying model, our results show that the model can achieve an average improvement of more than 12 BLEU and 12 COMET over its zero-shot performance across 10 translation directions from the WMT'21 (2 directions) and WMT'22 (8 directions) test datasets. The performance is significantly better than all prior work and even superior to the NLLB-54B model and GPT-3.5-text-davinci-003, with only 7B or 13B parameters. This method establishes the foundation for a novel training paradigm in machine translation.
### Memory-Augmented LLM Personalization with Short- and Long-Term Memory  Coordination
 - **Authors:** Kai Zhang, Fubang Zhao, Yangyang Kang, Xiaozhong Liu
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2309.11696
 - **Pdf link:** https://arxiv.org/pdf/2309.11696
 - **Abstract**
 Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. However, their unpersonalized generation paradigm may result in suboptimal user-specific outcomes. Typically, users converse differently based on their knowledge and preferences. This necessitates the task of enhancing user-oriented LLM which remains unexplored. While one can fully train an LLM for this objective, the resource consumption is unaffordable. Prior research has explored memory-based methods to store and retrieve knowledge to enhance generation without retraining for new queries. However, we contend that a mere memory module is inadequate to comprehend a user's preference, and fully training an LLM can be excessively costly. In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research into this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
### How Robust is Google's Bard to Adversarial Image Attacks?
 - **Authors:** Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.11751
 - **Pdf link:** https://arxiv.org/pdf/2309.11751
 - **Abstract**
 Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at https://github.com/thu-ml/Attack-Bard.
### Evaluating Large Language Models for Document-grounded Response  Generation in Information-Seeking Dialogues
 - **Authors:** Norbert Braunschweiler, Rama Doddipatla, Simon Keizer, Svetlana Stoyanchev
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.11838
 - **Pdf link:** https://arxiv.org/pdf/2309.11838
 - **Abstract**
 In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses. While both ChatGPT variants are more likely to include information not present in the relevant segments, possibly including a presence of hallucinations, they are rated higher than both the shared task winning system and human responses.
### LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset
 - **Authors:** Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric. P Xing, Joseph E. Gonzalez, Ion Stoica, Hao Zhang
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.11998
 - **Pdf link:** https://arxiv.org/pdf/2309.11998
 - **Abstract**
 Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at \url{https://huggingface.co/datasets/lmsys/lmsys-chat-1m}.
### AceGPT, Localizing Large Language Models in Arabic
 - **Authors:** Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2309.12053
 - **Pdf link:** https://arxiv.org/pdf/2309.12053
 - **Abstract**
 This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities. Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e., Arabic Vicuna-80 and Arabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), as well as the newly-proposed Arabic cultural \& value alignment benchmark. Notably, AceGPT outperforms ChatGPT in the popular Vicuna-80 benchmark when evaluated with GPT-4, despite the benchmark's limited scale. % Natural Language Understanding (NLU) benchmark (i.e., ALUE) Codes, data, and models are in https://github.com/FreedomIntelligence/AceGPT.
### Code Soliloquies for Accurate Calculations in Large Language Models
 - **Authors:** Shashank Sonkar, MyCo Le, Xinghe Chen, Naiming Liu, Debshila Basu Mallick, Richard G. Baraniuk
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2309.12161
 - **Pdf link:** https://arxiv.org/pdf/2309.12161
 - **Abstract**
 High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses.
### Bad Actor, Good Advisor: Exploring the Role of Large Language Models in  Fake News Detection
 - **Authors:** Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, Peng Qi
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2309.12247
 - **Pdf link:** https://arxiv.org/pdf/2309.12247
 - **Abstract**
 Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models.
### The Cambridge Law Corpus: A Corpus for Legal AI Research
 - **Authors:** Andreas Östling, Holli Sargeant, Huiyuan Xie, Ludwig Bull, Alexander Terenin, Leif Jonsson, Måns Magnusson, Felix Steffek
 - **Subjects:** Computation and Language (cs.CL); Computers and Society (cs.CY); Applications (stat.AP)
 - **Arxiv link:** https://arxiv.org/abs/2309.12269
 - **Pdf link:** https://arxiv.org/pdf/2309.12269
 - **Abstract**
 We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
### LLMR: Real-time Prompting of Interactive Worlds using Large Language  Models
 - **Authors:** Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier
 - **Subjects:** Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Emerging Technologies (cs.ET)
 - **Arxiv link:** https://arxiv.org/abs/2309.12276
 - **Pdf link:** https://arxiv.org/pdf/2309.12276
 - **Abstract**
 We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
### MetaMath: Bootstrap Your Own Mathematical Questions for Large Language  Models
 - **Authors:** Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.12284
 - **Pdf link:** https://arxiv.org/pdf/2309.12284
 - **Abstract**
 Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\%$ and $8.7\%$. Particularly, {MetaMath-70B} achieves an accuracy of $82.3\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}. We release the {MetaMathQA} dataset, the {MetaMath} models with different model sizes and the training code for public use.
### The Reversal Curse: LLMs trained on ""A is B"" fail to learn ""B is A""
 - **Authors:** Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans
 - **Subjects:** Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.12288
 - **Pdf link:** https://arxiv.org/pdf/2309.12288
 - **Abstract**
 We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form ""A is B"", it will not automatically generalize to the reverse direction ""B is A"". This is the Reversal Curse. For instance, if a model is trained on ""Olaf Scholz was the ninth Chancellor of Germany"", it will not automatically be able to answer the question, ""Who was the ninth Chancellor of Germany?"". Moreover, the likelihood of the correct answer (""Olaf Scholz"") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if ""A is B'' occurs, ""B is A"" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as ""Uriah Hawthorne is the composer of 'Abyssal Melodies'"" and showing that they fail to correctly answer ""Who composed 'Abyssal Melodies?'"". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as ""Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]"" and the reverse ""Who is Mary Lee Pfeiffer's son?"". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse.
",2023-09-22T01:05:33Z,2023-09-22T01:05:33Z,open,0,"paper submission, privacy issue of LLM-based CA (conventional agents) for users, dark pattern in CA system design, paper title: ""It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents","LLM based conversational agents, disclosure risks, design guidelines","LLM, UI/UX design, documentation",Papers/Docs/Sources,,,,,,,
https://api.github.com/repos/ConsumerDataStandardsAustralia/standards/issues/333,Decision Proposal 333 - Business Consumer Provisions,https://github.com/ConsumerDataStandardsAustralia/standards/issues/333,"**Tuesday 28 November: Decision Made**
The Data Standards Chair has approved this decision. 

The decision record can be found below:
[Decision 333 - Business Consumer Provisions.pdf](https://github.com/ConsumerDataStandardsAustralia/standards/files/13484736/Decision.333.-.Business.Consumer.Provisions.pdf)

This decision takes effect immediately and, as such, the new July 2023 business consumer provisions are now considered permitted CDR functionality.

**Tuesday 24 October: Decision Proposal Published**
Decision Proposal 333 proposes data standards for the new business consumer provisions introduced in the July 2023 CDR Rules.

The decision proposal can be found below:
[DP333 - Business Consumer Provisions.pdf](https://github.com/ConsumerDataStandardsAustralia/standards/files/13112154/DP333.-.Business.Consumer.Provisions.pdf)

The specific topics covered in this paper are:
- Business consumer statements
- Business consumer disclosure consents (BCDC)

This consultation progresses from [DP276](https://github.com/ConsumerDataStandardsAustralia/standards/issues/276) to outline which data standards are being proposed as binding. This paper reflects those proposals and, in response to feedback, incorporates minor wording changes in some instances for greater clarity.

Community views are now being sought before these standards are proposed to be made binding to support the 1 December 2023 obligation date for the new business consumer provisions.

This consultation will close on **Tuesday 21 November 2023**

",2023-10-21T00:33:31Z,2023-12-22T01:21:48Z,closed,19,"prevention of dark pattern, business consumer provisions, consent reviews","Business, exposing consumers","business consumer provisions, consent, avoid dark pattern",DPs prevention in software,,,,,,,
https://api.github.com/repos/kanidm/kanidm/issues/2321,Password length complaint unclear,https://github.com/kanidm/kanidm/issues/2321,"### I did this

Attempting to set a 10-character password results in error `TooShort(10)` from the web UI and `Password too was short, needs to be at least 10 characters long` from the CLI client. An 11-character password is accepted.

### I expected the following

Kanidm should accept the 10-character password as promised or, alternatively, demand an 11-character password instead.

### Kanidm version details

- Output of `kanidm(d) version`: `kanidmd 1.1.0-rc.15`, `kanidm 1.1.0-beta.13-dev`
- Are you running it in a container? If so, which image/tag?: `kanidm/server:latest`
- Operating System / Version (On Unix please post the output of `uname -a`): `Linux $(hostname) 6.2.0-36-generic #37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2 x86_64 GNU/Linux`",2023-11-18T04:38:33Z,2023-11-20T04:12:25Z,closed,10,"good ""forced action DP"" to make user to have a secure authentication, lengthy password","lengthy of password, dp for secure authorization","lengthy password, dark pattern to promote good behavior",DPs in design coding ,,,,,,,
https://api.github.com/repos/LeeKyungwook/get-arxiv-noti/issues/757,"New submissions for Wed, 13 Sep 23",https://github.com/LeeKyungwook/get-arxiv-noti/issues/757,"## Keyword: detection
### REVERSIM: A Game-Based Approach to Accessing Large Populations for  Studying Human Aspects in Hardware Reverse Engineering
 - **Authors:** Authors: Steffen Becker, Carina Wiesen, René Walendy, Nikol Rummel, Christof Paar
 - **Subjects:** Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2309.05740
 - **Pdf link:** https://arxiv.org/pdf/2309.05740
 - **Abstract**
 Hardware Reverse Engineering (HRE) is a technique for analyzing Integrated Circuits (ICs). Experts employ HRE for various security-critical tasks, such as design verification or the detection of intellectual property violations. However, HRE also enables threat actors to subvert the security of an IC. Previous studies have shown that analysts rely heavily on their cognitive abilities to perform HRE as no fully automated solutions exist. Therefore, conducting controlled experimental studies to assess the cognitive processes involved in HRE could open new avenues for hardware protection. However, researchers have faced the methodological challenge that HRE experts are largely unavailable for such empirical research. To address this scarcity, we have developed REVERSIM, a game-based simulation that mimics realistic HRE subprocesses and is specifically designed to require no prior knowledge. To support these claims, we conducted two empirical studies: First, we performed semi-structured interviews with 14 professionals and researchers from the HRE domain, who attested to the comparability of REVERSIM to real-world HRE problems. Second, we conducted a user study involving 89 non-expert participants, demonstrating that participants could engage in the simulation without prior knowledge in HRE or related domains. Finally, we outline several research directions for experiments with REVERSIM, highlighting its potential in advancing HRE research.
### Grey-box Bayesian Optimization for Sensor Placement in Assisted Living  Environments
 - **Authors:** Authors: Shadan Golestan, Omid Ardakanian, Pierre Boulanger
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2309.05784
 - **Pdf link:** https://arxiv.org/pdf/2309.05784
 - **Abstract**
 Optimizing the configuration and placement of sensors is crucial for reliable fall detection, indoor localization, and activity recognition in assisted living spaces. We propose a novel, sample-efficient approach to find a high-quality sensor placement in an arbitrary indoor space based on grey-box Bayesian optimization and simulation-based evaluation. Our key technical contribution lies in capturing domain-specific knowledge about the spatial distribution of activities and incorporating it into the iterative selection of query points in Bayesian optimization. Considering two simulated indoor environments and a real-world dataset containing human activities and sensor triggers, we show that our proposed method performs better compared to state-of-the-art black-box optimization techniques in identifying high-quality sensor placements, leading to accurate activity recognition in terms of F1-score, while also requiring a significantly lower (51.3% on average) number of expensive function queries.
### Use of a low-cost forward-looking sonar for collision avoidance in small  AUVs, analysis and experimental results
 - **Authors:** Authors: Christopher Morency, Daniel J. Stilwell, Stephen T. Krauss
 - **Subjects:** Robotics (cs.RO); Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2309.05785
 - **Pdf link:** https://arxiv.org/pdf/2309.05785
 - **Abstract**
 In this paper, we seek to evaluate the effectiveness of a novel forward-looking sonar system with a limited number of beams for collision avoidance for small autonomous underwater vehicles (AUVs). We present a collision avoidance strategy specifically designed for a novel forward-looking sonar system based on posterior expected loss, explicitly coupling the obstacle detection, collision avoidance, and planning. We demonstrate the strategy with field trials using the 690 AUV, built by the Center for Marine Autonomy and Robotics at Virginia Tech, and verify the forward-looking sonar system using a prototype sonar with nine beams. Post-processed simulations are performed while changing parameters in the sensitivity of the system to demonstrate the trade-off between the detection and false alarm rates.
### Adaptive User-centered Neuro-symbolic Learning for Multimodal  Interaction with Autonomous Systems
 - **Authors:** Authors: Amr Gomaa, Michael Feld
 - **Subjects:** Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.05787
 - **Pdf link:** https://arxiv.org/pdf/2309.05787
 - **Abstract**
 Recent advances in machine learning, particularly deep learning, have enabled autonomous systems to perceive and comprehend objects and their environments in a perceptual subsymbolic manner. These systems can now perform object detection, sensor data fusion, and language understanding tasks. However, there is a growing need to enhance these systems to understand objects and their environments more conceptually and symbolically. It is essential to consider both the explicit teaching provided by humans (e.g., describing a situation or explaining how to act) and the implicit teaching obtained by observing human behavior (e.g., through the system's sensors) to achieve this level of powerful artificial intelligence. Thus, the system must be designed with multimodal input and output capabilities to support implicit and explicit interaction models. In this position paper, we argue for considering both types of inputs, as well as human-in-the-loop and incremental learning techniques, for advancing the field of artificial intelligence and enabling autonomous systems to learn like humans. We propose several hypotheses and design guidelines and highlight a use case from related work to achieve this goal.
### Rice Plant Disease Detection and Diagnosis using Deep Convolutional  Neural Networks and Multispectral Imaging
 - **Authors:** Authors: Yara Ali Alnaggar, Ahmad Sebaq, Karim Amer, ElSayed Naeem, Mohamed Elhelw
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
 - **Arxiv link:** https://arxiv.org/abs/2309.05818
 - **Pdf link:** https://arxiv.org/pdf/2309.05818
 - **Abstract**
 Rice is considered a strategic crop in Egypt as it is regularly consumed in the Egyptian people's diet. Even though Egypt is the highest rice producer in Africa with a share of 6 million tons per year, it still imports rice to satisfy its local needs due to production loss, especially due to rice disease. Rice blast disease is responsible for 30% loss in rice production worldwide. Therefore, it is crucial to target limiting yield damage by detecting rice crops diseases in its early stages. This paper introduces a public multispectral and RGB images dataset and a deep learning pipeline for rice plant disease detection using multi-modal data. The collected multispectral images consist of Red, Green and Near-Infrared channels and we show that using multispectral along with RGB channels as input archives a higher F1 accuracy compared to using RGB input only.
### Effective Abnormal Activity Detection on Multivariate Time Series  Healthcare Data
 - **Authors:** Authors: Mengjia Niu, Yuchen Zhao, Hamed Haddadi
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.05845
 - **Pdf link:** https://arxiv.org/pdf/2309.05845
 - **Abstract**
 Multivariate time series (MTS) data collected from multiple sensors provide the potential for accurate abnormal activity detection in smart healthcare scenarios. However, anomalies exhibit diverse patterns and become unnoticeable in MTS data. Consequently, achieving accurate anomaly detection is challenging since we have to capture both temporal dependencies of time series and inter-relationships among variables. To address this problem, we propose a Residual-based Anomaly Detection approach, Rs-AD, for effective representation learning and abnormal activity detection. We evaluate our scheme on a real-world gait dataset and the experimental results demonstrate an F1 score of 0.839.
### Systemization of Knowledge (SoK)- Cross Impact of Transfer Learning in  Cybersecurity: Offensive, Defensive and Threat Intelligence Perspectives
 - **Authors:** Authors: Sofiya Makar, Ali Dehghantanha, Fattane Zarrinkalam, Gautam Srivastava, Abbas Yazdinejad
 - **Subjects:** Cryptography and Security (cs.CR)
 - **Arxiv link:** https://arxiv.org/abs/2309.05889
 - **Pdf link:** https://arxiv.org/pdf/2309.05889
 - **Abstract**
 Recent literature highlights a significant cross-impact between transfer learning and cybersecurity. Many studies have been conducted on using transfer learning to enhance security, leading to various applications in different cybersecurity tasks. However, previous research is focused on specific areas of cybersecurity. This paper presents a comprehensive survey of transfer learning applications in cybersecurity by covering a wide range of domains, identifying current trends, and shedding light on under-explored areas. The survey highlights the significance of transfer learning in addressing critical issues in cybersecurity, such as improving detection accuracy, reducing training time, handling data imbalance, and enhancing privacy preservation. Additional insights are provided on the common problems solved using transfer learning, such as the lack of labeled data, different data distributions, and privacy concerns. The paper identifies future research directions and challenges that require community attention, including the need for privacy-preserving models, automatic tools for knowledge transfer, metrics for measuring domain relatedness, and enhanced privacy preservation mechanisms. The insights and roadmap presented in this paper will guide researchers in further advancing transfer learning in cybersecurity, fostering the development of robust and efficient cybersecurity systems to counter emerging threats and protect sensitive information. To the best of our knowledge, this paper is the first of its kind to present a comprehensive taxonomy of all areas of cybersecurity that benefited from transfer learning and propose a detailed future roadmap to shape the possible research direction in this area.
### Adversarial Attacks Assessment of Salient Object Detection via Symbolic  Learning
 - **Authors:** Authors: Gustavo Olague, Roberto Pineda, Gerardo Ibarra-Vazquez, Matthieu Olague, Axel Martinez, Sambit Bakshi, Jonathan Vargas, Isnardo Reducindo
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
 - **Arxiv link:** https://arxiv.org/abs/2309.05900
 - **Pdf link:** https://arxiv.org/pdf/2309.05900
 - **Abstract**
 Machine learning is at the center of mainstream technology and outperforms classical approaches to handcrafted feature design. Aside from its learning process for artificial feature extraction, it has an end-to-end paradigm from input to output, reaching outstandingly accurate results. However, security concerns about its robustness to malicious and imperceptible perturbations have drawn attention since its prediction can be changed entirely. Salient object detection is a research area where deep convolutional neural networks have proven effective but whose trustworthiness represents a significant issue requiring analysis and solutions to hackers' attacks. Brain programming is a kind of symbolic learning in the vein of good old-fashioned artificial intelligence. This work provides evidence that symbolic learning robustness is crucial in designing reliable visual attention systems since it can withstand even the most intense perturbations. We test this evolutionary computation methodology against several adversarial attacks and noise perturbations using standard databases and a real-world problem of a shorebird called the Snowy Plover portraying a visual attention task. We compare our methodology with five different deep learning approaches, proving that they do not match the symbolic paradigm regarding robustness. All neural networks suffer significant performance losses, while brain programming stands its ground and remains unaffected. Also, by studying the Snowy Plover, we remark on the importance of security in surveillance activities regarding wildlife protection and conservation.
### Quality-Agnostic Deepfake Detection with Intra-model Collaborative  Learning
 - **Authors:** Authors: Binh M. Le, Simon S. Woo
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.05911
 - **Pdf link:** https://arxiv.org/pdf/2309.05911
 - **Abstract**
 Deepfake has recently raised a plethora of societal concerns over its possible security threats and dissemination of fake information. Much research on deepfake detection has been undertaken. However, detecting low quality as well as simultaneously detecting different qualities of deepfakes still remains a grave challenge. Most SOTA approaches are limited by using a single specific model for detecting certain deepfake video quality type. When constructing multiple models with prior information about video quality, this kind of strategy incurs significant computational cost, as well as model and training data overhead. Further, it cannot be scalable and practical to deploy in real-world settings. In this work, we propose a universal intra-model collaborative learning framework to enable the effective and simultaneous detection of different quality of deepfakes. That is, our approach is the quality-agnostic deepfake detection method, dubbed QAD . In particular, by observing the upper bound of general error expectation, we maximize the dependency between intermediate representations of images from different quality levels via Hilbert-Schmidt Independence Criterion. In addition, an Adversarial Weight Perturbation module is carefully devised to enable the model to be more robust against image corruption while boosting the overall model's performance. Extensive experiments over seven popular deepfake datasets demonstrate the superiority of our QAD model over prior SOTA benchmarks.
### GLAD: Content-aware Dynamic Graphs For Log Anomaly Detection
 - **Authors:** Authors: Yufei Li, Yanchi Liu, Haoyu Wang, Zhengzhang Chen, Wei Cheng, Yuncong Chen, Wenchao Yu, Haifeng Chen, Cong Liu
 - **Subjects:** Machine Learning (cs.LG); Information Retrieval (cs.IR)
 - **Arxiv link:** https://arxiv.org/abs/2309.05953
 - **Pdf link:** https://arxiv.org/pdf/2309.05953
 - **Abstract**
 Logs play a crucial role in system monitoring and debugging by recording valuable system information, including events and states. Although various methods have been proposed to detect anomalies in log sequences, they often overlook the significance of considering relations among system components, such as services and users, which can be identified from log contents. Understanding these relations is vital for detecting anomalies and their underlying causes. To address this issue, we introduce GLAD, a Graph-based Log Anomaly Detection framework designed to detect relational anomalies in system logs. GLAD incorporates log semantics, relational patterns, and sequential patterns into a unified framework for anomaly detection. Specifically, GLAD first introduces a field extraction module that utilizes prompt-based few-shot learning to identify essential fields from log contents. Then GLAD constructs dynamic log graphs for sliding windows by interconnecting extracted fields and log events parsed from the log parser. These graphs represent events and fields as nodes and their relations as edges. Subsequently, GLAD utilizes a temporal-attentive graph edge anomaly detection model for identifying anomalous relations in these dynamic log graphs. This model employs a Graph Neural Network (GNN)-based encoder enhanced with transformers to capture content, structural and temporal features. We evaluate our proposed method on three datasets, and the results demonstrate the effectiveness of GLAD in detecting anomalies indicated by varying relational patterns.
### Beyond Generation: Harnessing Text to Image Models for Object Detection  and Segmentation
 - **Authors:** Authors: Yunhao Ge, Jiashu Xu, Brian Nlong Zhao, Neel Joshi, Laurent Itti, Vibhav Vineet
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2309.05956
 - **Pdf link:** https://arxiv.org/pdf/2309.05956
 - **Abstract**
 We propose a new paradigm to automatically generate training data with accurate labels at scale using the text-to-image synthesis frameworks (e.g., DALL-E, Stable Diffusion, etc.). The proposed approach1 decouples training data generation into foreground object generation, and contextually coherent background generation. To generate foreground objects, we employ a straightforward textual template, incorporating the object class name as input prompts. This is fed into a text-to-image synthesis framework, producing various foreground images set against isolated backgrounds. A foreground-background segmentation algorithm is then used to generate foreground object masks. To generate context images, we begin by creating language descriptions of the context. This is achieved by applying an image captioning method to a small set of images representing the desired context. These textual descriptions are then transformed into a diverse array of context images via a text-to-image synthesis framework. Subsequently, we composite these with the foreground object masks produced in the initial step, utilizing a cut-and-paste method, to formulate the training data. We demonstrate the advantages of our approach on five object detection and segmentation datasets, including Pascal VOC and COCO. We found that detectors trained solely on synthetic data produced by our method achieve performance comparable to those trained on real data (Fig. 1). Moreover, a combination of real and synthetic data yields even much better results. Further analysis indicates that the synthetic data distribution complements the real data distribution effectively. Additionally, we emphasize the compositional nature of our data generation approach in out-of-distribution and zero-shot data generation scenarios. We open-source our code at https://github.com/gyhandy/Text2Image-for-Detection
### Optimizing Reported Age of Information with Short Error Correction and  Detection Codes
 - **Authors:** Authors: Sumanth S Raikar, Rajshekhar V Bhat
 - **Subjects:** Information Theory (cs.IT)
 - **Arxiv link:** https://arxiv.org/abs/2309.05974
 - **Pdf link:** https://arxiv.org/pdf/2309.05974
 - **Abstract**
 Timely sampling and fresh information delivery are important in 6G communications. This is achieved by encoding samples into short packets/codewords for transmission, with potential decoding errors. We consider a broadcasting base station (BS) that samples information from multiple sources and transmits to respective destinations/users, using short-blocklength cyclic and deep learning (DL) based codes for error correction, and cyclic-redundancy-check (CRC) codes for error detection. We use a metric called reported age of information (AoI), abbreviated as RAoI, to measure the freshness of information, which increases from an initial value if the CRC reports a failure, else is reset. We minimize long-term average expected RAoI, subject to constraints on transmission power and distortion, for which we obtain age-agnostic randomized and age-aware drift-plus-penalty policies that decide which user to transmit to, with what message-word length and transmit power, and derive bounds on their performance. Simulations show that longer CRC codes lead to higher RAoI, but the RAoI achieved is closer to the true, genie-aided AoI. DL-based codes achieve lower RAoI. Finally, we conclude that prior AoI optimization literature with finite blocklengths substantially underestimates AoI because they assume that all errors can be detected perfectly without using CRC.
### FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging  Long-Distance Dependencies
 - **Authors:** Authors: Xuefeng Wei, Xuan Zhou
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2309.05987
 - **Pdf link:** https://arxiv.org/pdf/2309.05987
 - **Abstract**
 Given the close association between colorectal cancer and polyps, the diagnosis and identification of colorectal polyps play a critical role in the detection and surgical intervention of colorectal cancer. In this context, the automatic detection and segmentation of polyps from various colonoscopy images has emerged as a significant problem that has attracted broad attention. Current polyp segmentation techniques face several challenges: firstly, polyps vary in size, texture, color, and pattern; secondly, the boundaries between polyps and mucosa are usually blurred, existing studies have focused on learning the local features of polyps while ignoring the long-range dependencies of the features, and also ignoring the local context and global contextual information of the combined features. To address these challenges, we propose FLDNet (Foreground-Long-Distance Network), a Transformer-based neural network that captures long-distance dependencies for accurate polyp segmentation. Specifically, the proposed model consists of three main modules: a pyramid-based Transformer encoder, a local context module, and a foreground-Aware module. Multilevel features with long-distance dependency information are first captured by the pyramid-based transformer encoder. On the high-level features, the local context module obtains the local characteristics related to the polyps by constructing different local context information. The coarse map obtained by decoding the reconstructed highest-level features guides the feature fusion process in the foreground-Aware module of the high-level features to achieve foreground enhancement of the polyps. Our proposed method, FLDNet, was evaluated using seven metrics on common datasets and demonstrated superiority over state-of-the-art methods on widely-used evaluation measures.
### ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution  Detection in Segmentation
 - **Authors:** Authors: Zhitong Gao, Shipeng Yan, Xuming He
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.05994
 - **Pdf link:** https://arxiv.org/pdf/2309.05994
 - **Abstract**
 Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models.
### A new meteor detection application robust to camera movements
 - **Authors:** Authors: Clara Ciocan (ALSOC), Mathuran Kandeepan (ALSOC), Adrien Cassagne (ALSOC), Jeremie Vaubaillon (IMCCE), Fabian Zander (USQ), Lionel Lacassagne (ALSOC)
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
 - **Arxiv link:** https://arxiv.org/abs/2309.06027
 - **Pdf link:** https://arxiv.org/pdf/2309.06027
 - **Abstract**
 This article presents a new tool for the automatic detection of meteors. Fast Meteor Detection Toolbox (FMDT) is able to detect meteor sightings by analyzing videos acquired by cameras onboard weather balloons or within airplane with stabilization. The challenge consists in designing a processing chain composed of simple algorithms, that are robust to the high fluctuation of the videos and that satisfy the constraints on power consumption (10 W) and real-time processing (25 frames per second).
### Normality Learning-based Graph Anomaly Detection via Multi-Scale  Contrastive Learning
 - **Authors:** Authors: Jingcan Duan, Pei Zhang, Siwei Wang, Jingtao Hu, Hu Jin, Jiaxin Zhang, Haifang Zhou, Haifang Zhou
 - **Subjects:** Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.06034
 - **Pdf link:** https://arxiv.org/pdf/2309.06034
 - **Abstract**
 Graph anomaly detection (GAD) has attracted increasing attention in machine learning and data mining. Recent works have mainly focused on how to capture richer information to improve the quality of node embeddings for GAD. Despite their significant advances in detection performance, there is still a relative dearth of research on the properties of the task. GAD aims to discern the anomalies that deviate from most nodes. However, the model is prone to learn the pattern of normal samples which make up the majority of samples. Meanwhile, anomalies can be easily detected when their behaviors differ from normality. Therefore, the performance can be further improved by enhancing the ability to learn the normal pattern. To this end, we propose a normality learning-based GAD framework via multi-scale contrastive learning networks (NLGAD for abbreviation). Specifically, we first initialize the model with the contrastive networks on different scales. To provide sufficient and reliable normal nodes for normality learning, we design an effective hybrid strategy for normality selection. Finally, the model is refined with the only input of reliable normal nodes and learns a more accurate estimate of normality so that anomalous nodes can be more easily distinguished. Eventually, extensive experiments on six benchmark graph datasets demonstrate the effectiveness of our normality learning-based scheme on GAD. Notably, the proposed algorithm improves the detection performance (up to 5.89% AUC gain) compared with the state-of-the-art methods. The source code is released at https://github.com/FelixDJC/NLGAD.
### Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms:  Exploring Tuning Strategies
 - **Authors:** Authors: Boshko Koloski, Blaž Škrlj, Marko Robnik-Šikonja, Senja Pollak
 - **Subjects:** Computation and Language (cs.CL); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2309.06089
 - **Pdf link:** https://arxiv.org/pdf/2309.06089
 - **Abstract**
 The cross-lingual transfer is a promising technique to solve tasks in less-resourced languages. In this empirical study, we compare two fine-tuning approaches combined with zero-shot and full-shot learning approaches for large language models in a cross-lingual setting. As fine-tuning strategies, we compare parameter-efficient adapter methods with fine-tuning of all parameters. As cross-lingual transfer strategies, we compare the intermediate-training (\textit{IT}) that uses each language sequentially and cross-lingual validation (\textit{CLV}) that uses a target language already in the validation phase of fine-tuning. We assess the success of transfer and the extent of catastrophic forgetting in a source language due to cross-lingual transfer, i.e., how much previously acquired knowledge is lost when we learn new information in a different language. The results on two different classification problems, hate speech detection and product reviews, each containing datasets in several languages, show that the \textit{IT} cross-lingual strategy outperforms \textit{CLV} for the target language. Our findings indicate that, in the majority of cases, the \textit{CLV} strategy demonstrates superior retention of knowledge in the base language (English) compared to the \textit{IT} strategy, when evaluating catastrophic forgetting in multiple cross-lingual transfers.
### JOADAA: joint online action detection and action anticipation
 - **Authors:** Authors: Mohammed Guermal, Francois Bremond, Rui Dai, Abid Ali
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.06130
 - **Pdf link:** https://arxiv.org/pdf/2309.06130
 - **Abstract**
 Action anticipation involves forecasting future actions by connecting past events to future ones. However, this reasoning ignores the real-life hierarchy of events which is considered to be composed of three main parts: past, present, and future. We argue that considering these three main parts and their dependencies could improve performance. On the other hand, online action detection is the task of predicting actions in a streaming manner. In this case, one has access only to the past and present information. Therefore, in online action detection (OAD) the existing approaches miss semantics or future information which limits their performance. To sum up, for both of these tasks, the complete set of knowledge (past-present-future) is missing, which makes it challenging to infer action dependencies, therefore having low performances. To address this limitation, we propose to fuse both tasks into a single uniform architecture. By combining action anticipation and online action detection, our approach can cover the missing dependencies of future information in online action detection. This method referred to as JOADAA, presents a uniform model that jointly performs action anticipation and online action detection. We validate our proposed model on three challenging datasets: THUMOS'14, which is a sparsely annotated dataset with one action per time step, CHARADES, and Multi-THUMOS, two densely annotated datasets with more complex scenarios. JOADAA achieves SOTA results on these benchmarks for both tasks.
### Cookiescanner: An Automated Tool for Detecting and Evaluating GDPR  Consent Notices on Websites
 - **Authors:** Authors: Ralf Gundelach, Dominik Herrmann
 - **Subjects:** Computers and Society (cs.CY)
 - **Arxiv link:** https://arxiv.org/abs/2309.06196
 - **Pdf link:** https://arxiv.org/pdf/2309.06196
 - **Abstract**
 The enforcement of the GDPR led to the widespread adoption of consent notices, colloquially known as cookie banners. Studies have shown that many website operators do not comply with the law and track users prior to any interaction with the consent notice, or attempt to trick users into giving consent through dark patterns. Previous research has relied on manually curated filter lists or automated detection methods limited to a subset of websites, making research on GDPR compliance of consent notices tedious or limited. We present \emph{cookiescanner}, an automated scanning tool that detects and extracts consent notices via various methods and checks if they offer a decline option or use color diversion. We evaluated cookiescanner on a random sample of the top 10,000 websites listed by Tranco. We found that manually curated filter lists have the highest precision but recall fewer consent notices than our keyword-based methods. Our BERT model achieves high precision for English notices, which is in line with previous work, but suffers from low recall due to insufficient candidate extraction. While the automated detection of decline options proved to be challenging due to the dynamic nature of many sites, detecting instances of different colors of the buttons was successful in most cases. Besides systematically evaluating our various detection techniques, we have manually annotated 1,000 websites to provide a ground-truth baseline, which has not existed previously. Furthermore, we release our code and the annotated dataset in the interest of reproducibility and repeatability.
### SCP: Scene Completion Pre-training for 3D Object Detection
 - **Authors:** Authors: Yiming Shan, Yan Xia, Yuhong Chen, Daniel Cremers
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.06199
 - **Pdf link:** https://arxiv.org/pdf/2309.06199
 - **Abstract**
 3D object detection using LiDAR point clouds is a fundamental task in the fields of computer vision, robotics, and autonomous driving. However, existing 3D detectors heavily rely on annotated datasets, which are both time-consuming and prone to errors during the process of labeling 3D bounding boxes. In this paper, we propose a Scene Completion Pre-training (SCP) method to enhance the performance of 3D object detectors with less labeled data. SCP offers three key advantages: (1) Improved initialization of the point cloud model. By completing the scene point clouds, SCP effectively captures the spatial and semantic relationships among objects within urban environments. (2) Elimination of the need for additional datasets. SCP serves as a valuable auxiliary network that does not impose any additional efforts or data requirements on the 3D detectors. (3) Reduction of the amount of labeled data for detection. With the help of SCP, the existing state-of-the-art 3D detectors can achieve comparable performance while only relying on 20% labeled data.
### Jersey Number Recognition using Keyframe Identification from  Low-Resolution Broadcast Videos
 - **Authors:** Authors: Bavesh Balaji, Jerrin Bright, Harish Prakash, Yuhao Chen, David A Clausi, John Zelek
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2309.06285
 - **Pdf link:** https://arxiv.org/pdf/2309.06285
 - **Abstract**
 Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production. However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions. Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames. Hence, identifying frames that contain the jersey number is a key sub-problem to tackle. To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number. A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video. Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately. Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps. These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.
### Self-Training and Multi-Task Learning for Limited Data: Evaluation Study  on Object Detection
 - **Authors:** Authors: Hoàng-Ân Lê, Minh-Tan Pham
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2309.06288
 - **Pdf link:** https://arxiv.org/pdf/2309.06288
 - **Abstract**
 Self-training allows a network to learn from the predictions of a more complicated model, thus often requires well-trained teacher models and mixture of teacher-student data while multi-task learning jointly optimizes different targets to learn salient interrelationship and requires multi-task annotations for each training example. These frameworks, despite being particularly data demanding have potentials for data exploitation if such assumptions can be relaxed. In this paper, we compare self-training object detection under the deficiency of teacher training data where students are trained on unseen examples by the teacher, and multi-task learning with partially annotated data, i.e. single-task annotation per training example. Both scenarios have their own limitation but potentially helpful with limited annotated data. Experimental results show the improvement of performance when using a weak teacher with unseen data for training a multi-task student. Despite the limited setup we believe the experimental results show the potential of multi-task knowledge distillation and self-training, which could be beneficial for future study. Source code is at https://lhoangan.github.io/multas.
### Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle
 - **Authors:** Authors: Maria Priisalu
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2309.06313
 - **Pdf link:** https://arxiv.org/pdf/2309.06313
 - **Abstract**
 It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle. Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often. This has led to the popularisation of traffic data-specific benchmarks. Recently Light Detection And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions. However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods. We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians.
### The Time Complexity of Fully Sparse Matrix Multiplication
 - **Authors:** Authors: Amir Abboud, Karl Bringmann, Nick Fischer, Marvin Künnemann
 - **Subjects:** Data Structures and Algorithms (cs.DS)
 - **Arxiv link:** https://arxiv.org/abs/2309.06317
 - **Pdf link:** https://arxiv.org/pdf/2309.06317
 - **Abstract**
 What is the time complexity of matrix multiplication of sparse integer matrices with $m_{in}$ nonzeros in the input and $m_{out}$ nonzeros in the output? This paper provides improved upper bounds for this question for almost any choice of $m_{in}$ vs. $m_{out}$, and provides evidence that these new bounds might be optimal up to further progress on fast matrix multiplication. Our main contribution is a new algorithm that reduces sparse matrix multiplication to dense (but smaller) rectangular matrix multiplication. Our running time thus depends on the optimal exponent $\omega(a,b,c)$ of multiplying dense $n^a\times n^b$ by $n^b\times n^c$ matrices. We discover that when $m_{out}=\Theta(m_{in}^r)$ the time complexity of sparse matrix multiplication is $O(m_{in}^{\sigma+\epsilon})$, for all $\epsilon > 0$, where $\sigma$ is the solution to the equation $\omega(\sigma-1,2-\sigma,1+r-\sigma)=\sigma$. No matter what $\omega(\cdot,\cdot,\cdot)$ turns out to be, and for all $r\in(0,2)$, the new bound beats the state of the art, and we provide evidence that it is optimal based on the complexity of the all-edge triangle problem. In particular, in terms of the input plus output size $m = m_{in} + m_{out}$ our algorithm runs in time $O(m^{1.3459})$. Even for Boolean matrices, this improves over the previous $m^{\frac{2\omega}{\omega+1}+\epsilon}=O(m^{1.4071})$ bound [Amossen, Pagh; 2009], which was a natural barrier since it coincides with the longstanding bound of all-edge triangle in sparse graphs [Alon, Yuster, Zwick; 1994]. We find it interesting that matrix multiplication can be solved faster than triangle detection in this natural setting. In fact, we establish an equivalence to a special case of the all-edge triangle problem.
## Keyword: face recognition
There is no result 
## Keyword: augmentation
### Enhancing Hyperedge Prediction with Context-Aware Self-Supervised  Learning
 - **Authors:** Authors: Yunyong Ko, Hanghang Tong, Sang-Wook Kim
 - **Subjects:** Machine Learning (cs.LG); Social and Information Networks (cs.SI)
 - **Arxiv link:** https://arxiv.org/abs/2309.05798
 - **Pdf link:** https://arxiv.org/pdf/2309.05798
 - **Abstract**
 Hypergraphs can naturally model group-wise relations (e.g., a group of users who co-purchase an item) as hyperedges. Hyperedge prediction is to predict future or unobserved hyperedges, which is a fundamental task in many real-world applications (e.g., group recommendation). Despite the recent breakthrough of hyperedge prediction methods, the following challenges have been rarely studied: (C1) How to aggregate the nodes in each hyperedge candidate for accurate hyperedge prediction? and (C2) How to mitigate the inherent data sparsity problem in hyperedge prediction? To tackle both challenges together, in this paper, we propose a novel hyperedge prediction framework (CASH) that employs (1) context-aware node aggregation to precisely capture complex relations among nodes in each hyperedge for (C1) and (2) self-supervised contrastive learning in the context of hyperedge prediction to enhance hypergraph representations for (C2). Furthermore, as for (C2), we propose a hyperedge-aware augmentation method to fully exploit the latent semantics behind the original hypergraph and consider both node-level and group-level contrasts (i.e., dual contrasts) for better node and hyperedge representations. Extensive experiments on six real-world hypergraphs reveal that CASH consistently outperforms all competing methods in terms of the accuracy in hyperedge prediction and each of the proposed strategies is effective in improving the model accuracy of CASH. For the detailed information of CASH, we provide the code and datasets at: https://github.com/yy-ko/cash.
### Optimizing Audio Augmentations for Contrastive Learning of  Health-Related Acoustic Signals
 - **Authors:** Authors: Louis Blankemeier, Sebastien Baur, Wei-Hung Weng, Jake Garrison, Yossi Matias, Shruthi Prabhakara, Diego Ardila, Zaid Nabulsi
 - **Subjects:** Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
 - **Arxiv link:** https://arxiv.org/abs/2309.05843
 - **Pdf link:** https://arxiv.org/pdf/2309.05843
 - **Abstract**
 Health-related acoustic signals, such as cough and breathing sounds, are relevant for medical diagnosis and continuous health monitoring. Most existing machine learning approaches for health acoustics are trained and evaluated on specific tasks, limiting their generalizability across various healthcare applications. In this paper, we leverage a self-supervised learning framework, SimCLR with a Slowfast NFNet backbone, for contrastive learning of health acoustics. A crucial aspect of optimizing Slowfast NFNet for this application lies in identifying effective audio augmentations. We conduct an in-depth analysis of various audio augmentation strategies and demonstrate that an appropriate augmentation strategy enhances the performance of the Slowfast NFNet audio encoder across a diverse set of health acoustic tasks. Our findings reveal that when augmentations are combined, they can produce synergistic effects that exceed the benefits seen when each is applied individually.
### Balanced and Explainable Social Media Analysis for Public Health with  Large Language Models
 - **Authors:** Authors: Yan Jiang, Ruihong Qiu, Yi Zhang, Peng-Fei Zhang
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2309.05951
 - **Pdf link:** https://arxiv.org/pdf/2309.05951
 - **Abstract**
 As social media becomes increasingly popular, more and more public health activities emerge, which is worth noting for pandemic monitoring and government decision-making. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). Although recent progress in LLMs has shown a strong ability to comprehend knowledge by being fine-tuned on specific domain datasets, the costs of training an in-domain LLM for every specific public health task are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally highly imbalanced, which will hinder the efficiency of LLMs tuning. To tackle these challenges, the data imbalance issue can be overcome by sophisticated data augmentation methods for social media datasets. In addition, the ability of the LLMs can be effectively utilised by prompting the model properly. In light of the above discussion, in this paper, a novel ALEX framework is proposed for social media analysis on public health. Specifically, an augmentation pipeline is developed to resolve the data imbalance issue. Furthermore, an LLMs explanation mechanism is proposed by prompting an LLM with the predicted results from BERT models. Extensive experiments conducted on three tasks at the Social Media Mining for Health 2023 (SMM4H) competition with the first ranking in two tasks demonstrate the superior performance of the proposed ALEX method. Our code has been released in https://github.com/YanJiangJerry/ALEX.
### BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise
 - **Authors:** Authors: Jeroen M. Galjaard, Robert Birke, Juan Perez, Lydia Y. Chen
 - **Subjects:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)
 - **Arxiv link:** https://arxiv.org/abs/2309.06046
 - **Pdf link:** https://arxiv.org/pdf/2309.06046
 - **Abstract**
 The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastive-shot tasks through augmentation, learning the embedding via a contrastive loss in meta-training, and then perform classification through zeroing on the embedding in meta-testing. We show that our approach can effectively mitigate the impact of meta-training label noise. Even with 60% wrong labels \batman and \man can limit the meta-testing accuracy drop to ${2.5}$, ${9.4}$, ${1.1}$ percent points, respectively, with existing meta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.
",2023-09-14T00:00:07Z,2023-09-14T00:00:07Z,open,0,"paper submission, cookiescanner tool, GDPR regulation on consent policy, paper title: Cookiescanner: An Automated Tool for Detecting and Evaluating GDPR Consent Notices on Websites","GDPR consent notices, tracking before consent","GDPR, regulation, consent, tracking, documentation",Papers/Docs/Sources,,,,,,,
https://api.github.com/repos/dear-digital/linter/issues/70,🔍 [DISCOVERY] - Best Practices for User Experience (UX),https://github.com/dear-digital/linter/issues/70,"### Is there an existing Discovery issue on this topic?

- [X] I have searched the existing issues

### Objective

Use chatGPT3.5 or chatGPT4 to ask the following question.

If using chatGPT3.5:
```
You are ChatGPT, and your role is to engage in a recursive, endless discussion with me on a topic we decide upon. If the conversation drifts away from the topic, I will use the command 'Align conversation' to bring it back on track. At the end of each conversation, provide a short analysis summarizing how the discussion relates to the topic at hand. Whenever you explain something, always include examples or scenarios to clarify your points and for better understanding. Keep a common objective in mind while answering.

Topic ""Best Practices for User Experience (UX)""
```

If using chatGPT4:
```
You are ChatGPT, and your role is to engage in a recursive, endless discussion with me on a topic we decide upon. If the conversation drifts away from the topic, I will use the command 'Align conversation' to bring it back on track. At the end of each conversation, provide a short analysis summarizing how the discussion relates to the topic at hand. Whenever you explain something, include examples to clarify your points. The ultimate goal is to create a knowledge base from our discussion that can be easily transferred to another person, allowing them to build upon it and add their own inputs. For every answer containing information that I've asked for, provide the data in a structured JSON format in key-value pairs like {""question"": ""answer""}, {""question"": ""answer""} that can be easily copied into a JSON file. Keep a common objective in mind while answering.

Topic ""Best Practices for User Experience (UX)""
```

Follow up on this topic with atleast 10 more such questions 


### Reference Materials

_No response_

### Expected Outcome

List down only the key insights gained from multiple rounds of questioning.
List all the questions/prompts used below in the comment section

### Example on how to write outcome
> #### Initial Prompt:
> - [given above]
> 
> #### Recursive Prompts:
> 1. ""How do linters work under the hood?""
> 2. ""What types of problems can linters catch?""
> 3. ""Explain the impact of linting on code quality.""
> 4. ""How can linting be integrated into a continuous integration (CI) system?""
> .
> .
> .
> 
> #### Outcome:
> 
> ##### Key Insights gained:
> - Linting is the process of checking source code for programmatic and stylistic errors.
> - Linters use static analysis to identify issues without running the code.
> - They can catch syntax errors, potential bugs, or even style guide violations.
> - Linting contributes to better code readability and maintainability.
> - It can be automated and integrated into CI pipelines for consistent code quality.
> .
> .
> .
> 



### Have you provided comprehensive details for this discovery task?

- [X] Yes, I have provided comprehensive details",2023-09-06T05:49:01Z,2023-09-08T11:08:14Z,closed,1,Best practices for UX topic in ChatGPT prompt,"User Experience, ethical issues","ChatGPT, prompt, user experience",DPs examples/definitions,,,,,,,
https://api.github.com/repos/patcg-individual-drafts/topics/issues/265,UX is misleading,https://github.com/patcg-individual-drafts/topics/issues/265,"#241 was locked due to another user’s inflammatory comments (now deleted), so I cannot participate in the thread, and my concerns appear to be ignored. I have reached out twice to @aramzs by email to ask how to proceed, but have not received a reply. Opening this new issue instead as I’m not sure how else to continue the discussion.",2023-10-14T07:26:45Z,2023-10-19T17:30:08Z,closed,10,"Chrome API, misleading language, forced action","Chrome, API, no user control","Chrome, API, misleading, forced action",DPs examples/definitions,,,,,,,
https://api.github.com/repos/Kong/insomnia/issues/6579,"All my data lost - ""Failed to create remote project""",https://github.com/Kong/insomnia/issues/6579,"### Expected Behavior

I had a lot of local data setup. After creating an account using Google, migration tool reports ""Failed to create remote project"". Everything seems lost, I have no idea how to recover my local data. I'm in the middle of some big work and this is truly screwed up as the app was auto-updated.

### Actual Behavior

""Failed to create remote project""

### Reproduction Steps

_No response_

### Is there an existing issue for this?

- [X] I have searched the [issue tracker](https://www.github.com/Kong/insomnia/issues) for this problem.

### Additional Information

_No response_

### Insomnia Version

8.0

### What operating system are you using?

macOS

### Operating System Version

13.6

### Installation method

downloaded

### Last Known Working Insomnia version

Before 8.0",2023-09-27T19:30:59Z,2024-01-04T13:55:23Z,closed,65,"Insomnia, cloud data backup, forced action, sign up to managed platform",local data lost due to creation of Google account,"Insomnia, forced action, signup/log-in required",DPs used in software,,,,,,,
https://api.github.com/repos/home-assistant/android/issues/3859,Matter over Thread device commissioning flow fails (some logcat exceptions),https://github.com/home-assistant/android/issues/3859,"**Android version(s):**
Android 10
**Device model(s):**
LG G8
**Home Assistant version:**
```
Home Assistant 2023.9.1
Supervisor 2023.08.3
Operating System 10.5
Frontend 20230908.0 - latest 
```
**Last working Home Assistant release (if known):**
_Not known_
**Description of problem, include YAML if issue is related to notifications:**
Failed to comission Matter over Thread devices when doing the standard commissioning flow, errors are in the below stacktrace
**Companion App Logs:**
```
E IntegrationRepository: io.homeassistant.companion.android.common.data.integration.IntegrationException: com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
E IntegrationRepository:  at [Source: (okhttp3.ResponseBody$BomAwareReader); line: 1, column: 0]
E IntegrationRepository: 	at io.homeassistant.companion.android.common.data.integration.impl.IntegrationRepositoryImpl.getConfig(IntegrationRepositoryImpl.kt:501)
E IntegrationRepository: 	at io.homeassistant.companion.android.common.data.integration.impl.IntegrationRepositoryImpl$getConfig$1.invokeSuspend(Unknown Source:14)
E IntegrationRepository: 	at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)
E IntegrationRepository: 	at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)
E IntegrationRepository: 	at kotlinx.coroutines.internal.LimitedDispatcher$Worker.run(LimitedDispatcher.kt:115)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.TaskImpl.run(Tasks.kt:103)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:584)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.executeTask(CoroutineScheduler.kt:793)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.runWorker(CoroutineScheduler.kt:697)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:684)
E IntegrationRepository: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
E IntegrationRepository:  at [Source: (okhttp3.ResponseBody$BomAwareReader); line: 1, column: 0]
E IntegrationRepository: 	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1741)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader._initForReading(ObjectReader.java:359)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2041)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1459)
E IntegrationRepository: 	at retrofit2.converter.jackson.JacksonResponseBodyConverter.convert(JacksonResponseBodyConverter.java:33)
E IntegrationRepository: 	at retrofit2.converter.jackson.JacksonResponseBodyConverter.convert(JacksonResponseBodyConverter.java:23)
E IntegrationRepository: 	at retrofit2.OkHttpCall.parseResponse(OkHttpCall.java:243)
E IntegrationRepository: 	at retrofit2.OkHttpCall$1.onResponse(OkHttpCall.java:153)
E IntegrationRepository: 	at okhttp3.internal.connection.RealCall$AsyncCall.run(RealCall.kt:519)
E IntegrationRepository: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
E IntegrationRepository: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
E IntegrationRepository: 	at java.lang.Thread.run(Thread.java:919)
E IntegrationRepository: Issue getting new version from core.
E IntegrationRepository: io.homeassistant.companion.android.common.data.integration.IntegrationException: com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
E IntegrationRepository:  at [Source: (okhttp3.ResponseBody$BomAwareReader); line: 1, column: 0]
E IntegrationRepository: 	at io.homeassistant.companion.android.common.data.integration.impl.IntegrationRepositoryImpl.getConfig(IntegrationRepositoryImpl.kt:501)
E IntegrationRepository: 	at io.homeassistant.companion.android.common.data.integration.impl.IntegrationRepositoryImpl$getConfig$1.invokeSuspend(Unknown Source:14)
E IntegrationRepository: 	at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)
E IntegrationRepository: 	at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)
E IntegrationRepository: 	at kotlinx.coroutines.internal.LimitedDispatcher$Worker.run(LimitedDispatcher.kt:115)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.TaskImpl.run(Tasks.kt:103)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:584)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.executeTask(CoroutineScheduler.kt:793)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.runWorker(CoroutineScheduler.kt:697)
E IntegrationRepository: 	at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:684)
E IntegrationRepository: Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
E IntegrationRepository:  at [Source: (okhttp3.ResponseBody$BomAwareReader); line: 1, column: 0]
E IntegrationRepository: 	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1741)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader._initForReading(ObjectReader.java:359)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2041)
E IntegrationRepository: 	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1459)
E IntegrationRepository: 	at retrofit2.converter.jackson.JacksonResponseBodyConverter.convert(JacksonResponseBodyConverter.java:33)
E IntegrationRepository: 	at retrofit2.converter.jackson.JacksonResponseBodyConverter.convert(JacksonResponseBodyConverter.java:23)
E IntegrationRepository: 	at retrofit2.OkHttpCall.parseResponse(OkHttpCall.java:243)
E IntegrationRepository: 	at retrofit2.OkHttpCall$1.onResponse(OkHttpCall.java:153)
E IntegrationRepository: 	at okhttp3.internal.connection.RealCall$AsyncCall.run(RealCall.kt:519)
E IntegrationRepository: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
E IntegrationRepository: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
E IntegrationRepository: 	at java.lang.Thread.run(Thread.java:919)
E VibratorService: Vibration finished, cleaning up
E VibratorService: Vibration finished, cleaning up
E native  : E0000 00:00:1694472866.874875   21654 chip_logging.cc:15] CHIP: FP: Failed to update pending Last Known Good Time: third_party/connectedhomeip/current/src/credentials/LastKnownGoodTime.cpp:173: CHIP Error 0x00000003: Incorrect state
E native  : E0000 00:00:1694472866.874951   21654 chip_logging.cc:15] CHIP: TS: Failed to commit Last Known Good Time: third_party/connectedhomeip/current/src/credentials/LastKnownGoodTime.cpp:192: CHIP Error 0x00000003: Incorrect state
E native  : E0000 00:00:1694472866.874973   21654 chip_logging.cc:15] CHIP: FP: Failed to commit Last Known Good Time: third_party/connectedhomeip/current/src/credentials/LastKnownGoodTime.cpp:192: CHIP Error 0x00000003: Incorrect state
E bt_stack: [ERROR:l2c_ble.cc(326)] linkstate 0
E bt_btm  : BTM_SetBleDataLength failed, peer does not support request
E bt_btif : bta_dm_acl_change new acl connetion:count = 1
E bt_stack: [ERROR:bta_gattc_cache.cc(723)] bta_gattc_cache_load: can't open GATT cache file /data/misc/bluetooth/gatt_cache_XXX for reading, error: No such file or directory
E [SmartSettings][TriggerProcessor]: Category is disabled or Not satisfied with Action value
E [SmartSettings][ITProcessor]: triggerId is null
E bt_btif_gattc: btif_gattc_upstreams_evt: Unhandled event (8)!
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E DeviceInfoLoader: Failed to load device info. [CONTEXT service_id=336 ]
E DeviceInfoLoader: m.fwx: RPC GetDeviceSetupData returned code UNAUTHENTICATED; Sherlog for GetDeviceSetupData is needed to diagnose.
E DeviceInfoLoader: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):314)
E DeviceInfoLoader: 	at m.qiw.bJ(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):14)
E DeviceInfoLoader: 	at m.qqy.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):114)
E DeviceInfoLoader: 	at m.dud.c(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):50)
E DeviceInfoLoader: 	at m.dud.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):76)
E DeviceInfoLoader: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
E DeviceInfoLoader: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
E DeviceInfoLoader: 	at aifk.run(:com.google.android.gms@233414028@23.34.14 (100400-560151436):8)
E DeviceInfoLoader: 	at java.lang.Thread.run(Thread.java:919)
E DeviceInfoLoader: Caused by: m.plu: UNAUTHENTICATED: Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.
E DeviceInfoLoader: 	at m.dsn.m(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):17)
E DeviceInfoLoader: 	at m.dsn.l(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):170)
E DeviceInfoLoader: 	at m.fwb.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):162)
E DeviceInfoLoader: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):166)
E DeviceInfoLoader: 	... 8 more
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E bt_btif : bta_gattc_process_indicate, ignore HID ind/notificiation
E SetupDeviceViewModel: Commissioning failed with state Failure obtaining credentials. [CONTEXT service_id=336 ]
E SetupDeviceViewModel: m.evt: Failed to retrieve nonces.
E SetupDeviceViewModel: 	at m.ewx.h(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):101)
E SetupDeviceViewModel: 	at m.ews.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):12)
E SetupDeviceViewModel: 	at m.qiw.bJ(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):14)
E SetupDeviceViewModel: 	at m.qqy.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):106)
E SetupDeviceViewModel: 	at android.os.Handler.handleCallback(Handler.java:883)
E SetupDeviceViewModel: 	at android.os.Handler.dispatchMessage(Handler.java:100)
E SetupDeviceViewModel: 	at android.os.Looper.loop(Looper.java:214)
E SetupDeviceViewModel: 	at android.app.ActivityThread.main(ActivityThread.java:7615)
E SetupDeviceViewModel: 	at java.lang.reflect.Method.invoke(Native Method)
E SetupDeviceViewModel: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
E SetupDeviceViewModel: 	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:964)
E SetupDeviceViewModel: Caused by: m.fwx: RPC GetCommissioningNonce returned code UNAUTHENTICATED; Sherlog for GetCommissioningNonce is needed to diagnose.
E SetupDeviceViewModel: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):314)
E SetupDeviceViewModel: 	at m.qiw.bJ(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):14)
E SetupDeviceViewModel: 	at m.qqy.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):114)
E SetupDeviceViewModel: 	at m.dud.c(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):50)
E SetupDeviceViewModel: 	at m.dud.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):76)
E SetupDeviceViewModel: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
E SetupDeviceViewModel: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
E SetupDeviceViewModel: 	at aifk.run(:com.google.android.gms@233414028@23.34.14 (100400-560151436):8)
E SetupDeviceViewModel: 	at java.lang.Thread.run(Thread.java:919)
E SetupDeviceViewModel: Caused by: m.plu: UNAUTHENTICATED: Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.
E SetupDeviceViewModel: 	at m.dsn.m(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):17)
E SetupDeviceViewModel: 	at m.dsn.l(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):170)
E SetupDeviceViewModel: 	at m.fvn.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):37)
E SetupDeviceViewModel: 	at m.fvz.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):49)
E SetupDeviceViewModel: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):166)
E SetupDeviceViewModel: 	... 8 more
E bt_stack: [ERROR:bta_gattc_utils.cc(458)] bta_gattc_mark_bg_conn unable to find the bg connection mask for bd_addr=
E SetupDeviceChimeraActiv: Showing error status. [CONTEXT service_id=336 ]
E SetupDeviceChimeraActiv: m.gin: Failed to retrieve nonces.
E SetupDeviceChimeraActiv: 	at m.gpo.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):401)
E SetupDeviceChimeraActiv: 	at m.qxc.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):84)
E SetupDeviceChimeraActiv: 	at m.qzg.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):3)
E SetupDeviceChimeraActiv: 	at m.qzf.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):137)
E SetupDeviceChimeraActiv: 	at m.ele.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):362)
E SetupDeviceChimeraActiv: 	at m.qiw.bJ(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):14)
E SetupDeviceChimeraActiv: 	at m.qqy.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):106)
E SetupDeviceChimeraActiv: 	at android.os.Handler.handleCallback(Handler.java:883)
E SetupDeviceChimeraActiv: 	at android.os.Handler.dispatchMessage(Handler.java:100)
E SetupDeviceChimeraActiv: 	at android.os.Looper.loop(Looper.java:214)
E SetupDeviceChimeraActiv: 	at android.app.ActivityThread.main(ActivityThread.java:7615)
E SetupDeviceChimeraActiv: 	at java.lang.reflect.Method.invoke(Native Method)
E SetupDeviceChimeraActiv: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
E SetupDeviceChimeraActiv: 	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:964)
E SetupDeviceChimeraActiv: Caused by: m.evt: Failed to retrieve nonces.
E SetupDeviceChimeraActiv: 	at m.ewx.h(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):101)
E SetupDeviceChimeraActiv: 	at m.ews.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):12)
E SetupDeviceChimeraActiv: 	... 9 more
E SetupDeviceChimeraActiv: Caused by: m.fwx: RPC GetCommissioningNonce returned code UNAUTHENTICATED; Sherlog for GetCommissioningNonce is needed to diagnose.
E SetupDeviceChimeraActiv: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):314)
E SetupDeviceChimeraActiv: 	at m.qiw.bJ(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):14)
E SetupDeviceChimeraActiv: 	at m.qqy.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):114)
E SetupDeviceChimeraActiv: 	at m.dud.c(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):50)
E SetupDeviceChimeraActiv: 	at m.dud.run(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):76)
E SetupDeviceChimeraActiv: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
E SetupDeviceChimeraActiv: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
E SetupDeviceChimeraActiv: 	at aifk.run(:com.google.android.gms@233414028@23.34.14 (100400-560151436):8)
E SetupDeviceChimeraActiv: 	at java.lang.Thread.run(Thread.java:919)
E SetupDeviceChimeraActiv: Caused by: m.plu: UNAUTHENTICATED: Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.
E SetupDeviceChimeraActiv: 	at m.dsn.m(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):17)
E SetupDeviceChimeraActiv: 	at m.dsn.l(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):170)
E SetupDeviceChimeraActiv: 	at m.fvn.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):37)
E SetupDeviceChimeraActiv: 	at m.fvz.a(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):49)
E SetupDeviceChimeraActiv: 	at m.fyb.b(:com.google.android.gms.optional_home@233414065@23.34.14 (100400-0):166)
E SetupDeviceChimeraActiv: 	... 8 more
```

**Screenshot or video of problem:**
<img src=""https://github.com/home-assistant/android/assets/144746995/c7bf71b0-bde9-427b-a534-dcde473750e9"" width=300></img>
<img src=""https://github.com/home-assistant/android/assets/144746995/3d284b35-2401-4e8f-b450-beb12854502b"" width=300></img>
<img src=""https://github.com/home-assistant/android/assets/144746995/7b3011ab-f08a-4d9c-9f92-1122ed4a4c13"" width=300></img>
<img src=""https://github.com/home-assistant/android/assets/144746995/adde39a6-c041-4911-82f7-59b563d39d07"" width=300></img>
",2023-09-12T00:18:38Z,2023-09-15T00:02:00Z,closed,8,"internet connection required, Google account required, Google Mobile Services (GMS) for commissioning devices, dependence on Google's ecosystem","Google, Matter offline use, require internet for GMS","Google, forced action, Matter, GMS",DPs used in software,,,,,,,